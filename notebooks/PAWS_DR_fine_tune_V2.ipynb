{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PAWS_DR_fine_tune_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/PAWS_DR_fine_tune_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5hlD-M-AULJ",
        "outputId": "d3649e05-5a67-4d48-8418-c53cba0f65af"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install --quiet -v --no-cache-dir ./"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8054, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 8054 (delta 68), reused 97 (delta 44), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8054/8054), 14.11 MiB | 19.57 MiB/s, done.\n",
            "Resolving deltas: 100% (5469/5469), done.\n",
            "/content/apex\n",
            "Processing /content/apex\n",
            "Building wheels for collected packages: apex\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp37-none-any.whl size=204709 sha256=18a9e0c7b004136746188b7e75695bea791984b24f7d1df88d5bb5e8cee51d93\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7pcwirul/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "Successfully installed apex-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCL0T19BAhwZ",
        "outputId": "df65c76e-b15f-4df6-bd95-9c5b5295cb07"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmQET3rEAknO",
        "outputId": "54e055ee-51c9-4e84-addd-3ee6ca1337a8"
      },
      "source": [
        "!pip install --quiet -U PyYAML"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10kB 24.5MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 31.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 22.2MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 16.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 9.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 593kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 8.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxKLx9eqAndQ",
        "outputId": "50f6411a-c9e8-46b3-d901-5f5323838e9b"
      },
      "source": [
        "!git clone -b feature/DR-images-v2 https://github.com/jmarrietar/suncet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'suncet'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Counting objects: 100% (269/269), done.\u001b[K\n",
            "remote: Compressing objects: 100% (168/168), done.\u001b[K\n",
            "remote: Total 269 (delta 155), reused 206 (delta 98), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (269/269), 1.10 MiB | 3.56 MiB/s, done.\n",
            "Resolving deltas: 100% (155/155), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c0W3iBTApIP",
        "outputId": "2ba9d611-d669-4685-a8e0-b7786153500e"
      },
      "source": [
        "cd suncet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U4gvRnhMAqWJ",
        "outputId": "2c85e9b1-5539-4863-f4b4-228722528431"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/suncet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4On1j-ZxAr2v",
        "outputId": "f456a1a9-c1c4-416d-cb31-af406aca2582"
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Check whether the file is already in the desired path or if it needs to be downloaded\n",
        "# File downloaded from source : https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\n",
        "\n",
        "base_path = '/content/suncet/datasets/dr/'\n",
        "file_path = 'sample@1000.zip'\n",
        "\n",
        "if not os.path.isfile(base_path + file_path):\n",
        "    subprocess.run(['mkdir', '-p', base_path])\n",
        "    subprocess.run(['mkdir', '-p', 'logs'])\n",
        "    subprocess.call(['python', 'download.py', '-d', file_path.split('.')[0]])\n",
        "else:\n",
        "    print('File already downloaded!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File already downloaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln-Ge4v-A_yP"
      },
      "source": [
        "`main.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZjEepEFBCQF",
        "outputId": "151de609-541c-4b2d-acd7-eaf9faff0fc2"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import argparse\n",
        "\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "import pprint\n",
        "import yaml\n",
        "\n",
        "from src.paws_train import main as paws\n",
        "from src.suncet_train import main as suncet\n",
        "from src.fine_tune import main as fine_tune\n",
        "from src.snn_fine_tune import main as snn_fine_tune\n",
        "\n",
        "from src.utils import init_distributed\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    \"--fname\", type=str, help=\"name of config file to load\", default=\"configs.yaml\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--devices\",\n",
        "    type=str,\n",
        "    nargs=\"+\",\n",
        "    default=[\"cuda:0\"],\n",
        "    help=\"which devices to use on local machine\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--sel\",\n",
        "    type=str,\n",
        "    help=\"which script to run\",\n",
        "    choices=[\"paws_train\", \"suncet_train\", \"fine_tune\", \"snn_fine_tune\"],\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--sel'], dest='sel', nargs=None, const=None, default=None, type=<class 'str'>, choices=['paws_train', 'suncet_train', 'fine_tune', 'snn_fine_tune'], help='which script to run', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS_6NXCIBFzI"
      },
      "source": [
        "args = parser.parse_args(['--sel', 'fine_tune',\n",
        "                          '--fname', 'configs/paws/dr_fine_tune.yaml'\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0G_CvPcBrD9"
      },
      "source": [
        "fname = args.fname\n",
        "sel = args.sel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YHQTaIUBrGw",
        "outputId": "bf40920d-40da-4069-dc31-db260096b37e"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "\n",
        "logger.info(f'called-params {sel} {fname}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:called-params fine_tune configs/paws/dr_fine_tune.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guYIscowBrJs"
      },
      "source": [
        "rank=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyCicIMIBrMx",
        "outputId": "3aaee045-6bb4-4786-8073-f981d8481b9d"
      },
      "source": [
        "# -- load script params\n",
        "params = None\n",
        "with open(fname, 'r') as y_file:\n",
        "    params = yaml.load(y_file, Loader=yaml.FullLoader)\n",
        "    logger.info('loaded params...')\n",
        "    if rank == 0:\n",
        "        pp = pprint.PrettyPrinter(indent=4)\n",
        "        pp.pprint(params)\n",
        "\n",
        "if rank == 0:\n",
        "    dump = os.path.join(params['logging']['folder'], f'params-{sel}.yaml')\n",
        "    with open(dump, 'w') as f:\n",
        "        yaml.dump(params, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:loaded params...\n",
            "{   'data': {   'data_seed': 152,\n",
            "                'dataset': 'dr_fine_tune',\n",
            "                'image_folder': 'dr/sample@1000/',\n",
            "                'normalize': True,\n",
            "                'num_classes': 1000,\n",
            "                'root_path': 'datasets/',\n",
            "                'subset_path': 'dr_subsets/',\n",
            "                'unlabeled_frac': 0.9},\n",
            "    'logging': {   'folder': 'logs/',\n",
            "                   'pretrain_path': 'paws-latest.pth.tar',\n",
            "                   'write_tag': 'paws-latest-SNN'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'master_port': 4029,\n",
            "                'model_name': 'resnet50',\n",
            "                'training': True,\n",
            "                'use_fp16': True},\n",
            "    'optimization': {   'epochs': 50,\n",
            "                        'lr': 0.02,\n",
            "                        'use_lars': False,\n",
            "                        'weight_decay': 0.0,\n",
            "                        'zero_init': True}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBZ_cA-KBrO3"
      },
      "source": [
        "args = params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91a9EGKyBzEG"
      },
      "source": [
        "# FINE TUNE TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mQKJg0ABrSi"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import os\n",
        "\n",
        "# -- FOR DISTRIBUTED TRAINING ENSURE ONLY 1 DEVICE VISIBLE PER PROCESS\n",
        "try:\n",
        "    # -- WARNING: IF DOING DISTRIBUTED TRAINING ON A NON-SLURM CLUSTER, MAKE\n",
        "    # --          SURE TO UPDATE THIS TO GET LOCAL-RANK ON NODE, OR ENSURE\n",
        "    # --          THAT YOUR JOBS ARE LAUNCHED WITH ONLY 1 DEVICE VISIBLE\n",
        "    # --          TO EACH PROCESS\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['SLURM_LOCALID']\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "import copy\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule\n",
        ")\n",
        "from src.data_manager import (\n",
        "    init_data,\n",
        "    make_transforms\n",
        ")\n",
        "from src.sgd import SGD\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "from src.lars import LARS\n",
        "\n",
        "# --\n",
        "log_timings = True\n",
        "log_freq = 10\n",
        "checkpoint_freq = 50\n",
        "# --\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "np.random.seed(_GLOBAL_SEED)\n",
        "torch.manual_seed(_GLOBAL_SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logger = logging.getLogger()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh8OlmleBrXj"
      },
      "source": [
        "def load_pretrained(\n",
        "    r_path,\n",
        "    encoder,\n",
        "    device_str\n",
        "):\n",
        "    checkpoint = torch.load(r_path, map_location='cpu')\n",
        "    pretrained_dict = {k.replace('module.', ''): v for k, v in checkpoint['encoder'].items()}\n",
        "    for k, v in encoder.state_dict().items():\n",
        "        if k not in pretrained_dict:\n",
        "            logger.info(f'key \"{k}\" could not be found in loaded state dict')\n",
        "        elif pretrained_dict[k].shape != v.shape:\n",
        "            logger.info(f'key \"{k}\" is of different shape in model and loaded state dict')\n",
        "            pretrained_dict[k] = v\n",
        "    msg = encoder.load_state_dict(pretrained_dict, strict=False)\n",
        "    logger.info(f'loaded pretrained model with msg: {msg}')\n",
        "    logger.info(f'loaded pretrained encoder from epoch: {checkpoint[\"epoch\"]} '\n",
        "                f'path: {r_path}')\n",
        "    del checkpoint\n",
        "    return encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZkNsaIrBrbD"
      },
      "source": [
        "def load_from_path(\n",
        "    r_path,\n",
        "    encoder,\n",
        "    opt,\n",
        "    sched,\n",
        "    scaler,\n",
        "    device_str,\n",
        "    use_fp16=False\n",
        "):\n",
        "    encoder = load_pretrained(r_path, encoder, device_str)\n",
        "    checkpoint = torch.load(r_path, map_location=device_str)\n",
        "\n",
        "    best_acc = None\n",
        "    if 'best_top1_acc' in checkpoint:\n",
        "        best_acc = checkpoint['best_top1_acc']\n",
        "\n",
        "    epoch = checkpoint['epoch']\n",
        "    if opt is not None:\n",
        "        if use_fp16:\n",
        "            scaler.load_state_dict(checkpoint['amp'])\n",
        "        opt.load_state_dict(checkpoint['opt'])\n",
        "        sched.load_state_dict(checkpoint['sched'])\n",
        "        logger.info(f'loaded optimizers from epoch {epoch}')\n",
        "    logger.info(f'read-path: {r_path}')\n",
        "    del checkpoint\n",
        "    return encoder, opt, sched, epoch, best_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfV-VdVHBrdQ"
      },
      "source": [
        "def init_model(\n",
        "    device,\n",
        "    device_str,\n",
        "    num_classes,\n",
        "    training,\n",
        "    use_fp16,\n",
        "    r_enc_path,\n",
        "    iterations_per_epoch,\n",
        "    world_size,\n",
        "    ref_lr,\n",
        "    num_epochs,\n",
        "    use_lars=False,\n",
        "    zero_init=True,\n",
        "    model_name='resnet50',\n",
        "    warmup_epochs=0,\n",
        "    weight_decay=0\n",
        "):\n",
        "    # -- init model\n",
        "    if 'wide_resnet' in model_name:\n",
        "        encoder = wide_resnet.__dict__[model_name](dropout_rate=0.0)\n",
        "        hidden_dim = 128\n",
        "    else:\n",
        "        encoder = resnet.__dict__[model_name]()\n",
        "        hidden_dim = 2048\n",
        "        if 'w2' in model_name:\n",
        "            hidden_dim *= 2\n",
        "        elif 'w4' in model_name:\n",
        "            hidden_dim *= 4\n",
        "\n",
        "    # -- projection head\n",
        "    encoder.fc = torch.nn.Sequential(OrderedDict([\n",
        "        ('fc1', torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "        ('bn1', torch.nn.BatchNorm1d(hidden_dim)),\n",
        "        ('relu1', torch.nn.ReLU(inplace=True)),\n",
        "        ('fc2', torch.nn.Linear(hidden_dim, num_classes))\n",
        "    ]))\n",
        "\n",
        "    encoder.to(device)\n",
        "    encoder = load_pretrained(\n",
        "        r_path=r_enc_path,\n",
        "        encoder=encoder,\n",
        "        device_str=device_str)\n",
        "\n",
        "    if zero_init:\n",
        "        for p in encoder.fc.fc2.parameters():\n",
        "            torch.nn.init.zeros_(p)\n",
        "\n",
        "    # -- init optimizer\n",
        "    optimizer, scheduler = None, None\n",
        "    if training:\n",
        "        param_groups = [\n",
        "            {'params': (p for n, p in encoder.named_parameters()\n",
        "                        if ('bias' not in n) and ('bn' not in n))},\n",
        "            {'params': (p for n, p in encoder.named_parameters()\n",
        "                        if ('bias' in n) or ('bn' in n)),\n",
        "             'LARS_exclude': True,\n",
        "             'weight_decay': 0}\n",
        "        ]\n",
        "        optimizer = SGD(\n",
        "            param_groups,\n",
        "            nesterov=True,\n",
        "            weight_decay=weight_decay,\n",
        "            momentum=0.9,\n",
        "            lr=ref_lr)\n",
        "        scheduler = WarmupCosineSchedule(\n",
        "            optimizer,\n",
        "            warmup_steps=warmup_epochs*iterations_per_epoch,\n",
        "            start_lr=ref_lr,\n",
        "            ref_lr=ref_lr,\n",
        "            T_max=num_epochs*iterations_per_epoch)\n",
        "        if use_lars:\n",
        "            optimizer = LARS(optimizer, trust_coefficient=0.001)\n",
        "    if world_size > 1:\n",
        "        encoder = DistributedDataParallel(encoder, broadcast_buffers=False)\n",
        "\n",
        "    return encoder, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq3v7zFLBrgG"
      },
      "source": [
        "# -- META\n",
        "model_name = args['meta']['model_name']\n",
        "port = args['meta']['master_port']\n",
        "load_checkpoint = args['meta']['load_checkpoint']\n",
        "training = args['meta']['training']\n",
        "copy_data = args['meta']['copy_data']\n",
        "use_fp16 = args['meta']['use_fp16']\n",
        "device = torch.device(args['meta']['device'])\n",
        "torch.cuda.set_device(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os4hgZObBrrP"
      },
      "source": [
        "# -- DATA\n",
        "unlabeled_frac = args['data']['unlabeled_frac']\n",
        "normalize = args['data']['normalize']\n",
        "root_path = args['data']['root_path']\n",
        "image_folder = args['data']['image_folder']\n",
        "dataset_name = args['data']['dataset']\n",
        "subset_path = args['data']['subset_path']\n",
        "num_classes = args['data']['num_classes']\n",
        "data_seed = None\n",
        "if 'cifar10' in dataset_name:\n",
        "    data_seed = args['data']['data_seed']\n",
        "crop_scale = (0.5, 1.0) if 'cifar10' in dataset_name else (0.08, 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "C2MbyBqwBrul",
        "outputId": "54dcf90a-4155-4271-eb4b-050d258222c3"
      },
      "source": [
        "image_folder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dr/sample@1000/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1zEZGGQBrw3"
      },
      "source": [
        "# -- OPTIMIZATION\n",
        "wd = float(args['optimization']['weight_decay'])\n",
        "ref_lr = args['optimization']['lr']\n",
        "use_lars = args['optimization']['use_lars']\n",
        "zero_init = args['optimization']['zero_init']\n",
        "num_epochs = args['optimization']['epochs']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT9t_7siDEiA"
      },
      "source": [
        "# -- LOGGING\n",
        "folder = args['logging']['folder']\n",
        "tag = args['logging']['write_tag']\n",
        "r_file_enc = args['logging']['pretrain_path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12zIU-oxDEqO"
      },
      "source": [
        "# -- log/checkpointing paths\n",
        "r_enc_path = os.path.join(folder, r_file_enc)\n",
        "w_enc_path = os.path.join(folder, f'{tag}-fine-tune.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQX97cCGDEtl",
        "outputId": "71ec3df0-ceaa-44de-d36d-cf0d16935be6"
      },
      "source": [
        "# -- init distributed\n",
        "world_size, rank = init_distributed(port)\n",
        "logger.info(f'initialized rank/world-size: {rank}/{world_size}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:distributed training not available\n",
            "INFO:root:initialized rank/world-size: 0/1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgKbHSR2DEwa"
      },
      "source": [
        "# -- optimization/evaluation params\n",
        "if training:\n",
        "    batch_size = 256\n",
        "else:\n",
        "    batch_size = 16\n",
        "    unlabeled_frac = 0.0\n",
        "    load_checkpoint = True\n",
        "    num_epochs = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRpDSN1zDEz8"
      },
      "source": [
        "# -- init loss\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROxh1sWHDE3L",
        "outputId": "3764ac70-e80c-47f0-f29b-4da2ece33d7d"
      },
      "source": [
        "# -- make train data transforms and data loaders/samples\n",
        "transform, init_transform = make_transforms(\n",
        "    dataset_name=dataset_name,\n",
        "    subset_path=subset_path,\n",
        "    unlabeled_frac=unlabeled_frac,\n",
        "    training=training,\n",
        "    crop_scale=crop_scale,\n",
        "    split_seed=data_seed,\n",
        "    basic_augmentations=True,\n",
        "    normalize=normalize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:making imagenet data transforms\n",
            "INFO:root:keep file: dr_subsets/90percent.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WZOnPx7DE-P",
        "outputId": "1acd8b25-474e-4435-94ee-947c77cb6bb4"
      },
      "source": [
        "(data_loader,\n",
        "    dist_sampler) = init_data(\n",
        "        dataset_name=dataset_name,\n",
        "        transform=transform,\n",
        "        init_transform=init_transform,\n",
        "        u_batch_size=None,\n",
        "        #s_batch_size=batch_size, # CHANGED HERE\n",
        "        s_batch_size=64,\n",
        "        classes_per_batch=2,\n",
        "        world_size=world_size,\n",
        "        rank=rank,\n",
        "        root_path=root_path,\n",
        "        image_folder=image_folder,\n",
        "        training=training,\n",
        "        copy_data=copy_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:copying data locally\n",
            "INFO:root:No job-id, will load directly from network file\n",
            "INFO:root:data-path datasets/dr/sample@1000/train/\n",
            "INFO:root:Initialized ImageDR\n",
            "INFO:root:ImageNet fine-tune dataset created\n",
            "self.multicrop_transform (0, None)\n",
            "INFO:root:flipping coin to keep labels\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1ZaEXJ0DFCc",
        "outputId": "6583905b-487f-4b13-e4b0-54b95b06974d"
      },
      "source": [
        "ipe = len(data_loader)\n",
        "logger.info(f'initialized data-loader (ipe {ipe})')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:initialized data-loader (ipe 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr3kuterDFL7",
        "outputId": "32d64bb7-ddcf-410f-df88-b186de128674"
      },
      "source": [
        "# -- init model and optimizer\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "encoder, optimizer, scheduler = init_model(\n",
        "    device=device,\n",
        "    device_str=args['meta']['device'],\n",
        "    num_classes=num_classes,\n",
        "    training=training,\n",
        "    use_fp16=use_fp16,\n",
        "    r_enc_path=r_enc_path,\n",
        "    iterations_per_epoch=ipe,\n",
        "    world_size=world_size,\n",
        "    ref_lr=ref_lr,\n",
        "    weight_decay=wd,\n",
        "    use_lars=use_lars,\n",
        "    zero_init=zero_init,\n",
        "    num_epochs=num_epochs,\n",
        "    model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:key \"fc.fc2.weight\" is of different shape in model and loaded state dict\n",
            "INFO:root:key \"fc.fc2.bias\" is of different shape in model and loaded state dict\n",
            "INFO:root:loaded pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['pred.bn1.weight', 'pred.bn1.bias', 'pred.bn1.running_mean', 'pred.bn1.running_var', 'pred.bn1.num_batches_tracked', 'pred.fc1.weight', 'pred.fc1.bias', 'pred.bn2.weight', 'pred.bn2.bias', 'pred.bn2.running_mean', 'pred.bn2.running_var', 'pred.bn2.num_batches_tracked', 'pred.fc2.weight', 'pred.fc2.bias', 'fc.bn2.weight', 'fc.bn2.bias', 'fc.bn2.running_mean', 'fc.bn2.running_var', 'fc.bn2.num_batches_tracked', 'fc.fc3.weight', 'fc.fc3.bias'])\n",
            "INFO:root:loaded pretrained encoder from epoch: 10 path: logs/paws-latest.pth.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG0qD6-iDFTW"
      },
      "source": [
        "best_acc = None\n",
        "start_epoch = 0\n",
        "# -- load checkpoint\n",
        "if not training or load_checkpoint:\n",
        "    encoder, optimizer, scheduler, start_epoch, best_acc = load_from_path(\n",
        "        r_path=w_enc_path,\n",
        "        encoder=encoder,\n",
        "        opt=optimizer,\n",
        "        sched=scheduler,\n",
        "        scaler=scaler,\n",
        "        device_str=args['meta']['device'],\n",
        "        use_fp16=use_fp16)\n",
        "if not training:\n",
        "    logger.info('putting model in eval mode')\n",
        "    encoder.eval()\n",
        "    logger.info(sum(p.numel() for n, p in encoder.named_parameters()\n",
        "                    if p.requires_grad and ('fc' not in n)))\n",
        "    start_epoch = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYRdk6r0DFVk",
        "outputId": "69038bb7-ad37-42ed-bd5e-c34e4fcf070d"
      },
      "source": [
        "for epoch in range(start_epoch, num_epochs):\n",
        "\n",
        "    def train_step():\n",
        "        # -- update distributed-data-loader epoch\n",
        "        top1_correct, total = 0, 0\n",
        "        for i, data in enumerate(data_loader):\n",
        "            with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = encoder(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            total += inputs.shape[0]\n",
        "            top1_correct += float(outputs.max(dim=1).indices.eq(labels).sum())\n",
        "            top1_acc = 100. * top1_correct / total\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            if i % log_freq == 0:\n",
        "                logger.info('[%d, %5d] %.3f%% (loss: %.3f)'\n",
        "                            % (epoch + 1, i, top1_acc, loss))\n",
        "        return 100. * top1_correct / total\n",
        "\n",
        "    train_top1 = 0.\n",
        "    train_top1 = train_step()\n",
        "\n",
        "    log_str = 'train:'\n",
        "    logger.info('[%d] (%s: %.3f%%) '\n",
        "                % (epoch + 1, log_str, train_top1))\n",
        "\n",
        "    # -- logging/checkpointing\n",
        "    if rank == 0:\n",
        "\n",
        "        save_dict = {\n",
        "            'encoder': encoder.state_dict(),\n",
        "            'opt': optimizer.state_dict(),\n",
        "            'sched': scheduler.state_dict(),\n",
        "            'epoch': epoch + 1,\n",
        "            'unlabel_prob': unlabeled_frac,\n",
        "            'world_size': world_size,\n",
        "            'batch_size': batch_size,\n",
        "            'lr': ref_lr,\n",
        "            'amp': scaler.state_dict()\n",
        "        }\n",
        "        torch.save(save_dict, w_enc_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:[1,     0] 54.688% (loss: 0.675)\n",
            "INFO:root:[1] (train:: 54.688%) \n",
            "INFO:root:[2,     0] 64.062% (loss: 0.807)\n",
            "INFO:root:[2] (train:: 64.062%) \n",
            "INFO:root:[3,     0] 54.688% (loss: 0.750)\n",
            "INFO:root:[3] (train:: 54.688%) \n",
            "INFO:root:[4,     0] 62.500% (loss: 0.696)\n",
            "INFO:root:[4] (train:: 62.500%) \n",
            "INFO:root:[5,     0] 60.938% (loss: 0.650)\n",
            "INFO:root:[5] (train:: 60.938%) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM29Hu4cDFYb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}