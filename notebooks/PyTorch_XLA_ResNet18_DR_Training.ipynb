{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "PyTorch/XLA ResNet18/DR Training",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/PyTorch_XLA_ResNet18_DR_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX1hxqUQn47M"
      },
      "source": [
        "## PyTorch/XLA ResNet18/CIFAR10 (GPU or TPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLQPoJ6Fn8wF"
      },
      "source": [
        "### [RUNME] Install Colab compatible PyTorch/XLA wheels and dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr3oYPye53E2"
      },
      "source": [
        "import gdown"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjC_ZzWM55ga"
      },
      "source": [
        "def download(data, url):\n",
        "    # Download dataset\n",
        "    import zipfile\n",
        "    url = url\n",
        "    output = \"{}.zip\".format(data)\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # Uncompress dataset\n",
        "    local_zip = '{}.zip'.format(data)\n",
        "    zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyd1aK557sH"
      },
      "source": [
        "data_samples = {\n",
        "    \"sample@200\": \"https://drive.google.com/uc?id=1FfV7YyDJvNUCDP5r3-8iQfZ2-xJp_pgb\",\n",
        "    \"sample@500\": \"https://drive.google.com/uc?id=1dHwUqpmSogEdjAB9rwDUL-OKFRUcVXte\",\n",
        "    \"sample@1000\": \"https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\",\n",
        "    \"sample@2000\": \"https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\",\n",
        "    \"sample@3000\": \"https://drive.google.com/uc?id=1_yre5K9YYvJgSrT4xvrI8eD_htucIywA\",\n",
        "    \"sample@4000_images\": \"https://drive.google.com/uc?id=1dqVB8EozEpwWzyuU80AauoQmsiw3Gtm2\",\n",
        "    \"sample@20000\": \"https://drive.google.com/uc?id=1MTDpLzpmhSiZq2jSdmHx2UDPn9FC8gzO\",\n",
        "    \"val-voets-tf\": \"https://drive.google.com/uc?id=1VzVgMGTkBBPG2qbzLunD9HvLzH6tcyrv\",\n",
        "    \"train_voets\": \"https://drive.google.com/uc?id=1AmcFh1MOOZ6aqKm2eO7XEdgmIEqHKTZ5\",\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\"\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oroPxW1C5881"
      },
      "source": [
        "UNLABELED = 'sample@2000'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJYWOqWZ5-x1",
        "outputId": "24324cc0-dd8f-4ed6-9aa9-c38c542a7cd8"
      },
      "source": [
        "URL_UNLABELED = data_samples[UNLABELED]\n",
        "download(UNLABELED, URL_UNLABELED)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\n",
            "To: /content/sample@2000.zip\n",
            "214MB [00:01, 134MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbnXNRlJrQXV"
      },
      "source": [
        "from google.colab import auth, drive\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVIHHvvTrRET",
        "outputId": "9bf2c99c-e0b7-46fa-e717-d1f2905f0588"
      },
      "source": [
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O53lrJMDn9Rd",
        "outputId": "0bb86b0a-16ca-4de3-b41b-62f74c0fc0c9"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n",
            "Requirement already satisfied: torch-xla==1.8.1 from https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.30.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (20.9)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (56.1.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IednejwkIW-K"
      },
      "source": [
        "Only run the below commented cell if you would like a nightly release"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-bBdzgeISaP"
      },
      "source": [
        "# VERSION = \"nightly\"  #@param [\"nightly\", \"20200516\"]  # or YYYYMMDD format\n",
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFzLg5gy7l6"
      },
      "source": [
        "# PyTorch/XLA GPU Setup (only if GPU runtime)\n",
        "import os\n",
        "if os.environ.get('COLAB_GPU', '0') == '1':\n",
        "  os.environ['GPU_NUM_DEVICES'] = '1'\n",
        "  os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda/'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rroH9yiAn-XE"
      },
      "source": [
        "### Define Parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy62hTvp9H9H"
      },
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHJ65sZygG2b"
      },
      "source": [
        "def accuracy_func(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMdPRFXIn_jH"
      },
      "source": [
        "# Define Parameters\n",
        "FLAGS = {}\n",
        "FLAGS['data_dir'] = \"/tmp/cifar\"\n",
        "FLAGS['batch_size'] = 64\n",
        "FLAGS['num_workers'] = 2\n",
        "FLAGS['learning_rate'] = 0.00003\n",
        "FLAGS['momentum'] = 0.9\n",
        "FLAGS['num_epochs'] = 50 \n",
        "FLAGS['num_cores'] = 8 if os.environ.get('TPU_NAME', None) else 1\n",
        "FLAGS['log_steps'] = 20\n",
        "FLAGS['metrics_debug'] = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF57q1swuvk5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    \"\"\"blur a single image on CPU\"\"\"\n",
        "    def __init__(self, kernel_size):\n",
        "        radias = kernel_size // 2\n",
        "        kernel_size = radias * 2 + 1\n",
        "        self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n",
        "                                stride=1, padding=0, bias=False, groups=3)\n",
        "        self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n",
        "                                stride=1, padding=0, bias=False, groups=3)\n",
        "        self.k = kernel_size\n",
        "        self.r = radias\n",
        "\n",
        "        self.blur = nn.Sequential(\n",
        "            nn.ReflectionPad2d(radias),\n",
        "            self.blur_h,\n",
        "            self.blur_v\n",
        "        )\n",
        "\n",
        "        self.pil_to_tensor = transforms.ToTensor()\n",
        "        self.tensor_to_pil = transforms.ToPILImage()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = self.pil_to_tensor(img).unsqueeze(0)\n",
        "\n",
        "        sigma = np.random.uniform(0.1, 2.0)\n",
        "        x = np.arange(-self.r, self.r + 1)\n",
        "        x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n",
        "        x = x / x.sum()\n",
        "        x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n",
        "\n",
        "        self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n",
        "        self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            img = self.blur(img)\n",
        "            img = img.squeeze()\n",
        "\n",
        "        img = self.tensor_to_pil(img)\n",
        "\n",
        "        return img\n",
        "\n",
        "class ContrastiveLearningViewGenerator(object):\n",
        "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
        "\n",
        "    def __init__(self, base_transform, n_views=2):\n",
        "        self.base_transform = base_transform\n",
        "        self.n_views = n_views\n",
        "\n",
        "    def __call__(self, x):\n",
        "        #return [self.base_transform(x) for i in range(self.n_views)][0]\n",
        "        return [self.base_transform(x) for i in range(self.n_views)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afsDoLfvuyBE"
      },
      "source": [
        "def get_simclr_pipeline_transform(size, s=1):\n",
        "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
        "    color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "    data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
        "                                            transforms.RandomHorizontalFlip(),\n",
        "                                            transforms.RandomApply([color_jitter], p=0.8),\n",
        "                                            transforms.RandomGrayscale(p=0.2),\n",
        "                                            GaussianBlur(kernel_size=int(0.1 * size)),\n",
        "                                            transforms.ToTensor()])\n",
        "    return data_transforms"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMQOBeMTu0My"
      },
      "source": [
        "def info_nce_loss(features, device):\n",
        "\n",
        "    labels = torch.cat([torch.arange(FLAGS['batch_size']) for i in range(2)], dim=0) # modifique a 2\n",
        "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
        "\n",
        "    labels = labels.to(device)\n",
        "    #labels = labels\n",
        "    \n",
        "    features = F.normalize(features, dim=1)\n",
        "\n",
        "    similarity_matrix = torch.matmul(features, features.T)\n",
        "    # assert similarity_matrix.shape == (\n",
        "    #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
        "    # assert similarity_matrix.shape == labels.shape\n",
        "\n",
        "    # discard the main diagonal from both: labels and similarities matrix\n",
        "    \n",
        "    mask = torch.eye(labels.shape[0], dtype=torch.bool).to(device)\n",
        "    #mask = torch.eye(labels.shape[0], dtype=torch.bool)\n",
        "\n",
        "    labels = labels[~mask].view(labels.shape[0], -1)\n",
        "    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
        "    # assert similarity_matrix.shape == labels.shape\n",
        "\n",
        "    # select and combine multiple positives\n",
        "    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
        "\n",
        "    # select only the negatives the negatives\n",
        "    negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
        "\n",
        "    logits = torch.cat([positives, negatives], dim=1)\n",
        "    labels = torch.zeros(logits.shape[0], dtype=torch.long).to(device)\n",
        "    #labels = torch.zeros(logits.shape[0], dtype=torch.long)\n",
        "\n",
        "    TEMPERATURE = 0.07 # Yo lo Hardcodie\n",
        "\n",
        "    logits = logits / TEMPERATURE\n",
        "    return logits, labels"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Micd3xZvoA-c",
        "outputId": "df5889ad-a762-4939-fea4-ad49fac9a08c"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.utils as xu\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import logging\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(\n",
        "        planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != self.expansion * planes:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(\n",
        "              in_planes,\n",
        "              self.expansion * planes,\n",
        "              kernel_size=1,\n",
        "              stride=stride,\n",
        "              bias=False), nn.BatchNorm2d(self.expansion * planes))\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "  def __init__(self, block, num_blocks, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_planes = 64\n",
        "\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "  def _make_layer(self, block, planes, num_blocks, stride):\n",
        "    strides = [stride] + [1] * (num_blocks - 1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.in_planes, planes, stride))\n",
        "      self.in_planes = planes * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "\n",
        "    out = F.avg_pool2d(out, 4)\n",
        "    out = torch.flatten(out, 1)\n",
        "    out = self.fc(out)\n",
        "\n",
        "\n",
        "    #return F.log_softmax(out, dim=1)\n",
        "    return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "  return ResNet(BasicBlock, [2, 2, 2, 2], 128)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnjt7xOa2Qia"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class BaseSimCLRException(Exception):\n",
        "    \"\"\"Base exception\"\"\"\n",
        "\n",
        "\n",
        "class InvalidBackboneError(BaseSimCLRException):\n",
        "    \"\"\"Raised when the choice of backbone Convnet is invalid.\"\"\"\n",
        "\n",
        "\n",
        "class InvalidDatasetSelection(BaseSimCLRException):\n",
        "    \"\"\"Raised when the choice of dataset is invalid.\"\"\"\n",
        "\n",
        "\n",
        "class ResNetSimCLR(nn.Module):\n",
        "\n",
        "    def __init__(self, base_model, out_dim):\n",
        "        super(ResNetSimCLR, self).__init__()\n",
        "        self.resnet_dict = {\"resnet18\": models.resnet18(pretrained=False, num_classes=out_dim),\n",
        "                            #\"resnet18\":ResNet18(),\n",
        "                            \"resnet50\": models.resnet50(pretrained=False, num_classes=out_dim)}\n",
        "\n",
        "        self.backbone = self._get_basemodel(base_model)\n",
        "        dim_mlp = self.backbone.fc.in_features\n",
        "\n",
        "        # add mlp projection head\n",
        "        self.backbone.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.backbone.fc)\n",
        "\n",
        "    def _get_basemodel(self, model_name):\n",
        "        try:\n",
        "            model = self.resnet_dict[model_name]\n",
        "        except KeyError:\n",
        "            raise InvalidBackboneError(\n",
        "                \"Invalid backbone architecture. Check the config file and pass one of: resnet18 or resnet50\")\n",
        "        else:\n",
        "            return model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64OZ6LR5u3Xc"
      },
      "source": [
        "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
        "\n",
        "WRAPPED_MODEL = xmp.MpModelWrapper(ResNetSimCLR(base_model='resnet18', out_dim=128))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DS6oZc94tLQ"
      },
      "source": [
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vMl96KLoCq8"
      },
      "source": [
        "def train_resnet18():\n",
        "  torch.manual_seed(1)\n",
        "\n",
        "  def get_dataset():\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(root=\"{}\".format(UNLABELED), \n",
        "                                         transform=ContrastiveLearningViewGenerator(\n",
        "                                        get_simclr_pipeline_transform(224),n_views=2))\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(\n",
        "        root=FLAGS['data_dir'],\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=ContrastiveLearningViewGenerator(get_simclr_pipeline_transform(32),n_views=2)\n",
        "        #transform=transform_test\n",
        "        )\n",
        "    \n",
        "    return train_dataset, test_dataset\n",
        "  \n",
        "  # Using the serial executor avoids multiple processes\n",
        "  # to download the same data.\n",
        "  train_dataset, test_dataset = SERIAL_EXEC.run(get_dataset)\n",
        "  #train_dataset, test_dataset = get_dataset()\n",
        "  \n",
        "  #train_sampler, test_sampler = None, None\n",
        "\n",
        "  \n",
        "  train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "      train_dataset,\n",
        "      num_replicas=xm.xrt_world_size(),\n",
        "      rank=xm.get_ordinal(),\n",
        "      shuffle=True)\n",
        "  \n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=FLAGS['batch_size'],\n",
        "      sampler=train_sampler,\n",
        "      num_workers=FLAGS['num_workers'],\n",
        "      drop_last=True)\n",
        "  \n",
        "\n",
        "  # Scale learning rate to num cores\n",
        "  learning_rate = FLAGS['learning_rate'] * xm.xrt_world_size()\n",
        "\n",
        "  # Get loss function, optimizer, and model\n",
        "  device = xm.xla_device()\n",
        "  model = WRAPPED_MODEL.to(device)\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), \n",
        "                               FLAGS['learning_rate'], \n",
        "                               weight_decay=5e-4)\n",
        "\n",
        "  loss_fn = nn.NLLLoss()\n",
        "\n",
        "  criterion = torch.nn.CrossEntropyLoss()  # YO\n",
        "\n",
        "  def train_loop_fn(loader):\n",
        "    tracker = xm.RateTracker()\n",
        "    model.train()\n",
        "\n",
        "    for x, (data, _) in enumerate(loader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      data = torch.cat(data, dim=0)\n",
        "\n",
        "      output = model(data)\n",
        "      logits, labels = info_nce_loss(output, device) # YO\n",
        "\n",
        "      loss = criterion(logits, labels) # YO\n",
        "\n",
        "      loss.backward()\n",
        "      xm.optimizer_step(optimizer)\n",
        "      tracker.add(FLAGS['batch_size'])\n",
        "\n",
        "      top1, top5 = accuracy_func(logits, labels, topk=(1, 5))\n",
        "\n",
        "      if x % FLAGS['log_steps'] == 0:\n",
        "        print('[xla:{}]({}) Loss={:.5f} Rate={:.2f} GlobalRate={:.2f} Time={}'.format(\n",
        "            xm.get_ordinal(), x, loss.item(), tracker.rate(),\n",
        "            tracker.global_rate(), time.asctime()), flush=True)\n",
        "        print(f\"Top1 accuracy: {top1[0]}\")\n",
        "\n",
        "\n",
        "  # Train and eval loops\n",
        "  accuracy = 0.0\n",
        "  data, pred, target = None, None, None\n",
        "  for epoch in range(1, FLAGS['num_epochs'] + 1):\n",
        "    para_loader = pl.ParallelLoader(train_loader, [device])\n",
        "    train_loop_fn(para_loader.per_device_loader(device))\n",
        "    xm.master_print(\"Finished training epoch {}\".format(epoch))\n",
        "\n",
        "    if FLAGS['metrics_debug']:\n",
        "      xm.master_print(met.metrics_report(), flush=True)\n",
        "\n",
        "  \n",
        "    xm.save(\n",
        "        model.state_dict(),\n",
        "        \"drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR.pt\"\n",
        "    )\n",
        "\n",
        "  return accuracy, data, pred, target\n",
        "  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2nL4HmloEyl",
        "outputId": "1a7bccca-90f7-42f2-866f-41ee086aad85"
      },
      "source": [
        "# Start training processes\n",
        "def _mp_fn(rank, flags):\n",
        "  global FLAGS\n",
        "  FLAGS = flags\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  accuracy, data, pred, target = train_resnet18()\n",
        "\n",
        "\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n",
        "          start_method='fork')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[xla:3](0) Loss=5.05465 Rate=3.97 GlobalRate=3.97 Time=Tue May 25 01:58:14 2021\n",
            "[xla:0](0) Loss=5.03917 Rate=3.75 GlobalRate=3.75 Time=Tue May 25 01:58:14 2021\n",
            "[xla:4](0) Loss=5.06966 Rate=4.45 GlobalRate=4.45 Time=Tue May 25 01:58:14 2021\n",
            "[xla:7](0) Loss=5.10389 Rate=6.25 GlobalRate=6.25 Time=Tue May 25 01:58:14 2021\n",
            "[xla:6](0) Loss=5.00914 Rate=3.68 GlobalRate=3.68 Time=Tue May 25 01:58:17 2021\n",
            "[xla:2](0) Loss=4.99734 Rate=4.54 GlobalRate=4.54 Time=Tue May 25 01:58:17 2021\n",
            "Top1 accuracy: 1.5625\n",
            "Top1 accuracy: 0.0\n",
            "Top1 accuracy: 1.5625\n",
            "Top1 accuracy: 0.0\n",
            "Top1 accuracy: 1.5625\n",
            "Top1 accuracy: 1.5625\n",
            "[xla:1](0) Loss=5.03987 Rate=6.16 GlobalRate=6.16 Time=Tue May 25 01:58:23 2021\n",
            "Top1 accuracy: 1.5625\n",
            "[xla:5](0) Loss=5.11773 Rate=7.50 GlobalRate=7.50 Time=Tue May 25 01:58:24 2021\n",
            "Top1 accuracy: 0.78125\n",
            "Finished training epoch 1\n",
            "[xla:0](0) Loss=4.76061 Rate=3.59 GlobalRate=3.59 Time=Tue May 25 01:59:02 2021\n",
            "Top1 accuracy: 0.78125\n",
            "[xla:4](0) Loss=4.79202 Rate=3.26 GlobalRate=3.26 Time=Tue May 25 01:59:04 2021\n",
            "Top1 accuracy: 3.125\n",
            "[xla:3](0) Loss=4.71500 Rate=3.16 GlobalRate=3.16 Time=Tue May 25 01:59:04 2021\n",
            "Top1 accuracy: 3.90625\n",
            "[xla:7](0) Loss=4.79413 Rate=2.83 GlobalRate=2.83 Time=Tue May 25 01:59:07 2021\n",
            "Top1 accuracy: 7.03125\n",
            "[xla:1](0) Loss=4.80757 Rate=2.74 GlobalRate=2.74 Time=Tue May 25 01:59:07 2021\n",
            "Top1 accuracy: 6.25\n",
            "[xla:2](0) Loss=4.77274 Rate=2.70 GlobalRate=2.70 Time=Tue May 25 01:59:08 2021\n",
            "Top1 accuracy: 4.6875\n",
            "[xla:6](0) Loss=4.76619 Rate=2.69 GlobalRate=2.69 Time=Tue May 25 01:59:08 2021\n",
            "Top1 accuracy: 7.03125\n",
            "[xla:5](0) Loss=4.74744 Rate=2.68 GlobalRate=2.68 Time=Tue May 25 01:59:08 2021\n",
            "Top1 accuracy: 7.03125\n",
            "Finished training epoch 2\n",
            "[xla:2](0) Loss=4.69718 Rate=3.05 GlobalRate=3.05 Time=Tue May 25 01:59:30 2021\n",
            "Top1 accuracy: 5.46875\n",
            "[xla:4](0) Loss=4.70968 Rate=3.02 GlobalRate=3.02 Time=Tue May 25 01:59:30 2021\n",
            "Top1 accuracy: 7.03125\n",
            "[xla:0](0) Loss=4.72765 Rate=3.01 GlobalRate=3.01 Time=Tue May 25 01:59:30 2021\n",
            "Top1 accuracy: 7.03125\n",
            "[xla:7](0) Loss=4.73228 Rate=2.97 GlobalRate=2.97 Time=Tue May 25 01:59:31 2021\n",
            "Top1 accuracy: 3.125\n",
            "[xla:5](0) Loss=4.70892 Rate=2.94 GlobalRate=2.94 Time=Tue May 25 01:59:31 2021\n",
            "Top1 accuracy: 6.25\n",
            "[xla:1](0) Loss=4.78144 Rate=2.79 GlobalRate=2.79 Time=Tue May 25 01:59:32 2021\n",
            "Top1 accuracy: 4.6875\n",
            "[xla:3](0) Loss=4.68735 Rate=2.73 GlobalRate=2.73 Time=Tue May 25 01:59:33 2021\n",
            "Top1 accuracy: 7.03125\n",
            "[xla:6](0) Loss=4.66671 Rate=2.71 GlobalRate=2.71 Time=Tue May 25 01:59:33 2021\n",
            "Top1 accuracy: 2.34375\n",
            "Finished training epoch 3\n",
            "[xla:1](0) Loss=4.83845 Rate=2.93 GlobalRate=2.93 Time=Tue May 25 01:59:56 2021\n",
            "Top1 accuracy: 3.125\n",
            "[xla:2](0) Loss=4.81540 Rate=2.88 GlobalRate=2.88 Time=Tue May 25 01:59:56 2021\n",
            "[xla:7](0) Loss=4.76303 Rate=2.88 GlobalRate=2.88 Time=Tue May 25 01:59:56 2021\n",
            "Top1 accuracy: 3.125\n",
            "Top1 accuracy: 3.90625\n",
            "[xla:4](0) Loss=4.82217 Rate=2.85 GlobalRate=2.85 Time=Tue May 25 01:59:56 2021\n",
            "Top1 accuracy: 1.5625\n",
            "[xla:6](0) Loss=4.79478 Rate=2.79 GlobalRate=2.79 Time=Tue May 25 01:59:57 2021\n",
            "Top1 accuracy: 2.34375\n",
            "[xla:0](0) Loss=4.80381 Rate=2.73 GlobalRate=2.73 Time=Tue May 25 01:59:57 2021\n",
            "Top1 accuracy: 3.90625\n",
            "[xla:5](0) Loss=4.80977 Rate=2.66 GlobalRate=2.66 Time=Tue May 25 01:59:58 2021\n",
            "Top1 accuracy: 3.125\n",
            "[xla:3](0) Loss=4.78522 Rate=2.63 GlobalRate=2.63 Time=Tue May 25 01:59:58 2021\n",
            "Top1 accuracy: 1.5625\n",
            "Finished training epoch 4\n",
            "[xla:7](0) Loss=4.77428 Rate=3.11 GlobalRate=3.11 Time=Tue May 25 02:00:20 2021\n",
            "Top1 accuracy: 4.6875\n",
            "[xla:1](0) Loss=4.83173 Rate=2.82 GlobalRate=2.82 Time=Tue May 25 02:00:22 2021\n",
            "[xla:4](0) Loss=4.80087 Rate=2.82 GlobalRate=2.82 Time=Tue May 25 02:00:22 2021\n",
            "Top1 accuracy: 2.34375\n",
            "Top1 accuracy: 3.90625\n",
            "[xla:2](0) Loss=4.75076 Rate=2.68 GlobalRate=2.68 Time=Tue May 25 02:00:23 2021\n",
            "Top1 accuracy: 3.90625\n",
            "[xla:3](0) Loss=4.75185 Rate=2.63 GlobalRate=2.63 Time=Tue May 25 02:00:23 2021\n",
            "[xla:0](0) Loss=4.74949 Rate=2.64 GlobalRate=2.64 Time=Tue May 25 02:00:23 2021\n",
            "Top1 accuracy: 3.90625\n",
            "[xla:6](0) Loss=4.75290 Rate=2.63 GlobalRate=2.63 Time=Tue May 25 02:00:24 2021\n",
            "Top1 accuracy: 3.90625\n",
            "Top1 accuracy: 3.125\n",
            "[xla:5](0) Loss=4.77208 Rate=2.61 GlobalRate=2.61 Time=Tue May 25 02:00:24 2021\n",
            "Top1 accuracy: 4.6875\n",
            "Finished training epoch 5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}