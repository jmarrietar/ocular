{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PAWS-DR-TPU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9nCj4YhjIkafapXESllw/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d9fb992adc10472986ccfa911f885939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_df8bc76653324e6bbe3e8aa6fc6517ef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_de46964ed7a44265bf8e5322befc23dd",
              "IPY_MODEL_c08e19fc9a9b4bfc80d35e612db85464"
            ]
          }
        },
        "df8bc76653324e6bbe3e8aa6fc6517ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de46964ed7a44265bf8e5322befc23dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7beb65d67dd8461b9b62239f4170c9c4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102530333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102530333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a4dc28cbf884d00b243b97670fb1d50"
          }
        },
        "c08e19fc9a9b4bfc80d35e612db85464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa946f689d9d4f94b850672e1b064026",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 57.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e240b15c4004e0c84d5e497756a90fa"
          }
        },
        "7beb65d67dd8461b9b62239f4170c9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a4dc28cbf884d00b243b97670fb1d50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa946f689d9d4f94b850672e1b064026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e240b15c4004e0c84d5e497756a90fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebook/PAWS_DR_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20nF2PuJ2XM_",
        "outputId": "ab972418-5c6f-4f4a-b74e-1f96cf283058"
      },
      "source": [
        "!lscpu\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               63\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2299.998\n",
            "BogoMIPS:            4599.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            46080K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jc1LaaY2jlr",
        "outputId": "3ad87fba-c3e7-41d2-e6aa-da5c4417a557"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install --quiet -v --no-cache-dir ./"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8102, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 8102 (delta 92), reused 123 (delta 63), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8102/8102), 14.16 MiB | 21.96 MiB/s, done.\n",
            "Resolving deltas: 100% (5491/5491), done.\n",
            "/content/apex\n",
            "Processing /content/apex\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Building wheels for collected packages: apex\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=205204 sha256=1a94ff3feb16ff19023ccc1f0ada8a7fc3d9d00f8a0be1156048590602ef9c70\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wc2t_3he/wheels/02/1d/54/16beaa489b73437cc70f3f4ef0bbaa36f0ac443dd94834df91\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "Successfully installed apex-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHFLhn1W2kup",
        "outputId": "afc9563a-295d-4621-c26a-4d6e5b842435"
      },
      "source": [
        "pip install PyYAML"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsdTC1HZ3wfB",
        "outputId": "178276b8-f124-4b26-bca5-0bc11045be77"
      },
      "source": [
        "pip install -U PyYAML"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (5.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah9qbCiO2n8Y",
        "outputId": "3930094c-d6f5-4f58-a47b-8d8178f1f593"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1ht7W422pZU",
        "outputId": "daac536f-c4c0-4c48-d0ed-094c9bff2a4a"
      },
      "source": [
        "!git clone -b feature/DR-images-v2 https://github.com/jmarrietar/suncet.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'suncet'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Counting objects: 100% (336/336), done.\u001b[K\n",
            "remote: Compressing objects: 100% (214/214), done.\u001b[K\n",
            "remote: Total 336 (delta 199), reused 250 (delta 119), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (336/336), 1.11 MiB | 7.92 MiB/s, done.\n",
            "Resolving deltas: 100% (199/199), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e8jdkjJ2r-_",
        "outputId": "03ebf3ff-4d26-480d-ee4c-7c44adb4c5f5"
      },
      "source": [
        "cd suncet"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "79SFkpvz2tfi",
        "outputId": "3b68850a-a252-4cdd-f3d8-7805124230e5"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/suncet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLhfQ_NB2vMB"
      },
      "source": [
        "!mkdir datasets\n",
        "!mkdir datasets/dr"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ORlSfjR22LZ"
      },
      "source": [
        "!mkdir logs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgoec03y231z",
        "outputId": "b7a88f80-258c-44bd-9845-4b4d372b18e7"
      },
      "source": [
        "!python download.py -d sample@1000"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\n",
            "To: /content/suncet/datasets/dr/sample@1000.zip\n",
            "108MB [00:00, 111MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB72kgFE3HdG"
      },
      "source": [
        "import argparse\n",
        "import yaml\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XTd-LTj3D7x",
        "outputId": "15f604d6-e4fa-492a-9cd8-20bb773911a5"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    '--fname', type=str,\n",
        "    help='name of config file to load',\n",
        "    default='configs.yaml')\n",
        "parser.add_argument(\n",
        "    '--devices', type=str, nargs='+', default=['cuda:0'],\n",
        "    help='which devices to use on local machine')\n",
        "parser.add_argument(\n",
        "    '--sel', type=str,\n",
        "    help='which script to run',\n",
        "    choices=[\n",
        "        'paws_train',\n",
        "        'suncet_train',\n",
        "        'fine_tune',\n",
        "        'snn_fine_tune'\n",
        "    ])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--sel'], dest='sel', nargs=None, const=None, default=None, type=<class 'str'>, choices=['paws_train', 'suncet_train', 'fine_tune', 'snn_fine_tune'], help='which script to run', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYDBe8dI3K2G"
      },
      "source": [
        "args = parser.parse_args(['--sel', 'paws_train',\n",
        "                            '--fname', 'configs/paws/dr_train.yaml'\n",
        "])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eWrpPBc3M3Z",
        "outputId": "229ee76d-2121-44d0-e553-11f581558416"
      },
      "source": [
        "args"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(devices=['cuda:0'], fname='configs/paws/dr_train.yaml', sel='paws_train')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA9U-sGlul5O"
      },
      "source": [
        "# Libraries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x97R5j4p1H2H"
      },
      "source": [
        "import os\n",
        "\n",
        "# -- FOR DISTRIBUTED TRAINING ENSURE ONLY 1 DEVICE VISIBLE PER PROCESS\n",
        "try:\n",
        "    # -- WARNING: IF DOING DISTRIBUTED TRAINING ON A NON-SLURM CLUSTER, MAKE\n",
        "    # --          SURE TO UPDATE THIS TO GET LOCAL-RANK ON NODE, OR ENSURE\n",
        "    # --          THAT YOUR JOBS ARE LAUNCHED WITH ONLY 1 DEVICE VISIBLE\n",
        "    # --          TO EACH PROCESS\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = os.environ[\"SLURM_LOCALID\"]\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    gpu_timer,\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule,\n",
        "    CSVLogger,\n",
        "    AverageMeter,\n",
        ")\n",
        "from src.losses import init_paws_loss, make_labels_matrix\n",
        "from src.data_manager import init_data, make_transforms, make_multicrop_transform\n",
        "from src.sgd import SGD\n",
        "from src.lars import LARS\n",
        "\n",
        "import torchvision.models as models\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "import apex\n",
        "from torch.nn.parallel import DistributedDataParallel"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFSjwz5t05Ul"
      },
      "source": [
        "def load_checkpoint(r_path, encoder, opt, scaler, use_fp16=False):\n",
        "    checkpoint = torch.load(r_path, map_location=\"cpu\")\n",
        "    epoch = checkpoint[\"epoch\"]\n",
        "\n",
        "    # -- loading encoder\n",
        "    encoder.load_state_dict(checkpoint[\"encoder\"])\n",
        "    logger.info(f\"loaded encoder from epoch {epoch}\")\n",
        "\n",
        "    # -- loading optimizer\n",
        "    opt.load_state_dict(checkpoint[\"opt\"])\n",
        "    if use_fp16:\n",
        "        scaler.load_state_dict(checkpoint[\"amp\"])\n",
        "    logger.info(f\"loaded optimizers from epoch {epoch}\")\n",
        "    logger.info(f\"read-path: {r_path}\")\n",
        "    del checkpoint\n",
        "    return encoder, opt, epoch\n",
        "\n",
        "\n",
        "def init_model(device, model_name=\"resnet50\", use_pred=False, output_dim=128):\n",
        "    if \"wide_resnet\" in model_name:\n",
        "        encoder = wide_resnet.__dict__[model_name](dropout_rate=0.0)\n",
        "        hidden_dim = 128\n",
        "    else:\n",
        "        encoder = resnet.__dict__[model_name]() \n",
        "\n",
        "        # Load pre-trained ResNetImagenNet\n",
        "        #logger.info(\"Load pre-trained ResNet ImagenNet weigths ...\")\n",
        "        #state_dict = load_state_dict_from_url('https://download.pytorch.org/models/resnet50-0676ba61.pth',\n",
        "                                              progress=True)\n",
        "        #log = encoder.load_state_dict(state_dict, strict=False)\n",
        "        #logger.info(log)\n",
        "    \n",
        "        hidden_dim = 2048\n",
        "        if \"w2\" in model_name:\n",
        "            hidden_dim *= 2\n",
        "        elif \"w4\" in model_name:\n",
        "            hidden_dim *= 4\n",
        "\n",
        "    # -- projection head\n",
        "    encoder.fc = torch.nn.Sequential(\n",
        "        OrderedDict(\n",
        "            [\n",
        "                (\"fc1\", torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "                (\"bn1\", torch.nn.BatchNorm1d(hidden_dim)),\n",
        "                (\"relu1\", torch.nn.ReLU(inplace=True)),\n",
        "                (\"fc2\", torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "                (\"bn2\", torch.nn.BatchNorm1d(hidden_dim)),\n",
        "                (\"relu2\", torch.nn.ReLU(inplace=True)),\n",
        "                (\"fc3\", torch.nn.Linear(hidden_dim, output_dim)),\n",
        "            ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # -- prediction head\n",
        "    encoder.pred = None\n",
        "    if use_pred:\n",
        "        mx = 4  # 4x bottleneck prediction head\n",
        "        pred_head = OrderedDict([])\n",
        "        pred_head[\"bn1\"] = torch.nn.BatchNorm1d(output_dim)\n",
        "        pred_head[\"fc1\"] = torch.nn.Linear(output_dim, output_dim // mx)\n",
        "        pred_head[\"bn2\"] = torch.nn.BatchNorm1d(output_dim // mx)\n",
        "        pred_head[\"relu\"] = torch.nn.ReLU(inplace=True)\n",
        "        pred_head[\"fc2\"] = torch.nn.Linear(output_dim // mx, output_dim)\n",
        "        encoder.pred = torch.nn.Sequential(pred_head)\n",
        "\n",
        "    encoder.to(device)\n",
        "    logger.info(encoder)\n",
        "    return encoder\n",
        "\n",
        "\n",
        "def init_opt(\n",
        "    encoder,\n",
        "    iterations_per_epoch,\n",
        "    start_lr,\n",
        "    ref_lr,\n",
        "    ref_mom,\n",
        "    nesterov,\n",
        "    warmup,\n",
        "    num_epochs,\n",
        "    weight_decay=1e-6,\n",
        "    final_lr=0.0,\n",
        "):\n",
        "    param_groups = [\n",
        "        {\n",
        "            \"params\": (\n",
        "                p\n",
        "                for n, p in encoder.named_parameters()\n",
        "                if (\"bias\" not in n) and (\"bn\" not in n)\n",
        "            )\n",
        "        },\n",
        "        {\n",
        "            \"params\": (\n",
        "                p for n, p in encoder.named_parameters() if (\"bias\" in n) or (\"bn\" in n)\n",
        "            ),\n",
        "            \"LARS_exclude\": True,\n",
        "            \"weight_decay\": 0,\n",
        "        },\n",
        "    ]\n",
        "    optimizer = SGD(\n",
        "        param_groups,\n",
        "        weight_decay=weight_decay,\n",
        "        momentum=0.9,\n",
        "        nesterov=nesterov,\n",
        "        lr=ref_lr,\n",
        "    )\n",
        "    scheduler = WarmupCosineSchedule(\n",
        "        optimizer,\n",
        "        warmup_steps=warmup * iterations_per_epoch,\n",
        "        start_lr=start_lr,\n",
        "        ref_lr=ref_lr,\n",
        "        final_lr=final_lr,\n",
        "        T_max=num_epochs * iterations_per_epoch,\n",
        "    )\n",
        "    optimizer = LARS(optimizer, trust_coefficient=0.001)\n",
        "    return encoder, optimizer, scheduler"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KVQ0Inbx9zC"
      },
      "source": [
        "# argparsers y demas Parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4QuJeoG3fbS"
      },
      "source": [
        "fname = args.fname\n",
        "sel = args.sel"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7er0AA0o4biJ"
      },
      "source": [
        "import pprint"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P56JlNO54OuT"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "\n",
        "logger.info(f'called-params {sel} {fname}')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTlQHYqy02LV",
        "outputId": "ed029701-1547-4bfd-8f90-f6db2eb07a0a"
      },
      "source": [
        "# -- load script params\n",
        "params = None\n",
        "with open(fname, 'r') as y_file:\n",
        "    params = yaml.load(y_file, Loader=yaml.FullLoader)\n",
        "    logger.info('loaded params...')\n",
        "    #if rank == 0:\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    pp.pprint(params)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{   'criterion': {   'classes_per_batch': 2,\n",
            "                     'me_max': True,\n",
            "                     'sharpen': 0.25,\n",
            "                     'supervised_imgs_per_class': 32,\n",
            "                     'supervised_views': 1,\n",
            "                     'temperature': 0.1,\n",
            "                     'unsupervised_batch_size': 32},\n",
            "    'data': {   'color_jitter_strength': 1.0,\n",
            "                'data_seed': None,\n",
            "                'dataset': 'dr',\n",
            "                'label_smoothing': 0.1,\n",
            "                'multicrop': 6,\n",
            "                'normalize': True,\n",
            "                'root_path': 'datasets/',\n",
            "                's_image_folder': 'dr/sample@1000/',\n",
            "                'subset_path': 'dr_subsets',\n",
            "                'u_image_folder': 'dr/train_voets/',\n",
            "                'unique_classes_per_rank': False,\n",
            "                'unlabeled_frac': 0.9},\n",
            "    'logging': {'folder': 'logs/', 'write_tag': 'paws'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'model_name': 'resnet50',\n",
            "                'output_dim': 2048,\n",
            "                'read_checkpoint': None,\n",
            "                'use_fp16': True,\n",
            "                'use_pred_head': True},\n",
            "    'optimization': {   'epochs': 100,\n",
            "                        'final_lr': 1e-05,\n",
            "                        'lr': 0.001,\n",
            "                        'momentum': 0.9,\n",
            "                        'nesterov': False,\n",
            "                        'start_lr': 0.001,\n",
            "                        'warmup': 10,\n",
            "                        'weight_decay': 1e-06}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hormj2p-4q6g"
      },
      "source": [
        "args = params"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38UM1QyN4vyz"
      },
      "source": [
        "# ----------------------------------------------------------------------- #\n",
        "#  PASSED IN PARAMS FROM CONFIG FILE\n",
        "# ----------------------------------------------------------------------- #\n",
        "# -- META\n",
        "model_name = args[\"meta\"][\"model_name\"]\n",
        "output_dim = args[\"meta\"][\"output_dim\"]\n",
        "load_model = args[\"meta\"][\"load_checkpoint\"]\n",
        "r_file = args[\"meta\"][\"read_checkpoint\"]\n",
        "copy_data = args[\"meta\"][\"copy_data\"]\n",
        "use_fp16 = args[\"meta\"][\"use_fp16\"]\n",
        "use_pred_head = args[\"meta\"][\"use_pred_head\"]\n",
        "device = torch.device(args[\"meta\"][\"device\"])\n",
        "#torch.cuda.set_device(device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yZgzava44Kn"
      },
      "source": [
        "# -- CRITERTION\n",
        "reg = args[\"criterion\"][\"me_max\"]\n",
        "supervised_views = args[\"criterion\"][\"supervised_views\"]\n",
        "classes_per_batch = args[\"criterion\"][\"classes_per_batch\"]\n",
        "s_batch_size = args[\"criterion\"][\"supervised_imgs_per_class\"]\n",
        "u_batch_size = args[\"criterion\"][\"unsupervised_batch_size\"]\n",
        "temperature = args[\"criterion\"][\"temperature\"]\n",
        "sharpen = args[\"criterion\"][\"sharpen\"]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S4Egm_w48BM"
      },
      "source": [
        "# -- DATA\n",
        "unlabeled_frac = args[\"data\"][\"unlabeled_frac\"]\n",
        "color_jitter = args[\"data\"][\"color_jitter_strength\"]\n",
        "normalize = args[\"data\"][\"normalize\"]\n",
        "root_path = args[\"data\"][\"root_path\"]\n",
        "s_image_folder = args[\"data\"][\"s_image_folder\"]\n",
        "u_image_folder = args[\"data\"][\"u_image_folder\"]\n",
        "dataset_name = args[\"data\"][\"dataset\"]\n",
        "subset_path = args[\"data\"][\"subset_path\"]\n",
        "unique_classes = args[\"data\"][\"unique_classes_per_rank\"]\n",
        "multicrop = args[\"data\"][\"multicrop\"]\n",
        "label_smoothing = args[\"data\"][\"label_smoothing\"]\n",
        "data_seed = None\n",
        "if \"cifar10\" in dataset_name:\n",
        "    data_seed = args[\"data\"][\"data_seed\"]\n",
        "    crop_scale = (0.75, 1.0) if multicrop > 0 else (0.5, 1.0)\n",
        "    mc_scale = (0.3, 0.75)\n",
        "    mc_size = 18\n",
        "else:\n",
        "    crop_scale = (0.14, 1.0) if multicrop > 0 else (0.08, 1.0)\n",
        "    mc_scale = (0.05, 0.14)\n",
        "    mc_size = 96"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWyg8xbO4_zc"
      },
      "source": [
        "# -- OPTIMIZATION\n",
        "wd = float(args[\"optimization\"][\"weight_decay\"])\n",
        "num_epochs = args[\"optimization\"][\"epochs\"]\n",
        "warmup = args[\"optimization\"][\"warmup\"]\n",
        "start_lr = args[\"optimization\"][\"start_lr\"]\n",
        "lr = args[\"optimization\"][\"lr\"]\n",
        "final_lr = args[\"optimization\"][\"final_lr\"]\n",
        "mom = args[\"optimization\"][\"momentum\"]\n",
        "nesterov = args[\"optimization\"][\"nesterov\"]\n",
        "\n",
        "# -- LOGGING\n",
        "folder = args[\"logging\"][\"folder\"]\n",
        "tag = args[\"logging\"][\"write_tag\"]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJPwU4wqysMI"
      },
      "source": [
        "# --\n",
        "log_timings = True\n",
        "log_freq = 10\n",
        "checkpoint_freq = 50\n",
        "# --\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "np.random.seed(_GLOBAL_SEED)\n",
        "torch.manual_seed(_GLOBAL_SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logger = logging.getLogger()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48mkx6b_yw1a"
      },
      "source": [
        "crop_scale = (0.14, 1.0) if multicrop > 0 else (0.08, 1.0)\n",
        "mc_scale = (0.05, 0.14)\n",
        "mc_size = 96"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7S5I0GvzFDb"
      },
      "source": [
        "# -- init torch distributed backend\n",
        "#world_size, rank = init_distributed()\n",
        "#logger.info(f\"Initialized (rank/world-size) {rank}/{world_size}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZOB9xlC5Yhf"
      },
      "source": [
        "#rank=0"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4AFTanpz48M"
      },
      "source": [
        "# -- log/checkpointing paths\n",
        "log_file = os.path.join(folder, f\"{tag}_r{rank}.csv\")\n",
        "save_path = os.path.join(folder, f\"{tag}\" + \"-ep{epoch}.pth.tar\")\n",
        "latest_path = os.path.join(folder, f\"{tag}-latest.pth.tar\")\n",
        "best_path = os.path.join(folder, f\"{tag}\" + \"-best.pth.tar\")\n",
        "load_path = None\n",
        "if load_model:\n",
        "    load_path = os.path.join(folder, r_file) if r_file is not None else latest_path\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1vpXnCGz7yr"
      },
      "source": [
        "# -- make csv_logger\n",
        "csv_logger = CSVLogger(\n",
        "    log_file,\n",
        "    (\"%d\", \"epoch\"),\n",
        "    (\"%d\", \"itr\"),\n",
        "    (\"%.5f\", \"paws-xent-loss\"),\n",
        "    (\"%.5f\", \"paws-me_max-reg\"),\n",
        "    (\"%d\", \"time (ms)\"),\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "d9fb992adc10472986ccfa911f885939",
            "df8bc76653324e6bbe3e8aa6fc6517ef",
            "de46964ed7a44265bf8e5322befc23dd",
            "c08e19fc9a9b4bfc80d35e612db85464",
            "7beb65d67dd8461b9b62239f4170c9c4",
            "8a4dc28cbf884d00b243b97670fb1d50",
            "aa946f689d9d4f94b850672e1b064026",
            "1e240b15c4004e0c84d5e497756a90fa"
          ]
        },
        "id": "YfGVpm40z_Zv",
        "outputId": "6f9b16bb-60b9-4af8-ae7b-0affcb5eb439"
      },
      "source": [
        "# -- init model\n",
        "encoder = init_model(\n",
        "    device=device,\n",
        "    model_name=model_name,\n",
        "    use_pred=use_pred_head,\n",
        "    output_dim=output_dim,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9fb992adc10472986ccfa911f885939",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102530333.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck9QqafQ0IVa"
      },
      "source": [
        "if world_size > 1:\n",
        "    process_group = apex.parallel.create_syncbn_process_group(0)\n",
        "    encoder = apex.parallel.convert_syncbn_model(\n",
        "        encoder, process_group=process_group\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WU6JhWZ0Ljd"
      },
      "source": [
        "# -- init losses\n",
        "paws = init_paws_loss(multicrop=multicrop, tau=temperature, T=sharpen, me_max=reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feAhSFCA0OF5"
      },
      "source": [
        "# -- assume support images are sampled with ClassStratifiedSampler\n",
        "labels_matrix = make_labels_matrix(\n",
        "    num_classes=classes_per_batch,\n",
        "    s_batch_size=s_batch_size,\n",
        "    world_size=world_size,\n",
        "    device=device,\n",
        "    unique_classes=unique_classes,\n",
        "    smoothing=label_smoothing,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agjOL8Ml0Sq5"
      },
      "source": [
        "# -- make data transforms\n",
        "transform, init_transform = make_transforms(\n",
        "    dataset_name=dataset_name,\n",
        "    subset_path=subset_path,\n",
        "    unlabeled_frac=unlabeled_frac,\n",
        "    training=True,\n",
        "    split_seed=data_seed,\n",
        "    crop_scale=crop_scale,\n",
        "    basic_augmentations=False,\n",
        "    color_jitter=color_jitter,\n",
        "    normalize=normalize,\n",
        ")\n",
        "multicrop_transform = (multicrop, None)\n",
        "if multicrop > 0:\n",
        "    multicrop_transform = make_multicrop_transform(\n",
        "        dataset_name=dataset_name,\n",
        "        num_crops=multicrop,\n",
        "        size=mc_size,\n",
        "        crop_scale=mc_scale,\n",
        "        normalize=normalize,\n",
        "        color_distortion=color_jitter,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLmKoCO-0VgL"
      },
      "source": [
        "# -- init data-loaders/samplers\n",
        "(\n",
        "    unsupervised_loader,\n",
        "    unsupervised_sampler,\n",
        "    supervised_loader,\n",
        "    supervised_sampler,\n",
        ") = init_data(\n",
        "    dataset_name=dataset_name,\n",
        "    transform=transform,\n",
        "    init_transform=init_transform,\n",
        "    supervised_views=supervised_views,\n",
        "    u_batch_size=u_batch_size,\n",
        "    s_batch_size=s_batch_size,\n",
        "    unique_classes=unique_classes,\n",
        "    classes_per_batch=classes_per_batch,\n",
        "    multicrop_transform=multicrop_transform,\n",
        "    world_size=world_size,\n",
        "    rank=rank,\n",
        "    root_path=root_path,\n",
        "    s_image_folder=s_image_folder,\n",
        "    u_image_folder=u_image_folder,\n",
        "    training=True,\n",
        "    copy_data=copy_data,\n",
        ")\n",
        "iter_supervised = None\n",
        "ipe = len(unsupervised_loader)\n",
        "logger.info(f\"iterations per epoch: {ipe}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwCOK9b80Ywh"
      },
      "source": [
        "# -- init optimizer and scheduler\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "encoder, optimizer, scheduler = init_opt(\n",
        "    encoder=encoder,\n",
        "    weight_decay=wd,\n",
        "    start_lr=start_lr,\n",
        "    ref_lr=lr,\n",
        "    final_lr=final_lr,\n",
        "    ref_mom=mom,\n",
        "    nesterov=nesterov,\n",
        "    iterations_per_epoch=ipe,\n",
        "    warmup=warmup,\n",
        "    num_epochs=num_epochs,\n",
        ")\n",
        "if world_size > 1:\n",
        "    encoder = DistributedDataParallel(encoder, broadcast_buffers=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySHSFxBR0dET"
      },
      "source": [
        "start_epoch = 0\n",
        "# -- load training checkpoint\n",
        "if load_model:\n",
        "    encoder, optimizer, start_epoch = load_checkpoint(\n",
        "        r_path=load_path,\n",
        "        encoder=encoder,\n",
        "        opt=optimizer,\n",
        "        scaler=scaler,\n",
        "        use_fp16=use_fp16,\n",
        "    )\n",
        "    for _ in range(start_epoch):\n",
        "        for _ in range(ipe):\n",
        "            scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gtz17Cd0kGB"
      },
      "source": [
        "# -- TRAINING LOOP\n",
        "best_loss = None\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    logger.info(\"Epoch %d\" % (epoch + 1))\n",
        "\n",
        "    # -- update distributed-data-loader epoch\n",
        "    unsupervised_sampler.set_epoch(epoch)\n",
        "    if supervised_sampler is not None:\n",
        "        supervised_sampler.set_epoch(epoch)\n",
        "\n",
        "    loss_meter = AverageMeter()\n",
        "    ploss_meter = AverageMeter()\n",
        "    rloss_meter = AverageMeter()\n",
        "    time_meter = AverageMeter()\n",
        "    data_meter = AverageMeter()\n",
        "\n",
        "    for itr, udata in enumerate(unsupervised_loader):\n",
        "\n",
        "        def load_imgs():\n",
        "            # -- unsupervised imgs\n",
        "            uimgs = [u.to(device, non_blocking=True) for u in udata[:-1]]\n",
        "            # -- supervised imgs\n",
        "            global iter_supervised\n",
        "            try:\n",
        "                sdata = next(iter_supervised)\n",
        "            except Exception:\n",
        "                iter_supervised = iter(supervised_loader)\n",
        "                logger.info(f\"len.supervised_loader: {len(iter_supervised)}\")\n",
        "                sdata = next(iter_supervised)\n",
        "            finally:\n",
        "                labels = torch.cat([labels_matrix for _ in range(supervised_views)])\n",
        "                simgs = [s.to(device, non_blocking=True) for s in sdata[:-1]]\n",
        "            # -- concatenate supervised imgs and unsupervised imgs\n",
        "            imgs = simgs + uimgs\n",
        "            return imgs, labels\n",
        "\n",
        "        (imgs, labels), dtime = gpu_timer(load_imgs)\n",
        "        data_meter.update(dtime)\n",
        "\n",
        "        def train_step():\n",
        "            with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # --\n",
        "                # h: representations of 'imgs' before head\n",
        "                # z: representations of 'imgs' after head\n",
        "                # -- If use_pred_head=False, then encoder.pred (prediction\n",
        "                #    head) is None, and _forward_head just returns the\n",
        "                #    identity, z=h\n",
        "                h, z = encoder(imgs, return_before_head=True)\n",
        "\n",
        "                # Compute paws loss in full precision\n",
        "                with torch.cuda.amp.autocast(enabled=False):\n",
        "\n",
        "                    # Step 1. convert representations to fp32\n",
        "                    h, z = h.float(), z.float()\n",
        "\n",
        "                    # Step 2. determine anchor views/supports and their\n",
        "                    #         corresponding target views/supports\n",
        "                    # --\n",
        "                    num_support = (\n",
        "                        supervised_views * s_batch_size * classes_per_batch\n",
        "                    )\n",
        "                    # --\n",
        "                    anchor_supports = z[:num_support]\n",
        "                    anchor_views = z[num_support:]\n",
        "                    # --\n",
        "                    target_supports = h[:num_support].detach()\n",
        "                    target_views = h[num_support:].detach()\n",
        "                    target_views = torch.cat(\n",
        "                        [\n",
        "                            target_views[u_batch_size : 2 * u_batch_size],\n",
        "                            target_views[:u_batch_size],\n",
        "                        ],\n",
        "                        dim=0,\n",
        "                    )\n",
        "\n",
        "                    # Step 3. compute paws loss with me-max regularization\n",
        "                    (ploss, me_max) = paws(\n",
        "                        anchor_views=anchor_views,\n",
        "                        anchor_supports=anchor_supports,\n",
        "                        anchor_support_labels=labels,\n",
        "                        target_views=target_views,\n",
        "                        target_supports=target_supports,\n",
        "                        target_support_labels=labels,\n",
        "                    )\n",
        "                    loss = ploss + me_max\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            lr_stats = scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            return (float(loss), float(ploss), float(me_max), lr_stats)\n",
        "\n",
        "        (loss, ploss, rloss, lr_stats), etime = gpu_timer(train_step)\n",
        "        loss_meter.update(loss)\n",
        "        ploss_meter.update(ploss)\n",
        "        rloss_meter.update(rloss)\n",
        "        time_meter.update(etime)\n",
        "\n",
        "        if (itr % log_freq == 0) or np.isnan(loss) or np.isinf(loss):\n",
        "            csv_logger.log(\n",
        "                epoch + 1, itr, ploss_meter.avg, rloss_meter.avg, time_meter.avg\n",
        "            )\n",
        "            logger.info(\n",
        "                \"[%d, %5d] loss: %.5f (%.5f %.5f) \"\n",
        "                \"(%d ms; %d ms)\"\n",
        "                % (\n",
        "                    epoch + 1,\n",
        "                    itr,\n",
        "                    loss_meter.avg,\n",
        "                    ploss_meter.avg,\n",
        "                    rloss_meter.avg,\n",
        "                    time_meter.avg,\n",
        "                    data_meter.avg,\n",
        "                )\n",
        "            )\n",
        "            if lr_stats is not None:\n",
        "                logger.info(\n",
        "                    \"[%d, %5d] lr_stats: %.5f (%.2e, %.2e)\"\n",
        "                    % (epoch + 1, itr, lr_stats.avg, lr_stats.min, lr_stats.max)\n",
        "                )\n",
        "\n",
        "        assert not np.isnan(loss), \"loss is nan\"\n",
        "\n",
        "    # -- logging/checkpointing\n",
        "    logger.info(\"avg. loss %.3f\" % loss_meter.avg)\n",
        "\n",
        "    if rank == 0:\n",
        "        save_dict = {\n",
        "            \"encoder\": encoder.state_dict(),\n",
        "            \"opt\": optimizer.state_dict(),\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"unlabel_prob\": unlabeled_frac,\n",
        "            \"loss\": loss_meter.avg,\n",
        "            \"s_batch_size\": s_batch_size,\n",
        "            \"u_batch_size\": u_batch_size,\n",
        "            \"world_size\": world_size,\n",
        "            \"lr\": lr,\n",
        "            \"temperature\": temperature,\n",
        "            \"amp\": scaler.state_dict(),\n",
        "        }\n",
        "        torch.save(save_dict, latest_path)\n",
        "        if best_loss is None or best_loss > loss_meter.avg:\n",
        "            best_loss = loss_meter.avg\n",
        "            logger.info('updating \"best\" checkpoint')\n",
        "            torch.save(save_dict, best_path)\n",
        "        if (\n",
        "            (epoch + 1) % checkpoint_freq == 0\n",
        "            or (epoch + 1) % 10 == 0\n",
        "            and epoch < checkpoint_freq\n",
        "        ):\n",
        "            torch.save(save_dict, save_path.format(epoch=f\"{epoch + 1}\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1og_585yA2R"
      },
      "source": [
        "#Loss functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14KxYWrIyrpu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pstze2ObyDNO"
      },
      "source": [
        "def train_resnet():\n",
        "    \"\"\"\n",
        "    Aqui tengo que incluir los dataloaders y demas\n",
        "\n",
        "    definir el train_loop_fn\n",
        "    \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYVzaIOQyOr3"
      },
      "source": [
        "# Start training processes\n",
        "def _mp_fn(rank, flags):\n",
        "    global FLAGS\n",
        "    FLAGS = flags\n",
        "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "    accuracy, data, pred, target = train_resnet()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfBF0mNfyNbe"
      },
      "source": [
        "# TO DO \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = init_argparse()\n",
        "    FLAGS = parser.parse_args()\n",
        "    print(FLAGS)\n",
        "    xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS.num_cores, start_method=\"fork\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}