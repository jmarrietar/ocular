{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prueba Pytorch XLA",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOlAN6ofFb3SqNexWGPVwDd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/Prueba_Pytorch_XLA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqTsJNBCaPgG"
      },
      "source": [
        "import gdown\n",
        "\n",
        "def download(data, url):\n",
        "    # Download dataset\n",
        "    import zipfile\n",
        "    url = url\n",
        "    output = \"{}.zip\".format(data)\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # Uncompress dataset\n",
        "    local_zip = '{}.zip'.format(data)\n",
        "    zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imFIHTdSayCb"
      },
      "source": [
        "data_samples = {\n",
        "    \"sample@200\": \"https://drive.google.com/uc?id=1FfV7YyDJvNUCDP5r3-8iQfZ2-xJp_pgb\",\n",
        "    \"sample@500\": \"https://drive.google.com/uc?id=1dHwUqpmSogEdjAB9rwDUL-OKFRUcVXte\",\n",
        "    \"sample@1000\": \"https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\",\n",
        "    \"sample@2000\": \"https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\",\n",
        "    \"sample@3000\": \"https://drive.google.com/uc?id=1_yre5K9YYvJgSrT4xvrI8eD_htucIywA\",\n",
        "    \"sample@4000_images\": \"https://drive.google.com/uc?id=1dqVB8EozEpwWzyuU80AauoQmsiw3Gtm2\",\n",
        "    \"sample@20000\": \"https://drive.google.com/uc?id=1MTDpLzpmhSiZq2jSdmHx2UDPn9FC8gzO\",\n",
        "    \"val-voets-tf\": \"https://drive.google.com/uc?id=1VzVgMGTkBBPG2qbzLunD9HvLzH6tcyrv\",\n",
        "    \"train_voets\": \"https://drive.google.com/uc?id=1AmcFh1MOOZ6aqKm2eO7XEdgmIEqHKTZ5\",\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\"\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jJgVayva20x"
      },
      "source": [
        "UNLABELED = 'sample@1000'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIQsaT_Ta75z",
        "outputId": "0d1d2552-78dd-448b-ad16-0d77ba556dd0"
      },
      "source": [
        "URL_UNLABELED = data_samples[UNLABELED]\n",
        "download(UNLABELED, URL_UNLABELED)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\n",
            "To: /content/sample@1000.zip\n",
            "108MB [00:00, 242MB/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uT6Jrl1Tj3H",
        "outputId": "f70a8e53-f241-45b8-f78d-fc2aba857c2b"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n",
            "Requirement already satisfied: torch-xla==1.8.1 from https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.30.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (20.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.0.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYbCW5nqO66d"
      },
      "source": [
        "import args_parse\n",
        "\n",
        "SUPPORTED_MODELS = [\n",
        "    'alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201',\n",
        "    'inception_v3', 'resnet101', 'resnet152', 'resnet18', 'resnet34',\n",
        "    'resnet50', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13',\n",
        "    'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn'\n",
        "]\n",
        "\n",
        "MODEL_OPTS = {\n",
        "    '--model': {\n",
        "        'choices': SUPPORTED_MODELS,\n",
        "        'default': 'resnet50',\n",
        "    },\n",
        "    '--test_set_batch_size': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--lr_scheduler_type': {\n",
        "        'type': str,\n",
        "    },\n",
        "    '--lr_scheduler_divide_every_n_epochs': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--lr_scheduler_divisor': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--test_only_at_end': {\n",
        "        'action': 'store_true',\n",
        "    },\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ggvTYidO9ZQ"
      },
      "source": [
        "FLAGS = args_parse.parse_common_options(\n",
        "    datadir=UNLABELED,\n",
        "    batch_size=None,\n",
        "    num_epochs=None,\n",
        "    momentum=None,\n",
        "    lr=None,\n",
        "    target_accuracy=None,\n",
        "    profiler_port=9012,\n",
        "    opts=MODEL_OPTS.items(),\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CSubsgJShgy"
      },
      "source": [
        "FLAGS.fake_data = False\n",
        "FLAGS.num_epochs = 2\n",
        "FLAGS.batch_size = 64\n",
        "FLAGS.log_steps = 100\n",
        "FLAGS.num_cores = 8"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-Hm9PfGpVOVL",
        "outputId": "187f9b6f-52ff-4a5c-8a4c-19b7cbacca1c"
      },
      "source": [
        "FLAGS.datadir"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sample@1000'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOH8ZjssOSd1",
        "outputId": "eae22467-dd12-4659-a51a-d63a8d93cc5f"
      },
      "source": [
        "import os\n",
        "import schedulers\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch_xla\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.utils.utils as xu\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.test.test_utils as test_utils"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SX0pnOwOxBP"
      },
      "source": [
        "DEFAULT_KWARGS = dict(\n",
        "    batch_size=128,\n",
        "    test_set_batch_size=64,\n",
        "    num_epochs=18,\n",
        "    momentum=0.9,\n",
        "    lr=0.1,\n",
        "    target_accuracy=0.0,\n",
        ")\n",
        "MODEL_SPECIFIC_DEFAULTS = {\n",
        "    # Override some of the args in DEFAULT_KWARGS, or add them to the dict\n",
        "    # if they don't exist.\n",
        "    'resnet50':\n",
        "        dict(\n",
        "            DEFAULT_KWARGS, **{\n",
        "                'lr': 0.5,\n",
        "                'lr_scheduler_divide_every_n_epochs': 20,\n",
        "                'lr_scheduler_divisor': 5,\n",
        "                'lr_scheduler_type': 'WarmupAndExponentialDecayScheduler',\n",
        "            })\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nad72u1lOyyh"
      },
      "source": [
        "# Set any args that were not explicitly given by the user.\n",
        "default_value_dict = MODEL_SPECIFIC_DEFAULTS.get(FLAGS.model, DEFAULT_KWARGS)\n",
        "for arg, value in default_value_dict.items():\n",
        "  if getattr(FLAGS, arg) is None:\n",
        "    setattr(FLAGS, arg, value)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDkym-NUUocK",
        "outputId": "8082173e-46ab-4f0b-cb9b-19a3a284720a"
      },
      "source": [
        "default_value_dict"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 128,\n",
              " 'lr': 0.5,\n",
              " 'lr_scheduler_divide_every_n_epochs': 20,\n",
              " 'lr_scheduler_divisor': 5,\n",
              " 'lr_scheduler_type': 'WarmupAndExponentialDecayScheduler',\n",
              " 'momentum': 0.9,\n",
              " 'num_epochs': 18,\n",
              " 'target_accuracy': 0.0,\n",
              " 'test_set_batch_size': 64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4xo5QNANY_Q"
      },
      "source": [
        "def get_model_property(key):\n",
        "  default_model_property = {\n",
        "      'img_dim': 224, # YO\n",
        "      'model_fn': getattr(torchvision.models, FLAGS.model)\n",
        "  }\n",
        "  model_properties = {\n",
        "      'inception_v3': {\n",
        "          'img_dim': 299,\n",
        "          'model_fn': lambda: torchvision.models.inception_v3(aux_logits=False)\n",
        "      },\n",
        "  }\n",
        "  model_fn = model_properties.get(FLAGS.model, default_model_property)[key]\n",
        "  return model_fn\n",
        "\n",
        "\n",
        "def _train_update(device, step, loss, tracker, epoch, writer):\n",
        "  test_utils.print_training_update(\n",
        "      device,\n",
        "      step,\n",
        "      loss.item(),\n",
        "      tracker.rate(),\n",
        "      tracker.global_rate(),\n",
        "      epoch,\n",
        "      summary_writer=writer)\n",
        "\n",
        "\n",
        "def train_imagenet():\n",
        "  print('==> Preparing data..')\n",
        "  img_dim = get_model_property('img_dim')\n",
        "  if FLAGS.fake_data:\n",
        "    train_dataset_len = 1200000  # Roughly the size of Imagenet dataset.\n",
        "    train_loader = xu.SampleGenerator(\n",
        "        data=(torch.zeros(FLAGS.batch_size, 3, img_dim, img_dim),\n",
        "              torch.zeros(FLAGS.batch_size, dtype=torch.int64)),\n",
        "        sample_count=train_dataset_len // FLAGS.batch_size //\n",
        "        xm.xrt_world_size())\n",
        "    test_loader = xu.SampleGenerator(\n",
        "        data=(torch.zeros(FLAGS.test_set_batch_size, 3, img_dim, img_dim),\n",
        "              torch.zeros(FLAGS.test_set_batch_size, dtype=torch.int64)),\n",
        "        sample_count=50000 // FLAGS.batch_size // xm.xrt_world_size())\n",
        "  else:\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    train_dataset = torchvision.datasets.ImageFolder(\n",
        "        os.path.join(FLAGS.datadir, 'train'),\n",
        "        transforms.Compose([\n",
        "            transforms.RandomResizedCrop(img_dim),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "    train_dataset_len = len(train_dataset.imgs)\n",
        "    resize_dim = max(img_dim, 256)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(\n",
        "        os.path.join(FLAGS.datadir, 'train'),\n",
        "        # Matches Torchvision's eval transforms except Torchvision uses size\n",
        "        # 256 resize for all models both here and in the train loader. Their\n",
        "        # version crashes during training on 299x299 images, e.g. inception.\n",
        "        transforms.Compose([\n",
        "            transforms.Resize(resize_dim),\n",
        "            transforms.CenterCrop(img_dim),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "\n",
        "    train_sampler, test_sampler = None, None\n",
        "    if xm.xrt_world_size() > 1:\n",
        "      train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "          train_dataset,\n",
        "          num_replicas=xm.xrt_world_size(),\n",
        "          rank=xm.get_ordinal(),\n",
        "          shuffle=True)\n",
        "      test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "          test_dataset,\n",
        "          num_replicas=xm.xrt_world_size(),\n",
        "          rank=xm.get_ordinal(),\n",
        "          shuffle=False)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=FLAGS.batch_size,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=FLAGS.drop_last,\n",
        "        shuffle=False if train_sampler else True,\n",
        "        num_workers=FLAGS.num_workers)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=FLAGS.test_set_batch_size,\n",
        "        sampler=test_sampler,\n",
        "        drop_last=FLAGS.drop_last,\n",
        "        shuffle=False,\n",
        "        num_workers=FLAGS.num_workers)\n",
        "\n",
        "  torch.manual_seed(42)\n",
        "\n",
        "  device = xm.xla_device()\n",
        "  model = get_model_property('model_fn')().to(device)\n",
        "  writer = None\n",
        "  if xm.is_master_ordinal():\n",
        "    writer = test_utils.get_summary_writer(FLAGS.logdir)\n",
        "  optimizer = optim.SGD(\n",
        "      model.parameters(),\n",
        "      lr=FLAGS.lr,\n",
        "      momentum=FLAGS.momentum,\n",
        "      weight_decay=1e-4)\n",
        "  num_training_steps_per_epoch = train_dataset_len // (\n",
        "      FLAGS.batch_size * xm.xrt_world_size())\n",
        "  lr_scheduler = schedulers.wrap_optimizer_with_scheduler(\n",
        "      optimizer,\n",
        "      scheduler_type=getattr(FLAGS, 'lr_scheduler_type', None),\n",
        "      scheduler_divisor=getattr(FLAGS, 'lr_scheduler_divisor', None),\n",
        "      scheduler_divide_every_n_epochs=getattr(\n",
        "          FLAGS, 'lr_scheduler_divide_every_n_epochs', None),\n",
        "      num_steps_per_epoch=num_training_steps_per_epoch,\n",
        "      summary_writer=writer)\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  def train_loop_fn(loader, epoch):\n",
        "    tracker = xm.RateTracker()\n",
        "    model.train()\n",
        "    for step, (data, target) in enumerate(loader):\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "      loss = loss_fn(output, target)\n",
        "      loss.backward()\n",
        "      xm.optimizer_step(optimizer)\n",
        "      tracker.add(FLAGS.batch_size)\n",
        "      if lr_scheduler:\n",
        "        lr_scheduler.step()\n",
        "      if step % FLAGS.log_steps == 0:\n",
        "        xm.add_step_closure(\n",
        "            _train_update, args=(device, step, loss, tracker, epoch, writer))\n",
        "\n",
        "  def test_loop_fn(loader, epoch):\n",
        "    total_samples, correct = 0, 0\n",
        "    model.eval()\n",
        "    for step, (data, target) in enumerate(loader):\n",
        "      output = model(data)\n",
        "      pred = output.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as(pred)).sum()\n",
        "      total_samples += data.size()[0]\n",
        "      if step % FLAGS.log_steps == 0:\n",
        "        xm.add_step_closure(\n",
        "            test_utils.print_test_update, args=(device, None, epoch, step))\n",
        "    accuracy = 100.0 * correct.item() / total_samples\n",
        "    accuracy = xm.mesh_reduce('test_accuracy', accuracy, np.mean)\n",
        "    return accuracy\n",
        "\n",
        "  train_device_loader = pl.MpDeviceLoader(train_loader, device)\n",
        "  test_device_loader = pl.MpDeviceLoader(test_loader, device)\n",
        "  accuracy, max_accuracy = 0.0, 0.0\n",
        "  for epoch in range(1, FLAGS.num_epochs + 1):\n",
        "    xm.master_print('Epoch {} train begin {}'.format(epoch, test_utils.now()))\n",
        "    train_loop_fn(train_device_loader, epoch)\n",
        "    xm.master_print('Epoch {} train end {}'.format(epoch, test_utils.now()))\n",
        "    if not FLAGS.test_only_at_end or epoch == FLAGS.num_epochs:\n",
        "      accuracy = test_loop_fn(test_device_loader, epoch)\n",
        "      xm.master_print('Epoch {} test end {}, Accuracy={:.2f}'.format(\n",
        "          epoch, test_utils.now(), accuracy))\n",
        "      max_accuracy = max(accuracy, max_accuracy)\n",
        "      test_utils.write_to_summary(\n",
        "          writer,\n",
        "          epoch,\n",
        "          dict_to_write={'Accuracy/test': accuracy},\n",
        "          write_xla_metrics=True)\n",
        "    if FLAGS.metrics_debug:\n",
        "      xm.master_print(met.metrics_report())\n",
        "\n",
        "  test_utils.close_summary_writer(writer)\n",
        "  xm.master_print('Max Accuracy: {:.2f}%'.format(max_accuracy))\n",
        "  return max_accuracy"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww2PE7HZOsGH"
      },
      "source": [
        "def _mp_fn(index, flags):\n",
        "  global FLAGS\n",
        "  FLAGS = flags\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  accuracy = train_imagenet()\n",
        "  if accuracy < FLAGS.target_accuracy:\n",
        "    print('Accuracy {} is below target {}'.format(accuracy,\n",
        "                                                  FLAGS.target_accuracy))\n",
        "    sys.exit(21)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9h_SHYQUw82",
        "outputId": "a68d643e-3891-4e22-b0f9-f329b82046b9"
      },
      "source": [
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Epoch 1 train begin 23:10:46\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "| Training Device=xla:0/1 Epoch=1 Step=0 Loss=6.92886 Rate=4.41 GlobalRate=4.41 Time=23:11:12\n",
            "| Training Device=xla:0/5 Epoch=1 Step=0 Loss=6.91855 Rate=4.62 GlobalRate=4.62 Time=23:11:12\n",
            "| Training Device=xla:0/4 Epoch=1 Step=0 Loss=6.93952 Rate=3.18 GlobalRate=3.18 Time=23:11:12\n",
            "| Training Device=xla:0/6 Epoch=1 Step=0 Loss=6.92669 Rate=3.79 GlobalRate=3.79 Time=23:11:12\n",
            "| Training Device=xla:0/2 Epoch=1 Step=0 Loss=6.92119 Rate=3.02 GlobalRate=3.02 Time=23:11:12\n",
            "| Training Device=xla:0/7 Epoch=1 Step=0 Loss=6.91724 Rate=3.90 GlobalRate=3.90 Time=23:11:12\n",
            "| Training Device=xla:0/3 Epoch=1 Step=0 Loss=6.92231 Rate=2.95 GlobalRate=2.95 Time=23:11:12\n",
            "| Training Device=xla:1/0 Epoch=1 Step=0 Loss=6.92930 Rate=2.50 GlobalRate=2.50 Time=23:11:12\n",
            "Epoch 1 train end 23:11:36\n",
            "| Test Device=xla:0/7 Step=0 Epoch=1 Time=23:11:43\n",
            "| Test Device=xla:0/5 Step=0 Epoch=1 Time=23:11:43\n",
            "| Test Device=xla:0/2 Step=0 Epoch=1 Time=23:11:43\n",
            "| Test Device=xla:0/4 Step=0 Epoch=1 Time=23:11:43\n",
            "| Test Device=xla:0/6 Step=0 Epoch=1 Time=23:11:43\n",
            "| Test Device=xla:0/3 Step=0 Epoch=1 Time=23:11:43\n",
            "| Test Device=xla:1/0 Step=0 Epoch=1 Time=23:11:43\n",
            "| Test Device=xla:0/1 Step=0 Epoch=1 Time=23:11:43\n",
            "Epoch 1 test end 23:11:46, Accuracy=50.00\n",
            "Epoch 2 train begin 23:11:46\n",
            "| Training Device=xla:0/3 Epoch=2 Step=0 Loss=234.29034 Rate=2.19 GlobalRate=2.19 Time=23:12:16\n",
            "| Training Device=xla:0/6 Epoch=2 Step=0 Loss=233.41656 Rate=2.19 GlobalRate=2.19 Time=23:12:16\n",
            "| Training Device=xla:1/0 Epoch=2 Step=0 Loss=138.31508 Rate=2.19 GlobalRate=2.19 Time=23:12:16\n",
            "| Training Device=xla:0/7 Epoch=2 Step=0 Loss=164.04413 Rate=2.19 GlobalRate=2.19 Time=23:12:16\n",
            "| Training Device=xla:0/1 Epoch=2 Step=0 Loss=169.43546 Rate=2.19 GlobalRate=2.19 Time=23:12:16\n",
            "| Training Device=xla:0/2 Epoch=2 Step=0 Loss=228.92073 Rate=2.19 GlobalRate=2.19 Time=23:12:16\n",
            "| Training Device=xla:0/4 Epoch=2 Step=0 Loss=171.30478 Rate=2.19 GlobalRate=2.19 Time=23:12:16\n",
            "| Training Device=xla:0/5 Epoch=2 Step=0 Loss=154.06575 Rate=2.19 GlobalRate=2.19 Time=23:12:16\n",
            "Epoch 2 train end 23:12:16\n",
            "| Test Device=xla:1/0 Step=0 Epoch=2 Time=23:12:20\n",
            "| Test Device=xla:0/5 Step=0 Epoch=2 Time=23:12:20\n",
            "| Test Device=xla:0/7 Step=0 Epoch=2 Time=23:12:21\n",
            "| Test Device=xla:0/4 Step=0 Epoch=2 Time=23:12:21\n",
            "| Test Device=xla:0/6 Step=0 Epoch=2 Time=23:12:21\n",
            "| Test Device=xla:0/2 Step=0 Epoch=2 Time=23:12:22\n",
            "| Test Device=xla:0/1 Step=0 Epoch=2 Time=23:12:22\n",
            "| Test Device=xla:0/3 Step=0 Epoch=2 Time=23:12:22\n",
            "Epoch 2 test end 23:12:22, Accuracy=0.00\n",
            "Max Accuracy: 50.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKoSLwU5U25t"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}