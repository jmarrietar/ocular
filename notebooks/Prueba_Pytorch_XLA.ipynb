{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prueba Pytorch XLA",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPt6AGRrRKVYXh+ajA7JB6x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/Prueba_Pytorch_XLA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqgt-SPZs69T"
      },
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "from google.colab import auth, drive\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycMSo6gEs84s",
        "outputId": "db88533a-d7dd-4891-c7a9-8eb71093c2f0"
      },
      "source": [
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt0HysgJtDr-",
        "outputId": "35de5b12-7031-449e-9b9b-277d8643983a"
      },
      "source": [
        "import torch_xla.utils.serialization as xser"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqTsJNBCaPgG"
      },
      "source": [
        "import gdown\n",
        "\n",
        "def download(data, url):\n",
        "    # Download dataset\n",
        "    import zipfile\n",
        "    url = url\n",
        "    output = \"{}.zip\".format(data)\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # Uncompress dataset\n",
        "    local_zip = '{}.zip'.format(data)\n",
        "    zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imFIHTdSayCb"
      },
      "source": [
        "data_samples = {\n",
        "    \"sample@200\": \"https://drive.google.com/uc?id=1FfV7YyDJvNUCDP5r3-8iQfZ2-xJp_pgb\",\n",
        "    \"sample@500\": \"https://drive.google.com/uc?id=1dHwUqpmSogEdjAB9rwDUL-OKFRUcVXte\",\n",
        "    \"sample@1000\": \"https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\",\n",
        "    \"sample@2000\": \"https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\",\n",
        "    \"sample@3000\": \"https://drive.google.com/uc?id=1_yre5K9YYvJgSrT4xvrI8eD_htucIywA\",\n",
        "    \"sample@4000_images\": \"https://drive.google.com/uc?id=1dqVB8EozEpwWzyuU80AauoQmsiw3Gtm2\",\n",
        "    \"sample@20000\": \"https://drive.google.com/uc?id=1MTDpLzpmhSiZq2jSdmHx2UDPn9FC8gzO\",\n",
        "    \"val-voets-tf\": \"https://drive.google.com/uc?id=1VzVgMGTkBBPG2qbzLunD9HvLzH6tcyrv\",\n",
        "    \"train_voets\": \"https://drive.google.com/uc?id=1AmcFh1MOOZ6aqKm2eO7XEdgmIEqHKTZ5\",\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\"\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jJgVayva20x"
      },
      "source": [
        "UNLABELED = 'sample@1000'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIQsaT_Ta75z",
        "outputId": "7a7b3512-2426-4c73-ceef-6049d3678b44"
      },
      "source": [
        "URL_UNLABELED = data_samples[UNLABELED]\n",
        "download(UNLABELED, URL_UNLABELED)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\n",
            "To: /content/sample@1000.zip\n",
            "108MB [00:00, 287MB/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uT6Jrl1Tj3H",
        "outputId": "d5f1f0a2-baa2-4dfe-c0ba-5e48ea1cd8aa"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n",
            "Requirement already satisfied: torch-xla==1.8.1 from https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.30.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (20.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYbCW5nqO66d"
      },
      "source": [
        "import args_parse\n",
        "\n",
        "SUPPORTED_MODELS = [\n",
        "    'alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201',\n",
        "    'inception_v3', 'resnet101', 'resnet152', 'resnet18', 'resnet34',\n",
        "    'resnet50', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13',\n",
        "    'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn'\n",
        "]\n",
        "\n",
        "MODEL_OPTS = {\n",
        "    '--model': {\n",
        "        'choices': SUPPORTED_MODELS,\n",
        "        'default': 'resnet50',\n",
        "    },\n",
        "    '--test_set_batch_size': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--lr_scheduler_type': {\n",
        "        'type': str,\n",
        "    },\n",
        "    '--lr_scheduler_divide_every_n_epochs': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--lr_scheduler_divisor': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--test_only_at_end': {\n",
        "        'action': 'store_true',\n",
        "    },\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ggvTYidO9ZQ"
      },
      "source": [
        "FLAGS = args_parse.parse_common_options(\n",
        "    datadir=UNLABELED,\n",
        "    batch_size=None,\n",
        "    num_epochs=None,\n",
        "    momentum=None,\n",
        "    lr=None,\n",
        "    target_accuracy=None,\n",
        "    profiler_port=9012,\n",
        "    opts=MODEL_OPTS.items(),\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CSubsgJShgy"
      },
      "source": [
        "FLAGS.fake_data = False\n",
        "FLAGS.num_epochs = 2\n",
        "FLAGS.batch_size = 32\n",
        "FLAGS.log_steps = 100\n",
        "FLAGS.num_cores = 8"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-Hm9PfGpVOVL",
        "outputId": "ba93304f-1d12-4f47-df53-1caef58232da"
      },
      "source": [
        "FLAGS.datadir"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sample@1000'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOH8ZjssOSd1"
      },
      "source": [
        "import os\n",
        "import schedulers\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch_xla\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.utils.utils as xu\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.test.test_utils as test_utils"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SX0pnOwOxBP"
      },
      "source": [
        "DEFAULT_KWARGS = dict(\n",
        "    batch_size=128,\n",
        "    test_set_batch_size=64,\n",
        "    num_epochs=18,\n",
        "    momentum=0.9,\n",
        "    lr=0.1,\n",
        "    target_accuracy=0.0,\n",
        ")\n",
        "MODEL_SPECIFIC_DEFAULTS = {\n",
        "    # Override some of the args in DEFAULT_KWARGS, or add them to the dict\n",
        "    # if they don't exist.\n",
        "    'resnet50':\n",
        "        dict(\n",
        "            DEFAULT_KWARGS, **{\n",
        "                'lr': 0.5,\n",
        "                'lr_scheduler_divide_every_n_epochs': 20,\n",
        "                'lr_scheduler_divisor': 5,\n",
        "                'lr_scheduler_type': 'WarmupAndExponentialDecayScheduler',\n",
        "            })\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nad72u1lOyyh"
      },
      "source": [
        "# Set any args that were not explicitly given by the user.\n",
        "default_value_dict = MODEL_SPECIFIC_DEFAULTS.get(FLAGS.model, DEFAULT_KWARGS)\n",
        "for arg, value in default_value_dict.items():\n",
        "  if getattr(FLAGS, arg) is None:\n",
        "    setattr(FLAGS, arg, value)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDkym-NUUocK",
        "outputId": "54db978c-8c89-4359-fb3b-b6c661709ecd"
      },
      "source": [
        "default_value_dict"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 128,\n",
              " 'lr': 0.5,\n",
              " 'lr_scheduler_divide_every_n_epochs': 20,\n",
              " 'lr_scheduler_divisor': 5,\n",
              " 'lr_scheduler_type': 'WarmupAndExponentialDecayScheduler',\n",
              " 'momentum': 0.9,\n",
              " 'num_epochs': 18,\n",
              " 'target_accuracy': 0.0,\n",
              " 'test_set_batch_size': 64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaSFCSsHeVxY"
      },
      "source": [
        "def get_model_property(key):\n",
        "  default_model_property = {\n",
        "      'img_dim': 224, # YO\n",
        "      'model_fn': getattr(torchvision.models, FLAGS.model)\n",
        "  }\n",
        "  model_properties = {\n",
        "      'inception_v3': {\n",
        "          'img_dim': 299,\n",
        "          'model_fn': lambda: torchvision.models.inception_v3(aux_logits=False)\n",
        "      },\n",
        "  }\n",
        "  model_fn = model_properties.get(FLAGS.model, default_model_property)[key]\n",
        "  return model_fn"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4xo5QNANY_Q"
      },
      "source": [
        "def _train_update(device, step, loss, tracker, epoch, writer):\n",
        "  test_utils.print_training_update(\n",
        "      device,\n",
        "      step,\n",
        "      loss.item(),\n",
        "      tracker.rate(),\n",
        "      tracker.global_rate(),\n",
        "      epoch,\n",
        "      summary_writer=writer)\n",
        "\n",
        "\n",
        "def train_imagenet():\n",
        "  print('==> Preparing data..')\n",
        "  img_dim = get_model_property('img_dim')\n",
        "  if FLAGS.fake_data:\n",
        "    train_dataset_len = 1200000  # Roughly the size of Imagenet dataset.\n",
        "    train_loader = xu.SampleGenerator(\n",
        "        data=(torch.zeros(FLAGS.batch_size, 3, img_dim, img_dim),\n",
        "              torch.zeros(FLAGS.batch_size, dtype=torch.int64)),\n",
        "        sample_count=train_dataset_len // FLAGS.batch_size //\n",
        "        xm.xrt_world_size())\n",
        "    test_loader = xu.SampleGenerator(\n",
        "        data=(torch.zeros(FLAGS.test_set_batch_size, 3, img_dim, img_dim),\n",
        "              torch.zeros(FLAGS.test_set_batch_size, dtype=torch.int64)),\n",
        "        sample_count=50000 // FLAGS.batch_size // xm.xrt_world_size())\n",
        "  else:\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    train_dataset = torchvision.datasets.ImageFolder(\n",
        "        os.path.join(FLAGS.datadir, 'train'),\n",
        "        transforms.Compose([\n",
        "            transforms.RandomResizedCrop(img_dim),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "    train_dataset_len = len(train_dataset.imgs)\n",
        "    resize_dim = max(img_dim, 256)\n",
        "    test_dataset = torchvision.datasets.ImageFolder(\n",
        "        os.path.join(FLAGS.datadir, 'train'),\n",
        "        # Matches Torchvision's eval transforms except Torchvision uses size\n",
        "        # 256 resize for all models both here and in the train loader. Their\n",
        "        # version crashes during training on 299x299 images, e.g. inception.\n",
        "        transforms.Compose([\n",
        "            transforms.Resize(resize_dim),\n",
        "            transforms.CenterCrop(img_dim),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "\n",
        "    train_sampler, test_sampler = None, None\n",
        "    if xm.xrt_world_size() > 1:\n",
        "      train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "          train_dataset,\n",
        "          num_replicas=xm.xrt_world_size(),\n",
        "          rank=xm.get_ordinal(),\n",
        "          shuffle=True)\n",
        "      test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "          test_dataset,\n",
        "          num_replicas=xm.xrt_world_size(),\n",
        "          rank=xm.get_ordinal(),\n",
        "          shuffle=False)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=FLAGS.batch_size,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=FLAGS.drop_last,\n",
        "        shuffle=False if train_sampler else True,\n",
        "        num_workers=FLAGS.num_workers)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=FLAGS.test_set_batch_size,\n",
        "        sampler=test_sampler,\n",
        "        drop_last=FLAGS.drop_last,\n",
        "        shuffle=False,\n",
        "        num_workers=FLAGS.num_workers)\n",
        "\n",
        "  torch.manual_seed(42)\n",
        "\n",
        "  device = xm.xla_device()\n",
        "  model = get_model_property('model_fn')().to(device)\n",
        "\n",
        "  model.fc = nn.Sequential(\n",
        "        nn.Linear(2048, 512),\n",
        "        nn.Linear(512, 1),\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  state_dict = xser.load('/content/drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR-70.pt')\n",
        "\n",
        "  for k in list(state_dict.keys()):\n",
        "\n",
        "    if k.startswith('backbone.'):\n",
        "      if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "        # remove prefix\n",
        "        state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "    del state_dict[k]\n",
        "\n",
        "  log = model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "  writer = None\n",
        "  if xm.is_master_ordinal():\n",
        "    writer = test_utils.get_summary_writer(FLAGS.logdir)\n",
        "  optimizer = optim.SGD(\n",
        "      model.parameters(),\n",
        "      lr=FLAGS.lr,\n",
        "      momentum=FLAGS.momentum,\n",
        "      weight_decay=1e-4)\n",
        "  num_training_steps_per_epoch = train_dataset_len // (\n",
        "      FLAGS.batch_size * xm.xrt_world_size())\n",
        "  lr_scheduler = schedulers.wrap_optimizer_with_scheduler(\n",
        "      optimizer,\n",
        "      scheduler_type=getattr(FLAGS, 'lr_scheduler_type', None),\n",
        "      scheduler_divisor=getattr(FLAGS, 'lr_scheduler_divisor', None),\n",
        "      scheduler_divide_every_n_epochs=getattr(\n",
        "          FLAGS, 'lr_scheduler_divide_every_n_epochs', None),\n",
        "      num_steps_per_epoch=num_training_steps_per_epoch,\n",
        "      summary_writer=writer)\n",
        "  \n",
        "\n",
        "  #loss_fn = nn.CrossEntropyLoss()\n",
        "  loss_fn = nn.BCELoss()\n",
        "\n",
        "  def train_loop_fn(loader, epoch):\n",
        "    tracker = xm.RateTracker()\n",
        "    model.train()\n",
        "    for step, (data, target) in enumerate(loader):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "\n",
        "      target = target.unsqueeze(1) ## YO\n",
        "      target = target.float() # YOO\n",
        "\n",
        "      loss = loss_fn(output, target)\n",
        "      loss.backward()\n",
        "      xm.optimizer_step(optimizer)\n",
        "      tracker.add(FLAGS.batch_size)\n",
        "      if lr_scheduler:\n",
        "        lr_scheduler.step()\n",
        "      if step % FLAGS.log_steps == 0:\n",
        "        xm.add_step_closure(\n",
        "            _train_update, args=(device, step, loss, tracker, epoch, writer))\n",
        "\n",
        "  def test_loop_fn(loader, epoch):\n",
        "    total_samples, correct = 0, 0\n",
        "    model.eval()\n",
        "    for step, (data, target) in enumerate(loader):\n",
        "      output = model(data)\n",
        "      pred = output.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as(pred)).sum()\n",
        "      total_samples += data.size()[0]\n",
        "      if step % FLAGS.log_steps == 0:\n",
        "        xm.add_step_closure(\n",
        "            test_utils.print_test_update, args=(device, None, epoch, step))\n",
        "    accuracy = 100.0 * correct.item() / total_samples\n",
        "    accuracy = xm.mesh_reduce('test_accuracy', accuracy, np.mean)\n",
        "    return accuracy\n",
        "\n",
        "  train_device_loader = pl.MpDeviceLoader(train_loader, device)\n",
        "  test_device_loader = pl.MpDeviceLoader(test_loader, device)\n",
        "  accuracy, max_accuracy = 0.0, 0.0\n",
        "  for epoch in range(1, FLAGS.num_epochs + 1):\n",
        "    xm.master_print('Epoch {} train begin {}'.format(epoch, test_utils.now()))\n",
        "    train_loop_fn(train_device_loader, epoch)\n",
        "    xm.master_print('Epoch {} train end {}'.format(epoch, test_utils.now()))\n",
        "    if not FLAGS.test_only_at_end or epoch == FLAGS.num_epochs:\n",
        "      accuracy = test_loop_fn(test_device_loader, epoch)\n",
        "      xm.master_print('Epoch {} test end {}, Accuracy={:.2f}'.format(\n",
        "          epoch, test_utils.now(), accuracy))\n",
        "      max_accuracy = max(accuracy, max_accuracy)\n",
        "      test_utils.write_to_summary(\n",
        "          writer,\n",
        "          epoch,\n",
        "          dict_to_write={'Accuracy/test': accuracy},\n",
        "          write_xla_metrics=True)\n",
        "    if FLAGS.metrics_debug:\n",
        "      xm.master_print(met.metrics_report())\n",
        "\n",
        "  test_utils.close_summary_writer(writer)\n",
        "  xm.master_print('Max Accuracy: {:.2f}%'.format(max_accuracy))\n",
        "  return max_accuracy"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww2PE7HZOsGH"
      },
      "source": [
        "def _mp_fn(index, flags):\n",
        "  global FLAGS\n",
        "  FLAGS = flags\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  accuracy = train_imagenet()\n",
        "  if accuracy < FLAGS.target_accuracy:\n",
        "    print('Accuracy {} is below target {}'.format(accuracy,\n",
        "                                                  FLAGS.target_accuracy))\n",
        "    sys.exit(21)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9h_SHYQUw82",
        "outputId": "4566e110-edf0-4b6d-cce5-c64a6f24fba9"
      },
      "source": [
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Epoch 1 train begin 00:45:29\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "| Training Device=xla:0/4 Epoch=1 Step=0 Loss=0.67525 Rate=23.47 GlobalRate=23.47 Time=00:45:53\n",
            "| Training Device=xla:0/5 Epoch=1 Step=0 Loss=0.68915 Rate=2.81 GlobalRate=2.81 Time=00:45:53\n",
            "| Training Device=xla:0/3 Epoch=1 Step=0 Loss=0.69202 Rate=4.71 GlobalRate=4.71 Time=00:45:53\n",
            "| Training Device=xla:0/6 Epoch=1 Step=0 Loss=0.67994 Rate=7.04 GlobalRate=7.04 Time=00:45:53\n",
            "| Training Device=xla:0/7 Epoch=1 Step=0 Loss=0.68424 Rate=10.18 GlobalRate=10.18 Time=00:45:53\n",
            "| Training Device=xla:0/2 Epoch=1 Step=0 Loss=0.68716 Rate=4.30 GlobalRate=4.30 Time=00:45:53\n",
            "| Training Device=xla:0/1 Epoch=1 Step=0 Loss=0.68334 Rate=5.88 GlobalRate=5.88 Time=00:45:53\n",
            "| Training Device=xla:1/0 Epoch=1 Step=0 Loss=0.68286 Rate=1.37 GlobalRate=1.37 Time=00:45:53\n",
            "Epoch 1 train end 00:45:53\n",
            "| Test Device=xla:0/7 Step=0 Epoch=1 Time=00:45:59\n",
            "| Test Device=xla:1/0 Step=0 Epoch=1 Time=00:45:59\n",
            "| Test Device=xla:0/4 Step=0 Epoch=1 Time=00:45:59\n",
            "| Test Device=xla:0/5 Step=0 Epoch=1 Time=00:45:59\n",
            "| Test Device=xla:0/3 Step=0 Epoch=1 Time=00:45:59\n",
            "| Test Device=xla:0/2 Step=0 Epoch=1 Time=00:45:59\n",
            "| Test Device=xla:0/6 Step=0 Epoch=1 Time=00:45:59\n",
            "| Test Device=xla:0/1 Step=0 Epoch=1 Time=00:46:00\n",
            "Epoch 1 test end 00:46:00, Accuracy=50.00\n",
            "Epoch 2 train begin 00:46:00\n",
            "| Training Device=xla:0/1 Epoch=2 Step=0 Loss=1.59217 Rate=4.76 GlobalRate=4.76 Time=00:46:06\n",
            "| Training Device=xla:1/0 Epoch=2 Step=0 Loss=1.25500 Rate=4.76 GlobalRate=4.76 Time=00:46:06\n",
            "| Training Device=xla:0/6 Epoch=2 Step=0 Loss=1.35608 Rate=4.76 GlobalRate=4.76 Time=00:46:06\n",
            "| Training Device=xla:0/7 Epoch=2 Step=0 Loss=1.90258 Rate=4.76 GlobalRate=4.76 Time=00:46:06\n",
            "| Training Device=xla:0/3 Epoch=2 Step=0 Loss=1.86184 Rate=4.76 GlobalRate=4.76 Time=00:46:07\n",
            "| Training Device=xla:0/5 Epoch=2 Step=0 Loss=1.58798 Rate=4.76 GlobalRate=4.76 Time=00:46:07\n",
            "| Training Device=xla:0/4 Epoch=2 Step=0 Loss=1.39224 Rate=4.76 GlobalRate=4.76 Time=00:46:07\n",
            "| Training Device=xla:0/2 Epoch=2 Step=0 Loss=1.39074 Rate=4.75 GlobalRate=4.75 Time=00:46:07\n",
            "Epoch 2 train end 00:46:07\n",
            "| Test Device=xla:1/0 Step=0 Epoch=2 Time=00:46:10\n",
            "| Test Device=xla:0/5 Step=0 Epoch=2 Time=00:46:12\n",
            "| Test Device=xla:0/3 Step=0 Epoch=2 Time=00:46:12\n",
            "| Test Device=xla:0/7 Step=0 Epoch=2 Time=00:46:12\n",
            "| Test Device=xla:0/2 Step=0 Epoch=2 Time=00:46:12\n",
            "| Test Device=xla:0/4 Step=0 Epoch=2 Time=00:46:13\n",
            "| Test Device=xla:0/6 Step=0 Epoch=2 Time=00:46:13\n",
            "| Test Device=xla:0/1 Step=0 Epoch=2 Time=00:46:13\n",
            "Epoch 2 test end 00:46:13, Accuracy=50.00\n",
            "Max Accuracy: 50.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKoSLwU5U25t"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}