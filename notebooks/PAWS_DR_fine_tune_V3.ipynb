{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PAWS_DR_fine_tune_V3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/PAWS_DR_fine_tune_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5hlD-M-AULJ",
        "outputId": "4a83aa7b-fa5c-40a7-92ec-b5ffe5657dc2"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install --quiet -v --no-cache-dir ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8054, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 8054 (delta 68), reused 97 (delta 44), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8054/8054), 14.11 MiB | 12.76 MiB/s, done.\n",
            "Resolving deltas: 100% (5469/5469), done.\n",
            "/content/apex\n",
            "Processing /content/apex\n",
            "Building wheels for collected packages: apex\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp37-none-any.whl size=204709 sha256=1ee40fb85ae858c35e75d575246664675a54d171969bd7f1dcfd945b5c6f91e8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ulwci7k1/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "Successfully installed apex-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCL0T19BAhwZ",
        "outputId": "26cbd1c9-a1e0-47c0-c57f-7993e8353737"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmQET3rEAknO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d522d1-9e61-4fb2-ad86-e8e022c1636e"
      },
      "source": [
        "!pip install --quiet -U PyYAML"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 18.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 11.5MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 593kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 4.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxKLx9eqAndQ",
        "outputId": "17067e18-4927-4e79-93ec-5f4657d66d86"
      },
      "source": [
        "!git clone -b feature/DR-images-v2 https://github.com/jmarrietar/suncet.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'suncet'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Counting objects: 100% (336/336), done.\u001b[K\n",
            "remote: Compressing objects: 100% (214/214), done.\u001b[K\n",
            "remote: Total 336 (delta 199), reused 250 (delta 119), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (336/336), 1.11 MiB | 5.47 MiB/s, done.\n",
            "Resolving deltas: 100% (199/199), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c0W3iBTApIP",
        "outputId": "bc1d0ede-62bf-4e67-877a-fc10c2b8ec00"
      },
      "source": [
        "cd suncet"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U4gvRnhMAqWJ",
        "outputId": "23a60a2c-f82e-4f05-fe11-29abfde13384"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/suncet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4On1j-ZxAr2v"
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Check whether the file is already in the desired path or if it needs to be downloaded\n",
        "# File downloaded from source : https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\n",
        "\n",
        "base_path = '/content/suncet/datasets/dr/'\n",
        "file_path = 'sample@1000.zip'\n",
        "\n",
        "if not os.path.isfile(base_path + file_path):\n",
        "    subprocess.run(['mkdir', '-p', base_path])\n",
        "    subprocess.run(['mkdir', '-p', 'logs'])\n",
        "    subprocess.call(['python', 'download.py', '-d', file_path.split('.')[0]])\n",
        "else:\n",
        "    print('File already downloaded!')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "Dl4xMk5J2Cgz",
        "outputId": "0715f6ea-00c2-4850-b687-4623e8136008"
      },
      "source": [
        "import gdown\n",
        "\n",
        "output = \"logs/paws-ep30.pth.tar\" # CHANGE NAME\n",
        "model_url = \"https://drive.google.com/uc?id=1S0tpW0HDOzCkkwToWKfmPuAPASeCaMV3\" # CHANGE URL\n",
        "\n",
        "gdown.download(model_url, output, quiet=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S0tpW0HDOzCkkwToWKfmPuAPASeCaMV3\n",
            "To: /content/suncet/logs/paws-ep30.pth.tar\n",
            "306MB [00:04, 71.7MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'logs/paws-ep30.pth.tar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln-Ge4v-A_yP"
      },
      "source": [
        "`main.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZjEepEFBCQF",
        "outputId": "a5446f71-aa7a-4091-f7fe-1cf4febd02a4"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import argparse\n",
        "\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "import pprint\n",
        "import yaml\n",
        "\n",
        "from src.paws_train import main as paws\n",
        "from src.suncet_train import main as suncet\n",
        "from src.fine_tune import main as fine_tune\n",
        "from src.snn_fine_tune import main as snn_fine_tune\n",
        "\n",
        "from src.utils import init_distributed\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    \"--fname\", type=str, help=\"name of config file to load\", default=\"configs.yaml\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--devices\",\n",
        "    type=str,\n",
        "    nargs=\"+\",\n",
        "    default=[\"cuda:0\"],\n",
        "    help=\"which devices to use on local machine\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--sel\",\n",
        "    type=str,\n",
        "    help=\"which script to run\",\n",
        "    choices=[\"paws_train\", \"suncet_train\", \"fine_tune\", \"snn_fine_tune\"],\n",
        ")\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--sel'], dest='sel', nargs=None, const=None, default=None, type=<class 'str'>, choices=['paws_train', 'suncet_train', 'fine_tune', 'snn_fine_tune'], help='which script to run', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS_6NXCIBFzI"
      },
      "source": [
        "args = parser.parse_args(['--sel', 'fine_tune',\n",
        "                          '--fname', 'configs/paws/dr_fine_tune.yaml'\n",
        "])"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0G_CvPcBrD9"
      },
      "source": [
        "fname = args.fname\n",
        "sel = args.sel"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YHQTaIUBrGw",
        "outputId": "6107bc49-9c0b-4d6a-cd4d-a2b050054878"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "\n",
        "logger.info(f'called-params {sel} {fname}')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:called-params fine_tune configs/paws/dr_fine_tune.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guYIscowBrJs"
      },
      "source": [
        "rank = 0"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyCicIMIBrMx",
        "outputId": "615b0c0c-d5c9-4eaa-ceb2-ab422fb9189f"
      },
      "source": [
        "# -- load script params\n",
        "params = None\n",
        "with open(fname, 'r') as y_file:\n",
        "    params = yaml.load(y_file, Loader=yaml.FullLoader)\n",
        "    logger.info('loaded params...')\n",
        "    if rank == 0:\n",
        "        pp = pprint.PrettyPrinter(indent=4)\n",
        "        pp.pprint(params)\n",
        "\n",
        "if rank == 0:\n",
        "    dump = os.path.join(params['logging']['folder'], f'params-{sel}.yaml')\n",
        "    with open(dump, 'w') as f:\n",
        "        yaml.dump(params, f)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:loaded params...\n",
            "{   'data': {   'data_seed': 152,\n",
            "                'dataset': 'dr_fine_tune',\n",
            "                'image_folder': 'dr/sample@1000/',\n",
            "                'normalize': True,\n",
            "                'num_classes': 2,\n",
            "                'root_path': 'datasets/',\n",
            "                'subset_path': 'dr_subsets/',\n",
            "                'unlabeled_frac': 0.9},\n",
            "    'logging': {   'folder': 'logs/',\n",
            "                   'pretrain_path': 'paws-ep30.pth.tar',\n",
            "                   'write_tag': 'paws-latest-SNN'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'master_port': 4029,\n",
            "                'model_name': 'resnet50',\n",
            "                'training': True,\n",
            "                'use_fp16': True},\n",
            "    'optimization': {   'epochs': 50,\n",
            "                        'lr': 1e-05,\n",
            "                        'use_lars': False,\n",
            "                        'weight_decay': 0.0,\n",
            "                        'zero_init': True}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBZ_cA-KBrO3"
      },
      "source": [
        "args = params"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqU77odjG_82",
        "outputId": "4bbc9ba9-4ebe-4fbb-b715-2e3dea88ca5c"
      },
      "source": [
        "args"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': {'data_seed': 152,\n",
              "  'dataset': 'dr_fine_tune',\n",
              "  'image_folder': 'dr/sample@1000/',\n",
              "  'normalize': True,\n",
              "  'num_classes': 2,\n",
              "  'root_path': 'datasets/',\n",
              "  'subset_path': 'dr_subsets/',\n",
              "  'unlabeled_frac': 0.9},\n",
              " 'logging': {'folder': 'logs/',\n",
              "  'pretrain_path': 'paws-ep30.pth.tar',\n",
              "  'write_tag': 'paws-latest-SNN'},\n",
              " 'meta': {'copy_data': True,\n",
              "  'device': 'cuda:0',\n",
              "  'load_checkpoint': False,\n",
              "  'master_port': 4029,\n",
              "  'model_name': 'resnet50',\n",
              "  'training': True,\n",
              "  'use_fp16': True},\n",
              " 'optimization': {'epochs': 50,\n",
              "  'lr': 1e-05,\n",
              "  'use_lars': False,\n",
              "  'weight_decay': 0.0,\n",
              "  'zero_init': True}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91a9EGKyBzEG"
      },
      "source": [
        "# FINE TUNE TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mQKJg0ABrSi"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import os\n",
        "\n",
        "# -- FOR DISTRIBUTED TRAINING ENSURE ONLY 1 DEVICE VISIBLE PER PROCESS\n",
        "try:\n",
        "    # -- WARNING: IF DOING DISTRIBUTED TRAINING ON A NON-SLURM CLUSTER, MAKE\n",
        "    # --          SURE TO UPDATE THIS TO GET LOCAL-RANK ON NODE, OR ENSURE\n",
        "    # --          THAT YOUR JOBS ARE LAUNCHED WITH ONLY 1 DEVICE VISIBLE\n",
        "    # --          TO EACH PROCESS\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['SLURM_LOCALID']\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "import copy\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule\n",
        ")\n",
        "from src.data_manager import (\n",
        "    init_data,\n",
        "    make_transforms\n",
        ")\n",
        "from src.sgd import SGD\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "from src.lars import LARS\n",
        "\n",
        "# --\n",
        "log_timings = True\n",
        "log_freq = 10\n",
        "checkpoint_freq = 50\n",
        "# --\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "np.random.seed(_GLOBAL_SEED)\n",
        "torch.manual_seed(_GLOBAL_SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logger = logging.getLogger()"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh8OlmleBrXj"
      },
      "source": [
        "def load_pretrained(\n",
        "    r_path,\n",
        "    encoder,\n",
        "    device_str\n",
        "):\n",
        "    checkpoint = torch.load(r_path, map_location='cpu')\n",
        "    pretrained_dict = {k.replace('module.', ''): v for k, v in checkpoint['encoder'].items()}\n",
        "    for k, v in encoder.state_dict().items():\n",
        "        if k not in pretrained_dict:\n",
        "            logger.info(f'key \"{k}\" could not be found in loaded state dict')\n",
        "        elif pretrained_dict[k].shape != v.shape:\n",
        "            logger.info(f'key \"{k}\" is of different shape in model and loaded state dict')\n",
        "            pretrained_dict[k] = v\n",
        "    msg = encoder.load_state_dict(pretrained_dict, strict=False)\n",
        "    logger.info(f'loaded pretrained model with msg: {msg}')\n",
        "    logger.info(f'loaded pretrained encoder from epoch: {checkpoint[\"epoch\"]} '\n",
        "                f'path: {r_path}')\n",
        "    del checkpoint\n",
        "    return encoder"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZkNsaIrBrbD"
      },
      "source": [
        "def load_from_path(\n",
        "    r_path,\n",
        "    encoder,\n",
        "    opt,\n",
        "    sched,\n",
        "    scaler,\n",
        "    device_str,\n",
        "    use_fp16=False\n",
        "):\n",
        "    encoder = load_pretrained(r_path, encoder, device_str)\n",
        "    checkpoint = torch.load(r_path, map_location=device_str)\n",
        "\n",
        "    best_acc = None\n",
        "    if 'best_top1_acc' in checkpoint:\n",
        "        best_acc = checkpoint['best_top1_acc']\n",
        "\n",
        "    epoch = checkpoint['epoch']\n",
        "    if opt is not None:\n",
        "        if use_fp16:\n",
        "            scaler.load_state_dict(checkpoint['amp'])\n",
        "        opt.load_state_dict(checkpoint['opt'])\n",
        "        sched.load_state_dict(checkpoint['sched'])\n",
        "        logger.info(f'loaded optimizers from epoch {epoch}')\n",
        "    logger.info(f'read-path: {r_path}')\n",
        "    del checkpoint\n",
        "    return encoder, opt, sched, epoch, best_acc"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfV-VdVHBrdQ"
      },
      "source": [
        "def init_model(\n",
        "    device,\n",
        "    device_str,\n",
        "    num_classes,\n",
        "    training,\n",
        "    use_fp16,\n",
        "    r_enc_path,\n",
        "    iterations_per_epoch,\n",
        "    world_size,\n",
        "    ref_lr,\n",
        "    num_epochs,\n",
        "    use_lars=False,\n",
        "    zero_init=True,\n",
        "    model_name='resnet50',\n",
        "    warmup_epochs=0,\n",
        "    weight_decay=0\n",
        "):\n",
        "    # -- init model\n",
        "    if 'wide_resnet' in model_name:\n",
        "        encoder = wide_resnet.__dict__[model_name](dropout_rate=0.0)\n",
        "        hidden_dim = 128\n",
        "    else:\n",
        "        encoder = resnet.__dict__[model_name]()\n",
        "        hidden_dim = 2048\n",
        "        if 'w2' in model_name:\n",
        "            hidden_dim *= 2\n",
        "        elif 'w4' in model_name:\n",
        "            hidden_dim *= 4\n",
        "\n",
        "    # -- projection head\n",
        "    encoder.fc = torch.nn.Sequential(OrderedDict([\n",
        "        ('fc1', torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "        ('bn1', torch.nn.BatchNorm1d(hidden_dim)),\n",
        "        ('relu1', torch.nn.ReLU(inplace=True)),\n",
        "        ('fc2', torch.nn.Linear(hidden_dim, 1)), # YO changed\n",
        "        ('sg', torch.nn.Sigmoid())  # YO \n",
        "    ]))\n",
        "\n",
        "    encoder.to(device)\n",
        "    encoder = load_pretrained(\n",
        "        r_path=r_enc_path,\n",
        "        encoder=encoder,\n",
        "        device_str=device_str)\n",
        "\n",
        "    if zero_init:\n",
        "        for p in encoder.fc.fc2.parameters():\n",
        "            torch.nn.init.zeros_(p)\n",
        "\n",
        "    # -- init optimizer\n",
        "    optimizer, scheduler = None, None\n",
        "    if training:\n",
        "        param_groups = [\n",
        "            {'params': (p for n, p in encoder.named_parameters()\n",
        "                        if ('bias' not in n) and ('bn' not in n))},\n",
        "            {'params': (p for n, p in encoder.named_parameters()\n",
        "                        if ('bias' in n) or ('bn' in n)),\n",
        "             'LARS_exclude': True,\n",
        "             'weight_decay': 0}\n",
        "        ]\n",
        "        optimizer = SGD(\n",
        "            param_groups,\n",
        "            nesterov=True,\n",
        "            weight_decay=weight_decay,\n",
        "            momentum=0.9,\n",
        "            lr=ref_lr)\n",
        "        scheduler = WarmupCosineSchedule(\n",
        "            optimizer,\n",
        "            warmup_steps=warmup_epochs*iterations_per_epoch,\n",
        "            start_lr=ref_lr,\n",
        "            ref_lr=ref_lr,\n",
        "            T_max=num_epochs*iterations_per_epoch)\n",
        "        if use_lars:\n",
        "            optimizer = LARS(optimizer, trust_coefficient=0.001)\n",
        "    if world_size > 1:\n",
        "        encoder = DistributedDataParallel(encoder, broadcast_buffers=False)\n",
        "\n",
        "    return encoder, optimizer, scheduler"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq3v7zFLBrgG"
      },
      "source": [
        "# -- META\n",
        "model_name = args['meta']['model_name']\n",
        "port = args['meta']['master_port']\n",
        "load_checkpoint = args['meta']['load_checkpoint']\n",
        "training = args['meta']['training']\n",
        "copy_data = args['meta']['copy_data']\n",
        "use_fp16 = args['meta']['use_fp16']\n",
        "device = torch.device(args['meta']['device'])\n",
        "torch.cuda.set_device(device)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os4hgZObBrrP"
      },
      "source": [
        "# -- DATA\n",
        "unlabeled_frac = args['data']['unlabeled_frac']\n",
        "normalize = args['data']['normalize']\n",
        "root_path = args['data']['root_path']\n",
        "image_folder = args['data']['image_folder']\n",
        "dataset_name = args['data']['dataset']\n",
        "subset_path = args['data']['subset_path']\n",
        "num_classes = args['data']['num_classes']\n",
        "data_seed = None\n",
        "if 'cifar10' in dataset_name:\n",
        "    data_seed = args['data']['data_seed']\n",
        "crop_scale = (0.5, 1.0) if 'cifar10' in dataset_name else (0.08, 1.0)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1zEZGGQBrw3"
      },
      "source": [
        "# -- OPTIMIZATION\n",
        "wd = float(args['optimization']['weight_decay'])\n",
        "ref_lr = args['optimization']['lr']\n",
        "use_lars = args['optimization']['use_lars']\n",
        "zero_init = args['optimization']['zero_init']\n",
        "num_epochs = args['optimization']['epochs']"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT9t_7siDEiA"
      },
      "source": [
        "# -- LOGGING\n",
        "folder = args['logging']['folder']\n",
        "tag = args['logging']['write_tag']\n",
        "r_file_enc = args['logging']['pretrain_path']"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12zIU-oxDEqO"
      },
      "source": [
        "# -- log/checkpointing paths\n",
        "r_enc_path = os.path.join(folder, r_file_enc)\n",
        "w_enc_path = os.path.join(folder, f'{tag}-fine-tune.pth.tar')"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQX97cCGDEtl",
        "outputId": "e005ead9-a13a-486a-ec49-1ce164c79bee"
      },
      "source": [
        "# -- init distributed\n",
        "world_size, rank = init_distributed(port)\n",
        "logger.info(f'initialized rank/world-size: {rank}/{world_size}')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:distributed training not available\n",
            "INFO:root:initialized rank/world-size: 0/1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgKbHSR2DEwa"
      },
      "source": [
        "# -- optimization/evaluation params\n",
        "if training:\n",
        "    batch_size = 32\n",
        "else:\n",
        "    batch_size = 16\n",
        "    unlabeled_frac = 0.0\n",
        "    load_checkpoint = True\n",
        "    num_epochs = 1"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRpDSN1zDEz8"
      },
      "source": [
        "# -- init loss\n",
        "#criterion = torch.nn.CrossEntropyLoss() \n",
        "criterion = torch.nn.BCELoss() # YO CHANGED HERE\n",
        "#criterion = torch.nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROxh1sWHDE3L",
        "outputId": "3405f01c-e54a-4956-bdad-6cea67e8ae61"
      },
      "source": [
        "# -- make train data transforms and data loaders/samples\n",
        "transform, init_transform = make_transforms(\n",
        "    dataset_name=dataset_name,\n",
        "    subset_path=subset_path,\n",
        "    unlabeled_frac=unlabeled_frac,\n",
        "    training=training,\n",
        "    crop_scale=crop_scale,\n",
        "    split_seed=data_seed,\n",
        "    basic_augmentations=True,\n",
        "    normalize=normalize)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:making imagenet data transforms\n",
            "INFO:root:keep file: dr_subsets/90percent.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WZOnPx7DE-P",
        "outputId": "a1098a0c-01fc-4a29-d0d4-50c31efee82a"
      },
      "source": [
        "(data_loader,\n",
        "    dist_sampler) = init_data(\n",
        "        dataset_name=dataset_name,\n",
        "        transform=transform,\n",
        "        init_transform=init_transform,\n",
        "        u_batch_size=None,\n",
        "        s_batch_size=batch_size,\n",
        "        classes_per_batch=2,\n",
        "        world_size=world_size,\n",
        "        rank=rank,\n",
        "        root_path=root_path,\n",
        "        image_folder=image_folder,\n",
        "        training=training,\n",
        "        copy_data=copy_data)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:copying data locally\n",
            "INFO:root:No job-id, will load directly from network file\n",
            "INFO:root:data-path datasets/dr/sample@1000/train/\n",
            "INFO:root:Initialized ImageDR\n",
            "INFO:root:ImageNet fine-tune dataset created\n",
            "self.multicrop_transform (0, None)\n",
            "INFO:root:flipping coin to keep labels\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1ZaEXJ0DFCc",
        "outputId": "99502d72-f4a7-4232-cc99-9a336d117195"
      },
      "source": [
        "ipe = len(data_loader)\n",
        "logger.info(f'initialized data-loader (ipe {ipe})')"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:initialized data-loader (ipe 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr3kuterDFL7",
        "outputId": "eb0d6d90-5509-4eac-b2f1-b31adca21294"
      },
      "source": [
        "# -- init model and optimizer\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "encoder, optimizer, scheduler = init_model(\n",
        "    device=device,\n",
        "    device_str=args['meta']['device'],\n",
        "    num_classes=num_classes,\n",
        "    training=training,\n",
        "    use_fp16=use_fp16,\n",
        "    r_enc_path=r_enc_path,\n",
        "    iterations_per_epoch=ipe,\n",
        "    world_size=world_size,\n",
        "    ref_lr=ref_lr,\n",
        "    weight_decay=wd,\n",
        "    use_lars=use_lars,\n",
        "    zero_init=zero_init,\n",
        "    num_epochs=num_epochs,\n",
        "    model_name=model_name)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:key \"fc.fc2.weight\" is of different shape in model and loaded state dict\n",
            "INFO:root:key \"fc.fc2.bias\" is of different shape in model and loaded state dict\n",
            "INFO:root:loaded pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['pred.bn1.weight', 'pred.bn1.bias', 'pred.bn1.running_mean', 'pred.bn1.running_var', 'pred.bn1.num_batches_tracked', 'pred.fc1.weight', 'pred.fc1.bias', 'pred.bn2.weight', 'pred.bn2.bias', 'pred.bn2.running_mean', 'pred.bn2.running_var', 'pred.bn2.num_batches_tracked', 'pred.fc2.weight', 'pred.fc2.bias', 'fc.bn2.weight', 'fc.bn2.bias', 'fc.bn2.running_mean', 'fc.bn2.running_var', 'fc.bn2.num_batches_tracked', 'fc.fc3.weight', 'fc.fc3.bias'])\n",
            "INFO:root:loaded pretrained encoder from epoch: 30 path: logs/paws-ep30.pth.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO78XesVOKdA",
        "outputId": "c32c8358-e2f8-4cd0-9514-84f29f8e058a"
      },
      "source": [
        "encoder"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "    (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (fc2): Linear(in_features=2048, out_features=1, bias=True)\n",
              "    (sg): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG0qD6-iDFTW"
      },
      "source": [
        "best_acc = None\n",
        "start_epoch = 0\n",
        "# -- load checkpoint\n",
        "if not training or load_checkpoint:\n",
        "    encoder, optimizer, scheduler, start_epoch, best_acc = load_from_path(\n",
        "        r_path=w_enc_path,\n",
        "        encoder=encoder,\n",
        "        opt=optimizer,\n",
        "        sched=scheduler,\n",
        "        scaler=scaler,\n",
        "        device_str=args['meta']['device'],\n",
        "        use_fp16=use_fp16)\n",
        "if not training:\n",
        "    logger.info('putting model in eval mode')\n",
        "    encoder.eval()\n",
        "    logger.info(sum(p.numel() for n, p in encoder.named_parameters()\n",
        "                    if p.requires_grad and ('fc' not in n)))\n",
        "    start_epoch = 0"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y4gAC5mOQ7s"
      },
      "source": [
        "num_epochs = 200 # CHANGE HERE"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYRdk6r0DFVk",
        "outputId": "171a5186-a223-475a-fbc3-5f032c848a74"
      },
      "source": [
        "for epoch in range(start_epoch, num_epochs):\n",
        "\n",
        "    def train_step():\n",
        "        # -- update distributed-data-loader epoch\n",
        "        top1_correct, total = 0, 0\n",
        "        for i, data in enumerate(data_loader):\n",
        "            with torch.cuda.amp.autocast(enabled=False): # Yo\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "                labels = labels.unsqueeze(1) ## YO\n",
        "                labels = labels.float() ## YO\n",
        "\n",
        "                outputs = encoder(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            total += inputs.shape[0]\n",
        "            top1_correct += float(sum(((outputs>0.5)*1 == labels)*1))\n",
        "            top1_acc = 100. * (top1_correct / total)\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            if i % log_freq == 0:\n",
        "                logger.info('[%d, %5d] %.3f%% (loss: %.3f)'\n",
        "                            % (epoch + 1, i, top1_acc, loss))\n",
        "        return 100. * (top1_correct / total)\n",
        "\n",
        "    train_top1 = 0.\n",
        "    train_top1 = train_step()\n",
        "\n",
        "    log_str = 'train:'\n",
        "    logger.info('[%d] (%s: %.3f%%) '\n",
        "                % (epoch + 1, log_str, train_top1))\n",
        "\n",
        "    # -- logging/checkpointing\n",
        "    if rank == 0:\n",
        "\n",
        "        save_dict = {\n",
        "            'encoder': encoder.state_dict(),\n",
        "            'opt': optimizer.state_dict(),\n",
        "            'sched': scheduler.state_dict(),\n",
        "            'epoch': epoch + 1,\n",
        "            'unlabel_prob': unlabeled_frac,\n",
        "            'world_size': world_size,\n",
        "            'batch_size': batch_size,\n",
        "            'lr': ref_lr,\n",
        "            'amp': scaler.state_dict()\n",
        "        }\n",
        "        torch.save(save_dict, w_enc_path)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:[1,     0] 50.000% (loss: 0.693)\n",
            "INFO:root:[1] (train:: 64.583%) \n",
            "INFO:root:[2,     0] 75.000% (loss: 0.693)\n",
            "INFO:root:[2] (train:: 75.000%) \n",
            "INFO:root:[3,     0] 68.750% (loss: 0.691)\n",
            "INFO:root:[3] (train:: 69.792%) \n",
            "INFO:root:[4,     0] 71.875% (loss: 0.690)\n",
            "INFO:root:[4] (train:: 69.792%) \n",
            "INFO:root:[5,     0] 68.750% (loss: 0.689)\n",
            "INFO:root:[5] (train:: 71.875%) \n",
            "INFO:root:[6,     0] 68.750% (loss: 0.687)\n",
            "INFO:root:[6] (train:: 66.667%) \n",
            "INFO:root:[7,     0] 71.875% (loss: 0.683)\n",
            "INFO:root:[7] (train:: 71.875%) \n",
            "INFO:root:[8,     0] 68.750% (loss: 0.683)\n",
            "INFO:root:[8] (train:: 70.833%) \n",
            "INFO:root:[9,     0] 71.875% (loss: 0.680)\n",
            "INFO:root:[9] (train:: 71.875%) \n",
            "INFO:root:[10,     0] 71.875% (loss: 0.676)\n",
            "INFO:root:[10] (train:: 72.917%) \n",
            "INFO:root:[11,     0] 71.875% (loss: 0.678)\n",
            "INFO:root:[11] (train:: 68.750%) \n",
            "INFO:root:[12,     0] 68.750% (loss: 0.676)\n",
            "INFO:root:[12] (train:: 71.875%) \n",
            "INFO:root:[13,     0] 75.000% (loss: 0.671)\n",
            "INFO:root:[13] (train:: 73.958%) \n",
            "INFO:root:[14,     0] 68.750% (loss: 0.669)\n",
            "INFO:root:[14] (train:: 68.750%) \n",
            "INFO:root:[15,     0] 68.750% (loss: 0.670)\n",
            "INFO:root:[15] (train:: 67.708%) \n",
            "INFO:root:[16,     0] 68.750% (loss: 0.670)\n",
            "INFO:root:[16] (train:: 69.792%) \n",
            "INFO:root:[17,     0] 71.875% (loss: 0.664)\n",
            "INFO:root:[17] (train:: 71.875%) \n",
            "INFO:root:[18,     0] 68.750% (loss: 0.666)\n",
            "INFO:root:[18] (train:: 71.875%) \n",
            "INFO:root:[19,     0] 68.750% (loss: 0.664)\n",
            "INFO:root:[19] (train:: 70.833%) \n",
            "INFO:root:[20,     0] 78.125% (loss: 0.663)\n",
            "INFO:root:[20] (train:: 73.958%) \n",
            "INFO:root:[21,     0] 71.875% (loss: 0.662)\n",
            "INFO:root:[21] (train:: 72.917%) \n",
            "INFO:root:[22,     0] 75.000% (loss: 0.656)\n",
            "INFO:root:[22] (train:: 76.042%) \n",
            "INFO:root:[23,     0] 71.875% (loss: 0.661)\n",
            "INFO:root:[23] (train:: 71.875%) \n",
            "INFO:root:[24,     0] 65.625% (loss: 0.653)\n",
            "INFO:root:[24] (train:: 67.708%) \n",
            "INFO:root:[25,     0] 75.000% (loss: 0.661)\n",
            "INFO:root:[25] (train:: 68.750%) \n",
            "INFO:root:[26,     0] 68.750% (loss: 0.653)\n",
            "INFO:root:[26] (train:: 69.792%) \n",
            "INFO:root:[27,     0] 68.750% (loss: 0.652)\n",
            "INFO:root:[27] (train:: 69.792%) \n",
            "INFO:root:[28,     0] 68.750% (loss: 0.652)\n",
            "INFO:root:[28] (train:: 71.875%) \n",
            "INFO:root:[29,     0] 68.750% (loss: 0.654)\n",
            "INFO:root:[29] (train:: 71.875%) \n",
            "INFO:root:[30,     0] 71.875% (loss: 0.647)\n",
            "INFO:root:[30] (train:: 73.958%) \n",
            "INFO:root:[31,     0] 68.750% (loss: 0.655)\n",
            "INFO:root:[31] (train:: 69.792%) \n",
            "INFO:root:[32,     0] 68.750% (loss: 0.650)\n",
            "INFO:root:[32] (train:: 73.958%) \n",
            "INFO:root:[33,     0] 68.750% (loss: 0.644)\n",
            "INFO:root:[33] (train:: 69.792%) \n",
            "INFO:root:[34,     0] 68.750% (loss: 0.648)\n",
            "INFO:root:[34] (train:: 71.875%) \n",
            "INFO:root:[35,     0] 68.750% (loss: 0.648)\n",
            "INFO:root:[35] (train:: 71.875%) \n",
            "INFO:root:[36,     0] 68.750% (loss: 0.650)\n",
            "INFO:root:[36] (train:: 67.708%) \n",
            "INFO:root:[37,     0] 71.875% (loss: 0.647)\n",
            "INFO:root:[37] (train:: 73.958%) \n",
            "INFO:root:[38,     0] 71.875% (loss: 0.653)\n",
            "INFO:root:[38] (train:: 70.833%) \n",
            "INFO:root:[39,     0] 71.875% (loss: 0.644)\n",
            "INFO:root:[39] (train:: 71.875%) \n",
            "INFO:root:[40,     0] 68.750% (loss: 0.644)\n",
            "INFO:root:[40] (train:: 70.833%) \n",
            "INFO:root:[41,     0] 68.750% (loss: 0.651)\n",
            "INFO:root:[41] (train:: 71.875%) \n",
            "INFO:root:[42,     0] 75.000% (loss: 0.641)\n",
            "INFO:root:[42] (train:: 73.958%) \n",
            "INFO:root:[43,     0] 71.875% (loss: 0.638)\n",
            "INFO:root:[43] (train:: 73.958%) \n",
            "INFO:root:[44,     0] 78.125% (loss: 0.637)\n",
            "INFO:root:[44] (train:: 77.083%) \n",
            "INFO:root:[45,     0] 75.000% (loss: 0.641)\n",
            "INFO:root:[45] (train:: 72.917%) \n",
            "INFO:root:[46,     0] 71.875% (loss: 0.646)\n",
            "INFO:root:[46] (train:: 68.750%) \n",
            "INFO:root:[47,     0] 75.000% (loss: 0.641)\n",
            "INFO:root:[47] (train:: 73.958%) \n",
            "INFO:root:[48,     0] 71.875% (loss: 0.641)\n",
            "INFO:root:[48] (train:: 70.833%) \n",
            "INFO:root:[49,     0] 68.750% (loss: 0.639)\n",
            "INFO:root:[49] (train:: 69.792%) \n",
            "INFO:root:[50,     0] 68.750% (loss: 0.648)\n",
            "INFO:root:[50] (train:: 72.917%) \n",
            "INFO:root:[51,     0] 68.750% (loss: 0.644)\n",
            "INFO:root:[51] (train:: 70.833%) \n",
            "INFO:root:[52,     0] 68.750% (loss: 0.654)\n",
            "INFO:root:[52] (train:: 70.833%) \n",
            "INFO:root:[53,     0] 71.875% (loss: 0.645)\n",
            "INFO:root:[53] (train:: 72.917%) \n",
            "INFO:root:[54,     0] 71.875% (loss: 0.641)\n",
            "INFO:root:[54] (train:: 72.917%) \n",
            "INFO:root:[55,     0] 75.000% (loss: 0.643)\n",
            "INFO:root:[55] (train:: 73.958%) \n",
            "INFO:root:[56,     0] 71.875% (loss: 0.644)\n",
            "INFO:root:[56] (train:: 69.792%) \n",
            "INFO:root:[57,     0] 75.000% (loss: 0.646)\n",
            "INFO:root:[57] (train:: 75.000%) \n",
            "INFO:root:[58,     0] 71.875% (loss: 0.654)\n",
            "INFO:root:[58] (train:: 72.917%) \n",
            "INFO:root:[59,     0] 71.875% (loss: 0.648)\n",
            "INFO:root:[59] (train:: 71.875%) \n",
            "INFO:root:[60,     0] 68.750% (loss: 0.654)\n",
            "INFO:root:[60] (train:: 71.875%) \n",
            "INFO:root:[61,     0] 75.000% (loss: 0.636)\n",
            "INFO:root:[61] (train:: 71.875%) \n",
            "INFO:root:[62,     0] 75.000% (loss: 0.647)\n",
            "INFO:root:[62] (train:: 71.875%) \n",
            "INFO:root:[63,     0] 75.000% (loss: 0.642)\n",
            "INFO:root:[63] (train:: 76.042%) \n",
            "INFO:root:[64,     0] 71.875% (loss: 0.642)\n",
            "INFO:root:[64] (train:: 75.000%) \n",
            "INFO:root:[65,     0] 68.750% (loss: 0.646)\n",
            "INFO:root:[65] (train:: 70.833%) \n",
            "INFO:root:[66,     0] 68.750% (loss: 0.647)\n",
            "INFO:root:[66] (train:: 72.917%) \n",
            "INFO:root:[67,     0] 71.875% (loss: 0.648)\n",
            "INFO:root:[67] (train:: 73.958%) \n",
            "INFO:root:[68,     0] 68.750% (loss: 0.646)\n",
            "INFO:root:[68] (train:: 75.000%) \n",
            "INFO:root:[69,     0] 71.875% (loss: 0.648)\n",
            "INFO:root:[69] (train:: 75.000%) \n",
            "INFO:root:[70,     0] 71.875% (loss: 0.644)\n",
            "INFO:root:[70] (train:: 70.833%) \n",
            "INFO:root:[71,     0] 71.875% (loss: 0.637)\n",
            "INFO:root:[71] (train:: 72.917%) \n",
            "INFO:root:[72,     0] 65.625% (loss: 0.649)\n",
            "INFO:root:[72] (train:: 73.958%) \n",
            "INFO:root:[73,     0] 71.875% (loss: 0.655)\n",
            "INFO:root:[73] (train:: 73.958%) \n",
            "INFO:root:[74,     0] 68.750% (loss: 0.649)\n",
            "INFO:root:[74] (train:: 70.833%) \n",
            "INFO:root:[75,     0] 75.000% (loss: 0.637)\n",
            "INFO:root:[75] (train:: 69.792%) \n",
            "INFO:root:[76,     0] 75.000% (loss: 0.641)\n",
            "INFO:root:[76] (train:: 75.000%) \n",
            "INFO:root:[77,     0] 71.875% (loss: 0.649)\n",
            "INFO:root:[77] (train:: 70.833%) \n",
            "INFO:root:[78,     0] 71.875% (loss: 0.635)\n",
            "INFO:root:[78] (train:: 71.875%) \n",
            "INFO:root:[79,     0] 71.875% (loss: 0.635)\n",
            "INFO:root:[79] (train:: 75.000%) \n",
            "INFO:root:[80,     0] 71.875% (loss: 0.631)\n",
            "INFO:root:[80] (train:: 70.833%) \n",
            "INFO:root:[81,     0] 75.000% (loss: 0.638)\n",
            "INFO:root:[81] (train:: 77.083%) \n",
            "INFO:root:[82,     0] 75.000% (loss: 0.639)\n",
            "INFO:root:[82] (train:: 73.958%) \n",
            "INFO:root:[83,     0] 71.875% (loss: 0.636)\n",
            "INFO:root:[83] (train:: 72.917%) \n",
            "INFO:root:[84,     0] 78.125% (loss: 0.622)\n",
            "INFO:root:[84] (train:: 75.000%) \n",
            "INFO:root:[85,     0] 75.000% (loss: 0.633)\n",
            "INFO:root:[85] (train:: 72.917%) \n",
            "INFO:root:[86,     0] 71.875% (loss: 0.645)\n",
            "INFO:root:[86] (train:: 71.875%) \n",
            "INFO:root:[87,     0] 65.625% (loss: 0.637)\n",
            "INFO:root:[87] (train:: 67.708%) \n",
            "INFO:root:[88,     0] 71.875% (loss: 0.638)\n",
            "INFO:root:[88] (train:: 73.958%) \n",
            "INFO:root:[89,     0] 71.875% (loss: 0.625)\n",
            "INFO:root:[89] (train:: 72.917%) \n",
            "INFO:root:[90,     0] 71.875% (loss: 0.638)\n",
            "INFO:root:[90] (train:: 73.958%) \n",
            "INFO:root:[91,     0] 71.875% (loss: 0.622)\n",
            "INFO:root:[91] (train:: 71.875%) \n",
            "INFO:root:[92,     0] 71.875% (loss: 0.619)\n",
            "INFO:root:[92] (train:: 72.917%) \n",
            "INFO:root:[93,     0] 75.000% (loss: 0.635)\n",
            "INFO:root:[93] (train:: 72.917%) \n",
            "INFO:root:[94,     0] 75.000% (loss: 0.625)\n",
            "INFO:root:[94] (train:: 70.833%) \n",
            "INFO:root:[95,     0] 71.875% (loss: 0.633)\n",
            "INFO:root:[95] (train:: 75.000%) \n",
            "INFO:root:[96,     0] 75.000% (loss: 0.614)\n",
            "INFO:root:[96] (train:: 73.958%) \n",
            "INFO:root:[97,     0] 71.875% (loss: 0.618)\n",
            "INFO:root:[97] (train:: 72.917%) \n",
            "INFO:root:[98,     0] 75.000% (loss: 0.606)\n",
            "INFO:root:[98] (train:: 76.042%) \n",
            "INFO:root:[99,     0] 71.875% (loss: 0.620)\n",
            "INFO:root:[99] (train:: 70.833%) \n",
            "INFO:root:[100,     0] 68.750% (loss: 0.622)\n",
            "INFO:root:[100] (train:: 73.958%) \n",
            "INFO:root:[101,     0] 71.875% (loss: 0.606)\n",
            "INFO:root:[101] (train:: 72.917%) \n",
            "INFO:root:[102,     0] 75.000% (loss: 0.623)\n",
            "INFO:root:[102] (train:: 73.958%) \n",
            "INFO:root:[103,     0] 71.875% (loss: 0.614)\n",
            "INFO:root:[103] (train:: 71.875%) \n",
            "INFO:root:[104,     0] 75.000% (loss: 0.612)\n",
            "INFO:root:[104] (train:: 76.042%) \n",
            "INFO:root:[105,     0] 75.000% (loss: 0.592)\n",
            "INFO:root:[105] (train:: 73.958%) \n",
            "INFO:root:[106,     0] 75.000% (loss: 0.589)\n",
            "INFO:root:[106] (train:: 71.875%) \n",
            "INFO:root:[107,     0] 71.875% (loss: 0.625)\n",
            "INFO:root:[107] (train:: 76.042%) \n",
            "INFO:root:[108,     0] 71.875% (loss: 0.598)\n",
            "INFO:root:[108] (train:: 70.833%) \n",
            "INFO:root:[109,     0] 75.000% (loss: 0.596)\n",
            "INFO:root:[109] (train:: 76.042%) \n",
            "INFO:root:[110,     0] 68.750% (loss: 0.591)\n",
            "INFO:root:[110] (train:: 69.792%) \n",
            "INFO:root:[111,     0] 75.000% (loss: 0.611)\n",
            "INFO:root:[111] (train:: 69.792%) \n",
            "INFO:root:[112,     0] 75.000% (loss: 0.609)\n",
            "INFO:root:[112] (train:: 73.958%) \n",
            "INFO:root:[113,     0] 75.000% (loss: 0.600)\n",
            "INFO:root:[113] (train:: 75.000%) \n",
            "INFO:root:[114,     0] 75.000% (loss: 0.608)\n",
            "INFO:root:[114] (train:: 71.875%) \n",
            "INFO:root:[115,     0] 78.125% (loss: 0.595)\n",
            "INFO:root:[115] (train:: 75.000%) \n",
            "INFO:root:[116,     0] 78.125% (loss: 0.596)\n",
            "INFO:root:[116] (train:: 75.000%) \n",
            "INFO:root:[117,     0] 75.000% (loss: 0.576)\n",
            "INFO:root:[117] (train:: 76.042%) \n",
            "INFO:root:[118,     0] 78.125% (loss: 0.588)\n",
            "INFO:root:[118] (train:: 76.042%) \n",
            "INFO:root:[119,     0] 75.000% (loss: 0.611)\n",
            "INFO:root:[119] (train:: 76.042%) \n",
            "INFO:root:[120,     0] 78.125% (loss: 0.595)\n",
            "INFO:root:[120] (train:: 77.083%) \n",
            "INFO:root:[121,     0] 71.875% (loss: 0.573)\n",
            "INFO:root:[121] (train:: 71.875%) \n",
            "INFO:root:[122,     0] 78.125% (loss: 0.580)\n",
            "INFO:root:[122] (train:: 75.000%) \n",
            "INFO:root:[123,     0] 68.750% (loss: 0.592)\n",
            "INFO:root:[123] (train:: 73.958%) \n",
            "INFO:root:[124,     0] 78.125% (loss: 0.571)\n",
            "INFO:root:[124] (train:: 75.000%) \n",
            "INFO:root:[125,     0] 71.875% (loss: 0.609)\n",
            "INFO:root:[125] (train:: 71.875%) \n",
            "INFO:root:[126,     0] 78.125% (loss: 0.580)\n",
            "INFO:root:[126] (train:: 78.125%) \n",
            "INFO:root:[127,     0] 68.750% (loss: 0.625)\n",
            "INFO:root:[127] (train:: 71.875%) \n",
            "INFO:root:[128,     0] 75.000% (loss: 0.590)\n",
            "INFO:root:[128] (train:: 72.917%) \n",
            "INFO:root:[129,     0] 68.750% (loss: 0.605)\n",
            "INFO:root:[129] (train:: 72.917%) \n",
            "INFO:root:[130,     0] 71.875% (loss: 0.588)\n",
            "INFO:root:[130] (train:: 73.958%) \n",
            "INFO:root:[131,     0] 68.750% (loss: 0.587)\n",
            "INFO:root:[131] (train:: 69.792%) \n",
            "INFO:root:[132,     0] 75.000% (loss: 0.565)\n",
            "INFO:root:[132] (train:: 77.083%) \n",
            "INFO:root:[133,     0] 75.000% (loss: 0.580)\n",
            "INFO:root:[133] (train:: 76.042%) \n",
            "INFO:root:[134,     0] 75.000% (loss: 0.577)\n",
            "INFO:root:[134] (train:: 77.083%) \n",
            "INFO:root:[135,     0] 71.875% (loss: 0.598)\n",
            "INFO:root:[135] (train:: 72.917%) \n",
            "INFO:root:[136,     0] 75.000% (loss: 0.572)\n",
            "INFO:root:[136] (train:: 77.083%) \n",
            "INFO:root:[137,     0] 78.125% (loss: 0.596)\n",
            "INFO:root:[137] (train:: 76.042%) \n",
            "INFO:root:[138,     0] 81.250% (loss: 0.572)\n",
            "INFO:root:[138] (train:: 78.125%) \n",
            "INFO:root:[139,     0] 78.125% (loss: 0.585)\n",
            "INFO:root:[139] (train:: 75.000%) \n",
            "INFO:root:[140,     0] 75.000% (loss: 0.603)\n",
            "INFO:root:[140] (train:: 76.042%) \n",
            "INFO:root:[141,     0] 75.000% (loss: 0.573)\n",
            "INFO:root:[141] (train:: 71.875%) \n",
            "INFO:root:[142,     0] 71.875% (loss: 0.603)\n",
            "INFO:root:[142] (train:: 73.958%) \n",
            "INFO:root:[143,     0] 68.750% (loss: 0.592)\n",
            "INFO:root:[143] (train:: 77.083%) \n",
            "INFO:root:[144,     0] 71.875% (loss: 0.573)\n",
            "INFO:root:[144] (train:: 76.042%) \n",
            "INFO:root:[145,     0] 68.750% (loss: 0.602)\n",
            "INFO:root:[145] (train:: 71.875%) \n",
            "INFO:root:[146,     0] 75.000% (loss: 0.584)\n",
            "INFO:root:[146] (train:: 78.125%) \n",
            "INFO:root:[147,     0] 78.125% (loss: 0.585)\n",
            "INFO:root:[147] (train:: 72.917%) \n",
            "INFO:root:[148,     0] 71.875% (loss: 0.593)\n",
            "INFO:root:[148] (train:: 72.917%) \n",
            "INFO:root:[149,     0] 78.125% (loss: 0.577)\n",
            "INFO:root:[149] (train:: 76.042%) \n",
            "INFO:root:[150,     0] 71.875% (loss: 0.586)\n",
            "INFO:root:[150] (train:: 71.875%) \n",
            "INFO:root:[151,     0] 75.000% (loss: 0.583)\n",
            "INFO:root:[151] (train:: 75.000%) \n",
            "INFO:root:[152,     0] 78.125% (loss: 0.563)\n",
            "INFO:root:[152] (train:: 80.208%) \n",
            "INFO:root:[153,     0] 78.125% (loss: 0.576)\n",
            "INFO:root:[153] (train:: 76.042%) \n",
            "INFO:root:[154,     0] 75.000% (loss: 0.597)\n",
            "INFO:root:[154] (train:: 72.917%) \n",
            "INFO:root:[155,     0] 78.125% (loss: 0.582)\n",
            "INFO:root:[155] (train:: 76.042%) \n",
            "INFO:root:[156,     0] 75.000% (loss: 0.580)\n",
            "INFO:root:[156] (train:: 75.000%) \n",
            "INFO:root:[157,     0] 71.875% (loss: 0.588)\n",
            "INFO:root:[157] (train:: 72.917%) \n",
            "INFO:root:[158,     0] 78.125% (loss: 0.575)\n",
            "INFO:root:[158] (train:: 76.042%) \n",
            "INFO:root:[159,     0] 75.000% (loss: 0.586)\n",
            "INFO:root:[159] (train:: 76.042%) \n",
            "INFO:root:[160,     0] 71.875% (loss: 0.587)\n",
            "INFO:root:[160] (train:: 73.958%) \n",
            "INFO:root:[161,     0] 68.750% (loss: 0.591)\n",
            "INFO:root:[161] (train:: 70.833%) \n",
            "INFO:root:[162,     0] 75.000% (loss: 0.598)\n",
            "INFO:root:[162] (train:: 76.042%) \n",
            "INFO:root:[163,     0] 75.000% (loss: 0.577)\n",
            "INFO:root:[163] (train:: 73.958%) \n",
            "INFO:root:[164,     0] 78.125% (loss: 0.573)\n",
            "INFO:root:[164] (train:: 78.125%) \n",
            "INFO:root:[165,     0] 71.875% (loss: 0.573)\n",
            "INFO:root:[165] (train:: 73.958%) \n",
            "INFO:root:[166,     0] 75.000% (loss: 0.578)\n",
            "INFO:root:[166] (train:: 76.042%) \n",
            "INFO:root:[167,     0] 71.875% (loss: 0.590)\n",
            "INFO:root:[167] (train:: 75.000%) \n",
            "INFO:root:[168,     0] 78.125% (loss: 0.571)\n",
            "INFO:root:[168] (train:: 71.875%) \n",
            "INFO:root:[169,     0] 71.875% (loss: 0.584)\n",
            "INFO:root:[169] (train:: 71.875%) \n",
            "INFO:root:[170,     0] 71.875% (loss: 0.583)\n",
            "INFO:root:[170] (train:: 76.042%) \n",
            "INFO:root:[171,     0] 75.000% (loss: 0.587)\n",
            "INFO:root:[171] (train:: 77.083%) \n",
            "INFO:root:[172,     0] 75.000% (loss: 0.565)\n",
            "INFO:root:[172] (train:: 79.167%) \n",
            "INFO:root:[173,     0] 75.000% (loss: 0.585)\n",
            "INFO:root:[173] (train:: 77.083%) \n",
            "INFO:root:[174,     0] 78.125% (loss: 0.581)\n",
            "INFO:root:[174] (train:: 77.083%) \n",
            "INFO:root:[175,     0] 71.875% (loss: 0.569)\n",
            "INFO:root:[175] (train:: 67.708%) \n",
            "INFO:root:[176,     0] 75.000% (loss: 0.590)\n",
            "INFO:root:[176] (train:: 73.958%) \n",
            "INFO:root:[177,     0] 71.875% (loss: 0.579)\n",
            "INFO:root:[177] (train:: 72.917%) \n",
            "INFO:root:[178,     0] 75.000% (loss: 0.572)\n",
            "INFO:root:[178] (train:: 76.042%) \n",
            "INFO:root:[179,     0] 78.125% (loss: 0.564)\n",
            "INFO:root:[179] (train:: 77.083%) \n",
            "INFO:root:[180,     0] 68.750% (loss: 0.611)\n",
            "INFO:root:[180] (train:: 72.917%) \n",
            "INFO:root:[181,     0] 75.000% (loss: 0.560)\n",
            "INFO:root:[181] (train:: 71.875%) \n",
            "INFO:root:[182,     0] 78.125% (loss: 0.571)\n",
            "INFO:root:[182] (train:: 72.917%) \n",
            "INFO:root:[183,     0] 78.125% (loss: 0.565)\n",
            "INFO:root:[183] (train:: 76.042%) \n",
            "INFO:root:[184,     0] 78.125% (loss: 0.574)\n",
            "INFO:root:[184] (train:: 76.042%) \n",
            "INFO:root:[185,     0] 71.875% (loss: 0.567)\n",
            "INFO:root:[185] (train:: 70.833%) \n",
            "INFO:root:[186,     0] 71.875% (loss: 0.581)\n",
            "INFO:root:[186] (train:: 73.958%) \n",
            "INFO:root:[187,     0] 71.875% (loss: 0.576)\n",
            "INFO:root:[187] (train:: 75.000%) \n",
            "INFO:root:[188,     0] 78.125% (loss: 0.580)\n",
            "INFO:root:[188] (train:: 78.125%) \n",
            "INFO:root:[189,     0] 75.000% (loss: 0.572)\n",
            "INFO:root:[189] (train:: 76.042%) \n",
            "INFO:root:[190,     0] 75.000% (loss: 0.588)\n",
            "INFO:root:[190] (train:: 73.958%) \n",
            "INFO:root:[191,     0] 78.125% (loss: 0.567)\n",
            "INFO:root:[191] (train:: 72.917%) \n",
            "INFO:root:[192,     0] 75.000% (loss: 0.577)\n",
            "INFO:root:[192] (train:: 70.833%) \n",
            "INFO:root:[193,     0] 71.875% (loss: 0.570)\n",
            "INFO:root:[193] (train:: 72.917%) \n",
            "INFO:root:[194,     0] 81.250% (loss: 0.575)\n",
            "INFO:root:[194] (train:: 77.083%) \n",
            "INFO:root:[195,     0] 78.125% (loss: 0.554)\n",
            "INFO:root:[195] (train:: 77.083%) \n",
            "INFO:root:[196,     0] 78.125% (loss: 0.558)\n",
            "INFO:root:[196] (train:: 77.083%) \n",
            "INFO:root:[197,     0] 75.000% (loss: 0.566)\n",
            "INFO:root:[197] (train:: 69.792%) \n",
            "INFO:root:[198,     0] 71.875% (loss: 0.569)\n",
            "INFO:root:[198] (train:: 75.000%) \n",
            "INFO:root:[199,     0] 68.750% (loss: 0.579)\n",
            "INFO:root:[199] (train:: 68.750%) \n",
            "INFO:root:[200,     0] 75.000% (loss: 0.576)\n",
            "INFO:root:[200] (train:: 76.042%) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3H-iYM4MTnD"
      },
      "source": [
        "## Script\n",
        "Didnt use it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5UUGnrhTkf2"
      },
      "source": [
        "#pwd"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjNgGdzpM5Ei"
      },
      "source": [
        "#cd suncet"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnzF3XuAMXFW"
      },
      "source": [
        "#!python main.py --sel fine_tune --fname configs/paws/dr_fine_tune.yaml"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "B5kQkbiz6nRs",
        "outputId": "d6a9f878-ade0-492e-af51-d1e261e73740"
      },
      "source": [
        "# Didnt work using this I would need to fix it in order to use it. \n",
        "\"\"\"\n",
        "import src.resnet as resnet\n",
        "\n",
        "device = \"cuda:0\"\n",
        "device_str = \"cuda:0\"\n",
        "\n",
        "folder = \"suncet/logs/\"\n",
        "r_file_enc = \"paws-ep30.pth.tar\" # CHANGE\n",
        "\n",
        "# -- log/checkpointing paths\n",
        "r_enc_path = os.path.join(folder, r_file_enc)\n",
        "w_enc_path = os.path.join(folder, f'{tag}-fine-tune.pth.tar')\n",
        "\n",
        "encoder = resnet.__dict__[\"resnet50\"]()\n",
        "\n",
        "hidden_dim = 2048\n",
        "if 'w2' in model_name:\n",
        "    hidden_dim *= 2\n",
        "elif 'w4' in model_name:\n",
        "    hidden_dim *= 4\n",
        "\n",
        "# -- projection head\n",
        "encoder.fc = torch.nn.Sequential(OrderedDict([\n",
        "    ('fc1', torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "    ('bn1', torch.nn.BatchNorm1d(hidden_dim)),\n",
        "    ('relu1', torch.nn.ReLU(inplace=True)),\n",
        "    ('fc2', torch.nn.Linear(hidden_dim, 1)), # YO changed\n",
        "    ('sg', torch.nn.Sigmoid())  # YO \n",
        "]))\n",
        "\n",
        "encoder = load_pretrained(\n",
        "    r_path=r_enc_path,\n",
        "    encoder=encoder,\n",
        "    device_str=device_str)\n",
        "\"\"\""
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport src.resnet as resnet\\n\\ndevice = \"cuda:0\"\\ndevice_str = \"cuda:0\"\\n\\nfolder = \"suncet/logs/\"\\nr_file_enc = \"paws-ep30.pth.tar\" # CHANGE\\n\\n# -- log/checkpointing paths\\nr_enc_path = os.path.join(folder, r_file_enc)\\nw_enc_path = os.path.join(folder, f\\'{tag}-fine-tune.pth.tar\\')\\n\\nencoder = resnet.__dict__[\"resnet50\"]()\\n\\nhidden_dim = 2048\\nif \\'w2\\' in model_name:\\n    hidden_dim *= 2\\nelif \\'w4\\' in model_name:\\n    hidden_dim *= 4\\n\\n# -- projection head\\nencoder.fc = torch.nn.Sequential(OrderedDict([\\n    (\\'fc1\\', torch.nn.Linear(hidden_dim, hidden_dim)),\\n    (\\'bn1\\', torch.nn.BatchNorm1d(hidden_dim)),\\n    (\\'relu1\\', torch.nn.ReLU(inplace=True)),\\n    (\\'fc2\\', torch.nn.Linear(hidden_dim, 1)), # YO changed\\n    (\\'sg\\', torch.nn.Sigmoid())  # YO \\n]))\\n\\nencoder = load_pretrained(\\n    r_path=r_enc_path,\\n    encoder=encoder,\\n    device_str=device_str)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYMJuCkw6lmp"
      },
      "source": [
        "## Test PAWS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGl9tX0j86w7",
        "outputId": "9fc91185-3b24-42df-e029-da22e64f147a"
      },
      "source": [
        "encoder"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "    (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (fc2): Linear(in_features=2048, out_features=1, bias=True)\n",
              "    (sg): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liTWKXSk8p2t"
      },
      "source": [
        "test_data = {\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\",\n",
        "    \"messidor2\": \"https://drive.google.com/uc?id=1HaUAxDtN4BNj0hpH8QYGmiX39Va-Ke8p\",\n",
        "}\n",
        "\n",
        "TEST_DATASET = 'messidor2'\n",
        "URL_TEST_DATASET = test_data[TEST_DATASET]"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFTyY-3S9-ZJ",
        "outputId": "3f2ccd2b-36fc-4758-f015-a2fa4f3d15d8"
      },
      "source": [
        "!gdown $URL_TEST_DATASET"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HaUAxDtN4BNj0hpH8QYGmiX39Va-Ke8p\n",
            "To: /content/suncet/messidor2.zip\n",
            "106MB [00:00, 202MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "09MLSbAoIJOh",
        "outputId": "ea749a6e-58ce-4262-8af9-f88ba2edf198"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/suncet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoekpReH-KTu"
      },
      "source": [
        "import zipfile\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH2Wn-Ss-BZv"
      },
      "source": [
        "local_zip = '{}.zip'.format(TEST_DATASET)\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPWFz71B-TTf"
      },
      "source": [
        "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
        "cifar10_std = (0.2471, 0.2435, 0.2616)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRkfHgyU-VUO"
      },
      "source": [
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=cifar10_mean, std=cifar10_std)  # What happens if I change This \n",
        "])"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7yq-EIQ-ubL",
        "outputId": "5e1fe10f-5022-4314-ec90-10b8cfb3b83a"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RE5t5oz-fLR"
      },
      "source": [
        "test_dataset = datasets.ImageFolder(root=\"messidor2\", transform=transform_val) # root: test/messidor2"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wrp0_Y1-gIq"
      },
      "source": [
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    num_workers=1,\n",
        "    shuffle=False)\n",
        "\n",
        "loader = test_loader"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj8Ay-IF_ICN"
      },
      "source": [
        "model = encoder"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar8BjCT6-_uz",
        "outputId": "a5b4c50c-f96e-44af-b6dd-53293eb6f1f8"
      },
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    with tqdm(total=len(loader)) as pbar:\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "\n",
        "            output = output.to(device)\n",
        "\n",
        "            # Yo le agrege esto\n",
        "            y_true.append(targets.cpu().detach().numpy()[0])\n",
        "            y_pred.append(output.cpu().detach().numpy()[0][0])\n",
        "\n",
        "            pbar.update(1)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1748/1748 [00:20<00:00, 83.58it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMBrm01w_o-G",
        "outputId": "02058905-e281-4bae-801b-250b21506dc8"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
        "metrics.auc(fpr, tpr)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7328985841797476"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "xtZ_ms7s_t6o",
        "outputId": "1c500660-7670-4f94-9564-c08a10fd9aae"
      },
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from mlxtend.plotting import plot_confusion_matrix \n",
        "# %matplotlib inline\n",
        "\n",
        "#cm=metrics.confusion_matrix(y_true, y_pred)\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "#print('AUC: %.3f' % auc)\n",
        "#print('Accuracy: {}'.format(accuracy_score(y_true, y_pred)))\n",
        "\n",
        "# Plot ROC curve\n",
        "lw = 2\n",
        "sns.set_style({'axes.grid' : False})\n",
        "sns.set_style(\"darkgrid\")\n",
        "ax1 = sns.lineplot(fpr, tpr, color='darkorange',\n",
        "        lw=lw, label='AUC = %0.2f' % auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "ax1.set_title('Receiver operating characteristic')\n",
        "ax1.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}