{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PAWS_DR_fine_tune_V3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/PAWS_DR_fine_tune_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5hlD-M-AULJ",
        "outputId": "851c2f0b-7566-4ea8-ef24-b2f43766f836"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install --quiet -v --no-cache-dir ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8054, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 8054 (delta 68), reused 97 (delta 44), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8054/8054), 14.11 MiB | 14.33 MiB/s, done.\n",
            "Resolving deltas: 100% (5469/5469), done.\n",
            "/content/apex\n",
            "Processing /content/apex\n",
            "Building wheels for collected packages: apex\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp37-none-any.whl size=204709 sha256=1aabc2f0690f96663e2377c664beb2e92078c7f03b651325769e9e5ed16bd010\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-40wyyrjx/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "Successfully installed apex-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCL0T19BAhwZ",
        "outputId": "c8dcae49-3e89-4c9b-ace4-7ac78c2ca3cb"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmQET3rEAknO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d20c02-0751-4765-ad6f-5823e4e9fefa"
      },
      "source": [
        "!pip install --quiet -U PyYAML"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10kB 29.8MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 34.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 37.3MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 22.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 15.3MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 12.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 13.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 593kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 14.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxKLx9eqAndQ",
        "outputId": "0e541f51-61f6-4667-bca9-ef9803a66303"
      },
      "source": [
        "!git clone -b feature/DR-images-v2 https://github.com/jmarrietar/suncet.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'suncet'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Counting objects: 100% (336/336), done.\u001b[K\n",
            "remote: Compressing objects: 100% (214/214), done.\u001b[K\n",
            "remote: Total 336 (delta 199), reused 250 (delta 119), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (336/336), 1.11 MiB | 4.24 MiB/s, done.\n",
            "Resolving deltas: 100% (199/199), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c0W3iBTApIP",
        "outputId": "dcc49fee-a4c9-4759-c8b5-a43f1f69385b"
      },
      "source": [
        "cd suncet"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U4gvRnhMAqWJ",
        "outputId": "45306b25-5717-46fb-8296-df4418954241"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/suncet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4On1j-ZxAr2v"
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "import gdown\n",
        "\n",
        "# Check whether the file is already in the desired path or if it needs to be downloaded\n",
        "# File downloaded from source : https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\n",
        "\n",
        "base_path = '/content/suncet/datasets/dr/'\n",
        "file_path = 'sample@1000.zip'\n",
        "\n",
        "if not os.path.isfile(base_path + file_path):\n",
        "    subprocess.run(['mkdir', '-p', base_path])\n",
        "    subprocess.run(['mkdir', '-p', 'logs'])\n",
        "    subprocess.call(['python', 'download.py', '-d', file_path.split('.')[0]])\n",
        "else:\n",
        "    print('File already downloaded!')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "088y7D-BB0ni"
      },
      "source": [
        "output = \"logs/paws-ep100.pth.tar\" # CHANGE NAME\n",
        "model_url = \"https://drive.google.com/uc?id=1SAYDN1w8jG4XuqTq0j_5areDvAerCTFA\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq0Kx50UKtyX"
      },
      "source": [
        "#output = \"logs/paws-best.pth.tar\"\n",
        "#model_url = \"https://drive.google.com/uc?id=1qHNVcg0q9v4VFGi6mvpB7k484Ivupp00\""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYeSWds5Uohh"
      },
      "source": [
        "#output = \"logs/paws-latest.pth.tar\"\n",
        "#model_url = \"https://drive.google.com/uc?id=1vne4U9Z31-9V2_SVOHdVqYyZpJaRXH6f\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "Dl4xMk5J2Cgz",
        "outputId": "8c4bc5bd-5c40-489e-b63e-7ca1931dad5a"
      },
      "source": [
        "gdown.download(model_url, output, quiet=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SAYDN1w8jG4XuqTq0j_5areDvAerCTFA\n",
            "To: /content/suncet/logs/paws-ep100.pth.tar\n",
            "306MB [00:02, 116MB/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'logs/paws-ep100.pth.tar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln-Ge4v-A_yP"
      },
      "source": [
        "`main.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZjEepEFBCQF",
        "outputId": "9ac748cc-c1c3-49aa-b726-506dc1ae088f"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import argparse\n",
        "\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "import pprint\n",
        "import yaml\n",
        "\n",
        "from src.paws_train import main as paws\n",
        "from src.suncet_train import main as suncet\n",
        "from src.fine_tune import main as fine_tune\n",
        "from src.snn_fine_tune import main as snn_fine_tune\n",
        "\n",
        "from src.utils import init_distributed\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    \"--fname\", type=str, help=\"name of config file to load\", default=\"configs.yaml\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--devices\",\n",
        "    type=str,\n",
        "    nargs=\"+\",\n",
        "    default=[\"cuda:0\"],\n",
        "    help=\"which devices to use on local machine\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--sel\",\n",
        "    type=str,\n",
        "    help=\"which script to run\",\n",
        "    choices=[\"paws_train\", \"suncet_train\", \"fine_tune\", \"snn_fine_tune\"],\n",
        ")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--sel'], dest='sel', nargs=None, const=None, default=None, type=<class 'str'>, choices=['paws_train', 'suncet_train', 'fine_tune', 'snn_fine_tune'], help='which script to run', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS_6NXCIBFzI"
      },
      "source": [
        "args = parser.parse_args(['--sel', 'fine_tune',\n",
        "                          '--fname', 'configs/paws/dr_fine_tune.yaml'\n",
        "])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0G_CvPcBrD9"
      },
      "source": [
        "fname = args.fname\n",
        "sel = args.sel"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YHQTaIUBrGw",
        "outputId": "8bfde35e-1df9-47ca-8c6e-019e101c132e"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "\n",
        "logger.info(f'called-params {sel} {fname}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:called-params fine_tune configs/paws/dr_fine_tune.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guYIscowBrJs"
      },
      "source": [
        "rank = 0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyCicIMIBrMx",
        "outputId": "c4dd95f3-9c08-4f99-8085-1378867d04f6"
      },
      "source": [
        "# -- load script params\n",
        "params = None\n",
        "with open(fname, 'r') as y_file:\n",
        "    params = yaml.load(y_file, Loader=yaml.FullLoader)\n",
        "    logger.info('loaded params...')\n",
        "    if rank == 0:\n",
        "        pp = pprint.PrettyPrinter(indent=4)\n",
        "        pp.pprint(params)\n",
        "\n",
        "if rank == 0:\n",
        "    dump = os.path.join(params['logging']['folder'], f'params-{sel}.yaml')\n",
        "    with open(dump, 'w') as f:\n",
        "        yaml.dump(params, f)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:loaded params...\n",
            "{   'data': {   'data_seed': 152,\n",
            "                'dataset': 'dr_fine_tune',\n",
            "                'image_folder': 'dr/sample@1000/',\n",
            "                'normalize': True,\n",
            "                'num_classes': 2,\n",
            "                'root_path': 'datasets/',\n",
            "                'subset_path': 'dr_subsets/',\n",
            "                'unlabeled_frac': 0.9},\n",
            "    'logging': {   'folder': 'logs/',\n",
            "                   'pretrain_path': 'paws-ep100.pth.tar',\n",
            "                   'write_tag': 'paws-latest-SNN'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'master_port': 4029,\n",
            "                'model_name': 'resnet50',\n",
            "                'training': True,\n",
            "                'use_fp16': True},\n",
            "    'optimization': {   'epochs': 50,\n",
            "                        'lr': 1e-05,\n",
            "                        'use_lars': False,\n",
            "                        'weight_decay': 0.0,\n",
            "                        'zero_init': True}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBZ_cA-KBrO3"
      },
      "source": [
        "args = params"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqU77odjG_82",
        "outputId": "0639df57-358d-481d-c7be-bd718163fb8d"
      },
      "source": [
        "args"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': {'data_seed': 152,\n",
              "  'dataset': 'dr_fine_tune',\n",
              "  'image_folder': 'dr/sample@1000/',\n",
              "  'normalize': True,\n",
              "  'num_classes': 2,\n",
              "  'root_path': 'datasets/',\n",
              "  'subset_path': 'dr_subsets/',\n",
              "  'unlabeled_frac': 0.9},\n",
              " 'logging': {'folder': 'logs/',\n",
              "  'pretrain_path': 'paws-ep100.pth.tar',\n",
              "  'write_tag': 'paws-latest-SNN'},\n",
              " 'meta': {'copy_data': True,\n",
              "  'device': 'cuda:0',\n",
              "  'load_checkpoint': False,\n",
              "  'master_port': 4029,\n",
              "  'model_name': 'resnet50',\n",
              "  'training': True,\n",
              "  'use_fp16': True},\n",
              " 'optimization': {'epochs': 50,\n",
              "  'lr': 1e-05,\n",
              "  'use_lars': False,\n",
              "  'weight_decay': 0.0,\n",
              "  'zero_init': True}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91a9EGKyBzEG"
      },
      "source": [
        "## FINE TUNE TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mQKJg0ABrSi"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import os\n",
        "\n",
        "# -- FOR DISTRIBUTED TRAINING ENSURE ONLY 1 DEVICE VISIBLE PER PROCESS\n",
        "try:\n",
        "    # -- WARNING: IF DOING DISTRIBUTED TRAINING ON A NON-SLURM CLUSTER, MAKE\n",
        "    # --          SURE TO UPDATE THIS TO GET LOCAL-RANK ON NODE, OR ENSURE\n",
        "    # --          THAT YOUR JOBS ARE LAUNCHED WITH ONLY 1 DEVICE VISIBLE\n",
        "    # --          TO EACH PROCESS\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['SLURM_LOCALID']\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "import copy\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule\n",
        ")\n",
        "from src.data_manager import (\n",
        "    init_data,\n",
        "    make_transforms\n",
        ")\n",
        "from src.sgd import SGD\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "from src.lars import LARS\n",
        "\n",
        "# --\n",
        "log_timings = True\n",
        "log_freq = 10\n",
        "checkpoint_freq = 50\n",
        "# --\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "np.random.seed(_GLOBAL_SEED)\n",
        "torch.manual_seed(_GLOBAL_SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logger = logging.getLogger()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh8OlmleBrXj"
      },
      "source": [
        "def load_pretrained(\n",
        "    r_path,\n",
        "    encoder,\n",
        "    device_str\n",
        "):\n",
        "    checkpoint = torch.load(r_path, map_location='cpu')\n",
        "    pretrained_dict = {k.replace('module.', ''): v for k, v in checkpoint['encoder'].items()}\n",
        "    for k, v in encoder.state_dict().items():\n",
        "        if k not in pretrained_dict:\n",
        "            logger.info(f'key \"{k}\" could not be found in loaded state dict')\n",
        "        elif pretrained_dict[k].shape != v.shape:\n",
        "            logger.info(f'key \"{k}\" is of different shape in model and loaded state dict')\n",
        "            pretrained_dict[k] = v\n",
        "    msg = encoder.load_state_dict(pretrained_dict, strict=False)\n",
        "    logger.info(f'loaded pretrained model with msg: {msg}')\n",
        "    logger.info(f'loaded pretrained encoder from epoch: {checkpoint[\"epoch\"]} '\n",
        "                f'path: {r_path}')\n",
        "    del checkpoint\n",
        "    return encoder"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZkNsaIrBrbD"
      },
      "source": [
        "def load_from_path(\n",
        "    r_path,\n",
        "    encoder,\n",
        "    opt,\n",
        "    sched,\n",
        "    scaler,\n",
        "    device_str,\n",
        "    use_fp16=False\n",
        "):\n",
        "    encoder = load_pretrained(r_path, encoder, device_str)\n",
        "    checkpoint = torch.load(r_path, map_location=device_str)\n",
        "\n",
        "    best_acc = None\n",
        "    if 'best_top1_acc' in checkpoint:\n",
        "        best_acc = checkpoint['best_top1_acc']\n",
        "\n",
        "    epoch = checkpoint['epoch']\n",
        "    if opt is not None:\n",
        "        if use_fp16:\n",
        "            scaler.load_state_dict(checkpoint['amp'])\n",
        "        opt.load_state_dict(checkpoint['opt'])\n",
        "        sched.load_state_dict(checkpoint['sched'])\n",
        "        logger.info(f'loaded optimizers from epoch {epoch}')\n",
        "    logger.info(f'read-path: {r_path}')\n",
        "    del checkpoint\n",
        "    return encoder, opt, sched, epoch, best_acc"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfV-VdVHBrdQ"
      },
      "source": [
        "def init_model(\n",
        "    device,\n",
        "    device_str,\n",
        "    num_classes,\n",
        "    training,\n",
        "    use_fp16,\n",
        "    r_enc_path,\n",
        "    iterations_per_epoch,\n",
        "    world_size,\n",
        "    ref_lr,\n",
        "    num_epochs,\n",
        "    use_lars=False,\n",
        "    zero_init=True,\n",
        "    model_name='resnet50',\n",
        "    warmup_epochs=0,\n",
        "    weight_decay=0\n",
        "):\n",
        "    # -- init model\n",
        "    if 'wide_resnet' in model_name:\n",
        "        encoder = wide_resnet.__dict__[model_name](dropout_rate=0.0)\n",
        "        hidden_dim = 128\n",
        "    else:\n",
        "        encoder = resnet.__dict__[model_name]()\n",
        "        hidden_dim = 2048\n",
        "        if 'w2' in model_name:\n",
        "            hidden_dim *= 2\n",
        "        elif 'w4' in model_name:\n",
        "            hidden_dim *= 4\n",
        "\n",
        "    # -- projection head\n",
        "    encoder.fc = torch.nn.Sequential(OrderedDict([\n",
        "        ('fc1', torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "        ('bn1', torch.nn.BatchNorm1d(hidden_dim)),\n",
        "        ('relu1', torch.nn.ReLU(inplace=True)),\n",
        "        ('fc2', torch.nn.Linear(hidden_dim, 1)), # YO changed\n",
        "        ('sg', torch.nn.Sigmoid())  # YO \n",
        "    ]))\n",
        "\n",
        "    encoder.to(device)\n",
        "    encoder = load_pretrained(\n",
        "        r_path=r_enc_path,\n",
        "        encoder=encoder,\n",
        "        device_str=device_str)\n",
        "\n",
        "    if zero_init:\n",
        "        for p in encoder.fc.fc2.parameters():\n",
        "            torch.nn.init.zeros_(p)\n",
        "\n",
        "    # -- init optimizer\n",
        "    optimizer, scheduler = None, None\n",
        "    if training:\n",
        "        param_groups = [\n",
        "            {'params': (p for n, p in encoder.named_parameters()\n",
        "                        if ('bias' not in n) and ('bn' not in n))},\n",
        "            {'params': (p for n, p in encoder.named_parameters()\n",
        "                        if ('bias' in n) or ('bn' in n)),\n",
        "             'LARS_exclude': True,\n",
        "             'weight_decay': 0}\n",
        "        ]\n",
        "        optimizer = SGD(\n",
        "            param_groups,\n",
        "            nesterov=True,\n",
        "            weight_decay=weight_decay,\n",
        "            momentum=0.9,\n",
        "            lr=ref_lr)\n",
        "        scheduler = WarmupCosineSchedule(\n",
        "            optimizer,\n",
        "            warmup_steps=warmup_epochs*iterations_per_epoch,\n",
        "            start_lr=ref_lr,\n",
        "            ref_lr=ref_lr,\n",
        "            T_max=num_epochs*iterations_per_epoch)\n",
        "        if use_lars:\n",
        "            optimizer = LARS(optimizer, trust_coefficient=0.001)\n",
        "    if world_size > 1:\n",
        "        encoder = DistributedDataParallel(encoder, broadcast_buffers=False)\n",
        "\n",
        "    return encoder, optimizer, scheduler"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq3v7zFLBrgG"
      },
      "source": [
        "# -- META\n",
        "model_name = args['meta']['model_name']\n",
        "port = args['meta']['master_port']\n",
        "load_checkpoint = args['meta']['load_checkpoint']\n",
        "training = args['meta']['training']\n",
        "copy_data = args['meta']['copy_data']\n",
        "use_fp16 = args['meta']['use_fp16']\n",
        "device = torch.device(args['meta']['device'])\n",
        "torch.cuda.set_device(device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os4hgZObBrrP"
      },
      "source": [
        "# -- DATA\n",
        "unlabeled_frac = args['data']['unlabeled_frac']\n",
        "normalize = args['data']['normalize']\n",
        "root_path = args['data']['root_path']\n",
        "image_folder = args['data']['image_folder']\n",
        "dataset_name = args['data']['dataset']\n",
        "subset_path = args['data']['subset_path']\n",
        "num_classes = args['data']['num_classes']\n",
        "data_seed = None\n",
        "if 'cifar10' in dataset_name:\n",
        "    data_seed = args['data']['data_seed']\n",
        "crop_scale = (0.5, 1.0) if 'cifar10' in dataset_name else (0.08, 1.0)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1zEZGGQBrw3"
      },
      "source": [
        "# -- OPTIMIZATION\n",
        "wd = float(args['optimization']['weight_decay'])\n",
        "ref_lr = args['optimization']['lr']\n",
        "use_lars = args['optimization']['use_lars']\n",
        "zero_init = args['optimization']['zero_init']\n",
        "num_epochs = args['optimization']['epochs']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT9t_7siDEiA"
      },
      "source": [
        "# -- LOGGING\n",
        "folder = args['logging']['folder']\n",
        "tag = args['logging']['write_tag']\n",
        "r_file_enc = args['logging']['pretrain_path']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12zIU-oxDEqO"
      },
      "source": [
        "# -- log/checkpointing paths\n",
        "r_enc_path = os.path.join(folder, r_file_enc)\n",
        "w_enc_path = os.path.join(folder, f'{tag}-fine-tune.pth.tar')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQX97cCGDEtl",
        "outputId": "564b7f4e-bf4b-4f40-9a5f-ead9e5aef033"
      },
      "source": [
        "# -- init distributed\n",
        "world_size, rank = init_distributed(port)\n",
        "logger.info(f'initialized rank/world-size: {rank}/{world_size}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:distributed training not available\n",
            "INFO:root:initialized rank/world-size: 0/1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgKbHSR2DEwa"
      },
      "source": [
        "# -- optimization/evaluation params\n",
        "if training:\n",
        "    batch_size = 32\n",
        "else:\n",
        "    batch_size = 16\n",
        "    unlabeled_frac = 0.0\n",
        "    load_checkpoint = True\n",
        "    num_epochs = 1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRpDSN1zDEz8"
      },
      "source": [
        "# -- init loss\n",
        "#criterion = torch.nn.CrossEntropyLoss() \n",
        "criterion = torch.nn.BCELoss() # YO CHANGED HERE\n",
        "#criterion = torch.nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROxh1sWHDE3L",
        "outputId": "50b03d8b-b13e-490c-ace3-45df8c73bc96"
      },
      "source": [
        "# -- make train data transforms and data loaders/samples\n",
        "transform, init_transform = make_transforms(\n",
        "    dataset_name=dataset_name,\n",
        "    subset_path=subset_path,\n",
        "    unlabeled_frac=unlabeled_frac,\n",
        "    training=training,\n",
        "    crop_scale=crop_scale,\n",
        "    split_seed=data_seed,\n",
        "    basic_augmentations=True,\n",
        "    normalize=normalize)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:making imagenet data transforms\n",
            "INFO:root:keep file: dr_subsets/90percent.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WZOnPx7DE-P",
        "outputId": "98e98054-d54b-47c8-c31b-6854375b7e8f"
      },
      "source": [
        "(data_loader,\n",
        "    dist_sampler) = init_data(\n",
        "        dataset_name=dataset_name,\n",
        "        transform=transform,\n",
        "        init_transform=init_transform,\n",
        "        u_batch_size=None,\n",
        "        s_batch_size=batch_size,\n",
        "        classes_per_batch=2,\n",
        "        world_size=world_size,\n",
        "        rank=rank,\n",
        "        root_path=root_path,\n",
        "        image_folder=image_folder,\n",
        "        training=training,\n",
        "        copy_data=copy_data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:copying data locally\n",
            "INFO:root:No job-id, will load directly from network file\n",
            "INFO:root:data-path datasets/dr/sample@1000/train/\n",
            "INFO:root:Initialized ImageDR\n",
            "INFO:root:ImageNet fine-tune dataset created\n",
            "self.multicrop_transform (0, None)\n",
            "INFO:root:flipping coin to keep labels\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1ZaEXJ0DFCc",
        "outputId": "f5879594-55ad-4d50-96ce-dff793cdd532"
      },
      "source": [
        "ipe = len(data_loader)\n",
        "logger.info(f'initialized data-loader (ipe {ipe})')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:initialized data-loader (ipe 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr3kuterDFL7",
        "outputId": "db197022-acf3-4da9-dca8-7760237e6665"
      },
      "source": [
        "# -- init model and optimizer\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "encoder, optimizer, scheduler = init_model(\n",
        "    device=device,\n",
        "    device_str=args['meta']['device'],\n",
        "    num_classes=num_classes,\n",
        "    training=training,\n",
        "    use_fp16=use_fp16,\n",
        "    r_enc_path=r_enc_path,\n",
        "    iterations_per_epoch=ipe,\n",
        "    world_size=world_size,\n",
        "    ref_lr=ref_lr,\n",
        "    weight_decay=wd,\n",
        "    use_lars=use_lars,\n",
        "    zero_init=zero_init,\n",
        "    num_epochs=num_epochs,\n",
        "    model_name=model_name)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:key \"fc.fc2.weight\" is of different shape in model and loaded state dict\n",
            "INFO:root:key \"fc.fc2.bias\" is of different shape in model and loaded state dict\n",
            "INFO:root:loaded pretrained model with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['pred.bn1.weight', 'pred.bn1.bias', 'pred.bn1.running_mean', 'pred.bn1.running_var', 'pred.bn1.num_batches_tracked', 'pred.fc1.weight', 'pred.fc1.bias', 'pred.bn2.weight', 'pred.bn2.bias', 'pred.bn2.running_mean', 'pred.bn2.running_var', 'pred.bn2.num_batches_tracked', 'pred.fc2.weight', 'pred.fc2.bias', 'fc.bn2.weight', 'fc.bn2.bias', 'fc.bn2.running_mean', 'fc.bn2.running_var', 'fc.bn2.num_batches_tracked', 'fc.fc3.weight', 'fc.fc3.bias'])\n",
            "INFO:root:loaded pretrained encoder from epoch: 100 path: logs/paws-ep100.pth.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO78XesVOKdA",
        "outputId": "bf3b85a0-d36a-41ac-a00f-247eef6fa271"
      },
      "source": [
        "encoder"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "    (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (fc2): Linear(in_features=2048, out_features=1, bias=True)\n",
              "    (sg): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG0qD6-iDFTW"
      },
      "source": [
        "best_acc = None\n",
        "start_epoch = 0\n",
        "# -- load checkpoint\n",
        "if not training or load_checkpoint:\n",
        "    encoder, optimizer, scheduler, start_epoch, best_acc = load_from_path(\n",
        "        r_path=w_enc_path,\n",
        "        encoder=encoder,\n",
        "        opt=optimizer,\n",
        "        sched=scheduler,\n",
        "        scaler=scaler,\n",
        "        device_str=args['meta']['device'],\n",
        "        use_fp16=use_fp16)\n",
        "if not training:\n",
        "    logger.info('putting model in eval mode')\n",
        "    encoder.eval()\n",
        "    logger.info(sum(p.numel() for n, p in encoder.named_parameters()\n",
        "                    if p.requires_grad and ('fc' not in n)))\n",
        "    start_epoch = 0"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y4gAC5mOQ7s"
      },
      "source": [
        "num_epochs = 200 # CHANGE HERE"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYRdk6r0DFVk",
        "outputId": "03fe0a71-8e35-44a0-95ea-9767621ce2b1"
      },
      "source": [
        "for epoch in range(start_epoch, num_epochs):\n",
        "\n",
        "    def train_step():\n",
        "        # -- update distributed-data-loader epoch\n",
        "        top1_correct, total = 0, 0\n",
        "        for i, data in enumerate(data_loader):\n",
        "            with torch.cuda.amp.autocast(enabled=False): # Yo\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "                labels = labels.unsqueeze(1) ## YO\n",
        "                labels = labels.float() ## YO\n",
        "\n",
        "                outputs = encoder(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            total += inputs.shape[0]\n",
        "            top1_correct += float(sum(((outputs>0.5)*1 == labels)*1))\n",
        "            top1_acc = 100. * (top1_correct / total)\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            if i % log_freq == 0:\n",
        "                logger.info('[%d, %5d] %.3f%% (loss: %.3f)'\n",
        "                            % (epoch + 1, i, top1_acc, loss))\n",
        "        return 100. * (top1_correct / total)\n",
        "\n",
        "    train_top1 = 0.\n",
        "    train_top1 = train_step()\n",
        "\n",
        "    log_str = 'train:'\n",
        "    logger.info('[%d] (%s: %.3f%%) '\n",
        "                % (epoch + 1, log_str, train_top1))\n",
        "\n",
        "    # -- logging/checkpointing\n",
        "    if rank == 0:\n",
        "\n",
        "        save_dict = {\n",
        "            'encoder': encoder.state_dict(),\n",
        "            'opt': optimizer.state_dict(),\n",
        "            'sched': scheduler.state_dict(),\n",
        "            'epoch': epoch + 1,\n",
        "            'unlabel_prob': unlabeled_frac,\n",
        "            'world_size': world_size,\n",
        "            'batch_size': batch_size,\n",
        "            'lr': ref_lr,\n",
        "            'amp': scaler.state_dict()\n",
        "        }\n",
        "        torch.save(save_dict, w_enc_path)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:[1,     0] 50.000% (loss: 0.693)\n",
            "INFO:root:[1] (train:: 64.583%) \n",
            "INFO:root:[2,     0] 75.000% (loss: 0.693)\n",
            "INFO:root:[2] (train:: 75.000%) \n",
            "INFO:root:[3,     0] 68.750% (loss: 0.691)\n",
            "INFO:root:[3] (train:: 71.875%) \n",
            "INFO:root:[4,     0] 68.750% (loss: 0.690)\n",
            "INFO:root:[4] (train:: 73.958%) \n",
            "INFO:root:[5,     0] 71.875% (loss: 0.689)\n",
            "INFO:root:[5] (train:: 73.958%) \n",
            "INFO:root:[6,     0] 71.875% (loss: 0.687)\n",
            "INFO:root:[6] (train:: 68.750%) \n",
            "INFO:root:[7,     0] 71.875% (loss: 0.683)\n",
            "INFO:root:[7] (train:: 71.875%) \n",
            "INFO:root:[8,     0] 71.875% (loss: 0.683)\n",
            "INFO:root:[8] (train:: 73.958%) \n",
            "INFO:root:[9,     0] 68.750% (loss: 0.679)\n",
            "INFO:root:[9] (train:: 70.833%) \n",
            "INFO:root:[10,     0] 71.875% (loss: 0.678)\n",
            "INFO:root:[10] (train:: 69.792%) \n",
            "INFO:root:[11,     0] 71.875% (loss: 0.677)\n",
            "INFO:root:[11] (train:: 73.958%) \n",
            "INFO:root:[12,     0] 71.875% (loss: 0.675)\n",
            "INFO:root:[12] (train:: 70.833%) \n",
            "INFO:root:[13,     0] 68.750% (loss: 0.672)\n",
            "INFO:root:[13] (train:: 72.917%) \n",
            "INFO:root:[14,     0] 68.750% (loss: 0.668)\n",
            "INFO:root:[14] (train:: 68.750%) \n",
            "INFO:root:[15,     0] 68.750% (loss: 0.674)\n",
            "INFO:root:[15] (train:: 66.667%) \n",
            "INFO:root:[16,     0] 68.750% (loss: 0.666)\n",
            "INFO:root:[16] (train:: 70.833%) \n",
            "INFO:root:[17,     0] 71.875% (loss: 0.664)\n",
            "INFO:root:[17] (train:: 71.875%) \n",
            "INFO:root:[18,     0] 68.750% (loss: 0.667)\n",
            "INFO:root:[18] (train:: 72.917%) \n",
            "INFO:root:[19,     0] 68.750% (loss: 0.668)\n",
            "INFO:root:[19] (train:: 69.792%) \n",
            "INFO:root:[20,     0] 78.125% (loss: 0.662)\n",
            "INFO:root:[20] (train:: 75.000%) \n",
            "INFO:root:[21,     0] 71.875% (loss: 0.661)\n",
            "INFO:root:[21] (train:: 72.917%) \n",
            "INFO:root:[22,     0] 75.000% (loss: 0.656)\n",
            "INFO:root:[22] (train:: 76.042%) \n",
            "INFO:root:[23,     0] 68.750% (loss: 0.667)\n",
            "INFO:root:[23] (train:: 67.708%) \n",
            "INFO:root:[24,     0] 68.750% (loss: 0.653)\n",
            "INFO:root:[24] (train:: 72.917%) \n",
            "INFO:root:[25,     0] 75.000% (loss: 0.659)\n",
            "INFO:root:[25] (train:: 69.792%) \n",
            "INFO:root:[26,     0] 71.875% (loss: 0.652)\n",
            "INFO:root:[26] (train:: 75.000%) \n",
            "INFO:root:[27,     0] 68.750% (loss: 0.651)\n",
            "INFO:root:[27] (train:: 69.792%) \n",
            "INFO:root:[28,     0] 71.875% (loss: 0.657)\n",
            "INFO:root:[28] (train:: 71.875%) \n",
            "INFO:root:[29,     0] 71.875% (loss: 0.660)\n",
            "INFO:root:[29] (train:: 73.958%) \n",
            "INFO:root:[30,     0] 68.750% (loss: 0.650)\n",
            "INFO:root:[30] (train:: 73.958%) \n",
            "INFO:root:[31,     0] 71.875% (loss: 0.655)\n",
            "INFO:root:[31] (train:: 70.833%) \n",
            "INFO:root:[32,     0] 65.625% (loss: 0.660)\n",
            "INFO:root:[32] (train:: 69.792%) \n",
            "INFO:root:[33,     0] 71.875% (loss: 0.641)\n",
            "INFO:root:[33] (train:: 72.917%) \n",
            "INFO:root:[34,     0] 68.750% (loss: 0.649)\n",
            "INFO:root:[34] (train:: 73.958%) \n",
            "INFO:root:[35,     0] 71.875% (loss: 0.647)\n",
            "INFO:root:[35] (train:: 71.875%) \n",
            "INFO:root:[36,     0] 71.875% (loss: 0.656)\n",
            "INFO:root:[36] (train:: 68.750%) \n",
            "INFO:root:[37,     0] 75.000% (loss: 0.649)\n",
            "INFO:root:[37] (train:: 73.958%) \n",
            "INFO:root:[38,     0] 68.750% (loss: 0.654)\n",
            "INFO:root:[38] (train:: 69.792%) \n",
            "INFO:root:[39,     0] 71.875% (loss: 0.648)\n",
            "INFO:root:[39] (train:: 72.917%) \n",
            "INFO:root:[40,     0] 75.000% (loss: 0.650)\n",
            "INFO:root:[40] (train:: 72.917%) \n",
            "INFO:root:[41,     0] 71.875% (loss: 0.656)\n",
            "INFO:root:[41] (train:: 70.833%) \n",
            "INFO:root:[42,     0] 71.875% (loss: 0.644)\n",
            "INFO:root:[42] (train:: 71.875%) \n",
            "INFO:root:[43,     0] 75.000% (loss: 0.645)\n",
            "INFO:root:[43] (train:: 69.792%) \n",
            "INFO:root:[44,     0] 71.875% (loss: 0.645)\n",
            "INFO:root:[44] (train:: 73.958%) \n",
            "INFO:root:[45,     0] 75.000% (loss: 0.648)\n",
            "INFO:root:[45] (train:: 75.000%) \n",
            "INFO:root:[46,     0] 71.875% (loss: 0.651)\n",
            "INFO:root:[46] (train:: 70.833%) \n",
            "INFO:root:[47,     0] 75.000% (loss: 0.648)\n",
            "INFO:root:[47] (train:: 75.000%) \n",
            "INFO:root:[48,     0] 71.875% (loss: 0.653)\n",
            "INFO:root:[48] (train:: 71.875%) \n",
            "INFO:root:[49,     0] 71.875% (loss: 0.641)\n",
            "INFO:root:[49] (train:: 70.833%) \n",
            "INFO:root:[50,     0] 71.875% (loss: 0.652)\n",
            "INFO:root:[50] (train:: 73.958%) \n",
            "INFO:root:[51,     0] 68.750% (loss: 0.649)\n",
            "INFO:root:[51] (train:: 72.917%) \n",
            "INFO:root:[52,     0] 65.625% (loss: 0.657)\n",
            "INFO:root:[52] (train:: 69.792%) \n",
            "INFO:root:[53,     0] 68.750% (loss: 0.646)\n",
            "INFO:root:[53] (train:: 70.833%) \n",
            "INFO:root:[54,     0] 71.875% (loss: 0.650)\n",
            "INFO:root:[54] (train:: 73.958%) \n",
            "INFO:root:[55,     0] 71.875% (loss: 0.645)\n",
            "INFO:root:[55] (train:: 73.958%) \n",
            "INFO:root:[56,     0] 75.000% (loss: 0.645)\n",
            "INFO:root:[56] (train:: 75.000%) \n",
            "INFO:root:[57,     0] 75.000% (loss: 0.647)\n",
            "INFO:root:[57] (train:: 76.042%) \n",
            "INFO:root:[58,     0] 71.875% (loss: 0.653)\n",
            "INFO:root:[58] (train:: 69.792%) \n",
            "INFO:root:[59,     0] 75.000% (loss: 0.648)\n",
            "INFO:root:[59] (train:: 71.875%) \n",
            "INFO:root:[60,     0] 68.750% (loss: 0.660)\n",
            "INFO:root:[60] (train:: 71.875%) \n",
            "INFO:root:[61,     0] 71.875% (loss: 0.638)\n",
            "INFO:root:[61] (train:: 68.750%) \n",
            "INFO:root:[62,     0] 75.000% (loss: 0.652)\n",
            "INFO:root:[62] (train:: 71.875%) \n",
            "INFO:root:[63,     0] 71.875% (loss: 0.646)\n",
            "INFO:root:[63] (train:: 70.833%) \n",
            "INFO:root:[64,     0] 71.875% (loss: 0.648)\n",
            "INFO:root:[64] (train:: 72.917%) \n",
            "INFO:root:[65,     0] 65.625% (loss: 0.647)\n",
            "INFO:root:[65] (train:: 69.792%) \n",
            "INFO:root:[66,     0] 68.750% (loss: 0.659)\n",
            "INFO:root:[66] (train:: 70.833%) \n",
            "INFO:root:[67,     0] 78.125% (loss: 0.645)\n",
            "INFO:root:[67] (train:: 77.083%) \n",
            "INFO:root:[68,     0] 68.750% (loss: 0.646)\n",
            "INFO:root:[68] (train:: 70.833%) \n",
            "INFO:root:[69,     0] 68.750% (loss: 0.651)\n",
            "INFO:root:[69] (train:: 73.958%) \n",
            "INFO:root:[70,     0] 68.750% (loss: 0.649)\n",
            "INFO:root:[70] (train:: 73.958%) \n",
            "INFO:root:[71,     0] 75.000% (loss: 0.642)\n",
            "INFO:root:[71] (train:: 75.000%) \n",
            "INFO:root:[72,     0] 62.500% (loss: 0.653)\n",
            "INFO:root:[72] (train:: 68.750%) \n",
            "INFO:root:[73,     0] 75.000% (loss: 0.658)\n",
            "INFO:root:[73] (train:: 72.917%) \n",
            "INFO:root:[74,     0] 68.750% (loss: 0.653)\n",
            "INFO:root:[74] (train:: 70.833%) \n",
            "INFO:root:[75,     0] 75.000% (loss: 0.639)\n",
            "INFO:root:[75] (train:: 70.833%) \n",
            "INFO:root:[76,     0] 75.000% (loss: 0.651)\n",
            "INFO:root:[76] (train:: 76.042%) \n",
            "INFO:root:[77,     0] 71.875% (loss: 0.644)\n",
            "INFO:root:[77] (train:: 70.833%) \n",
            "INFO:root:[78,     0] 68.750% (loss: 0.633)\n",
            "INFO:root:[78] (train:: 70.833%) \n",
            "INFO:root:[79,     0] 75.000% (loss: 0.632)\n",
            "INFO:root:[79] (train:: 73.958%) \n",
            "INFO:root:[80,     0] 71.875% (loss: 0.643)\n",
            "INFO:root:[80] (train:: 70.833%) \n",
            "INFO:root:[81,     0] 75.000% (loss: 0.635)\n",
            "INFO:root:[81] (train:: 77.083%) \n",
            "INFO:root:[82,     0] 71.875% (loss: 0.639)\n",
            "INFO:root:[82] (train:: 72.917%) \n",
            "INFO:root:[83,     0] 71.875% (loss: 0.641)\n",
            "INFO:root:[83] (train:: 73.958%) \n",
            "INFO:root:[84,     0] 78.125% (loss: 0.625)\n",
            "INFO:root:[84] (train:: 72.917%) \n",
            "INFO:root:[85,     0] 71.875% (loss: 0.643)\n",
            "INFO:root:[85] (train:: 75.000%) \n",
            "INFO:root:[86,     0] 71.875% (loss: 0.650)\n",
            "INFO:root:[86] (train:: 72.917%) \n",
            "INFO:root:[87,     0] 65.625% (loss: 0.634)\n",
            "INFO:root:[87] (train:: 67.708%) \n",
            "INFO:root:[88,     0] 75.000% (loss: 0.640)\n",
            "INFO:root:[88] (train:: 72.917%) \n",
            "INFO:root:[89,     0] 75.000% (loss: 0.628)\n",
            "INFO:root:[89] (train:: 73.958%) \n",
            "INFO:root:[90,     0] 71.875% (loss: 0.640)\n",
            "INFO:root:[90] (train:: 73.958%) \n",
            "INFO:root:[91,     0] 75.000% (loss: 0.626)\n",
            "INFO:root:[91] (train:: 75.000%) \n",
            "INFO:root:[92,     0] 71.875% (loss: 0.623)\n",
            "INFO:root:[92] (train:: 71.875%) \n",
            "INFO:root:[93,     0] 75.000% (loss: 0.635)\n",
            "INFO:root:[93] (train:: 70.833%) \n",
            "INFO:root:[94,     0] 71.875% (loss: 0.633)\n",
            "INFO:root:[94] (train:: 70.833%) \n",
            "INFO:root:[95,     0] 75.000% (loss: 0.639)\n",
            "INFO:root:[95] (train:: 72.917%) \n",
            "INFO:root:[96,     0] 75.000% (loss: 0.616)\n",
            "INFO:root:[96] (train:: 72.917%) \n",
            "INFO:root:[97,     0] 75.000% (loss: 0.618)\n",
            "INFO:root:[97] (train:: 70.833%) \n",
            "INFO:root:[98,     0] 75.000% (loss: 0.617)\n",
            "INFO:root:[98] (train:: 73.958%) \n",
            "INFO:root:[99,     0] 75.000% (loss: 0.622)\n",
            "INFO:root:[99] (train:: 72.917%) \n",
            "INFO:root:[100,     0] 75.000% (loss: 0.628)\n",
            "INFO:root:[100] (train:: 76.042%) \n",
            "INFO:root:[101,     0] 75.000% (loss: 0.617)\n",
            "INFO:root:[101] (train:: 72.917%) \n",
            "INFO:root:[102,     0] 71.875% (loss: 0.624)\n",
            "INFO:root:[102] (train:: 75.000%) \n",
            "INFO:root:[103,     0] 75.000% (loss: 0.617)\n",
            "INFO:root:[103] (train:: 75.000%) \n",
            "INFO:root:[104,     0] 75.000% (loss: 0.609)\n",
            "INFO:root:[104] (train:: 72.917%) \n",
            "INFO:root:[105,     0] 78.125% (loss: 0.600)\n",
            "INFO:root:[105] (train:: 77.083%) \n",
            "INFO:root:[106,     0] 75.000% (loss: 0.599)\n",
            "INFO:root:[106] (train:: 72.917%) \n",
            "INFO:root:[107,     0] 75.000% (loss: 0.630)\n",
            "INFO:root:[107] (train:: 75.000%) \n",
            "INFO:root:[108,     0] 75.000% (loss: 0.616)\n",
            "INFO:root:[108] (train:: 76.042%) \n",
            "INFO:root:[109,     0] 78.125% (loss: 0.588)\n",
            "INFO:root:[109] (train:: 72.917%) \n",
            "INFO:root:[110,     0] 71.875% (loss: 0.600)\n",
            "INFO:root:[110] (train:: 69.792%) \n",
            "INFO:root:[111,     0] 78.125% (loss: 0.619)\n",
            "INFO:root:[111] (train:: 73.958%) \n",
            "INFO:root:[112,     0] 75.000% (loss: 0.606)\n",
            "INFO:root:[112] (train:: 76.042%) \n",
            "INFO:root:[113,     0] 78.125% (loss: 0.610)\n",
            "INFO:root:[113] (train:: 73.958%) \n",
            "INFO:root:[114,     0] 75.000% (loss: 0.622)\n",
            "INFO:root:[114] (train:: 71.875%) \n",
            "INFO:root:[115,     0] 78.125% (loss: 0.602)\n",
            "INFO:root:[115] (train:: 73.958%) \n",
            "INFO:root:[116,     0] 75.000% (loss: 0.610)\n",
            "INFO:root:[116] (train:: 72.917%) \n",
            "INFO:root:[117,     0] 78.125% (loss: 0.588)\n",
            "INFO:root:[117] (train:: 78.125%) \n",
            "INFO:root:[118,     0] 75.000% (loss: 0.606)\n",
            "INFO:root:[118] (train:: 73.958%) \n",
            "INFO:root:[119,     0] 71.875% (loss: 0.622)\n",
            "INFO:root:[119] (train:: 75.000%) \n",
            "INFO:root:[120,     0] 71.875% (loss: 0.593)\n",
            "INFO:root:[120] (train:: 71.875%) \n",
            "INFO:root:[121,     0] 75.000% (loss: 0.593)\n",
            "INFO:root:[121] (train:: 71.875%) \n",
            "INFO:root:[122,     0] 75.000% (loss: 0.575)\n",
            "INFO:root:[122] (train:: 73.958%) \n",
            "INFO:root:[123,     0] 71.875% (loss: 0.596)\n",
            "INFO:root:[123] (train:: 73.958%) \n",
            "INFO:root:[124,     0] 71.875% (loss: 0.594)\n",
            "INFO:root:[124] (train:: 72.917%) \n",
            "INFO:root:[125,     0] 71.875% (loss: 0.617)\n",
            "INFO:root:[125] (train:: 68.750%) \n",
            "INFO:root:[126,     0] 75.000% (loss: 0.591)\n",
            "INFO:root:[126] (train:: 71.875%) \n",
            "INFO:root:[127,     0] 71.875% (loss: 0.637)\n",
            "INFO:root:[127] (train:: 72.917%) \n",
            "INFO:root:[128,     0] 71.875% (loss: 0.601)\n",
            "INFO:root:[128] (train:: 73.958%) \n",
            "INFO:root:[129,     0] 68.750% (loss: 0.615)\n",
            "INFO:root:[129] (train:: 70.833%) \n",
            "INFO:root:[130,     0] 75.000% (loss: 0.600)\n",
            "INFO:root:[130] (train:: 71.875%) \n",
            "INFO:root:[131,     0] 75.000% (loss: 0.598)\n",
            "INFO:root:[131] (train:: 70.833%) \n",
            "INFO:root:[132,     0] 75.000% (loss: 0.579)\n",
            "INFO:root:[132] (train:: 73.958%) \n",
            "INFO:root:[133,     0] 75.000% (loss: 0.600)\n",
            "INFO:root:[133] (train:: 73.958%) \n",
            "INFO:root:[134,     0] 75.000% (loss: 0.596)\n",
            "INFO:root:[134] (train:: 75.000%) \n",
            "INFO:root:[135,     0] 75.000% (loss: 0.594)\n",
            "INFO:root:[135] (train:: 73.958%) \n",
            "INFO:root:[136,     0] 75.000% (loss: 0.584)\n",
            "INFO:root:[136] (train:: 76.042%) \n",
            "INFO:root:[137,     0] 75.000% (loss: 0.612)\n",
            "INFO:root:[137] (train:: 73.958%) \n",
            "INFO:root:[138,     0] 75.000% (loss: 0.592)\n",
            "INFO:root:[138] (train:: 71.875%) \n",
            "INFO:root:[139,     0] 78.125% (loss: 0.600)\n",
            "INFO:root:[139] (train:: 70.833%) \n",
            "INFO:root:[140,     0] 75.000% (loss: 0.608)\n",
            "INFO:root:[140] (train:: 75.000%) \n",
            "INFO:root:[141,     0] 75.000% (loss: 0.581)\n",
            "INFO:root:[141] (train:: 71.875%) \n",
            "INFO:root:[142,     0] 68.750% (loss: 0.615)\n",
            "INFO:root:[142] (train:: 67.708%) \n",
            "INFO:root:[143,     0] 71.875% (loss: 0.597)\n",
            "INFO:root:[143] (train:: 75.000%) \n",
            "INFO:root:[144,     0] 75.000% (loss: 0.589)\n",
            "INFO:root:[144] (train:: 76.042%) \n",
            "INFO:root:[145,     0] 71.875% (loss: 0.596)\n",
            "INFO:root:[145] (train:: 71.875%) \n",
            "INFO:root:[146,     0] 78.125% (loss: 0.593)\n",
            "INFO:root:[146] (train:: 79.167%) \n",
            "INFO:root:[147,     0] 75.000% (loss: 0.579)\n",
            "INFO:root:[147] (train:: 73.958%) \n",
            "INFO:root:[148,     0] 75.000% (loss: 0.605)\n",
            "INFO:root:[148] (train:: 75.000%) \n",
            "INFO:root:[149,     0] 78.125% (loss: 0.575)\n",
            "INFO:root:[149] (train:: 72.917%) \n",
            "INFO:root:[150,     0] 78.125% (loss: 0.594)\n",
            "INFO:root:[150] (train:: 75.000%) \n",
            "INFO:root:[151,     0] 78.125% (loss: 0.592)\n",
            "INFO:root:[151] (train:: 76.042%) \n",
            "INFO:root:[152,     0] 78.125% (loss: 0.565)\n",
            "INFO:root:[152] (train:: 76.042%) \n",
            "INFO:root:[153,     0] 75.000% (loss: 0.588)\n",
            "INFO:root:[153] (train:: 73.958%) \n",
            "INFO:root:[154,     0] 75.000% (loss: 0.606)\n",
            "INFO:root:[154] (train:: 76.042%) \n",
            "INFO:root:[155,     0] 71.875% (loss: 0.594)\n",
            "INFO:root:[155] (train:: 72.917%) \n",
            "INFO:root:[156,     0] 75.000% (loss: 0.586)\n",
            "INFO:root:[156] (train:: 77.083%) \n",
            "INFO:root:[157,     0] 78.125% (loss: 0.592)\n",
            "INFO:root:[157] (train:: 72.917%) \n",
            "INFO:root:[158,     0] 78.125% (loss: 0.577)\n",
            "INFO:root:[158] (train:: 77.083%) \n",
            "INFO:root:[159,     0] 78.125% (loss: 0.595)\n",
            "INFO:root:[159] (train:: 75.000%) \n",
            "INFO:root:[160,     0] 75.000% (loss: 0.602)\n",
            "INFO:root:[160] (train:: 77.083%) \n",
            "INFO:root:[161,     0] 75.000% (loss: 0.589)\n",
            "INFO:root:[161] (train:: 72.917%) \n",
            "INFO:root:[162,     0] 81.250% (loss: 0.597)\n",
            "INFO:root:[162] (train:: 78.125%) \n",
            "INFO:root:[163,     0] 71.875% (loss: 0.590)\n",
            "INFO:root:[163] (train:: 70.833%) \n",
            "INFO:root:[164,     0] 75.000% (loss: 0.582)\n",
            "INFO:root:[164] (train:: 73.958%) \n",
            "INFO:root:[165,     0] 75.000% (loss: 0.593)\n",
            "INFO:root:[165] (train:: 75.000%) \n",
            "INFO:root:[166,     0] 78.125% (loss: 0.589)\n",
            "INFO:root:[166] (train:: 78.125%) \n",
            "INFO:root:[167,     0] 75.000% (loss: 0.597)\n",
            "INFO:root:[167] (train:: 72.917%) \n",
            "INFO:root:[168,     0] 78.125% (loss: 0.579)\n",
            "INFO:root:[168] (train:: 71.875%) \n",
            "INFO:root:[169,     0] 71.875% (loss: 0.607)\n",
            "INFO:root:[169] (train:: 73.958%) \n",
            "INFO:root:[170,     0] 75.000% (loss: 0.593)\n",
            "INFO:root:[170] (train:: 73.958%) \n",
            "INFO:root:[171,     0] 71.875% (loss: 0.600)\n",
            "INFO:root:[171] (train:: 76.042%) \n",
            "INFO:root:[172,     0] 75.000% (loss: 0.578)\n",
            "INFO:root:[172] (train:: 73.958%) \n",
            "INFO:root:[173,     0] 75.000% (loss: 0.589)\n",
            "INFO:root:[173] (train:: 73.958%) \n",
            "INFO:root:[174,     0] 78.125% (loss: 0.590)\n",
            "INFO:root:[174] (train:: 72.917%) \n",
            "INFO:root:[175,     0] 75.000% (loss: 0.569)\n",
            "INFO:root:[175] (train:: 71.875%) \n",
            "INFO:root:[176,     0] 71.875% (loss: 0.591)\n",
            "INFO:root:[176] (train:: 73.958%) \n",
            "INFO:root:[177,     0] 78.125% (loss: 0.582)\n",
            "INFO:root:[177] (train:: 73.958%) \n",
            "INFO:root:[178,     0] 68.750% (loss: 0.582)\n",
            "INFO:root:[178] (train:: 72.917%) \n",
            "INFO:root:[179,     0] 78.125% (loss: 0.579)\n",
            "INFO:root:[179] (train:: 76.042%) \n",
            "INFO:root:[180,     0] 68.750% (loss: 0.616)\n",
            "INFO:root:[180] (train:: 70.833%) \n",
            "INFO:root:[181,     0] 75.000% (loss: 0.570)\n",
            "INFO:root:[181] (train:: 73.958%) \n",
            "INFO:root:[182,     0] 71.875% (loss: 0.589)\n",
            "INFO:root:[182] (train:: 72.917%) \n",
            "INFO:root:[183,     0] 71.875% (loss: 0.579)\n",
            "INFO:root:[183] (train:: 72.917%) \n",
            "INFO:root:[184,     0] 71.875% (loss: 0.578)\n",
            "INFO:root:[184] (train:: 71.875%) \n",
            "INFO:root:[185,     0] 75.000% (loss: 0.589)\n",
            "INFO:root:[185] (train:: 71.875%) \n",
            "INFO:root:[186,     0] 71.875% (loss: 0.600)\n",
            "INFO:root:[186] (train:: 71.875%) \n",
            "INFO:root:[187,     0] 75.000% (loss: 0.573)\n",
            "INFO:root:[187] (train:: 75.000%) \n",
            "INFO:root:[188,     0] 78.125% (loss: 0.572)\n",
            "INFO:root:[188] (train:: 73.958%) \n",
            "INFO:root:[189,     0] 78.125% (loss: 0.569)\n",
            "INFO:root:[189] (train:: 75.000%) \n",
            "INFO:root:[190,     0] 78.125% (loss: 0.576)\n",
            "INFO:root:[190] (train:: 73.958%) \n",
            "INFO:root:[191,     0] 78.125% (loss: 0.574)\n",
            "INFO:root:[191] (train:: 76.042%) \n",
            "INFO:root:[192,     0] 75.000% (loss: 0.568)\n",
            "INFO:root:[192] (train:: 73.958%) \n",
            "INFO:root:[193,     0] 78.125% (loss: 0.551)\n",
            "INFO:root:[193] (train:: 76.042%) \n",
            "INFO:root:[194,     0] 71.875% (loss: 0.583)\n",
            "INFO:root:[194] (train:: 71.875%) \n",
            "INFO:root:[195,     0] 78.125% (loss: 0.587)\n",
            "INFO:root:[195] (train:: 73.958%) \n",
            "INFO:root:[196,     0] 75.000% (loss: 0.573)\n",
            "INFO:root:[196] (train:: 77.083%) \n",
            "INFO:root:[197,     0] 78.125% (loss: 0.579)\n",
            "INFO:root:[197] (train:: 72.917%) \n",
            "INFO:root:[198,     0] 71.875% (loss: 0.573)\n",
            "INFO:root:[198] (train:: 76.042%) \n",
            "INFO:root:[199,     0] 75.000% (loss: 0.589)\n",
            "INFO:root:[199] (train:: 75.000%) \n",
            "INFO:root:[200,     0] 75.000% (loss: 0.582)\n",
            "INFO:root:[200] (train:: 76.042%) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3H-iYM4MTnD"
      },
      "source": [
        "## Script\n",
        "Didnt use it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5UUGnrhTkf2"
      },
      "source": [
        "#pwd"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjNgGdzpM5Ei"
      },
      "source": [
        "#cd suncet"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnzF3XuAMXFW"
      },
      "source": [
        "#!python main.py --sel fine_tune --fname configs/paws/dr_fine_tune.yaml"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "B5kQkbiz6nRs",
        "outputId": "6f48da40-cb49-46a8-c471-54413a9abdf1"
      },
      "source": [
        "# Didnt work using this I would need to fix it in order to use it. \n",
        "\"\"\"\n",
        "import src.resnet as resnet\n",
        "\n",
        "device = \"cuda:0\"\n",
        "device_str = \"cuda:0\"\n",
        "\n",
        "folder = \"suncet/logs/\"\n",
        "r_file_enc = \"paws-ep30.pth.tar\" # CHANGE\n",
        "\n",
        "# -- log/checkpointing paths\n",
        "r_enc_path = os.path.join(folder, r_file_enc)\n",
        "w_enc_path = os.path.join(folder, f'{tag}-fine-tune.pth.tar')\n",
        "\n",
        "encoder = resnet.__dict__[\"resnet50\"]()\n",
        "\n",
        "hidden_dim = 2048\n",
        "if 'w2' in model_name:\n",
        "    hidden_dim *= 2\n",
        "elif 'w4' in model_name:\n",
        "    hidden_dim *= 4\n",
        "\n",
        "# -- projection head\n",
        "encoder.fc = torch.nn.Sequential(OrderedDict([\n",
        "    ('fc1', torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "    ('bn1', torch.nn.BatchNorm1d(hidden_dim)),\n",
        "    ('relu1', torch.nn.ReLU(inplace=True)),\n",
        "    ('fc2', torch.nn.Linear(hidden_dim, 1)), # YO changed\n",
        "    ('sg', torch.nn.Sigmoid())  # YO \n",
        "]))\n",
        "\n",
        "encoder = load_pretrained(\n",
        "    r_path=r_enc_path,\n",
        "    encoder=encoder,\n",
        "    device_str=device_str)\n",
        "\"\"\""
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport src.resnet as resnet\\n\\ndevice = \"cuda:0\"\\ndevice_str = \"cuda:0\"\\n\\nfolder = \"suncet/logs/\"\\nr_file_enc = \"paws-ep30.pth.tar\" # CHANGE\\n\\n# -- log/checkpointing paths\\nr_enc_path = os.path.join(folder, r_file_enc)\\nw_enc_path = os.path.join(folder, f\\'{tag}-fine-tune.pth.tar\\')\\n\\nencoder = resnet.__dict__[\"resnet50\"]()\\n\\nhidden_dim = 2048\\nif \\'w2\\' in model_name:\\n    hidden_dim *= 2\\nelif \\'w4\\' in model_name:\\n    hidden_dim *= 4\\n\\n# -- projection head\\nencoder.fc = torch.nn.Sequential(OrderedDict([\\n    (\\'fc1\\', torch.nn.Linear(hidden_dim, hidden_dim)),\\n    (\\'bn1\\', torch.nn.BatchNorm1d(hidden_dim)),\\n    (\\'relu1\\', torch.nn.ReLU(inplace=True)),\\n    (\\'fc2\\', torch.nn.Linear(hidden_dim, 1)), # YO changed\\n    (\\'sg\\', torch.nn.Sigmoid())  # YO \\n]))\\n\\nencoder = load_pretrained(\\n    r_path=r_enc_path,\\n    encoder=encoder,\\n    device_str=device_str)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYMJuCkw6lmp"
      },
      "source": [
        "## Test PAWS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGl9tX0j86w7",
        "outputId": "948778e0-c52a-4c2a-c5e1-87f9bfef6457"
      },
      "source": [
        "encoder"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "    (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (fc2): Linear(in_features=2048, out_features=1, bias=True)\n",
              "    (sg): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liTWKXSk8p2t"
      },
      "source": [
        "test_data = {\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\",\n",
        "    \"messidor2\": \"https://drive.google.com/uc?id=1HaUAxDtN4BNj0hpH8QYGmiX39Va-Ke8p\",\n",
        "}\n",
        "\n",
        "TEST_DATASET = 'voets_test_images'\n",
        "URL_TEST_DATASET = test_data[TEST_DATASET]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFTyY-3S9-ZJ",
        "outputId": "cea6045d-63b7-4945-b83e-5556c8d6098e"
      },
      "source": [
        "!gdown $URL_TEST_DATASET"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\n",
            "To: /content/voets_test_images.zip\n",
            "475MB [00:04, 100MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "09MLSbAoIJOh",
        "outputId": "b2750f93-ed6f-4b12-8e49-df12ac79d666"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoekpReH-KTu"
      },
      "source": [
        "import zipfile\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH2Wn-Ss-BZv"
      },
      "source": [
        "local_zip = '{}.zip'.format(TEST_DATASET)\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPWFz71B-TTf"
      },
      "source": [
        "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
        "cifar10_std = (0.2471, 0.2435, 0.2616)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRkfHgyU-VUO"
      },
      "source": [
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=cifar10_mean, std=cifar10_std)  # What happens if I change This \n",
        "])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7yq-EIQ-ubL",
        "outputId": "83de5bac-b880-47cc-fa5e-cdb44da75282"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RE5t5oz-fLR"
      },
      "source": [
        "test_dataset = datasets.ImageFolder(root=\"test\", transform=transform_val) # root: test/messidor2"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wrp0_Y1-gIq"
      },
      "source": [
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    num_workers=1,\n",
        "    shuffle=False)\n",
        "\n",
        "loader = test_loader"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj8Ay-IF_ICN"
      },
      "source": [
        "model = encoder"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar8BjCT6-_uz",
        "outputId": "c88a701d-4bfc-4587-e6d3-3e3faf56023d"
      },
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    with tqdm(total=len(loader)) as pbar:\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "\n",
        "            output = output.to(device)\n",
        "\n",
        "            # Yo le agrege esto\n",
        "            y_true.append(targets.cpu().detach().numpy()[0])\n",
        "            y_pred.append(output.cpu().detach().numpy()[0][0])\n",
        "\n",
        "            pbar.update(1)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8790/8790 [01:35<00:00, 91.62it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMBrm01w_o-G",
        "outputId": "769cc0fc-c04a-45ef-be80-68d77ed1b47d"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
        "metrics.auc(fpr, tpr)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8072923192582384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "xtZ_ms7s_t6o",
        "outputId": "c3ab5e82-9de4-496d-8687-eef0d133f193"
      },
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from mlxtend.plotting import plot_confusion_matrix \n",
        "# %matplotlib inline\n",
        "\n",
        "#cm=metrics.confusion_matrix(y_true, y_pred)\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "#print('AUC: %.3f' % auc)\n",
        "#print('Accuracy: {}'.format(accuracy_score(y_true, y_pred)))\n",
        "\n",
        "# Plot ROC curve\n",
        "lw = 2\n",
        "sns.set_style({'axes.grid' : False})\n",
        "sns.set_style(\"darkgrid\")\n",
        "ax1 = sns.lineplot(fpr, tpr, color='darkorange',\n",
        "        lw=lw, label='AUC = %0.2f' % auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "ax1.set_title('Receiver operating characteristic')\n",
        "ax1.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0GT7rfFLiis"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}