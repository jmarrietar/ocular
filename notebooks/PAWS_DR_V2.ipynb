{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRUEBA-PAWS-DR-V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMOK---fIybU",
        "outputId": "86df6cde-6742-4066-8dfa-d61688152bba"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --no-cache-dir ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'apex' already exists and is not an empty directory.\n",
            "/content/apex\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-6exx890d\n",
            "Created temporary directory: /tmp/pip-req-tracker-fp6dy2q4\n",
            "Created requirements tracker '/tmp/pip-req-tracker-fp6dy2q4'\n",
            "Created temporary directory: /tmp/pip-install-hub1g1kw\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-xi7_j_d6\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-fp6dy2q4'\n",
            "    Running setup.py (path:/tmp/pip-req-build-xi7_j_d6/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.8.1+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-xi7_j_d6/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-xi7_j_d6/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-xi7_j_d6/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-xi7_j_d6/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-xi7_j_d6/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file '/tmp/pip-req-build-xi7_j_d6/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-xi7_j_d6/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-xi7_j_d6 has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-fp6dy2q4'\n",
            "Building wheels for collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-wheel-r97mhsrh\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-r97mhsrh\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-xi7_j_d6/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-xi7_j_d6/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-r97mhsrh --python-tag cp37\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.8.1+cu101\n",
            "\n",
            "\n",
            "  /tmp/pip-req-build-xi7_j_d6/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/apex\n",
            "  copying apex/__init__.py -> build/lib/apex\n",
            "  creating build/lib/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
            "  creating build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
            "  creating build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
            "  creating build/lib/apex/mlp\n",
            "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
            "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
            "  creating build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
            "  creating build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
            "  creating build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
            "  creating build/lib/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
            "  creating build/lib/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
            "  creating build/lib/apex/pyprof\n",
            "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
            "  creating build/lib/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
            "  creating build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
            "  creating build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
            "  creating build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
            "  creating build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
            "  creating build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/__init__.py -> build/lib/apex/contrib/layer_norm\n",
            "  creating build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/test.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/__init__.py -> build/lib/apex/contrib/bottleneck\n",
            "  creating build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/transducer.py -> build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/__init__.py -> build/lib/apex/contrib/transducer\n",
            "  creating build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
            "  creating build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
            "  creating build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
            "  creating build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/fmha.py -> build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/__init__.py -> build/lib/apex/contrib/fmha\n",
            "  creating build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  creating build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.7.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-r97mhsrh/apex-0.1-cp37-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'apex/__init__.py'\n",
            "  adding 'apex/RNN/RNNBackend.py'\n",
            "  adding 'apex/RNN/__init__.py'\n",
            "  adding 'apex/RNN/cells.py'\n",
            "  adding 'apex/RNN/models.py'\n",
            "  adding 'apex/amp/__init__.py'\n",
            "  adding 'apex/amp/__version__.py'\n",
            "  adding 'apex/amp/_amp_state.py'\n",
            "  adding 'apex/amp/_initialize.py'\n",
            "  adding 'apex/amp/_process_optimizer.py'\n",
            "  adding 'apex/amp/amp.py'\n",
            "  adding 'apex/amp/compat.py'\n",
            "  adding 'apex/amp/frontend.py'\n",
            "  adding 'apex/amp/handle.py'\n",
            "  adding 'apex/amp/opt.py'\n",
            "  adding 'apex/amp/rnn_compat.py'\n",
            "  adding 'apex/amp/scaler.py'\n",
            "  adding 'apex/amp/utils.py'\n",
            "  adding 'apex/amp/wrap.py'\n",
            "  adding 'apex/amp/lists/__init__.py'\n",
            "  adding 'apex/amp/lists/functional_overrides.py'\n",
            "  adding 'apex/amp/lists/tensor_overrides.py'\n",
            "  adding 'apex/amp/lists/torch_overrides.py'\n",
            "  adding 'apex/contrib/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/bottleneck.py'\n",
            "  adding 'apex/contrib/bottleneck/test.py'\n",
            "  adding 'apex/contrib/fmha/__init__.py'\n",
            "  adding 'apex/contrib/fmha/fmha.py'\n",
            "  adding 'apex/contrib/groupbn/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
            "  adding 'apex/contrib/layer_norm/__init__.py'\n",
            "  adding 'apex/contrib/layer_norm/layer_norm.py'\n",
            "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
            "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
            "  adding 'apex/contrib/sparsity/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/asp.py'\n",
            "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
            "  adding 'apex/contrib/transducer/__init__.py'\n",
            "  adding 'apex/contrib/transducer/transducer.py'\n",
            "  adding 'apex/contrib/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
            "  adding 'apex/fp16_utils/__init__.py'\n",
            "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
            "  adding 'apex/fp16_utils/fp16util.py'\n",
            "  adding 'apex/fp16_utils/loss_scaler.py'\n",
            "  adding 'apex/mlp/__init__.py'\n",
            "  adding 'apex/mlp/mlp.py'\n",
            "  adding 'apex/multi_tensor_apply/__init__.py'\n",
            "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
            "  adding 'apex/normalization/__init__.py'\n",
            "  adding 'apex/normalization/fused_layer_norm.py'\n",
            "  adding 'apex/optimizers/__init__.py'\n",
            "  adding 'apex/optimizers/fused_adagrad.py'\n",
            "  adding 'apex/optimizers/fused_adam.py'\n",
            "  adding 'apex/optimizers/fused_lamb.py'\n",
            "  adding 'apex/optimizers/fused_novograd.py'\n",
            "  adding 'apex/optimizers/fused_sgd.py'\n",
            "  adding 'apex/parallel/LARC.py'\n",
            "  adding 'apex/parallel/__init__.py'\n",
            "  adding 'apex/parallel/distributed.py'\n",
            "  adding 'apex/parallel/multiproc.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
            "  adding 'apex/parallel/sync_batchnorm.py'\n",
            "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
            "  adding 'apex/pyprof/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
            "  adding 'apex/pyprof/parse/__init__.py'\n",
            "  adding 'apex/pyprof/parse/__main__.py'\n",
            "  adding 'apex/pyprof/parse/db.py'\n",
            "  adding 'apex/pyprof/parse/kernel.py'\n",
            "  adding 'apex/pyprof/parse/nvvp.py'\n",
            "  adding 'apex/pyprof/parse/parse.py'\n",
            "  adding 'apex/pyprof/prof/__init__.py'\n",
            "  adding 'apex/pyprof/prof/__main__.py'\n",
            "  adding 'apex/pyprof/prof/activation.py'\n",
            "  adding 'apex/pyprof/prof/base.py'\n",
            "  adding 'apex/pyprof/prof/blas.py'\n",
            "  adding 'apex/pyprof/prof/conv.py'\n",
            "  adding 'apex/pyprof/prof/convert.py'\n",
            "  adding 'apex/pyprof/prof/data.py'\n",
            "  adding 'apex/pyprof/prof/dropout.py'\n",
            "  adding 'apex/pyprof/prof/embedding.py'\n",
            "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
            "  adding 'apex/pyprof/prof/linear.py'\n",
            "  adding 'apex/pyprof/prof/loss.py'\n",
            "  adding 'apex/pyprof/prof/misc.py'\n",
            "  adding 'apex/pyprof/prof/normalization.py'\n",
            "  adding 'apex/pyprof/prof/optim.py'\n",
            "  adding 'apex/pyprof/prof/output.py'\n",
            "  adding 'apex/pyprof/prof/pointwise.py'\n",
            "  adding 'apex/pyprof/prof/pooling.py'\n",
            "  adding 'apex/pyprof/prof/prof.py'\n",
            "  adding 'apex/pyprof/prof/randomSample.py'\n",
            "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
            "  adding 'apex/pyprof/prof/reduction.py'\n",
            "  adding 'apex/pyprof/prof/softmax.py'\n",
            "  adding 'apex/pyprof/prof/usage.py'\n",
            "  adding 'apex/pyprof/prof/utility.py'\n",
            "  adding 'apex/reparameterization/__init__.py'\n",
            "  adding 'apex/reparameterization/reparameterization.py'\n",
            "  adding 'apex/reparameterization/weight_norm.py'\n",
            "  adding 'apex-0.1.dist-info/LICENSE'\n",
            "  adding 'apex-0.1.dist-info/METADATA'\n",
            "  adding 'apex-0.1.dist-info/WHEEL'\n",
            "  adding 'apex-0.1.dist-info/top_level.txt'\n",
            "  adding 'apex-0.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp37-none-any.whl size=204709 sha256=44f6f17e397a886b241da07050a66ad99c16b4ac99098e1bb4fd0efd20de6a78\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6exx890d/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n",
            "  Removing source in /tmp/pip-req-build-xi7_j_d6\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "  Found existing installation: apex 0.1\n",
            "    Uninstalling apex-0.1:\n",
            "      Created temporary directory: /usr/local/lib/python3.7/dist-packages/~pex-0.1.dist-info\n",
            "      Removing file or directory /usr/local/lib/python3.7/dist-packages/apex-0.1.dist-info/\n",
            "      Created temporary directory: /usr/local/lib/python3.7/dist-packages/~pex\n",
            "      Removing file or directory /usr/local/lib/python3.7/dist-packages/apex/\n",
            "      Successfully uninstalled apex-0.1\n",
            "\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-fp6dy2q4'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNJ6Mm47L8va",
        "outputId": "43b58f17-1751-4ce0-8ef9-1d1665f9bacb"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLnv9a1KI4Kw",
        "outputId": "c5b0886d-83e4-4dc2-f568-190b3aee9151"
      },
      "source": [
        "!pip install -U PyYAML"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: PyYAML in /usr/local/lib/python3.7/dist-packages (5.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtzuPkdULBN3",
        "outputId": "5af0f31f-fe79-4291-f87f-7a5f654143c3"
      },
      "source": [
        "!git clone -b feature/DR-images https://github.com/jmarrietar/suncet.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'suncet' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Wde8n6Lt1o",
        "outputId": "83ccc646-8cc3-4575-eecf-c1c6082485c2"
      },
      "source": [
        "cd suncet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3k2tcpwL0CI"
      },
      "source": [
        "!mkdir datasets"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw-m0tC1LsaY"
      },
      "source": [
        "!mkdir datasets/dr"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvbAmvhfLxFR"
      },
      "source": [
        "!mkdir logs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmsEG-_tNxUU",
        "outputId": "e552a90e-f5a5-4f01-d231-3c51132f02a9"
      },
      "source": [
        "!python download.py -d sample@1000"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\n",
            "To: /content/suncet/datasets/dr/sample@1000.zip\n",
            "108MB [00:00, 110MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "err0RvLzOC0d",
        "outputId": "456268f3-b636-4082-9a76-6ed6feee6ab5"
      },
      "source": [
        "!python3 main.py --sel paws_train --fname configs/paws/dr_train.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:called-params paws_train configs/paws/dr_train.yaml\n",
            "INFO:root:loaded params...\n",
            "{   'criterion': {   'classes_per_batch': 2,\n",
            "                     'me_max': True,\n",
            "                     'sharpen': 0.25,\n",
            "                     'supervised_epochs': 10,\n",
            "                     'supervised_imgs_per_class': 32,\n",
            "                     'supervised_views': 1,\n",
            "                     'temperature': 0.1,\n",
            "                     'unsupervised_batch_size': 32},\n",
            "    'data': {   'color_jitter_strength': 1.0,\n",
            "                'data_seed': None,\n",
            "                'dataset': 'dr',\n",
            "                'image_folder': 'dr/sample@1000/',\n",
            "                'label_smoothing': 0.1,\n",
            "                'multicrop': 0,\n",
            "                'normalize': True,\n",
            "                'root_path': 'datasets/',\n",
            "                'subset_path': 'dr_subsets',\n",
            "                'unique_classes_per_rank': False,\n",
            "                'unlabeled_frac': 0.9},\n",
            "    'logging': {'folder': 'logs/', 'write_tag': 'paws'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'model_name': 'resnet50',\n",
            "                'output_dim': 2048,\n",
            "                'read_checkpoint': None,\n",
            "                'use_fp16': True,\n",
            "                'use_pred_head': True},\n",
            "    'optimization': {   'epochs': 10,\n",
            "                        'final_lr': 0.064,\n",
            "                        'lr': 6.4,\n",
            "                        'momentum': 0.9,\n",
            "                        'nesterov': False,\n",
            "                        'start_lr': 0.3,\n",
            "                        'warmup': 10,\n",
            "                        'weight_decay': 1e-06}}\n",
            "INFO:root:Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO:root:Running paws_train (rank: 0/1)\n",
            "INFO:root:Initialized (rank/world-size) 0/1\n",
            "INFO:root:ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "    (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu1): ReLU(inplace=True)\n",
            "    (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "    (bn2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu2): ReLU(inplace=True)\n",
            "    (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "  )\n",
            "  (pred): Sequential(\n",
            "    (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (fc2): Linear(in_features=512, out_features=2048, bias=True)\n",
            "  )\n",
            ")\n",
            "normalize True\n",
            "INFO:root:making imagenet data transforms\n",
            "INFO:root:keep file: dr_subsets/90percent.txt\n",
            "INFO:root:copying data locally\n",
            "INFO:root:No job-id, will load directly from network file\n",
            "INFO:root:data-path datasets/dr/sample@1000/train/\n",
            "INFO:root:Initialized ImageDR\n",
            "INFO:root:ImageDR dataset created\n",
            "self.multicrop_transform (0, None)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "INFO:root:ImageDR unsupervised data loader created\n",
            "INFO:root:Making supervised ImageDR data loader...\n",
            "self.multicrop_transform (0, None)\n",
            "INFO:root:flipping coin to keep labels\n",
            "INFO:root:supervised-reset-period 31\n",
            "INFO:root:ImageDR supervised data loader created\n",
            "INFO:root:iterations per epoch: 31\n",
            "INFO:root:Epoch 1\n",
            "INFO:root:len.supervised_loader: 31\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "INFO:root:[1,     0] loss: 0.018 (0.700 -0.682) (5742 ms; 8555 ms)\n",
            "INFO:root:[1,    10] loss: 0.006 (0.695 -0.689) (1183 ms; 792 ms)\n",
            "INFO:root:[1,    10] lr_stats: 0.095 (4.32e-05, 2.58e+00)\n",
            "INFO:root:[1,    20] loss: 0.010 (0.699 -0.689) (1009 ms; 420 ms)\n",
            "INFO:root:[1,    20] lr_stats: 0.106 (4.02e-05, 2.91e+00)\n",
            "INFO:root:[1,    30] loss: 0.012 (0.701 -0.689) (860 ms; 287 ms)\n",
            "INFO:root:[1,    30] lr_stats: 0.148 (1.45e-04, 3.93e+00)\n",
            "INFO:root:avg. loss 0.012\n",
            "INFO:root:updating \"best\" checkpoint\n",
            "INFO:root:Epoch 2\n",
            "INFO:root:len.supervised_loader: 31\n",
            "INFO:root:[2,     0] loss: 0.011 (0.698 -0.687) (831 ms; 9313 ms)\n",
            "INFO:root:[2,     0] lr_stats: 0.137 (1.94e-04, 3.62e+00)\n",
            "INFO:root:[2,    10] loss: 0.000 (0.689 -0.689) (873 ms; 865 ms)\n",
            "INFO:root:[2,    10] lr_stats: 0.261 (4.74e-04, 6.41e+00)\n",
            "INFO:root:[2,    20] loss: 0.007 (0.694 -0.687) (875 ms; 508 ms)\n",
            "INFO:root:[2,    20] lr_stats: 0.522 (2.18e-03, 1.14e+01)\n",
            "INFO:root:[2,    30] loss: 0.005 (0.692 -0.688) (772 ms; 347 ms)\n",
            "INFO:root:[2,    30] lr_stats: 2.126 (6.06e-03, 4.36e+01)\n",
            "INFO:root:avg. loss 0.005\n",
            "INFO:root:updating \"best\" checkpoint\n",
            "INFO:root:Epoch 3\n",
            "INFO:root:len.supervised_loader: 31\n",
            "INFO:root:[3,     0] loss: -0.010 (0.683 -0.693) (825 ms; 9280 ms)\n",
            "INFO:root:[3,     0] lr_stats: 1.845 (4.16e-03, 3.77e+01)\n",
            "INFO:root:[3,    10] loss: 0.003 (0.694 -0.691) (868 ms; 870 ms)\n",
            "INFO:root:[3,    10] lr_stats: 6.533 (6.72e-03, 1.38e+02)\n",
            "INFO:root:[3,    20] loss: 0.002 (0.693 -0.691) (860 ms; 499 ms)\n",
            "INFO:root:[3,    20] lr_stats: 8.060 (1.05e-02, 1.61e+02)\n",
            "INFO:root:[3,    30] loss: 0.002 (0.694 -0.692) (764 ms; 340 ms)\n",
            "INFO:root:[3,    30] lr_stats: 6.238 (6.23e-03, 1.24e+02)\n",
            "INFO:root:avg. loss 0.002\n",
            "INFO:root:updating \"best\" checkpoint\n",
            "INFO:root:Epoch 4\n",
            "INFO:root:len.supervised_loader: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnsVn-76YM-L"
      },
      "source": [
        "TO DO: Averiguar esto del Multicrop y por que PAWS funciono funciono luego de que lo cambiara a zero?. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO8tH43fQkOy"
      },
      "source": [
        "###################################\n",
        "########### DEBUG #################\n",
        "###################################"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrIVUPQ-OtgA"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import os\n",
        "\n",
        "# -- FOR DISTRIBUTED TRAINING ENSURE ONLY 1 DEVICE VISIBLE PER PROCESS\n",
        "try:\n",
        "    # -- WARNING: IF DOING DISTRIBUTED TRAINING ON A NON-SLURM CLUSTER, MAKE\n",
        "    # --          SURE TO UPDATE THIS TO GET LOCAL-RANK ON NODE, OR ENSURE\n",
        "    # --          THAT YOUR JOBS ARE LAUNCHED WITH ONLY 1 DEVICE VISIBLE\n",
        "    # --          TO EACH PROCESS\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['SLURM_LOCALID']\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    gpu_timer,\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule,\n",
        "    CSVLogger,\n",
        "    AverageMeter\n",
        ")\n",
        "from src.losses import (\n",
        "    init_simclr_loss,\n",
        "    init_suncet_loss,\n",
        "    make_labels_matrix\n",
        ")\n",
        "from src.data_manager import (\n",
        "    init_data,\n",
        "    make_transforms\n",
        ")\n",
        "from src.sgd import SGD\n",
        "from src.lars import LARS\n",
        "\n",
        "import apex\n",
        "from torch.nn.parallel import DistributedDataParallel"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipzQE81M8M34"
      },
      "source": [
        "import argparse\n",
        "\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "import pprint\n",
        "import yaml"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwAs6qDZOt-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64565c5-2ee3-4b8a-cc2a-16ac3e557d2a"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    '--fname', type=str,\n",
        "    help='name of config file to load',\n",
        "    default='configs.yaml')\n",
        "parser.add_argument(\n",
        "    '--devices', type=str, nargs='+', default=['cuda:0'],\n",
        "    help='which devices to use on local machine')\n",
        "parser.add_argument(\n",
        "    '--sel', type=str,\n",
        "    help='which script to run',\n",
        "    choices=[\n",
        "        'paws_train',\n",
        "        'suncet_train',\n",
        "        'fine_tune',\n",
        "        'snn_fine_tune'\n",
        "    ])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--sel'], dest='sel', nargs=None, const=None, default=None, type=<class 'str'>, choices=['paws_train', 'suncet_train', 'fine_tune', 'snn_fine_tune'], help='which script to run', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn4XZJQp8PeP"
      },
      "source": [
        "args = parser.parse_args(['--sel', 'paws_train',\n",
        "                            '--fname', 'configs/paws/dr_train.yaml'\n",
        "])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSgFwGeQ8hXH"
      },
      "source": [
        "fname = args.fname\n",
        "sel = args.sel"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmjn7Zox9A8R"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "\n",
        "logger.info(f'called-params {sel} {fname}')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxvQkH7W9F1m"
      },
      "source": [
        "rank = 0"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLnfu2Cy8a2s",
        "outputId": "da13b7cf-1c75-4c03-aa3e-452ead56e42e"
      },
      "source": [
        "# -- load script params\n",
        "params = None\n",
        "with open(fname, 'r') as y_file:\n",
        "    params = yaml.load(y_file, Loader=yaml.FullLoader)\n",
        "    logger.info('loaded params...')\n",
        "    if rank == 0:\n",
        "        pp = pprint.PrettyPrinter(indent=4)\n",
        "        pp.pprint(params)\n",
        "\n",
        "if rank == 0:\n",
        "    dump = os.path.join(params['logging']['folder'], f'params-{sel}.yaml')\n",
        "    with open(dump, 'w') as f:\n",
        "        yaml.dump(params, f)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{   'criterion': {   'classes_per_batch': 2,\n",
            "                     'me_max': True,\n",
            "                     'sharpen': 0.25,\n",
            "                     'supervised_epochs': 10,\n",
            "                     'supervised_imgs_per_class': 32,\n",
            "                     'supervised_views': 1,\n",
            "                     'temperature': 0.1,\n",
            "                     'unsupervised_batch_size': 32},\n",
            "    'data': {   'color_jitter_strength': 1.0,\n",
            "                'data_seed': None,\n",
            "                'dataset': 'dr',\n",
            "                'image_folder': 'dr/sample@1000/',\n",
            "                'label_smoothing': 0.1,\n",
            "                'multicrop': 6,\n",
            "                'normalize': True,\n",
            "                'root_path': 'datasets/',\n",
            "                'subset_path': 'dr_subsets',\n",
            "                'unique_classes_per_rank': False,\n",
            "                'unlabeled_frac': 0.9},\n",
            "    'logging': {'folder': 'logs/', 'write_tag': 'paws'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'model_name': 'resnet50',\n",
            "                'output_dim': 2048,\n",
            "                'read_checkpoint': None,\n",
            "                'use_fp16': True,\n",
            "                'use_pred_head': True},\n",
            "    'optimization': {   'epochs': 10,\n",
            "                        'final_lr': 0.064,\n",
            "                        'lr': 6.4,\n",
            "                        'momentum': 0.9,\n",
            "                        'nesterov': False,\n",
            "                        'start_lr': 0.3,\n",
            "                        'warmup': 10,\n",
            "                        'weight_decay': 1e-06}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt2vccIl9TVG"
      },
      "source": [
        "args = params"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkNEurLVBoGR"
      },
      "source": [
        "# PAWS TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9AB7j11CyvV"
      },
      "source": [
        "def init_model(\n",
        "    device,\n",
        "    model_name='resnet50',\n",
        "    use_pred=False,\n",
        "    output_dim=128\n",
        "):\n",
        "    if 'wide_resnet' in model_name:\n",
        "        encoder = wide_resnet.__dict__[model_name](dropout_rate=0.0)\n",
        "        hidden_dim = 128\n",
        "    else:\n",
        "        encoder = resnet.__dict__[model_name]()\n",
        "        hidden_dim = 2048\n",
        "        if 'w2' in model_name:\n",
        "            hidden_dim *= 2\n",
        "        elif 'w4' in model_name:\n",
        "            hidden_dim *= 4\n",
        "\n",
        "    # -- projection head\n",
        "    encoder.fc = torch.nn.Sequential(OrderedDict([\n",
        "        ('fc1', torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "        ('bn1', torch.nn.BatchNorm1d(hidden_dim)),\n",
        "        ('relu1', torch.nn.ReLU(inplace=True)),\n",
        "        ('fc2', torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "        ('bn2', torch.nn.BatchNorm1d(hidden_dim)),\n",
        "        ('relu2', torch.nn.ReLU(inplace=True)),\n",
        "        ('fc3', torch.nn.Linear(hidden_dim, output_dim))\n",
        "    ]))\n",
        "\n",
        "    # -- prediction head\n",
        "    encoder.pred = None\n",
        "    if use_pred:\n",
        "        mx = 4  # 4x bottleneck prediction head\n",
        "        pred_head = OrderedDict([])\n",
        "        pred_head['bn1'] = torch.nn.BatchNorm1d(output_dim)\n",
        "        pred_head['fc1'] = torch.nn.Linear(output_dim, output_dim//mx)\n",
        "        pred_head['bn2'] = torch.nn.BatchNorm1d(output_dim//mx)\n",
        "        pred_head['relu'] = torch.nn.ReLU(inplace=True)\n",
        "        pred_head['fc2'] = torch.nn.Linear(output_dim//mx, output_dim)\n",
        "        encoder.pred = torch.nn.Sequential(pred_head)\n",
        "\n",
        "    encoder.to(device)\n",
        "    logger.info(encoder)\n",
        "    return encoder"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMVCrtVqDf1z"
      },
      "source": [
        "def init_opt(\n",
        "    encoder,\n",
        "    iterations_per_epoch,\n",
        "    start_lr,\n",
        "    ref_lr,\n",
        "    ref_mom,\n",
        "    nesterov,\n",
        "    warmup,\n",
        "    num_epochs,\n",
        "    weight_decay=1e-6,\n",
        "    final_lr=0.0\n",
        "):\n",
        "    param_groups = [\n",
        "        {'params': (p for n, p in encoder.named_parameters()\n",
        "                    if ('bias' not in n) and ('bn' not in n))},\n",
        "        {'params': (p for n, p in encoder.named_parameters()\n",
        "                    if ('bias' in n) or ('bn' in n)),\n",
        "         'LARS_exclude': True,\n",
        "         'weight_decay': 0}\n",
        "    ]\n",
        "    optimizer = SGD(\n",
        "        param_groups,\n",
        "        weight_decay=weight_decay,\n",
        "        momentum=0.9,\n",
        "        nesterov=nesterov,\n",
        "        lr=ref_lr)\n",
        "    scheduler = WarmupCosineSchedule(\n",
        "        optimizer,\n",
        "        warmup_steps=warmup*iterations_per_epoch,\n",
        "        start_lr=start_lr,\n",
        "        ref_lr=ref_lr,\n",
        "        final_lr=final_lr,\n",
        "        T_max=num_epochs*iterations_per_epoch)\n",
        "    optimizer = LARS(optimizer, trust_coefficient=0.001)\n",
        "    return encoder, optimizer, scheduler\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v0FVncWBrZp"
      },
      "source": [
        "import os\n",
        "\n",
        "# -- FOR DISTRIBUTED TRAINING ENSURE ONLY 1 DEVICE VISIBLE PER PROCESS\n",
        "try:\n",
        "    # -- WARNING: IF DOING DISTRIBUTED TRAINING ON A NON-SLURM CLUSTER, MAKE\n",
        "    # --          SURE TO UPDATE THIS TO GET LOCAL-RANK ON NODE, OR ENSURE\n",
        "    # --          THAT YOUR JOBS ARE LAUNCHED WITH ONLY 1 DEVICE VISIBLE\n",
        "    # --          TO EACH PROCESS\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['SLURM_LOCALID']\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    gpu_timer,\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule,\n",
        "    CSVLogger,\n",
        "    AverageMeter\n",
        ")\n",
        "from src.losses import (\n",
        "    init_paws_loss,\n",
        "    make_labels_matrix\n",
        ")\n",
        "from src.data_manager import (\n",
        "    init_data,\n",
        "    make_transforms,\n",
        "    make_multicrop_transform\n",
        ")\n",
        "from src.sgd import SGD\n",
        "from src.lars import LARS\n",
        "\n",
        "import apex\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "\n",
        "# --\n",
        "log_timings = True\n",
        "log_freq = 10\n",
        "checkpoint_freq = 50\n",
        "# --\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "np.random.seed(_GLOBAL_SEED)\n",
        "torch.manual_seed(_GLOBAL_SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logger = logging.getLogger()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzC_rC89CHYX"
      },
      "source": [
        "# ----------------------------------------------------------------------- #\n",
        "#  PASSED IN PARAMS FROM CONFIG FILE\n",
        "# ----------------------------------------------------------------------- #\n",
        "# -- META\n",
        "model_name = args['meta']['model_name']\n",
        "output_dim = args['meta']['output_dim']\n",
        "load_model = args['meta']['load_checkpoint']\n",
        "r_file = args['meta']['read_checkpoint']\n",
        "copy_data = args['meta']['copy_data']\n",
        "use_fp16 = args['meta']['use_fp16']\n",
        "use_pred_head = args['meta']['use_pred_head']\n",
        "device = torch.device(args['meta']['device'])\n",
        "torch.cuda.set_device(device)\n",
        "\n",
        "# -- CRITERTION\n",
        "reg = args['criterion']['me_max']\n",
        "supervised_views = args['criterion']['supervised_views']\n",
        "classes_per_batch = args['criterion']['classes_per_batch']\n",
        "s_batch_size = args['criterion']['supervised_imgs_per_class']\n",
        "u_batch_size = args['criterion']['unsupervised_batch_size']\n",
        "temperature = args['criterion']['temperature']\n",
        "sharpen = args['criterion']['sharpen']\n",
        "\n",
        "# -- DATA\n",
        "unlabeled_frac = args['data']['unlabeled_frac']\n",
        "color_jitter = args['data']['color_jitter_strength']\n",
        "normalize = args['data']['normalize']\n",
        "root_path = args['data']['root_path']\n",
        "image_folder = args['data']['image_folder']\n",
        "dataset_name = args['data']['dataset']\n",
        "subset_path = args['data']['subset_path']\n",
        "unique_classes = args['data']['unique_classes_per_rank']\n",
        "multicrop = args['data']['multicrop']\n",
        "label_smoothing = args['data']['label_smoothing']\n",
        "data_seed = None\n",
        "if 'cifar10' in dataset_name:\n",
        "    data_seed = args['data']['data_seed']\n",
        "    crop_scale = (0.75, 1.0) if multicrop > 0 else (0.5, 1.0)\n",
        "    mc_scale = (0.3, 0.75)\n",
        "    mc_size = 18\n",
        "else:\n",
        "    crop_scale = (0.14, 1.0) if multicrop > 0 else (0.08, 1.0)\n",
        "    mc_scale = (0.05, 0.14)\n",
        "    mc_size = 96"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-RHC0VvCczc"
      },
      "source": [
        "# -- OPTIMIZATION\n",
        "wd = float(args['optimization']['weight_decay'])\n",
        "num_epochs = args['optimization']['epochs']\n",
        "warmup = args['optimization']['warmup']\n",
        "start_lr = args['optimization']['start_lr']\n",
        "lr = args['optimization']['lr']\n",
        "final_lr = args['optimization']['final_lr']\n",
        "mom = args['optimization']['momentum']\n",
        "nesterov = args['optimization']['nesterov']\n",
        "\n",
        "# -- LOGGING\n",
        "folder = args['logging']['folder']\n",
        "tag = args['logging']['write_tag']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4yW-TZyCaDr",
        "outputId": "27c6b0d4-8029-4712-f46b-7600a0bd9147"
      },
      "source": [
        "label_smoothing"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywgvunpjCgoG"
      },
      "source": [
        "world_size = 1\n",
        "rank = 0 "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFc-1_1BCktT"
      },
      "source": [
        "# -- log/checkpointing paths\n",
        "log_file = os.path.join(folder, f'{tag}_r{rank}.csv')\n",
        "save_path = os.path.join(folder, f'{tag}' + '-ep{epoch}.pth.tar')\n",
        "latest_path = os.path.join(folder, f'{tag}-latest.pth.tar')\n",
        "best_path = os.path.join(folder, f'{tag}' + '-best.pth.tar')\n",
        "load_path = None\n",
        "if load_model:\n",
        "    load_path = os.path.join(folder, r_file) if r_file is not None else latest_path"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKXZjQG_Cn_C"
      },
      "source": [
        "# -- make csv_logger\n",
        "csv_logger = CSVLogger(log_file,\n",
        "                        ('%d', 'epoch'),\n",
        "                        ('%d', 'itr'),\n",
        "                        ('%.5f', 'paws-xent-loss'),\n",
        "                        ('%.5f', 'paws-me_max-reg'),\n",
        "                        ('%d', 'time (ms)'))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRVLWHy5CoE0"
      },
      "source": [
        "# -- init model\n",
        "encoder = init_model(\n",
        "    device=device,\n",
        "    model_name=model_name,\n",
        "    use_pred=use_pred_head,\n",
        "    output_dim=output_dim)\n",
        "if world_size > 1:\n",
        "    process_group = apex.parallel.create_syncbn_process_group(0)\n",
        "    encoder = apex.parallel.convert_syncbn_model(encoder, process_group=process_group)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKqlwxYyCoJD"
      },
      "source": [
        "# -- init losses\n",
        "paws = init_paws_loss(\n",
        "    #multicrop=multicrop,\n",
        "    tau=temperature,\n",
        "    T=sharpen,\n",
        "    me_max=reg)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrpG2LxkC5bR"
      },
      "source": [
        "# -- assume support images are sampled with ClassStratifiedSampler\n",
        "labels_matrix = make_labels_matrix(\n",
        "    num_classes=classes_per_batch,\n",
        "    s_batch_size=s_batch_size,\n",
        "    world_size=world_size,\n",
        "    device=device,\n",
        "    unique_classes=unique_classes,\n",
        "    smoothing=label_smoothing)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqD2va1LC5zr",
        "outputId": "aaa0baf0-7183-4ee5-c2af-b61e389fd32f"
      },
      "source": [
        "print(\"normalize {}\".format(normalize))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normalize True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpMXCBcGDKkG"
      },
      "source": [
        "# -- make data transforms\n",
        "transform, init_transform = make_transforms(\n",
        "    dataset_name=dataset_name,\n",
        "    subset_path=subset_path,\n",
        "    unlabeled_frac=unlabeled_frac,\n",
        "    training=True,\n",
        "    split_seed=data_seed,\n",
        "    crop_scale=crop_scale,\n",
        "    basic_augmentations=False,\n",
        "    color_jitter=color_jitter,\n",
        "    normalize=normalize)\n",
        "multicrop_transform = (multicrop, None)\n",
        "if multicrop > 0:\n",
        "    multicrop_transform = make_multicrop_transform(\n",
        "            dataset_name=dataset_name,\n",
        "            num_crops=multicrop,\n",
        "            size=mc_size,\n",
        "            crop_scale=mc_scale,\n",
        "            normalize=normalize,\n",
        "            color_distortion=color_jitter)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmLg0LcUDKoK",
        "outputId": "f1efcfdd-2aae-457f-bcb9-790bf5de676b"
      },
      "source": [
        "# -- init data-loaders/samplers\n",
        "(unsupervised_loader,\n",
        "    unsupervised_sampler,\n",
        "    supervised_loader,\n",
        "    supervised_sampler) = init_data(\n",
        "        dataset_name=dataset_name,\n",
        "        transform=transform,\n",
        "        init_transform=init_transform,\n",
        "        supervised_views=supervised_views,\n",
        "        u_batch_size=u_batch_size,\n",
        "        s_batch_size=s_batch_size,\n",
        "        unique_classes=unique_classes,\n",
        "        classes_per_batch=classes_per_batch,\n",
        "        multicrop_transform=multicrop_transform,\n",
        "        world_size=world_size,\n",
        "        rank=rank,\n",
        "        root_path=root_path,\n",
        "        image_folder=image_folder,\n",
        "        training=True,\n",
        "        copy_data=copy_data)\n",
        "iter_supervised = None\n",
        "ipe = len(unsupervised_loader)\n",
        "logger.info(f'iterations per epoch: {ipe}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "self.multicrop_transform (0, None)\n",
            "self.multicrop_transform (0, None)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGnyPg1TDKrP"
      },
      "source": [
        "# -- init optimizer and scheduler\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "encoder, optimizer, scheduler = init_opt(\n",
        "    encoder=encoder,\n",
        "    weight_decay=wd,\n",
        "    start_lr=start_lr,\n",
        "    ref_lr=lr,\n",
        "    final_lr=final_lr,\n",
        "    ref_mom=mom,\n",
        "    nesterov=nesterov,\n",
        "    iterations_per_epoch=ipe,\n",
        "    warmup=warmup,\n",
        "    num_epochs=num_epochs)\n",
        "if world_size > 1:\n",
        "    encoder = DistributedDataParallel(encoder, broadcast_buffers=False)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWO7E5iADKui"
      },
      "source": [
        "start_epoch = 0\n",
        "# -- load training checkpoint\n",
        "if load_model:\n",
        "    encoder, optimizer, start_epoch = load_checkpoint(\n",
        "        r_path=load_path,\n",
        "        encoder=encoder,\n",
        "        opt=optimizer,\n",
        "        scaler=scaler,\n",
        "        use_fp16=use_fp16)\n",
        "    for _ in range(start_epoch):\n",
        "        for _ in range(ipe):\n",
        "            scheduler.step()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh9Siq6PDyp_"
      },
      "source": [
        "################## DEBUG #################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSdZ0vdNERQp"
      },
      "source": [
        "epoch = 0 "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9jMmx_dEVvw"
      },
      "source": [
        "# -- update distributed-data-loader epoch\n",
        "unsupervised_sampler.set_epoch(epoch)\n",
        "if supervised_sampler is not None:\n",
        "    supervised_sampler.set_epoch(epoch)\n",
        "\n",
        "loss_meter = AverageMeter()\n",
        "ploss_meter = AverageMeter()\n",
        "rloss_meter = AverageMeter()\n",
        "time_meter = AverageMeter()\n",
        "data_meter = AverageMeter()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0cj9DLZEYyb"
      },
      "source": [
        "best_loss = None"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00JstHk5MSOo",
        "outputId": "902adfbc-a40b-4cfd-f225-e682ceeb5364"
      },
      "source": [
        "for itr, udata in enumerate(unsupervised_loader):\n",
        "\n",
        "    def load_imgs():\n",
        "        # -- unsupervised imgs\n",
        "        uimgs = [u.to(device, non_blocking=True) for u in udata[:-1]]\n",
        "        # -- supervised imgs\n",
        "        global iter_supervised\n",
        "        try:\n",
        "            sdata = next(iter_supervised)\n",
        "        except Exception:\n",
        "            iter_supervised = iter(supervised_loader)\n",
        "            logger.info(f'len.supervised_loader: {len(iter_supervised)}')\n",
        "            sdata = next(iter_supervised)\n",
        "        finally:\n",
        "            labels = torch.cat([labels_matrix for _ in range(supervised_views)])\n",
        "            simgs = [s.to(device, non_blocking=True) for s in sdata[:-1]]\n",
        "        # -- concatenate supervised imgs and unsupervised imgs\n",
        "        imgs = simgs + uimgs\n",
        "        return imgs, labels\n",
        "    (imgs, labels), dtime = gpu_timer(load_imgs)\n",
        "    data_meter.update(dtime)\n",
        "    break"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5_0KntFRJSM"
      },
      "source": [
        "from logging import getLogger\n",
        "import torch\n",
        "from src.utils import (\n",
        "    AllGather,\n",
        "    AllReduce\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsgAXVkMUJo6"
      },
      "source": [
        "multicrop=0\n",
        "tau=0.1\n",
        "T=0.25\n",
        "me_max=True"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Feyj4amWOpRC"
      },
      "source": [
        "with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # --\n",
        "    # h: representations of 'imgs' before head\n",
        "    # z: representations of 'imgs' after head\n",
        "    # -- If use_pred_head=False, then encoder.pred (prediction\n",
        "    #    head) is None, and _forward_head just returns the\n",
        "    #    identity, z=h\n",
        "    h, z = encoder(imgs, return_before_head=True)\n",
        "\n",
        "    # Compute paws loss in full precision\n",
        "    with torch.cuda.amp.autocast(enabled=False):\n",
        "\n",
        "        # Step 1. convert representations to fp32\n",
        "        h, z = h.float(), z.float()\n",
        "\n",
        "        # Step 2. determine anchor views/supports and their\n",
        "        #         corresponding target views/supports\n",
        "        # --\n",
        "        num_support = supervised_views * s_batch_size * classes_per_batch\n",
        "        # --\n",
        "        anchor_supports = z[:num_support]\n",
        "        anchor_views = z[num_support:]\n",
        "        # --\n",
        "        target_supports = h[:num_support].detach()\n",
        "        target_views = h[num_support:].detach()\n",
        "        target_views = torch.cat([\n",
        "            target_views[u_batch_size:2*u_batch_size],\n",
        "            target_views[:u_batch_size]], dim=0)\n",
        "\n",
        "        softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        def sharpen(p):\n",
        "            sharp_p = p**(1./T)\n",
        "            sharp_p /= torch.sum(sharp_p, dim=1, keepdim=True)\n",
        "            return sharp_p\n",
        "\n",
        "        def snn(query, supports, labels):\n",
        "            \"\"\" Soft Nearest Neighbours similarity classifier \"\"\"\n",
        "            # Step 1: normalize embeddings\n",
        "            query = torch.nn.functional.normalize(query)\n",
        "            supports = torch.nn.functional.normalize(supports)\n",
        "\n",
        "            # Step 2: gather embeddings from all workers\n",
        "            supports = AllGather.apply(supports)\n",
        "\n",
        "            # Step 3: compute similarlity between local embeddings\n",
        "            return softmax(query @ supports.T / tau) @ labels\n",
        "\n",
        "\n",
        "        #anchor_views=anchor_views\n",
        "        #anchor_supports=anchor_supports\n",
        "        anchor_support_labels=labels\n",
        "        #target_views=target_views\n",
        "        #target_supports=target_supports\n",
        "        target_support_labels=labels\n",
        "        # -- NOTE: num views of each unlabeled instance = 2+multicrop\n",
        "        batch_size = len(anchor_views) // (2+multicrop)\n",
        "\n",
        "        # Step 1: compute anchor predictions\n",
        "        probs = snn(anchor_views, anchor_supports, anchor_support_labels)\n",
        "\n",
        "\n",
        "        # Step 2: compute targets for anchor predictions\n",
        "        with torch.no_grad():\n",
        "            targets = snn(target_views, target_supports, target_support_labels)\n",
        "            targets = sharpen(targets)\n",
        "            if multicrop > 0:\n",
        "                mc_target = 0.5*(targets[:batch_size]+targets[batch_size:])\n",
        "                targets = torch.cat([targets, *[mc_target for _ in range(multicrop)]], dim=0)\n",
        "            targets[targets < 1e-4] *= 0  # numerical stability\n",
        "\n",
        "        # Step 3: compute cross-entropy loss H(targets, queries)\n",
        "        loss = torch.mean(torch.sum(torch.log(probs**(-targets)), dim=1))\n",
        "\n",
        "        # Step 4: compute me-max regularizer\n",
        "        rloss = 0.\n",
        "        if me_max:\n",
        "            avg_probs = AllReduce.apply(torch.mean(sharpen(probs), dim=0))\n",
        "            rloss -= torch.sum(torch.log(avg_probs**(-avg_probs)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SIoYZP7Vsrp",
        "outputId": "a90d33e7-81fe-4b68-b918-b3f6be76709f"
      },
      "source": [
        "loss"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6944, device='cuda:0', grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1tyw4AKPBmd",
        "outputId": "3bc793d5-643b-4388-bbf2-35096392c0d0"
      },
      "source": [
        "batch_size"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvEd7rnrBjg-"
      },
      "source": [
        "# Suncet Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeWUsvHm1syb"
      },
      "source": [
        "import os\n",
        "\n",
        "# -- FOR DISTRIBUTED TRAINING ENSURE ONLY 1 DEVICE VISIBLE PER PROCESS\n",
        "try:\n",
        "    # -- WARNING: IF DOING DISTRIBUTED TRAINING ON A NON-SLURM CLUSTER, MAKE\n",
        "    # --          SURE TO UPDATE THIS TO GET LOCAL-RANK ON NODE, OR ENSURE\n",
        "    # --          THAT YOUR JOBS ARE LAUNCHED WITH ONLY 1 DEVICE VISIBLE\n",
        "    # --          TO EACH PROCESS\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['SLURM_LOCALID']\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    gpu_timer,\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule,\n",
        "    CSVLogger,\n",
        "    AverageMeter\n",
        ")\n",
        "from src.losses import (\n",
        "    init_paws_loss,\n",
        "    make_labels_matrix\n",
        ")\n",
        "from src.data_manager import (\n",
        "    init_data,\n",
        "    make_transforms,\n",
        "    make_multicrop_transform\n",
        ")\n",
        "from src.sgd import SGD\n",
        "from src.lars import LARS\n",
        "\n",
        "import apex\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "\n",
        "# --\n",
        "log_timings = True\n",
        "log_freq = 10\n",
        "checkpoint_freq = 50\n",
        "# --\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "np.random.seed(_GLOBAL_SEED)\n",
        "torch.manual_seed(_GLOBAL_SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logger = logging.getLogger()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k0W9pB-8dfj"
      },
      "source": [
        "# ----------------------------------------------------------------------- #\n",
        "#  PASSED IN PARAMS FROM CONFIG FILE\n",
        "# ----------------------------------------------------------------------- #\n",
        "# -- META\n",
        "model_name = args['meta']['model_name']\n",
        "output_dim = args['meta']['output_dim']\n",
        "load_model = args['meta']['load_checkpoint']\n",
        "r_file = args['meta']['read_checkpoint']\n",
        "copy_data = args['meta']['copy_data']\n",
        "use_fp16 = args['meta']['use_fp16']\n",
        "use_pred_head = args['meta']['use_pred_head']\n",
        "device = torch.device(args['meta']['device'])\n",
        "torch.cuda.set_device(device)\n",
        "\n",
        "# -- CRITERTION\n",
        "supervised_epochs = args['criterion']['supervised_epochs']\n",
        "supervised_views = args['criterion']['supervised_views']\n",
        "classes_per_batch = args['criterion']['classes_per_batch']\n",
        "s_batch_size = args['criterion']['supervised_imgs_per_class']\n",
        "u_batch_size = args['criterion']['unsupervised_batch_size']\n",
        "temperature = args['criterion']['temperature']\n",
        "\n",
        "# -- DATA\n",
        "unlabeled_frac = args['data']['unlabeled_frac']\n",
        "color_jitter = args['data']['color_jitter_strength']\n",
        "normalize = args['data']['normalize']\n",
        "root_path = args['data']['root_path']\n",
        "image_folder = args['data']['image_folder']\n",
        "dataset_name = args['data']['dataset']\n",
        "subset_path = args['data']['subset_path']\n",
        "unique_classes = args['data']['unique_classes_per_rank']\n",
        "label_smoothing = args['data']['label_smoothing']\n",
        "crop_scale = (0.5, 1.0) if 'cifar10' in dataset_name else (0.08, 1.0)\n",
        "data_seed = None\n",
        "if 'cifar10' in dataset_name:\n",
        "    data_seed = args['data']['data_seed']\n",
        "\n",
        "# -- OPTIMIZATION\n",
        "wd = float(args['optimization']['weight_decay'])\n",
        "num_epochs = args['optimization']['epochs']\n",
        "warmup = args['optimization']['warmup']\n",
        "start_lr = args['optimization']['start_lr']\n",
        "lr = args['optimization']['lr']\n",
        "final_lr = args['optimization']['final_lr']\n",
        "mom = args['optimization']['momentum']\n",
        "nesterov = args['optimization']['nesterov']\n",
        "\n",
        "# -- LOGGING\n",
        "folder = args['logging']['folder']\n",
        "tag = args['logging']['write_tag']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUtw9IVg-NG1"
      },
      "source": [
        "from suncet.src.suncet_train import init_model, init_opt"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXMZ2QSd2BVV"
      },
      "source": [
        "# -- log/checkpointing paths\n",
        "log_file = os.path.join(folder, f'{tag}_r{rank}.csv')\n",
        "save_path = os.path.join(folder, f'{tag}' + '-ep{epoch}.pth.tar')\n",
        "latest_path = os.path.join(folder, f'{tag}-latest.pth.tar')\n",
        "best_path = os.path.join(folder, f'{tag}' + '-best.pth.tar')\n",
        "load_path = None\n",
        "if load_model:\n",
        "    load_path = os.path.join(folder, r_file) if r_file is not None else latest_path"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyxPmPiS15uq"
      },
      "source": [
        "# -- make csv_logger\n",
        "csv_logger = CSVLogger(log_file,\n",
        "                        ('%d', 'epoch'),\n",
        "                        ('%d', 'itr'),\n",
        "                        ('%.5f', 'paws-xent-loss'),\n",
        "                        ('%.5f', 'paws-me_max-reg'),\n",
        "                        ('%d', 'time (ms)'))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kmdx9cw9PHJ"
      },
      "source": [
        "encoder = init_model(\n",
        "    device=device,\n",
        "    model_name=model_name,\n",
        "    use_pred=use_pred_head,\n",
        "    output_dim=output_dim)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI4S-cAi-fOP"
      },
      "source": [
        "world_size = 1"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTcCpJ-R-ZXy"
      },
      "source": [
        "ntxent = init_simclr_loss(\n",
        "    batch_size=u_batch_size,\n",
        "    world_size=world_size,\n",
        "    rank=rank,\n",
        "    temperature=temperature,\n",
        "    device=device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8tVtZQ9-eEx"
      },
      "source": [
        "suncet = init_suncet_loss(\n",
        "        num_classes=classes_per_batch,\n",
        "        batch_size=s_batch_size*supervised_views,\n",
        "        world_size=world_size,\n",
        "        rank=rank,\n",
        "        temperature=temperature,\n",
        "        device=device,\n",
        "        unique_classes=unique_classes)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW3yINXm-icg"
      },
      "source": [
        "# -- assume support images are sampled with ClassStratifiedSampler\n",
        "labels = make_labels_matrix(\n",
        "    num_classes=classes_per_batch,\n",
        "    s_batch_size=s_batch_size,\n",
        "    world_size=world_size,\n",
        "    device=device,\n",
        "    #unique_classes=unique_classes,\n",
        "    unique_classes=False,\n",
        "    smoothing=label_smoothing)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skUkhq9xpqw7",
        "outputId": "6a8376a6-df39-49f0-c650-8c3eb1eb608d"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7uKwCgRVPqi",
        "outputId": "e08845ac-1242-4223-c506-deb247beee4c"
      },
      "source": [
        "unique_classes"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKhuEeul-mTI"
      },
      "source": [
        "# -- make data transforms\n",
        "transform, init_transform = make_transforms(\n",
        "    dataset_name=dataset_name,\n",
        "    subset_path=subset_path,\n",
        "    unlabeled_frac=unlabeled_frac,\n",
        "    training=True,\n",
        "    split_seed=data_seed,\n",
        "    crop_scale=crop_scale,\n",
        "    basic_augmentations=False,\n",
        "    color_jitter=color_jitter,\n",
        "    normalize=normalize)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj0c8nFHbeAQ"
      },
      "source": [
        "_GLOBAL_SEED = 0"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL5WLnUeDMnh"
      },
      "source": [
        "########### DEBUG INTERIOR FUNCTION ##########\n",
        "\n",
        "def _init_dr_data(\n",
        "    transform,\n",
        "    init_transform,\n",
        "    u_batch_size,\n",
        "    s_batch_size,\n",
        "    classes_per_batch,\n",
        "    unique_classes=False,\n",
        "    multicrop_transform=(0, None),\n",
        "    supervised_views=1,\n",
        "    world_size=1,\n",
        "    rank=0,\n",
        "    root_path='/datasets/',\n",
        "    image_folder='imagenet_full_size/061417/',\n",
        "    training=True,\n",
        "    copy_data=False,\n",
        "    tar_folder='imagenet_full_size/',\n",
        "    tar_file='imagenet_full_size-061417.tar'\n",
        "):\n",
        "    imagedr = ImageDR(\n",
        "        root=root_path,\n",
        "        image_folder=image_folder,\n",
        "        tar_folder=tar_folder,\n",
        "        tar_file=tar_file,\n",
        "        transform=transform,\n",
        "        train=training,\n",
        "        copy_data=copy_data)\n",
        "    logger.info('ImageDR dataset created')\n",
        "    unsupervised_set = TransImageDR(\n",
        "        dataset=imagedr,\n",
        "        supervised=False,\n",
        "        init_transform=init_transform,\n",
        "        multicrop_transform=multicrop_transform,\n",
        "        seed=_GLOBAL_SEED)\n",
        "    unsupervised_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        dataset=unsupervised_set,\n",
        "        num_replicas=world_size,\n",
        "        rank=rank)\n",
        "    unsupervised_loader = torch.utils.data.DataLoader(\n",
        "        unsupervised_set,\n",
        "        sampler=unsupervised_sampler,\n",
        "        batch_size=u_batch_size,\n",
        "        drop_last=True,\n",
        "        pin_memory=True,\n",
        "        num_workers=8)\n",
        "    logger.info('ImageDR unsupervised data loader created')\n",
        "\n",
        "    supervised_sampler, supervised_loader = None, None\n",
        "    if classes_per_batch > 0 and s_batch_size > 0:\n",
        "        logger.info('Making supervised ImageDR data loader...')\n",
        "        supervised_set = TransImageDR(\n",
        "            dataset=imagedr,\n",
        "            supervised=True,\n",
        "            supervised_views=supervised_views,\n",
        "            init_transform=init_transform,\n",
        "            seed=_GLOBAL_SEED)\n",
        "        supervised_sampler = ClassStratifiedSampler(\n",
        "            data_source=supervised_set,\n",
        "            world_size=world_size,\n",
        "            rank=rank,\n",
        "            batch_size=s_batch_size,\n",
        "            classes_per_batch=classes_per_batch,\n",
        "            unique_classes=unique_classes,\n",
        "            seed=_GLOBAL_SEED)\n",
        "        supervised_loader = torch.utils.data.DataLoader(\n",
        "            supervised_set,\n",
        "            batch_sampler=supervised_sampler,\n",
        "            pin_memory=True,\n",
        "            num_workers=8)\n",
        "        if len(supervised_loader) > 0:\n",
        "            tmp = ceil(len(unsupervised_loader) / len(supervised_loader))\n",
        "            supervised_sampler.set_inner_epochs(tmp)\n",
        "            logger.info(f'supervised-reset-period {tmp}')\n",
        "        logger.info('ImageDR supervised data loader created')\n",
        "\n",
        "    return (unsupervised_loader, unsupervised_sampler,\n",
        "            supervised_loader, supervised_sampler)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVu-fHRpJNVk"
      },
      "source": [
        "tar_folder='imagenet_full_size/',\n",
        "tar_file='imagenet_full_size-061417.tar'\n",
        "training=True\n",
        "copy_data=False"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5o4TGWbN7wR"
      },
      "source": [
        "class ClassStratifiedSampler(torch.utils.data.Sampler):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_source,\n",
        "        world_size,\n",
        "        rank,\n",
        "        batch_size=1,\n",
        "        classes_per_batch=10,\n",
        "        epochs=1,\n",
        "        seed=0,\n",
        "        unique_classes=False\n",
        "    ):\n",
        "        \"\"\"\n",
        "        ClassStratifiedSampler\n",
        "\n",
        "        Batch-sampler that samples 'batch-size' images from subset of randomly\n",
        "        chosen classes e.g., if classes a,b,c are randomly sampled,\n",
        "        the sampler returns\n",
        "            torch.cat([a,b,c], [a,b,c], ..., [a,b,c], dim=0)\n",
        "        where a,b,c, are images from classes a,b,c respectively.\n",
        "        Sampler, samples images WITH REPLACEMENT (i.e., not epoch-based)\n",
        "\n",
        "        :param data_source: dataset of type \"TransImageNet\" or \"TransCIFAR10'\n",
        "        :param world_size: total number of workers in network\n",
        "        :param rank: local rank in network\n",
        "        :param batch_size: num. images to load from each class\n",
        "        :param classes_per_batch: num. classes to randomly sample for batch\n",
        "        :param epochs: num consecutive epochs thru data_source before gen.reset\n",
        "        :param seed: common seed across workers for subsampling classes\n",
        "        :param unique_classes: true ==> each worker samples a distinct set of classes; false ==> all workers sample the same classes\n",
        "        \"\"\"\n",
        "        super(ClassStratifiedSampler, self).__init__(data_source)\n",
        "        self.data_source = data_source\n",
        "\n",
        "        self.rank = rank\n",
        "        self.world_size = world_size\n",
        "        self.cpb = classes_per_batch\n",
        "        self.unique_cpb = unique_classes\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = len(data_source.classes)\n",
        "        self.epochs = epochs\n",
        "        self.outer_epoch = 0\n",
        "\n",
        "        if not self.unique_cpb:\n",
        "            assert self.num_classes % self.cpb == 0\n",
        "\n",
        "        self.base_seed = seed  # instance seed\n",
        "        self.seed = seed  # subsample sampler seed\n",
        "\n",
        "    def set_epoch(self, epoch):\n",
        "        self.outer_epoch = epoch\n",
        "\n",
        "    def set_inner_epochs(self, epochs):\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def _next_perm(self):\n",
        "        self.seed += 1\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(self.seed)\n",
        "        self._perm = torch.randperm(self.num_classes, generator=g)\n",
        "\n",
        "    def _get_perm_ssi(self):\n",
        "        start = self._ssi\n",
        "        end = self._ssi + self.cpb\n",
        "        subsample = self._perm[start:end]\n",
        "        return subsample\n",
        "\n",
        "    def _next_ssi(self):\n",
        "        if not self.unique_cpb:\n",
        "            self._ssi = (self._ssi + self.cpb) % self.num_classes\n",
        "            if self._ssi == 0:\n",
        "                self._next_perm()\n",
        "        else:\n",
        "            self._ssi += self.cpb * self.world_size\n",
        "            max_end = self._ssi + self.cpb * (self.world_size - self.rank)\n",
        "            if max_end > self.num_classes:\n",
        "                self._ssi = self.rank * self.cpb\n",
        "                self._next_perm()\n",
        "\n",
        "    def _get_local_samplers(self, epoch):\n",
        "        \"\"\" Generate samplers for local data set in given epoch \"\"\"\n",
        "        seed = int(self.base_seed + epoch\n",
        "                   + self.epochs * self.rank\n",
        "                   + self.outer_epoch * self.epochs * self.world_size)\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(seed)\n",
        "        samplers = []\n",
        "        for t in range(self.num_classes):\n",
        "            t_indices = np.array(self.data_source.target_indices[t])\n",
        "            if not self.unique_cpb:\n",
        "                i_size = len(t_indices) // self.world_size\n",
        "                if i_size > 0:\n",
        "                    t_indices = t_indices[self.rank*i_size:(self.rank+1)*i_size]\n",
        "            if len(t_indices) > 1:\n",
        "                t_indices = t_indices[torch.randperm(len(t_indices), generator=g)]\n",
        "            samplers.append(iter(t_indices))\n",
        "        return samplers\n",
        "\n",
        "    def _subsample_samplers(self, samplers):\n",
        "        \"\"\" Subsample a small set of samplers from all class-samplers \"\"\"\n",
        "        subsample = self._get_perm_ssi()\n",
        "        subsampled_samplers = []\n",
        "        for i in subsample:\n",
        "            subsampled_samplers.append(samplers[i])\n",
        "        self._next_ssi()\n",
        "        return zip(*subsampled_samplers)\n",
        "\n",
        "    def __iter__(self):\n",
        "        self._ssi = self.rank*self.cpb if self.unique_cpb else 0\n",
        "        self._next_perm()\n",
        "\n",
        "        # -- iterations per epoch (extract batch-size samples from each class)\n",
        "        ipe = (self.num_classes // self.cpb if not self.unique_cpb\n",
        "               else self.num_classes // (self.cpb * self.world_size)) * self.batch_size\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            # -- shuffle class order\n",
        "            samplers = self._get_local_samplers(epoch)\n",
        "            subsampled_samplers = self._subsample_samplers(samplers)\n",
        "\n",
        "            counter, batch = 0, []\n",
        "            for i in range(ipe):\n",
        "                batch += list(next(subsampled_samplers))\n",
        "                counter += 1\n",
        "                if counter == self.batch_size:\n",
        "                    yield batch\n",
        "                    counter, batch = 0, []\n",
        "                    if i + 1 < ipe:\n",
        "                        subsampled_samplers = self._subsample_samplers(samplers)\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.batch_size == 0:\n",
        "            return 0\n",
        "\n",
        "        ipe = (self.num_classes // self.cpb if not self.unique_cpb\n",
        "               else self.num_classes // (self.cpb * self.world_size))\n",
        "        return self.epochs * ipe\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDf6I7YYIY5H"
      },
      "source": [
        "from src.data_manager import ImageDR, TransImageDR\n",
        "# ClassStratifiedSampler"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA2LB_Q5I83Y"
      },
      "source": [
        "imagedr = ImageDR(\n",
        "    root=root_path,\n",
        "    image_folder=image_folder,\n",
        "    tar_folder=tar_folder,\n",
        "    tar_file=tar_file,\n",
        "    transform=transform,\n",
        "    train=training,\n",
        "    copy_data=copy_data)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs3FjaHicoxy"
      },
      "source": [
        "multicrop_transform=(0, None)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLyrSi-KcMWf",
        "outputId": "b5628651-bf8e-4a6d-a80a-ef74b225bc4e"
      },
      "source": [
        "unsupervised_set = TransImageDR(\n",
        "    dataset=imagedr,\n",
        "    supervised=False,\n",
        "    init_transform=init_transform,\n",
        "    multicrop_transform=multicrop_transform,\n",
        "    seed=_GLOBAL_SEED)\n",
        "unsupervised_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "    dataset=unsupervised_set,\n",
        "    num_replicas=world_size,\n",
        "    rank=rank)\n",
        "unsupervised_loader = torch.utils.data.DataLoader(\n",
        "    unsupervised_set,\n",
        "    sampler=unsupervised_sampler,\n",
        "    batch_size=u_batch_size,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    num_workers=8)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "self.multicrop_transform (0, None)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLY9N-ngJmY7",
        "outputId": "19e0b5f6-9f5c-4e87-c000-a4c3bf954ccd"
      },
      "source": [
        "supervised_set = TransImageDR(\n",
        "    dataset=imagedr,\n",
        "    supervised=True,\n",
        "    supervised_views=supervised_views,\n",
        "    init_transform=init_transform,\n",
        "    seed=_GLOBAL_SEED)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "self.multicrop_transform (0, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmmva0tkJnvA"
      },
      "source": [
        "supervised_sampler = ClassStratifiedSampler(\n",
        "    data_source=supervised_set,\n",
        "    world_size=world_size,\n",
        "    #world_size=4,\n",
        "    rank=rank,\n",
        "    batch_size=s_batch_size,\n",
        "    #classes_per_batch=classes_per_batch,\n",
        "    classes_per_batch=2,\n",
        "    #unique_classes=unique_classes,\n",
        "    unique_classes=False,\n",
        "    seed=_GLOBAL_SEED)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceA9MB4ZPkZJ",
        "outputId": "765bed38-bb89-4e86-bc2b-39933d4839f5"
      },
      "source": [
        "len(supervised_sampler)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC8BuOJNI2AM",
        "outputId": "5b9dc76c-ec23-4913-ff1c-e7230e373060"
      },
      "source": [
        "supervised_loader = torch.utils.data.DataLoader(\n",
        "    supervised_set,\n",
        "    batch_sampler=supervised_sampler,\n",
        "    pin_memory=True,\n",
        "    num_workers=8)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0i8LrqHDeyM",
        "outputId": "a6031979-993e-4ae3-c95d-392d96b946dd"
      },
      "source": [
        "len(supervised_loader)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "3ugBPCWb_A4d",
        "outputId": "32782be1-fa37-4464-9e41-17e8372e9ec5"
      },
      "source": [
        "\"\"\"\n",
        "# -- init data-loaders/samplers\n",
        "(unsupervised_loader,\n",
        "    unsupervised_sampler,\n",
        "    supervised_loader,\n",
        "    supervised_sampler) = init_data(\n",
        "        dataset_name=dataset_name,\n",
        "        transform=transform,\n",
        "        init_transform=init_transform,\n",
        "        supervised_views=supervised_views,\n",
        "        u_batch_size=u_batch_size,\n",
        "        s_batch_size=s_batch_size,\n",
        "        unique_classes=unique_classes,\n",
        "        classes_per_batch=classes_per_batch,\n",
        "        world_size=world_size,\n",
        "        rank=rank,\n",
        "        root_path=root_path,\n",
        "        image_folder=image_folder,\n",
        "        training=True,\n",
        "        copy_data=copy_data)\n",
        "iter_supervised = None\n",
        "ipe = len(unsupervised_loader)\n",
        "logger.info(f'iterations per epoch: {ipe}')\n",
        "\"\"\""
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# -- init data-loaders/samplers\\n(unsupervised_loader,\\n    unsupervised_sampler,\\n    supervised_loader,\\n    supervised_sampler) = init_data(\\n        dataset_name=dataset_name,\\n        transform=transform,\\n        init_transform=init_transform,\\n        supervised_views=supervised_views,\\n        u_batch_size=u_batch_size,\\n        s_batch_size=s_batch_size,\\n        unique_classes=unique_classes,\\n        classes_per_batch=classes_per_batch,\\n        world_size=world_size,\\n        rank=rank,\\n        root_path=root_path,\\n        image_folder=image_folder,\\n        training=True,\\n        copy_data=copy_data)\\niter_supervised = None\\nipe = len(unsupervised_loader)\\nlogger.info(f'iterations per epoch: {ipe}')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvqwKzkBb7dU",
        "outputId": "8c95423f-badf-4958-905a-307922369984"
      },
      "source": [
        "ipe = len(unsupervised_loader)\n",
        "print(f'iterations per epoch: {ipe}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iterations per epoch: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXmgM5I1_HNU"
      },
      "source": [
        "# -- init optimizer and scheduler\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "encoder, optimizer, scheduler = init_opt(\n",
        "    encoder=encoder,\n",
        "    weight_decay=wd,\n",
        "    start_lr=start_lr,\n",
        "    ref_lr=lr,\n",
        "    final_lr=final_lr,\n",
        "    ref_mom=mom,\n",
        "    nesterov=nesterov,\n",
        "    iterations_per_epoch=ipe,\n",
        "    warmup=warmup,\n",
        "    num_epochs=num_epochs)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw2LF-DHAAvA"
      },
      "source": [
        "start_epoch = 0\n",
        "# -- load training checkpoint\n",
        "if load_model:\n",
        "    encoder, optimizer, start_epoch = load_checkpoint(\n",
        "        r_path=load_path,\n",
        "        encoder=encoder,\n",
        "        opt=optimizer,\n",
        "        scaler=scaler,\n",
        "        use_fp16=use_fp16)\n",
        "    for _ in range(start_epoch):\n",
        "        for _ in range(ipe):\n",
        "            scheduler.step()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcgFdMDOCcEl",
        "outputId": "71e375c7-d84b-4ab0-872f-5aca8e4f038e"
      },
      "source": [
        "iter_supervised = iter(supervised_loader)\n",
        "print(f'len.supervised_loader: {len(iter_supervised)}')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "len.supervised_loader: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbK7MdXOS047",
        "outputId": "6c547e42-d622-4782-9517-c5e460cda99b"
      },
      "source": [
        "len(iter_supervised)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "pCN0rrrxAnIv",
        "outputId": "abb1c3e0-704b-4cc2-f309-b176ae7e5e17"
      },
      "source": [
        "# -- TRAINING LOOP\n",
        "best_loss = None\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    logger.info('Epoch %d' % (epoch + 1))\n",
        "\n",
        "    # -- update distributed-data-loader epoch\n",
        "    unsupervised_sampler.set_epoch(epoch)\n",
        "    if supervised_sampler is not None:\n",
        "        supervised_sampler.set_epoch(epoch)\n",
        "\n",
        "    loss_meter = AverageMeter()\n",
        "    ploss_meter = AverageMeter()\n",
        "    rloss_meter = AverageMeter()\n",
        "    time_meter = AverageMeter()\n",
        "    data_meter = AverageMeter()\n",
        "\n",
        "    for itr, udata in enumerate(unsupervised_loader):\n",
        "        if use_fp16:\n",
        "            udata = [u.half() for u in udata]\n",
        "\n",
        "        def load_imgs():\n",
        "            # -- unsupervised imgs (2 views)\n",
        "            imgs = [u.to(device) for u in udata[:2]]\n",
        "\n",
        "            # -- labeled imgs\n",
        "            global iter_supervised\n",
        "            try:\n",
        "                sdata = next(iter_supervised)\n",
        "            except Exception:\n",
        "                iter_supervised = iter(supervised_loader)\n",
        "                logger.info(f'len.supervised_loader: {len(iter_supervised)}')\n",
        "                sdata = next(iter_supervised)\n",
        "                if use_fp16:\n",
        "                    sdata = [s.half() for s in sdata]\n",
        "            finally:\n",
        "                # -- shuffle images in sampled support mini-batch\n",
        "                simgs = [s.to(device) for s in sdata[:-1]]\n",
        "\n",
        "            # -- concatenate unlabeled images and labeled images\n",
        "            return torch.cat(imgs + simgs, dim=0)\n",
        "        (imgs), dtime = gpu_timer(load_imgs)\n",
        "        data_meter.update(dtime)\n",
        "\n",
        "        def train_step():\n",
        "            with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "                optimizer.zero_grad()\n",
        "                z = encoder(imgs)\n",
        "                # -- simclr loss\n",
        "                uloss = ntxent(z[:2*u_batch_size])\n",
        "                # -- suncet loss\n",
        "                sloss = suncet(z[2*u_batch_size:], labels)\n",
        "                loss = uloss\n",
        "                if epoch < supervised_epochs:\n",
        "                    loss += sloss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            lr_stats = scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            return (float(loss), float(sloss), float(uloss), lr_stats)\n",
        "        (loss, ploss, rloss, lr_stats), etime = gpu_timer(train_step)\n",
        "        loss_meter.update(loss)\n",
        "        ploss_meter.update(ploss)\n",
        "        rloss_meter.update(rloss)\n",
        "        time_meter.update(etime)\n",
        "\n",
        "        if (itr % log_freq == 0) or np.isnan(loss) or np.isinf(loss):\n",
        "            csv_logger.log(epoch + 1, itr,\n",
        "                            ploss_meter.avg,\n",
        "                            rloss_meter.avg,\n",
        "                            time_meter.avg)\n",
        "            logger.info('[%d, %5d] loss: %.3f (%.3f %.3f) '\n",
        "                        '(%d ms; %d ms)'\n",
        "                        % (epoch + 1, itr,\n",
        "                            loss_meter.avg,\n",
        "                            ploss_meter.avg,\n",
        "                            rloss_meter.avg,\n",
        "                            time_meter.avg,\n",
        "                            data_meter.avg))\n",
        "            if lr_stats is not None:\n",
        "                logger.info('[%d, %5d] lr_stats: %.3f (%.2e, %.2e)'\n",
        "                            % (epoch + 1, itr,\n",
        "                                lr_stats.avg,\n",
        "                                lr_stats.min,\n",
        "                                lr_stats.max))\n",
        "\n",
        "        assert not np.isnan(loss), 'loss is nan'\n",
        "\n",
        "    # -- logging/checkpointing\n",
        "    logger.info('avg. loss %.3f' % loss_meter.avg)\n",
        "\n",
        "    if rank == 0:\n",
        "        save_dict = {\n",
        "            'encoder': encoder.state_dict(),\n",
        "            'opt': optimizer.state_dict(),\n",
        "            'epoch': epoch + 1,\n",
        "            'unlabel_prob': unlabeled_frac,\n",
        "            'loss': loss_meter.avg,\n",
        "            's_batch_size': s_batch_size,\n",
        "            'u_batch_size': u_batch_size,\n",
        "            'world_size': world_size,\n",
        "            'lr': lr,\n",
        "            'temperature': temperature,\n",
        "            'amp': scaler.state_dict()\n",
        "        }\n",
        "        torch.save(save_dict, latest_path)\n",
        "        if best_loss is None or best_loss > loss_meter.avg:\n",
        "            best_loss = loss_meter.avg\n",
        "            logger.info('updating \"best\" checkpoint')\n",
        "            torch.save(save_dict, best_path)\n",
        "        if (epoch + 1) % checkpoint_freq == 0 \\\n",
        "                or (epoch + 1) % 10 == 0 and epoch < checkpoint_freq:\n",
        "            torch.save(save_dict, save_path.format(epoch=f'{epoch + 1}'))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-732342c2b60e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mloss_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mploss_meter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mploss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/suncet/src/utils.py\u001b[0m in \u001b[0;36mgpu_timer\u001b[0;34m(closure, log_timings)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlog_timings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-732342c2b60e>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mlr_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbqGcQw8eOPA"
      },
      "source": [
        "########### DEBUG TRAIN STEP #################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4GRb0xjfaYl"
      },
      "source": [
        "# -- update distributed-data-loader epoch\n",
        "unsupervised_sampler.set_epoch(epoch)\n",
        "if supervised_sampler is not None:\n",
        "    supervised_sampler.set_epoch(epoch)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw-7JGnJfnXY",
        "outputId": "d96532d9-0dcb-42a7-92b8-4350a148861e"
      },
      "source": [
        "for itr, udata in enumerate(unsupervised_loader):\n",
        "    if use_fp16:\n",
        "        udata = [u.half() for u in udata]\n",
        "\n",
        "    def load_imgs():\n",
        "        # -- unsupervised imgs (2 views)\n",
        "        imgs = [u.to(device) for u in udata[:2]]\n",
        "\n",
        "        # -- labeled imgs\n",
        "        global iter_supervised\n",
        "        try:\n",
        "            sdata = next(iter_supervised)\n",
        "        except Exception:\n",
        "            iter_supervised = iter(supervised_loader)\n",
        "            logger.info(f'len.supervised_loader: {len(iter_supervised)}')\n",
        "            sdata = next(iter_supervised)\n",
        "            if use_fp16:\n",
        "                sdata = [s.half() for s in sdata]\n",
        "        finally:\n",
        "            # -- shuffle images in sampled support mini-batch\n",
        "            simgs = [s.to(device) for s in sdata[:-1]]\n",
        "\n",
        "        # -- concatenate unlabeled images and labeled images\n",
        "        return torch.cat(imgs + simgs, dim=0)\n",
        "\n",
        "    break"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zRKLzt9fvPH",
        "outputId": "34a79e8f-495b-469c-897e-5ff3dc6997d0"
      },
      "source": [
        "udata[0].shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 224, 224])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbogNaX5e_Ig",
        "outputId": "36a9050b-3819-4b7c-c6fd-030a1a11f04f"
      },
      "source": [
        "udata[1].shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 224, 224])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq1e37_LgEsS",
        "outputId": "629a5435-2f66-45ce-801c-9ccd1e2345cf"
      },
      "source": [
        "(imgs), dtime = gpu_timer(load_imgs)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vkzFANRgGY4",
        "outputId": "2bd64d75-31e3-41c7-9fe5-7ea7213335d4"
      },
      "source": [
        "imgs.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 3, 224, 224])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFrNdUavka9a"
      },
      "source": [
        "def init_suncet_loss(\n",
        "    num_classes,\n",
        "    batch_size,\n",
        "    world_size,\n",
        "    rank,\n",
        "    temperature,\n",
        "    device,\n",
        "    unique_classes=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Make SuNCEt supervised contrastive loss\n",
        "\n",
        "    NOTE: Assumes data is loaded with data-loaders constrcuted from 'init_data'\n",
        "          method in data_manager.py\n",
        "\n",
        "    :param num_classes: num. image classes per batch\n",
        "    :param batch_size: num. images per class in each batch\n",
        "    :param world_size: total number of workers in network\n",
        "    :param rank: local rank in network\n",
        "    :param temperature: temp. param\n",
        "    :param device: device to map tensors onto\n",
        "    :param unique_classes: whether each worker loads the same set of classes\n",
        "    \"\"\"\n",
        "    local_images = batch_size*num_classes\n",
        "    total_images = local_images*world_size\n",
        "    diag_mask = torch.ones(local_images, total_images).to(device)\n",
        "    offset = rank*local_images\n",
        "    for i in range(local_images):\n",
        "        diag_mask[i, offset + i] = 0.\n",
        "\n",
        "    def contrastive_loss(z, labels):\n",
        "\n",
        "        # Step 1: normalize embeddings\n",
        "        z = torch.nn.functional.normalize(z)\n",
        "\n",
        "        # Step 2: gather embeddings from all workers\n",
        "        z_buffer = AllGather.apply(z)\n",
        "\n",
        "        # Step 3: compute class predictions\n",
        "        exp_cs = torch.exp(z @ z_buffer.T / temperature) * diag_mask\n",
        "        probs = exp_cs.div(exp_cs.sum(dim=1, keepdim=True)) @ labels\n",
        "\n",
        "        # Step 4: compute loss for predictions\n",
        "        targets = labels[offset:offset+local_images]\n",
        "        overlap = probs**(-targets)\n",
        "        loss = torch.mean(torch.sum(torch.log(overlap), dim=1))\n",
        "        return loss\n",
        "\n",
        "    return contrastive_loss"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p047HFo-j7VS"
      },
      "source": [
        "suncet = init_suncet_loss(\n",
        "        num_classes=classes_per_batch,\n",
        "        batch_size=s_batch_size*supervised_views,\n",
        "        world_size=world_size,\n",
        "        rank=rank,\n",
        "        temperature=temperature,\n",
        "        device=device,\n",
        "        unique_classes=unique_classes)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "o01FR0YdgLN3",
        "outputId": "21541002-eec8-4846-97a9-57c22e1af3fc"
      },
      "source": [
        "with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "    optimizer.zero_grad()\n",
        "    z = encoder(imgs)\n",
        "    # -- simclr loss\n",
        "    uloss = ntxent(z[:2*u_batch_size])\n",
        "    # -- suncet loss\n",
        "    sloss = suncet(z[2*u_batch_size:], labels)\n",
        "    loss = uloss"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-ea4c20fe3134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0muloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntxent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mu_batch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# -- suncet loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuncet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mu_batch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/suncet/src/losses.py\u001b[0m in \u001b[0;36mcontrastive_loss\u001b[0;34m(z, labels)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Step 3: compute class predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mexp_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mz_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiag_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_cs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_cs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (480) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MtcchIao3JA"
      },
      "source": [
        "z = z[2*u_batch_size:]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2zV2SBvoVzm"
      },
      "source": [
        "from src.utils import (\n",
        "    AllGather,\n",
        "    AllReduce\n",
        ")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iaGbLknopyL",
        "outputId": "07a5c1e9-e855-4a00-9ae2-0080567f34a1"
      },
      "source": [
        "s_batch_size"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "OFvDZ7jcoL0B",
        "outputId": "d8946612-87bd-4de9-89da-3a6ffee0d5ab"
      },
      "source": [
        "with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "\n",
        "    batch_size=s_batch_size*supervised_views\n",
        "    num_classes=classes_per_batch\n",
        "\n",
        "    local_images = batch_size*num_classes\n",
        "    total_images = local_images*world_size\n",
        "    diag_mask = torch.ones(local_images, total_images).to(device)\n",
        "    offset = rank*local_images\n",
        "    for i in range(local_images):\n",
        "        diag_mask[i, offset + i] = 0.\n",
        "\n",
        "    # Step 1: normalize embeddings\n",
        "    z = torch.nn.functional.normalize(z)\n",
        "\n",
        "    # Step 2: gather embeddings from all workers\n",
        "    z_buffer = AllGather.apply(z)\n",
        "\n",
        "    exp_cs = torch.exp(z @ z_buffer.T / temperature) * diag_mask\n",
        "\n",
        "    # Step 3: compute class predictions\n",
        "    probs = exp_cs.div(exp_cs.sum(dim=1, keepdim=True)) @ labels"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-478c6f82922e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mz_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAllGather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mexp_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mz_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiag_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Step 3: compute class predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (480) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "Knrqk2EGlAdL",
        "outputId": "75e93bd4-81fb-4ad5-ed99-e179374e680f"
      },
      "source": [
        "exp_cs.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-08a90542ae06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp_cs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'exp_cs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpbI7STBpQfN",
        "outputId": "aff1660c-e605-4c6d-de73-1bd67a8dd379"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4smnwIqgLXP"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 4: compute loss for predictions\n",
        "targets = labels[offset:offset+local_images]\n",
        "overlap = probs**(-targets)\n",
        "loss = torch.mean(torch.sum(torch.log(overlap), dim=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDfYaBSpgLaM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLvrW7V6gLdK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "estt7G71e-__"
      },
      "source": [
        "best_loss = None\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    logger.info('Epoch %d' % (epoch + 1))\n",
        "\n",
        "    # -- update distributed-data-loader epoch\n",
        "    unsupervised_sampler.set_epoch(epoch)\n",
        "    if supervised_sampler is not None:\n",
        "        supervised_sampler.set_epoch(epoch)\n",
        "\n",
        "    loss_meter = AverageMeter()\n",
        "    ploss_meter = AverageMeter()\n",
        "    rloss_meter = AverageMeter()\n",
        "    time_meter = AverageMeter()\n",
        "    data_meter = AverageMeter()\n",
        "\n",
        "    for itr, udata in enumerate(unsupervised_loader):\n",
        "        if use_fp16:\n",
        "            udata = [u.half() for u in udata]\n",
        "\n",
        "        def load_imgs():\n",
        "            # -- unsupervised imgs (2 views)\n",
        "            imgs = [u.to(device) for u in udata[:2]]\n",
        "\n",
        "            # -- labeled imgs\n",
        "            global iter_supervised\n",
        "            try:\n",
        "                sdata = next(iter_supervised)\n",
        "            except Exception:\n",
        "                iter_supervised = iter(supervised_loader)\n",
        "                logger.info(f'len.supervised_loader: {len(iter_supervised)}')\n",
        "                sdata = next(iter_supervised)\n",
        "                if use_fp16:\n",
        "                    sdata = [s.half() for s in sdata]\n",
        "            finally:\n",
        "                # -- shuffle images in sampled support mini-batch\n",
        "                simgs = [s.to(device) for s in sdata[:-1]]\n",
        "\n",
        "            # -- concatenate unlabeled images and labeled images\n",
        "            return torch.cat(imgs + simgs, dim=0)\n",
        "        (imgs), dtime = gpu_timer(load_imgs)\n",
        "        data_meter.update(dtime)\n",
        "\n",
        "        def train_step():\n",
        "            with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "                optimizer.zero_grad()\n",
        "                z = encoder(imgs)\n",
        "                # -- simclr loss\n",
        "                uloss = ntxent(z[:2*u_batch_size])\n",
        "                # -- suncet loss\n",
        "                sloss = suncet(z[2*u_batch_size:], labels)\n",
        "                loss = uloss\n",
        "                if epoch < supervised_epochs:\n",
        "                    loss += sloss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk7PY2ELe_Qo",
        "outputId": "788947ef-dd2e-428b-8732-620799dc5ea9"
      },
      "source": [
        "z[2*u_batch_size:].shape"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 2048])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n21qtnTUf4Ca",
        "outputId": "5d478fbb-de4c-4fbe-dbe4-a33ef6b95e39"
      },
      "source": [
        "z.shape"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([96, 2048])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H8UhVMOf4OY",
        "outputId": "e7cf93d5-e91d-4336-aedb-6b6ee8400436"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "HMyIo0UVf4e9",
        "outputId": "fe248a1e-1af1-4171-8bc2-990605f0b70c"
      },
      "source": [
        "sloss = suncet(z[2*u_batch_size:], labels)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-5f908c5359ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuncet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mu_batch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/suncet/src/losses.py\u001b[0m in \u001b[0;36mcontrastive_loss\u001b[0;34m(z, labels)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Step 3: compute class predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mexp_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mz_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiag_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_cs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_cs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# Step 4: compute loss for predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmZ7-W0AeYPS"
      },
      "source": [
        "##############################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNQ8C9LqAvY2",
        "outputId": "441b49d3-4cf9-4bbe-cae6-ba5c68ba117b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun 18 02:36:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6cMYXwHXI1C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}