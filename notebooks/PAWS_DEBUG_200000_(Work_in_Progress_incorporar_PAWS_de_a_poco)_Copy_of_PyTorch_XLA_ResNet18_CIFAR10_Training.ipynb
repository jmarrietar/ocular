{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " PAWS_DEBUG 200000 (Work in Progress incorporar PAWS de a poco) - Copy of PyTorch/XLA ResNet18/CIFAR10 Training",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/PAWS_DEBUG_200000_(Work_in_Progress_incorporar_PAWS_de_a_poco)_Copy_of_PyTorch_XLA_ResNet18_CIFAR10_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mskoYvt0MCaq",
        "outputId": "dc84813f-ef79-46d6-d6b4-7f77a99d3a75"
      },
      "source": [
        "pip install -U PyYAML"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l9EOMw3yQQlX",
        "outputId": "c1b0c3e6-0ea6-4cf9-a044-86c3e66a9e24"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6KiMba_MHkU",
        "outputId": "50219748-e5c7-4d55-b753-724bf6048c28"
      },
      "source": [
        "!git clone -b feature/DR-images-v2 https://github.com/jmarrietar/suncet.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'suncet'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Counting objects: 100% (336/336), done.\u001b[K\n",
            "remote: Compressing objects: 100% (214/214), done.\u001b[K\n",
            "remote: Total 336 (delta 199), reused 250 (delta 119), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (336/336), 1.11 MiB | 9.06 MiB/s, done.\n",
            "Resolving deltas: 100% (199/199), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtWmyuh4MK0J",
        "outputId": "6b872bb0-a939-41ca-c6df-ef2a83a866de"
      },
      "source": [
        "cd suncet"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mKok-0lMK4s"
      },
      "source": [
        "!mkdir datasets\n",
        "!mkdir datasets/dr\n",
        "!mkdir logs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTLU6dWXMK9B",
        "outputId": "36356256-46b2-4f33-9192-9caeee5b4490"
      },
      "source": [
        "!python download.py -d sample@2000"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\n",
            "To: /content/suncet/datasets/dr/sample@2000.zip\n",
            "214MB [00:02, 96.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDgnK-9LMLA4"
      },
      "source": [
        "import argparse\n",
        "import yaml"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pCIJ3u5MWBZ",
        "outputId": "fe4921ac-7364-403c-e8c3-a203d02a2a05"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    '--fname', type=str,\n",
        "    help='name of config file to load',\n",
        "    default='configs.yaml')\n",
        "parser.add_argument(\n",
        "    '--devices', type=str, nargs='+', default=['cuda:0'],\n",
        "    help='which devices to use on local machine')\n",
        "parser.add_argument(\n",
        "    '--sel', type=str,\n",
        "    help='which script to run',\n",
        "    choices=[\n",
        "        'paws_train',\n",
        "        'suncet_train',\n",
        "        'fine_tune',\n",
        "        'snn_fine_tune'\n",
        "    ])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--sel'], dest='sel', nargs=None, const=None, default=None, type=<class 'str'>, choices=['paws_train', 'suncet_train', 'fine_tune', 'snn_fine_tune'], help='which script to run', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "halcMg65MqwY"
      },
      "source": [
        "args = parser.parse_args(['--sel', 'paws_train',\n",
        "                            '--fname', 'configs/paws/dr_train.yaml'\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz8KUfZZPNlq"
      },
      "source": [
        "fname = args.fname\n",
        "sel = args.sel"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7G3xNSPPUrl"
      },
      "source": [
        "import pprint\n",
        "import logging\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "\n",
        "logger.info(f'called-params {sel} {fname}')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iRvWJmdPWqr",
        "outputId": "41f52eaa-747e-4ab4-f179-6baed2c3d2e8"
      },
      "source": [
        "# -- load script params\n",
        "params = None\n",
        "with open(fname, 'r') as y_file:\n",
        "    #params = yaml.load(y_file, Loader=yaml.FullLoader)\n",
        "    params = yaml.load(y_file)\n",
        "    logger.info('loaded params...')\n",
        "    #if rank == 0:\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    pp.pprint(params)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{   'criterion': {   'classes_per_batch': 2,\n",
            "                     'me_max': True,\n",
            "                     'sharpen': 0.25,\n",
            "                     'supervised_imgs_per_class': 32,\n",
            "                     'supervised_views': 1,\n",
            "                     'temperature': 0.1,\n",
            "                     'unsupervised_batch_size': 32},\n",
            "    'data': {   'color_jitter_strength': 1.0,\n",
            "                'data_seed': None,\n",
            "                'dataset': 'dr',\n",
            "                'label_smoothing': 0.1,\n",
            "                'multicrop': 6,\n",
            "                'normalize': True,\n",
            "                'root_path': 'datasets/',\n",
            "                's_image_folder': 'dr/sample@2000/',\n",
            "                'subset_path': 'dr_subsets',\n",
            "                'u_image_folder': 'dr/sample@2000/',\n",
            "                'unique_classes_per_rank': False,\n",
            "                'unlabeled_frac': 0.9},\n",
            "    'logging': {'folder': 'logs/', 'write_tag': 'paws'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'model_name': 'resnet50',\n",
            "                'output_dim': 2048,\n",
            "                'read_checkpoint': None,\n",
            "                'use_fp16': True,\n",
            "                'use_pred_head': True},\n",
            "    'optimization': {   'epochs': 100,\n",
            "                        'final_lr': 1e-05,\n",
            "                        'lr': 0.001,\n",
            "                        'momentum': 0.9,\n",
            "                        'nesterov': False,\n",
            "                        'start_lr': 0.001,\n",
            "                        'warmup': 10,\n",
            "                        'weight_decay': 1e-06}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IyTUPjAPYst"
      },
      "source": [
        "args = params"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIAvyISkOxSt"
      },
      "source": [
        "import os"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMdPRFXIn_jH"
      },
      "source": [
        "# Define Parameters\n",
        "FLAGS = {}\n",
        "FLAGS['data_dir'] = \"/tmp/cifar\"\n",
        "FLAGS['batch_size'] = 32\n",
        "FLAGS['num_workers'] = 2\n",
        "FLAGS['learning_rate'] = 0.02\n",
        "FLAGS['momentum'] = 0.9\n",
        "FLAGS['num_epochs'] = 10\n",
        "FLAGS['num_cores'] = 8 if os.environ.get('TPU_NAME', None) else 1\n",
        "FLAGS['log_steps'] = 20\n",
        "FLAGS['metrics_debug'] = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3npOhg9RuaH"
      },
      "source": [
        "FLAGS['model_name'] = args[\"meta\"][\"model_name\"]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8IkOQ9iZTzQ"
      },
      "source": [
        "model_name = args[\"meta\"][\"model_name\"]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzhD4JoAS5MP"
      },
      "source": [
        "output_dim = args[\"meta\"][\"output_dim\"]\n",
        "multicrop = args[\"data\"][\"multicrop\"]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFQzNvSTTFax"
      },
      "source": [
        "# -- CRITERTION\n",
        "reg = args[\"criterion\"][\"me_max\"]\n",
        "supervised_views = args[\"criterion\"][\"supervised_views\"]\n",
        "classes_per_batch = args[\"criterion\"][\"classes_per_batch\"]\n",
        "s_batch_size = args[\"criterion\"][\"supervised_imgs_per_class\"]\n",
        "u_batch_size = args[\"criterion\"][\"unsupervised_batch_size\"]\n",
        "temperature = args[\"criterion\"][\"temperature\"]\n",
        "sharpen = args[\"criterion\"][\"sharpen\"]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VPX6eJ7UgMK"
      },
      "source": [
        "# -- DATA\n",
        "unlabeled_frac = args[\"data\"][\"unlabeled_frac\"]\n",
        "color_jitter = args[\"data\"][\"color_jitter_strength\"]\n",
        "normalize = args[\"data\"][\"normalize\"]\n",
        "root_path = args[\"data\"][\"root_path\"]\n",
        "s_image_folder = args[\"data\"][\"s_image_folder\"]\n",
        "u_image_folder = args[\"data\"][\"u_image_folder\"]\n",
        "dataset_name = args[\"data\"][\"dataset\"]\n",
        "subset_path = args[\"data\"][\"subset_path\"]\n",
        "unique_classes = args[\"data\"][\"unique_classes_per_rank\"]\n",
        "label_smoothing = args[\"data\"][\"label_smoothing\"]\n",
        "data_seed = None"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBzLKYbOUtYO"
      },
      "source": [
        "crop_scale = (0.14, 1.0) if multicrop > 0 else (0.08, 1.0)\n",
        "mc_scale = (0.05, 0.14)\n",
        "mc_size = 96"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwZVxR2ZU7pn"
      },
      "source": [
        "copy_data = args[\"meta\"][\"copy_data\"]\n",
        "use_pred_head = args[\"meta\"][\"use_pred_head\"]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqLceQ2_aoGr"
      },
      "source": [
        "use_fp16 = args[\"meta\"][\"use_fp16\"]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s_OIC5Ma-1V"
      },
      "source": [
        "# -- OPTIMIZATION\n",
        "wd = float(args[\"optimization\"][\"weight_decay\"])\n",
        "num_epochs = args[\"optimization\"][\"epochs\"]\n",
        "warmup = args[\"optimization\"][\"warmup\"]\n",
        "start_lr = args[\"optimization\"][\"start_lr\"]\n",
        "lr = args[\"optimization\"][\"lr\"]\n",
        "final_lr = args[\"optimization\"][\"final_lr\"]\n",
        "mom = args[\"optimization\"][\"momentum\"]\n",
        "nesterov = args[\"optimization\"][\"nesterov\"]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lEMWRcAPa38"
      },
      "source": [
        "# ----------------------------------------------------------------------- #\n",
        "#  PASSED IN PARAMS FROM CONFIG FILE\n",
        "# ----------------------------------------------------------------------- #\n",
        "# -- META\n",
        "\n",
        "\n",
        "load_model = args[\"meta\"][\"load_checkpoint\"]\n",
        "r_file = args[\"meta\"][\"read_checkpoint\"]\n",
        "\n",
        "\n",
        "#device = torch.device(args[\"meta\"][\"device\"])\n",
        "device = xm.xla_device()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -- LOGGING\n",
        "folder = args[\"logging\"][\"folder\"]\n",
        "tag = args[\"logging\"][\"write_tag\"]\n",
        "# ----------------------------------------------------------------------- #\n",
        "\n",
        "# -- init torch distributed backend\n",
        "#world_size, rank = init_distributed()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7N60VarMvrC"
      },
      "source": [
        "import logging\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    gpu_timer,\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule,\n",
        "    CSVLogger,\n",
        "    AverageMeter,\n",
        ")\n",
        "from src.losses import init_paws_loss, make_labels_matrix\n",
        "from src.data_manager import init_data, make_transforms, make_multicrop_transform\n",
        "from src.sgd import SGD\n",
        "from src.lars import LARS\n",
        "\n",
        "import torchvision.models as models\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "#import apex\n",
        "from torch.nn.parallel import DistributedDataParallel"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhgKoRE3OKlW"
      },
      "source": [
        "def load_checkpoint(r_path, encoder, opt, scaler, use_fp16=False):\n",
        "    checkpoint = torch.load(r_path, map_location=\"cpu\")\n",
        "    epoch = checkpoint[\"epoch\"]\n",
        "\n",
        "    # -- loading encoder\n",
        "    encoder.load_state_dict(checkpoint[\"encoder\"])\n",
        "    logger.info(f\"loaded encoder from epoch {epoch}\")\n",
        "\n",
        "    # -- loading optimizer\n",
        "    opt.load_state_dict(checkpoint[\"opt\"])\n",
        "    if use_fp16:\n",
        "        scaler.load_state_dict(checkpoint[\"amp\"])\n",
        "    logger.info(f\"loaded optimizers from epoch {epoch}\")\n",
        "    logger.info(f\"read-path: {r_path}\")\n",
        "    del checkpoint\n",
        "    return encoder, opt, epoch\n",
        "\n",
        "\n",
        "def init_model(device, model_name=\"resnet50\", use_pred=False, output_dim=128):\n",
        "    if \"wide_resnet\" in model_name:\n",
        "        encoder = wide_resnet.__dict__[model_name](dropout_rate=0.0)\n",
        "        hidden_dim = 128\n",
        "    else:\n",
        "        encoder = resnet.__dict__[model_name]() \n",
        "\n",
        "        # Load pre-trained ResNetImagenNet\n",
        "        #logger.info(\"Load pre-trained ResNet ImagenNet weigths ...\")\n",
        "        #state_dict = load_state_dict_from_url('https://download.pytorch.org/models/resnet50-0676ba61.pth',progress=True)\n",
        "        #log = encoder.load_state_dict(state_dict, strict=False)\n",
        "        #logger.info(log)\n",
        "    \n",
        "        hidden_dim = 2048\n",
        "        if \"w2\" in model_name:\n",
        "            hidden_dim *= 2\n",
        "        elif \"w4\" in model_name:\n",
        "            hidden_dim *= 4\n",
        "\n",
        "    # -- projection head\n",
        "    encoder.fc = torch.nn.Sequential(\n",
        "        OrderedDict(\n",
        "            [\n",
        "                (\"fc1\", torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "                (\"bn1\", torch.nn.BatchNorm1d(hidden_dim)),\n",
        "                (\"relu1\", torch.nn.ReLU(inplace=True)),\n",
        "                (\"fc2\", torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "                (\"bn2\", torch.nn.BatchNorm1d(hidden_dim)),\n",
        "                (\"relu2\", torch.nn.ReLU(inplace=True)),\n",
        "                (\"fc3\", torch.nn.Linear(hidden_dim, output_dim)),\n",
        "            ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # -- prediction head\n",
        "    encoder.pred = None\n",
        "    if use_pred:\n",
        "        mx = 4  # 4x bottleneck prediction head\n",
        "        pred_head = OrderedDict([])\n",
        "        pred_head[\"bn1\"] = torch.nn.BatchNorm1d(output_dim)\n",
        "        pred_head[\"fc1\"] = torch.nn.Linear(output_dim, output_dim // mx)\n",
        "        pred_head[\"bn2\"] = torch.nn.BatchNorm1d(output_dim // mx)\n",
        "        pred_head[\"relu\"] = torch.nn.ReLU(inplace=True)\n",
        "        pred_head[\"fc2\"] = torch.nn.Linear(output_dim // mx, output_dim)\n",
        "        encoder.pred = torch.nn.Sequential(pred_head)\n",
        "\n",
        "    encoder.to(device)\n",
        "    logger.info(encoder)\n",
        "    return encoder\n",
        "\n",
        "\n",
        "def init_opt(\n",
        "    encoder,\n",
        "    iterations_per_epoch,\n",
        "    start_lr,\n",
        "    ref_lr,\n",
        "    ref_mom,\n",
        "    nesterov,\n",
        "    warmup,\n",
        "    num_epochs,\n",
        "    weight_decay=1e-6,\n",
        "    final_lr=0.0,\n",
        "):\n",
        "    param_groups = [\n",
        "        {\n",
        "            \"params\": (\n",
        "                p\n",
        "                for n, p in encoder.named_parameters()\n",
        "                if (\"bias\" not in n) and (\"bn\" not in n)\n",
        "            )\n",
        "        },\n",
        "        {\n",
        "            \"params\": (\n",
        "                p for n, p in encoder.named_parameters() if (\"bias\" in n) or (\"bn\" in n)\n",
        "            ),\n",
        "            \"LARS_exclude\": True,\n",
        "            \"weight_decay\": 0,\n",
        "        },\n",
        "    ]\n",
        "    optimizer = SGD(\n",
        "        param_groups,\n",
        "        weight_decay=weight_decay,\n",
        "        momentum=0.9,\n",
        "        nesterov=nesterov,\n",
        "        lr=ref_lr,\n",
        "    )\n",
        "    scheduler = WarmupCosineSchedule(\n",
        "        optimizer,\n",
        "        warmup_steps=warmup * iterations_per_epoch,\n",
        "        start_lr=start_lr,\n",
        "        ref_lr=ref_lr,\n",
        "        final_lr=final_lr,\n",
        "        T_max=num_epochs * iterations_per_epoch,\n",
        "    )\n",
        "    optimizer = LARS(optimizer, trust_coefficient=0.001)\n",
        "    return encoder, optimizer, scheduler"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX1hxqUQn47M"
      },
      "source": [
        "## PyTorch/XLA ResNet18/CIFAR10 (GPU or TPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLQPoJ6Fn8wF"
      },
      "source": [
        "### [RUNME] Install Colab compatible PyTorch/XLA wheels and dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O53lrJMDn9Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2516782c-7b11-460b-f445-6e43adcdf1e7"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-xla==1.8.1\n",
            "  Using cached https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl (145.0 MB)\n",
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.32.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (21.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.2.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy5ndp3nJPbD",
        "outputId": "585dfe98-7ca6-4994-f5a7-aa3f98aed18d"
      },
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch==1.8.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 1.8.1\n",
            "Uninstalling torch-1.8.1:\n",
            "  Successfully uninstalled torch-1.8.1\n",
            "Collecting torch==1.8.1\n",
            "  Using cached torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJSWXG7FKF5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203ace38-dd51-4e91-afd7-76a7e69095fa"
      },
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.serialization as xser\n",
        "import torch_xla.utils.utils as xu\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6H47dPVMAIJ"
      },
      "source": [
        "import gdown"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyHKXfPULVP1"
      },
      "source": [
        "def download(data, url):\n",
        "    # Download dataset\n",
        "    import zipfile\n",
        "    url = url\n",
        "    output = \"{}.zip\".format(data)\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # Uncompress dataset\n",
        "    local_zip = '{}.zip'.format(data)\n",
        "    zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDhpxrcKLX7W"
      },
      "source": [
        "data_samples = {\n",
        "    \"sample@200\": \"https://drive.google.com/uc?id=1FfV7YyDJvNUCDP5r3-8iQfZ2-xJp_pgb\",\n",
        "    \"sample@500\": \"https://drive.google.com/uc?id=1dHwUqpmSogEdjAB9rwDUL-OKFRUcVXte\",\n",
        "    \"sample@1000\": \"https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\",\n",
        "    \"sample@2000\": \"https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\",\n",
        "    \"sample@3000\": \"https://drive.google.com/uc?id=1_yre5K9YYvJgSrT4xvrI8eD_htucIywA\",\n",
        "    \"sample@4000_images\": \"https://drive.google.com/uc?id=1dqVB8EozEpwWzyuU80AauoQmsiw3Gtm2\",\n",
        "    \"sample@20000\": \"https://drive.google.com/uc?id=1MTDpLzpmhSiZq2jSdmHx2UDPn9FC8gzO\",\n",
        "    \"val-voets-tf\": \"https://drive.google.com/uc?id=1VzVgMGTkBBPG2qbzLunD9HvLzH6tcyrv\",\n",
        "    \"train_voets\": \"https://drive.google.com/uc?id=1AmcFh1MOOZ6aqKm2eO7XEdgmIEqHKTZ5\",\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\"\n",
        "}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q1J6gqYLZC7"
      },
      "source": [
        "UNLABELED = 'sample@2000'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy-BZSTOLaFm"
      },
      "source": [
        "URL_UNLABELED = data_samples[UNLABELED]\n",
        "download(UNLABELED, URL_UNLABELED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IednejwkIW-K"
      },
      "source": [
        "Only run the below commented cell if you would like a nightly release"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-bBdzgeISaP"
      },
      "source": [
        "# VERSION = \"nightly\"  #@param [\"nightly\", \"20200516\"]  # or YYYYMMDD format\n",
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --version $VERSION\n",
        "# import os \n",
        "# os.environ['LD_LIBRARY_PATH']='/usr/local/lib'\n",
        "# !echo $LD_LIBRARY_PATH\n",
        "\n",
        "# !sudo ln -s /usr/local/lib/libmkl_intel_lp64.so /usr/local/lib/libmkl_intel_lp64.so.1\n",
        "# !sudo ln -s /usr/local/lib/libmkl_intel_thread.so /usr/local/lib/libmkl_intel_thread.so.1\n",
        "# !sudo ln -s /usr/local/lib/libmkl_core.so /usr/local/lib/libmkl_core.so.1\n",
        "\n",
        "# !ldconfig\n",
        "# !ldd /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFzLg5gy7l6"
      },
      "source": [
        "# PyTorch/XLA GPU Setup (only if GPU runtime)\n",
        "import os\n",
        "if os.environ.get('COLAB_GPU', '0') == '1':\n",
        "  os.environ['GPU_NUM_DEVICES'] = '1'\n",
        "  os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda/'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rroH9yiAn-XE"
      },
      "source": [
        "### Define Parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMojPWZUqr2s"
      },
      "source": [
        "# Result Visualization Helper\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "M, N = 4, 6\n",
        "RESULT_IMG_PATH = '/tmp/test_result.jpg'\n",
        "CIFAR10_LABELS = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "def plot_results(images, labels, preds):\n",
        "  images, labels, preds = images[:M*N], labels[:M*N], preds[:M*N]\n",
        "  inv_norm = transforms.Normalize(\n",
        "      mean=(-0.4914/0.2023, -0.4822/0.1994, -0.4465/0.2010),\n",
        "      std=(1/0.2023, 1/0.1994, 1/0.2010))\n",
        "\n",
        "  num_images = images.shape[0]\n",
        "  fig, axes = plt.subplots(M, N, figsize=(16, 9))\n",
        "  fig.suptitle('Correct / Predicted Labels (Red text for incorrect ones)')\n",
        "\n",
        "  for i, ax in enumerate(fig.axes):\n",
        "    ax.axis('off')\n",
        "    if i >= num_images:\n",
        "      continue\n",
        "    img, label, prediction = images[i], labels[i], preds[i]\n",
        "    img = inv_norm(img)\n",
        "    img = img.permute(1, 2, 0) # (C, M, N) -> (M, N, C)\n",
        "    label, prediction = label.item(), prediction.item()\n",
        "    if label == prediction:\n",
        "      ax.set_title(u'\\u2713', color='blue', fontsize=22)\n",
        "    else:\n",
        "      ax.set_title(\n",
        "          'X {}/{}'.format(CIFAR10_LABELS[label],\n",
        "                          CIFAR10_LABELS[prediction]), color='red')\n",
        "    ax.imshow(img)\n",
        "  plt.savefig(RESULT_IMG_PATH, transparent=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Micd3xZvoA-c"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.utils as xu\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(\n",
        "        planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != self.expansion * planes:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(\n",
        "              in_planes,\n",
        "              self.expansion * planes,\n",
        "              kernel_size=1,\n",
        "              stride=stride,\n",
        "              bias=False), nn.BatchNorm2d(self.expansion * planes))\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "  def __init__(self, block, num_blocks, num_classes=2):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_planes = 64\n",
        "\n",
        "    self.conv1 = nn.Conv2d(\n",
        "        3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "    self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "  def _make_layer(self, block, planes, num_blocks, stride):\n",
        "    strides = [stride] + [1] * (num_blocks - 1)\n",
        "    layers = []\n",
        "    for stride in strides:\n",
        "      layers.append(block(self.in_planes, planes, stride))\n",
        "      self.in_planes = planes * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = F.avg_pool2d(out, 4)\n",
        "    out = torch.flatten(out, 1)\n",
        "    out = self.linear(out)\n",
        "    return F.log_softmax(out, dim=1)\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "  return ResNet(BasicBlock, [2, 2, 2, 2])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-JwDHNgcNoY7",
        "outputId": "0d0c4be3-5641-47e0-d071-22f04c8235f1"
      },
      "source": [
        "UNLABELED"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sample@2000'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAQa6S0zNphR"
      },
      "source": [
        "from src.utils import (\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule,\n",
        "    CSVLogger,\n",
        "    AverageMeter,\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxcIdOv7S69w"
      },
      "source": [
        "############## DEBUG #################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtarGcwWXfKU"
      },
      "source": [
        "transform, init_transform = make_transforms(\n",
        "  dataset_name=dataset_name,\n",
        "  subset_path=subset_path,\n",
        "  unlabeled_frac=unlabeled_frac,\n",
        "  training=True,\n",
        "  split_seed=data_seed,\n",
        "  crop_scale=crop_scale,\n",
        "  basic_augmentations=False,\n",
        "  color_jitter=color_jitter,\n",
        "  normalize=normalize,\n",
        ")\n",
        "multicrop_transform = (multicrop, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eVb1N6iTAS7",
        "outputId": "e6d4458b-7fb2-4c4f-8ea1-b971d65d4595"
      },
      "source": [
        "(\n",
        "    unsupervised_loader,\n",
        "    unsupervised_sampler,\n",
        "    supervised_loader,\n",
        "    supervised_sampler,\n",
        ") = init_data(\n",
        "    dataset_name=dataset_name,\n",
        "    transform=transform,\n",
        "    init_transform=init_transform,\n",
        "    supervised_views=supervised_views,\n",
        "    u_batch_size=u_batch_size,\n",
        "    s_batch_size=s_batch_size,\n",
        "    unique_classes=unique_classes,\n",
        "    classes_per_batch=classes_per_batch,\n",
        "    multicrop_transform=multicrop_transform,\n",
        "    world_size=xm.xrt_world_size(),\n",
        "    rank=xm.get_ordinal(),\n",
        "    root_path=root_path,\n",
        "    s_image_folder=s_image_folder,\n",
        "    u_image_folder=u_image_folder,\n",
        "    training=True,\n",
        "    copy_data=copy_data,\n",
        "  )"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "self.multicrop_transform (6, None)\n",
            "self.multicrop_transform (0, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXcyjZICWPDu",
        "outputId": "28acc065-27a6-4944-a8b8-b2be11b59d29"
      },
      "source": [
        "supervised_loader"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fe55a0393d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAQQC149W-Xy"
      },
      "source": [
        "iter_supervised = iter(supervised_loader)\n",
        "logger.info(f\"len.supervised_loader: {len(iter_supervised)}\")\n",
        "sdata = next(iter_supervised)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgExk0u1YeOC"
      },
      "source": [
        "ipe = len(unsupervised_loader)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw-SBfkcYfHr",
        "outputId": "812f2a6f-77d7-4597-c518-5393a4a975b4"
      },
      "source": [
        "ipe"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9RgBpklZRCV"
      },
      "source": [
        "# -- init model\n",
        "encoder = init_model(\n",
        "  device=device,\n",
        "  model_name=model_name,\n",
        "  use_pred=use_pred_head,\n",
        "  output_dim=output_dim,\n",
        ")\n",
        "\n",
        "# -- init losses\n",
        "paws = init_paws_loss(multicrop=multicrop, tau=temperature, T=sharpen, me_max=reg)\n",
        "# -- assume support images are sampled with ClassStratifiedSampler\n",
        "labels_matrix = make_labels_matrix(\n",
        "  num_classes=classes_per_batch,\n",
        "  s_batch_size=s_batch_size,\n",
        "  world_size=xm.xrt_world_size(),\n",
        "  device=device,\n",
        "  unique_classes=unique_classes,\n",
        "  smoothing=label_smoothing,\n",
        ") "
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiWsnZqqaFyb"
      },
      "source": [
        "scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "encoder, optimizer, scheduler = init_opt(\n",
        "      encoder=encoder,\n",
        "      weight_decay=wd,\n",
        "      start_lr=start_lr,\n",
        "      ref_lr=lr,\n",
        "      final_lr=final_lr,\n",
        "      ref_mom=mom,\n",
        "      nesterov=nesterov,\n",
        "      iterations_per_epoch=ipe,\n",
        "      warmup=warmup,\n",
        "      num_epochs=num_epochs,\n",
        "  )"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UGlVSh8Y3EV"
      },
      "source": [
        "device = xm.xla_device()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4fSnJbzYwY0"
      },
      "source": [
        "def train_loop_fn(supervised_loader, unsupervised_loader, epoch):\n",
        "    print(\"Entre a `train_loop_fn`\")\n",
        "\n",
        "    # -- TRAINING LOOP\n",
        "    best_loss = None\n",
        "\n",
        "    logger.info(\"Epoch %d\" % (epoch + 1))\n",
        "\n",
        "    \"\"\"\n",
        "    TO DO: Hacer un Double CHECK EN este Sampler!!!\n",
        "    \"\"\"\n",
        "    # -- update distributed-data-loader epoch\n",
        "    unsupervised_sampler.set_epoch(epoch)\n",
        "    if supervised_sampler is not None:\n",
        "        supervised_sampler.set_epoch(epoch)\n",
        "\n",
        "    loss_meter = AverageMeter()\n",
        "    ploss_meter = AverageMeter()\n",
        "    rloss_meter = AverageMeter()\n",
        "    time_meter = AverageMeter()\n",
        "    data_meter = AverageMeter()\n",
        "\n",
        "    for itr, udata in enumerate(unsupervised_loader):\n",
        "\n",
        "        def load_imgs():\n",
        "            # -- unsupervised imgs\n",
        "            uimgs = [u.to(device, non_blocking=True) for u in udata[:-1]]\n",
        "            # -- supervised imgs\n",
        "            global iter_supervised\n",
        "            try:\n",
        "                sdata = next(iter_supervised)\n",
        "            except Exception:\n",
        "                iter_supervised = iter(supervised_loader)\n",
        "                logger.info(f\"len.supervised_loader: {len(iter_supervised)}\")\n",
        "                sdata = next(iter_supervised)\n",
        "            finally:\n",
        "                labels = torch.cat([labels_matrix for _ in range(supervised_views)])\n",
        "                simgs = [s.to(device, non_blocking=True) for s in sdata[:-1]]\n",
        "            # -- concatenate supervised imgs and unsupervised imgs\n",
        "            imgs = simgs + uimgs\n",
        "            return imgs, labels\n",
        "\n",
        "        (imgs, labels) = load_imgs()\n",
        "\n",
        "        def train_step():\n",
        "            with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # --\n",
        "                # h: representations of 'imgs' before head\n",
        "                # z: representations of 'imgs' after head\n",
        "                # -- If use_pred_head=False, then encoder.pred (prediction\n",
        "                #    head) is None, and _forward_head just returns the\n",
        "                #    identity, z=h\n",
        "                h, z = encoder(imgs, return_before_head=True)\n",
        "\n",
        "                # Compute paws loss in full precision\n",
        "                with torch.cuda.amp.autocast(enabled=False):\n",
        "\n",
        "                    # Step 1. convert representations to fp32\n",
        "                    h, z = h.float(), z.float()\n",
        "\n",
        "                    # Step 2. determine anchor views/supports and their\n",
        "                    #         corresponding target views/supports\n",
        "                    # --\n",
        "                    num_support = (\n",
        "                        supervised_views * s_batch_size * classes_per_batch\n",
        "                    )\n",
        "                    # --\n",
        "                    anchor_supports = z[:num_support]\n",
        "                    anchor_views = z[num_support:]\n",
        "                    # --\n",
        "                    target_supports = h[:num_support].detach()\n",
        "                    target_views = h[num_support:].detach()\n",
        "                    target_views = torch.cat(\n",
        "                        [\n",
        "                            target_views[u_batch_size : 2 * u_batch_size],\n",
        "                            target_views[:u_batch_size],\n",
        "                        ],\n",
        "                        dim=0,\n",
        "                    )\n",
        "\n",
        "                    # Step 3. compute paws loss with me-max regularization\n",
        "                    (ploss, me_max) = paws(\n",
        "                        anchor_views=anchor_views,\n",
        "                        anchor_supports=anchor_supports,\n",
        "                        anchor_support_labels=labels,\n",
        "                        target_views=target_views,\n",
        "                        target_supports=target_supports,\n",
        "                        target_support_labels=labels,\n",
        "                    )\n",
        "                    loss = ploss + me_max\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            lr_stats = scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            return (float(loss), float(ploss), float(me_max), lr_stats)\n",
        "\n",
        "        (loss, ploss, rloss, lr_stats) = train_step()\n",
        "        loss_meter.update(loss)\n",
        "        ploss_meter.update(ploss)\n",
        "        rloss_meter.update(rloss)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ufI2Ti2S9EN"
      },
      "source": [
        "######################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vMl96KLoCq8"
      },
      "source": [
        "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
        "# Only instantiate model weights once in memory.\n",
        "WRAPPED_MODEL = xmp.MpModelWrapper(ResNet18())\n",
        "\n",
        "def train_resnet18():\n",
        "  torch.manual_seed(1)\n",
        "\n",
        "  ############# PAWS CODE ##################\n",
        "\n",
        "  device = xm.xla_device()\n",
        "\n",
        "  # -- init model\n",
        "  encoder = init_model(\n",
        "    device=device,\n",
        "    model_name=model_name,\n",
        "    use_pred=use_pred_head,\n",
        "    output_dim=output_dim,\n",
        "  )\n",
        "\n",
        "  # -- init losses\n",
        "  paws = init_paws_loss(multicrop=multicrop, tau=temperature, T=sharpen, me_max=reg)\n",
        "  # -- assume support images are sampled with ClassStratifiedSampler\n",
        "  labels_matrix = make_labels_matrix(\n",
        "    num_classes=classes_per_batch,\n",
        "    s_batch_size=s_batch_size,\n",
        "    world_size=xm.xrt_world_size(),\n",
        "    device=device,\n",
        "    unique_classes=unique_classes,\n",
        "    smoothing=label_smoothing,\n",
        "  ) \n",
        "\n",
        "  print(\"normalize {}\".format(normalize))\n",
        "\n",
        "# -- make data transforms\n",
        "  transform, init_transform = make_transforms(\n",
        "    dataset_name=dataset_name,\n",
        "    subset_path=subset_path,\n",
        "    unlabeled_frac=unlabeled_frac,\n",
        "    training=True,\n",
        "    split_seed=data_seed,\n",
        "    crop_scale=crop_scale,\n",
        "    basic_augmentations=False,\n",
        "    color_jitter=color_jitter,\n",
        "    normalize=normalize,\n",
        "  )\n",
        "  multicrop_transform = (multicrop, None)\n",
        "  if multicrop > 0:\n",
        "    multicrop_transform = make_multicrop_transform(\n",
        "        dataset_name=dataset_name,\n",
        "        num_crops=multicrop,\n",
        "        size=mc_size,\n",
        "        crop_scale=mc_scale,\n",
        "        normalize=normalize,\n",
        "        color_distortion=color_jitter,\n",
        "    )\n",
        "\n",
        "# -- init data-loaders/samplers\n",
        "  (\n",
        "    unsupervised_loader,\n",
        "    unsupervised_sampler,\n",
        "    supervised_loader,\n",
        "    supervised_sampler,\n",
        ") = init_data(\n",
        "    dataset_name=dataset_name,\n",
        "    transform=transform,\n",
        "    init_transform=init_transform,\n",
        "    supervised_views=supervised_views,\n",
        "    u_batch_size=u_batch_size,\n",
        "    s_batch_size=s_batch_size,\n",
        "    unique_classes=unique_classes,\n",
        "    classes_per_batch=classes_per_batch,\n",
        "    multicrop_transform=multicrop_transform,\n",
        "    world_size=xm.xrt_world_size(),\n",
        "    rank=xm.get_ordinal(),\n",
        "    root_path=root_path,\n",
        "    s_image_folder=s_image_folder,\n",
        "    u_image_folder=u_image_folder,\n",
        "    training=True,\n",
        "    copy_data=copy_data,\n",
        "  )\n",
        "  iter_supervised = None\n",
        "  ipe = len(unsupervised_loader)\n",
        "\n",
        "  print(\"len unsuupervised dataloader IS: {}\".format(ipe))\n",
        "\n",
        "\n",
        "  iter_supervised = None\n",
        "  ipe = len(unsupervised_loader)\n",
        "  logger.info(f\"iterations per epoch: {ipe}\")\n",
        "\n",
        "    # -- init optimizer and scheduler\n",
        "  scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "  encoder, optimizer, scheduler = init_opt(\n",
        "        encoder=encoder,\n",
        "        weight_decay=wd,\n",
        "        start_lr=start_lr,\n",
        "        ref_lr=lr,\n",
        "        final_lr=final_lr,\n",
        "        ref_mom=mom,\n",
        "        nesterov=nesterov,\n",
        "        iterations_per_epoch=ipe,\n",
        "        warmup=warmup,\n",
        "        num_epochs=num_epochs,\n",
        "    )\n",
        "  \n",
        "    #if xm.xrt_world_size() > 1:\n",
        "    #    encoder = DistributedDataParallel(encoder, broadcast_buffers=False)\n",
        "\n",
        "\n",
        "\n",
        "  start_epoch = 0\n",
        "\n",
        "  def train_loop_fn(supervised_loader, unsupervised_loader, epoch):\n",
        "      print(\"Entre a `train_loop_fn`\")\n",
        "\n",
        "      # -- TRAINING LOOP\n",
        "      best_loss = None\n",
        "\n",
        "      logger.info(\"Epoch %d\" % (epoch + 1))\n",
        "\n",
        "      \"\"\"\n",
        "      TO DO: Hacer un Double CHECK EN este Sampler!!!\n",
        "      \"\"\"\n",
        "      # -- update distributed-data-loader epoch\n",
        "      unsupervised_sampler.set_epoch(epoch)\n",
        "      if supervised_sampler is not None:\n",
        "          supervised_sampler.set_epoch(epoch)\n",
        "\n",
        "      loss_meter = AverageMeter()\n",
        "      ploss_meter = AverageMeter()\n",
        "      rloss_meter = AverageMeter()\n",
        "      time_meter = AverageMeter()\n",
        "      data_meter = AverageMeter()\n",
        "\n",
        "      for itr, udata in enumerate(unsupervised_loader):\n",
        "          print(\"Entre a `for itr, udata`\")\n",
        "          def load_imgs():\n",
        "              # -- unsupervised imgs\n",
        "              uimgs = [u.to(device, non_blocking=True) for u in udata[:-1]]\n",
        "              # -- supervised imgs\n",
        "              global iter_supervised\n",
        "              try:\n",
        "                  sdata = next(iter_supervised)\n",
        "              except Exception:\n",
        "                  iter_supervised = iter(supervised_loader)\n",
        "                  logger.info(f\"len.supervised_loader: {len(iter_supervised)}\")\n",
        "                  sdata = next(iter_supervised)\n",
        "              finally:\n",
        "                  labels = torch.cat([labels_matrix for _ in range(supervised_views)])\n",
        "                  simgs = [s.to(device, non_blocking=True) for s in sdata[:-1]]\n",
        "              # -- concatenate supervised imgs and unsupervised imgs\n",
        "              imgs = simgs + uimgs\n",
        "              return imgs, labels\n",
        "\n",
        "          (imgs, labels) = load_imgs()\n",
        "          \n",
        "          def train_step():\n",
        "              print(\"Entre a train_step()\")\n",
        "              with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "                  optimizer.zero_grad()\n",
        "\n",
        "                  # --\n",
        "                  # h: representations of 'imgs' before head\n",
        "                  # z: representations of 'imgs' after head\n",
        "                  # -- If use_pred_head=False, then encoder.pred (prediction\n",
        "                  #    head) is None, and _forward_head just returns the\n",
        "                  #    identity, z=h\n",
        "                  h, z = encoder(imgs, return_before_head=True)\n",
        "\n",
        "                  # Compute paws loss in full precision\n",
        "                  with torch.cuda.amp.autocast(enabled=False):\n",
        "\n",
        "                      # Step 1. convert representations to fp32\n",
        "                      h, z = h.float(), z.float()\n",
        "\n",
        "                      # Step 2. determine anchor views/supports and their\n",
        "                      #         corresponding target views/supports\n",
        "                      # --\n",
        "                      num_support = (\n",
        "                          supervised_views * s_batch_size * classes_per_batch\n",
        "                      )\n",
        "                      # --\n",
        "                      anchor_supports = z[:num_support]\n",
        "                      anchor_views = z[num_support:]\n",
        "                      # --\n",
        "                      target_supports = h[:num_support].detach()\n",
        "                      target_views = h[num_support:].detach()\n",
        "                      target_views = torch.cat(\n",
        "                          [\n",
        "                              target_views[u_batch_size : 2 * u_batch_size],\n",
        "                              target_views[:u_batch_size],\n",
        "                          ],\n",
        "                          dim=0,\n",
        "                      )\n",
        "\n",
        "                      # Step 3. compute paws loss with me-max regularization\n",
        "                      (ploss, me_max) = paws(\n",
        "                          anchor_views=anchor_views,\n",
        "                          anchor_supports=anchor_supports,\n",
        "                          anchor_support_labels=labels,\n",
        "                          target_views=target_views,\n",
        "                          target_supports=target_supports,\n",
        "                          target_support_labels=labels,\n",
        "                      )\n",
        "                      loss = ploss + me_max\n",
        "\n",
        "              scaler.scale(loss).backward(). # DOUBLE CHECK HERE, SI ESTA CORDE CON TPU?\n",
        "              lr_stats = scaler.step(optimizer)\n",
        "              scaler.update()\n",
        "              scheduler.step()\n",
        "              return (float(loss), float(ploss), float(me_max), lr_stats)\n",
        "\n",
        "          (loss, ploss, rloss, lr_stats) = train_step()\n",
        "          #(loss, ploss, rloss, lr_stats) = (0,0,0,0)\n",
        "          loss_meter.update(loss)\n",
        "          ploss_meter.update(ploss)\n",
        "          rloss_meter.update(rloss)\n",
        "\n",
        "  ##########################################\n",
        "\n",
        "  \"\"\"\n",
        "  # Scale learning rate to num cores\n",
        "  learning_rate = FLAGS['learning_rate'] * xm.xrt_world_size()\n",
        "\n",
        "  # Get loss function, optimizer, and model\n",
        "  device = xm.xla_device()\n",
        "  model = WRAPPED_MODEL.to(device)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
        "                        momentum=FLAGS['momentum'], weight_decay=5e-4)\n",
        "  loss_fn = nn.NLLLoss()\n",
        "\n",
        "  def train_loop_fn(loader):\n",
        "    tracker = xm.RateTracker()\n",
        "    model.train()\n",
        "    for x, (data, target) in enumerate(loader):\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "      loss = loss_fn(output, target)\n",
        "      loss.backward()\n",
        "      xm.optimizer_step(optimizer)\n",
        "      tracker.add(FLAGS['batch_size'])\n",
        "      if x % FLAGS['log_steps'] == 0:\n",
        "        print('[xla:{}]({}) Loss={:.5f} Rate={:.2f} GlobalRate={:.2f} Time={}'.format(\n",
        "            xm.get_ordinal(), x, loss.item(), tracker.rate(),\n",
        "            tracker.global_rate(), time.asctime()), flush=True)\n",
        "\n",
        "\n",
        "  # Train and eval loops\n",
        "  accuracy = 0.0\n",
        "  data, pred, target = None, None, None\n",
        "  for epoch in range(1, FLAGS['num_epochs'] + 1):\n",
        "    para_loader = pl.ParallelLoader(train_loader, [device])\n",
        "    train_loop_fn(para_loader.per_device_loader(device))\n",
        "    xm.master_print(\"Finished training epoch {}\".format(epoch))\n",
        "\n",
        "  return accuracy, data, pred, target\n",
        "  \"\"\"\n",
        "  data, pred, target = None, None, None\n",
        "\n",
        "  train_supervised_loader = pl.MpDeviceLoader(supervised_loader, device)\n",
        "  train_unsupervised_loader = pl.MpDeviceLoader(unsupervised_loader, device)\n",
        "\n",
        "  #for epoch in range(start_epoch, end_epoch):\n",
        "  for epoch in range(start_epoch, 10):\n",
        "      print(\"Epoch is {}\".format(epoch))\n",
        "      #para_loader_1 = pl.ParallelLoader(supervised_loader, [device])\n",
        "      #para_loader_2 = pl.ParallelLoader(unsupervised_loader, [device])\n",
        "      # train_loop_fn(para_loader.per_device_loader(device))\n",
        "      train_loop_fn(train_supervised_loader, train_unsupervised_loader, epoch)\n",
        "      xm.master_print(\"Finished training epoch {}\".format(epoch))\n",
        "  return accuracy, data, pred, target"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4XH5qFgkvRf"
      },
      "source": [
        "\"\"\"\n",
        "TO DO: \n",
        "  - Ando Teniendo un problema ademas en el train_step() DEBUGGEARLO. \n",
        "  - ¿Por que se me esta rompiendo ahi?\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2nL4HmloEyl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ace6260b-c0a6-4ed4-d9f8-d250a6638321"
      },
      "source": [
        "# Start training processes\n",
        "def _mp_fn(rank, flags):\n",
        "  global FLAGS\n",
        "  FLAGS = flags\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  accuracy, data, pred, target = train_resnet18()\n",
        "\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n",
        "          start_method='fork')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normalize True\n",
            "self.multicrop_transform (6, Compose(\n",
            "    Compose(\n",
            "    RandomResizedCrop(size=(96, 96), scale=(0.05, 0.14), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    Compose(\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            ")\n",
            "    <src.data_manager.GaussianBlur object at 0x7f835d2a92d0>\n",
            "    ToTensor()\n",
            ")\n",
            "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "))\n",
            "self.multicrop_transform (0, None)\n",
            "len unsuupervised dataloader IS: 7\n",
            "Epoch is 0\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Finished training epoch 0\n",
            "Epoch is 1\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Finished training epoch 1\n",
            "Epoch is 2\n",
            "Entre a `train_loop_fn`\n",
            "normalize True\n",
            "self.multicrop_transform (6, Compose(\n",
            "    Compose(\n",
            "    RandomResizedCrop(size=(96, 96), scale=(0.05, 0.14), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    Compose(\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            ")\n",
            "    <src.data_manager.GaussianBlur object at 0x7f835d2a77d0>\n",
            "    ToTensor()\n",
            ")\n",
            "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "))\n",
            "self.multicrop_transform (0, None)\n",
            "len unsuupervised dataloader IS: 7\n",
            "Epoch is 0\n",
            "Entre a `train_loop_fn`\n",
            "normalize True\n",
            "self.multicrop_transform (6, Compose(\n",
            "    Compose(\n",
            "    RandomResizedCrop(size=(96, 96), scale=(0.05, 0.14), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    Compose(\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            ")\n",
            "    <src.data_manager.GaussianBlur object at 0x7f835d2ad390>\n",
            "    ToTensor()\n",
            ")\n",
            "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "))\n",
            "self.multicrop_transform (0, None)\n",
            "len unsuupervised dataloader IS: 7\n",
            "Epoch is 0\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "normalize True\n",
            "self.multicrop_transform (6, Compose(\n",
            "    Compose(\n",
            "    RandomResizedCrop(size=(96, 96), scale=(0.05, 0.14), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    Compose(\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            ")\n",
            "    <src.data_manager.GaussianBlur object at 0x7f835d29ed50>\n",
            "    ToTensor()\n",
            ")\n",
            "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "))\n",
            "self.multicrop_transform (0, None)\n",
            "len unsuupervised dataloader IS: 7\n",
            "Epoch is 0\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "normalize True\n",
            "self.multicrop_transform (6, Compose(\n",
            "    Compose(\n",
            "    RandomResizedCrop(size=(96, 96), scale=(0.05, 0.14), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    Compose(\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            ")\n",
            "    <src.data_manager.GaussianBlur object at 0x7f835d2a3a90>\n",
            "    ToTensor()\n",
            ")\n",
            "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "))\n",
            "self.multicrop_transform (0, None)\n",
            "Entre a `for itr, udata`\n",
            "len unsuupervised dataloader IS: 7\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 0\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 1\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Finished training epoch 2\n",
            "Epoch is 3\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 1\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 1\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 1\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 2\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 2\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Finished training epoch 3\n",
            "Epoch is 4\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "normalize True\n",
            "Entre a `for itr, udata`\n",
            "self.multicrop_transform (6, Compose(\n",
            "    Compose(\n",
            "    RandomResizedCrop(size=(96, 96), scale=(0.05, 0.14), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    Compose(\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            ")\n",
            "    <src.data_manager.GaussianBlur object at 0x7f835d2b40d0>\n",
            "    ToTensor()\n",
            ")\n",
            "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "))\n",
            "self.multicrop_transform (0, None)\n",
            "len unsuupervised dataloader IS: 7\n",
            "Epoch is 0\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 3\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 2\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 2\n",
            "Entre a `train_loop_fn`\n",
            "normalize True\n",
            "self.multicrop_transform (6, Compose(\n",
            "    Compose(\n",
            "    RandomResizedCrop(size=(96, 96), scale=(0.05, 0.14), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    Compose(\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            ")\n",
            "    <src.data_manager.GaussianBlur object at 0x7f835d2ac650>\n",
            "    ToTensor()\n",
            ")\n",
            "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "))\n",
            "self.multicrop_transform (0, None)\n",
            "len unsuupervised dataloader IS: 7\n",
            "Epoch is 0\n",
            "Entre a `train_loop_fn`\n",
            "normalize True\n",
            "self.multicrop_transform (6, Compose(\n",
            "    Compose(\n",
            "    RandomResizedCrop(size=(96, 96), scale=(0.05, 0.14), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    Compose(\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            ")\n",
            "    <src.data_manager.GaussianBlur object at 0x7f835d2a9510>\n",
            "    ToTensor()\n",
            ")\n",
            "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "))\n",
            "self.multicrop_transform (0, None)\n",
            "len unsuupervised dataloader IS: 7\n",
            "Epoch is 0\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 3\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Finished training epoch 4\n",
            "Epoch is 5\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 1\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 3\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 1\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 4\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 3\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 4\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 4\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 1\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 2\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Finished training epoch 5\n",
            "Epoch is 6\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 4\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 5\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 2\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 5\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 5\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 5\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 2\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Finished training epoch 6\n",
            "Epoch is 7\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 3\n",
            "Entre a `train_loop_fn`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Entre a `for itr, udata`\n",
            "Epoch is 6\n",
            "Entre a `train_loop_fn`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-d45824df1ca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n\u001b[0;32m----> 9\u001b[0;31m           start_method='fork')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m         ready = multiprocessing.connection.wait(\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         )\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wt7wEVJoFmf"
      },
      "source": [
        "## Visualize Predictions"
      ]
    }
  ]
}