{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " PAWS_TPU-DR-PyTorch/XLA",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/PAWS_TPU_DR_PyTorch_XLA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wF3c4xmKQofR",
        "outputId": "a3ae1602-219c-449c-a9ee-bd5054f29630"
      },
      "source": [
        "\"\"\"\n",
        "To Do: \n",
        "  - Dont Donwload several Times ResNet model. How?. \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nTo Do: \\n  - Dont Donwload several Times ResNet model. How?. \\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O53lrJMDn9Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16a0c37-5724-40d6-d6e7-44160c434ac5"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-xla==1.8.1\n",
            "  Using cached https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl (145.0 MB)\n",
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.34.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (21.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy5ndp3nJPbD",
        "outputId": "1501b1a1-8da7-4838-bad2-048612e1cd29"
      },
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch==1.8.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 1.8.1\n",
            "Uninstalling torch-1.8.1:\n",
            "  Successfully uninstalled torch-1.8.1\n",
            "Collecting torch==1.8.1\n",
            "  Using cached torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Micd3xZvoA-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d30a7db-5814-4ac5-da80-890083c92459"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.utils as xu\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import argparse\n",
        "import yaml\n",
        "import pprint\n",
        "import logging\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_c5YRxZRjL1o",
        "outputId": "f776e108-ff8a-40b3-d659-499b1a8fb87a"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mskoYvt0MCaq",
        "outputId": "6b6aa27c-4392-4ad5-cb14-d8b4df8d6876"
      },
      "source": [
        "pip install -U PyYAML"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (5.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l9EOMw3yQQlX",
        "outputId": "81e1986a-26ad-47f5-9742-a5f94b7cb8a5"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6KiMba_MHkU",
        "outputId": "c7ab691a-6c27-416e-9a12-bda321154477"
      },
      "source": [
        "!git clone -b feature/DR-images-v2 https://github.com/jmarrietar/suncet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'suncet' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtWmyuh4MK0J",
        "outputId": "e3940021-c78a-44c7-c523-3eba7936b548"
      },
      "source": [
        "cd suncet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mKok-0lMK4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28bf4f7-23eb-42f1-8218-9ad97224cd54"
      },
      "source": [
        "!mkdir datasets\n",
        "!mkdir datasets/dr\n",
        "!mkdir logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘datasets’: File exists\n",
            "mkdir: cannot create directory ‘datasets/dr’: File exists\n",
            "mkdir: cannot create directory ‘logs’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTLU6dWXMK9B",
        "outputId": "d444f350-f238-4a0a-e42d-73c74e41d0fd"
      },
      "source": [
        "!python download.py -d sample@2000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\n",
            "To: /content/suncet/datasets/dr/sample@2000.zip\n",
            "214MB [00:01, 173MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBmSTGMT_3KO",
        "outputId": "bce0b9c0-5372-4abe-f89f-9b935752f484"
      },
      "source": [
        "!python download.py -d train_voets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AmcFh1MOOZ6aqKm2eO7XEdgmIEqHKTZ5\n",
            "To: /content/suncet/datasets/dr/train_voets.zip\n",
            "3.09GB [00:41, 74.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gy-BZSTOLaFm",
        "outputId": "2db8c475-965b-446d-c5b2-d3d381d65445"
      },
      "source": [
        "\"\"\"\n",
        "UNLABELED = 'sample@2000'\n",
        "\n",
        "URL_UNLABELED = data_samples[UNLABELED]\n",
        "download(UNLABELED, URL_UNLABELED)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nUNLABELED = 'sample@2000'\\n\\nURL_UNLABELED = data_samples[UNLABELED]\\ndownload(UNLABELED, URL_UNLABELED)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pCIJ3u5MWBZ",
        "outputId": "1cf04994-f72f-4379-9220-5c74b48496a7"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    '--fname', type=str,\n",
        "    help='name of config file to load',\n",
        "    default='configs.yaml')\n",
        "parser.add_argument(\n",
        "    '--devices', type=str, nargs='+', default=['cuda:0'],\n",
        "    help='which devices to use on local machine')\n",
        "parser.add_argument(\n",
        "    '--sel', type=str,\n",
        "    help='which script to run',\n",
        "    choices=[\n",
        "        'paws_train',\n",
        "        'suncet_train',\n",
        "        'fine_tune',\n",
        "        'snn_fine_tune'\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--sel'], dest='sel', nargs=None, const=None, default=None, type=<class 'str'>, choices=['paws_train', 'suncet_train', 'fine_tune', 'snn_fine_tune'], help='which script to run', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "halcMg65MqwY"
      },
      "source": [
        "args = parser.parse_args(['--sel', 'paws_train',\n",
        "                            '--fname', 'configs/paws/dr_train.yaml'\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz8KUfZZPNlq"
      },
      "source": [
        "fname = args.fname\n",
        "sel = args.sel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7G3xNSPPUrl"
      },
      "source": [
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "\n",
        "logger.info(f'called-params {sel} {fname}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iRvWJmdPWqr",
        "outputId": "b25f5187-ea35-4633-ca40-fc7b99fb1b4f"
      },
      "source": [
        "# -- load script params\n",
        "params = None\n",
        "with open(fname, 'r') as y_file:\n",
        "    #params = yaml.load(y_file, Loader=yaml.FullLoader)\n",
        "    params = yaml.load(y_file)\n",
        "    logger.info('loaded params...')\n",
        "    #if rank == 0:\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    pp.pprint(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{   'criterion': {   'classes_per_batch': 2,\n",
            "                     'me_max': True,\n",
            "                     'sharpen': 0.25,\n",
            "                     'supervised_imgs_per_class': 8,\n",
            "                     'supervised_views': 1,\n",
            "                     'temperature': 0.1,\n",
            "                     'unsupervised_batch_size': 32},\n",
            "    'data': {   'color_jitter_strength': 1.0,\n",
            "                'data_seed': None,\n",
            "                'dataset': 'dr',\n",
            "                'label_smoothing': 0.1,\n",
            "                'multicrop': 6,\n",
            "                'normalize': True,\n",
            "                'root_path': 'datasets/',\n",
            "                's_image_folder': 'dr/sample@2000/',\n",
            "                'subset_path': 'dr_subsets',\n",
            "                'u_image_folder': 'dr/train_voets/',\n",
            "                'unique_classes_per_rank': False,\n",
            "                'unlabeled_frac': 0.9},\n",
            "    'logging': {'folder': 'logs/', 'write_tag': 'paws'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'model_name': 'resnet50',\n",
            "                'output_dim': 2048,\n",
            "                'read_checkpoint': None,\n",
            "                'use_fp16': True,\n",
            "                'use_pred_head': True},\n",
            "    'optimization': {   'epochs': 100,\n",
            "                        'final_lr': 1e-05,\n",
            "                        'lr': 0.001,\n",
            "                        'momentum': 0.9,\n",
            "                        'nesterov': False,\n",
            "                        'start_lr': 0.001,\n",
            "                        'warmup': 10,\n",
            "                        'weight_decay': 1e-06}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IyTUPjAPYst"
      },
      "source": [
        "args = params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMdPRFXIn_jH"
      },
      "source": [
        "# Define Parameters\n",
        "FLAGS = {}\n",
        "FLAGS['data_dir'] = \"/tmp/cifar\"\n",
        "FLAGS['batch_size'] = 32\n",
        "FLAGS['num_workers'] = 2\n",
        "FLAGS['learning_rate'] = 0.02\n",
        "FLAGS['momentum'] = 0.9\n",
        "FLAGS['num_epochs'] = 10\n",
        "FLAGS['num_cores'] = 8 if os.environ.get('TPU_NAME', None) else 1\n",
        "FLAGS['log_steps'] = 20\n",
        "FLAGS['metrics_debug'] = False\n",
        "FLAGS['model_name'] = args[\"meta\"][\"model_name\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzhD4JoAS5MP"
      },
      "source": [
        "model_name = args[\"meta\"][\"model_name\"]\n",
        "output_dim = args[\"meta\"][\"output_dim\"]\n",
        "multicrop = args[\"data\"][\"multicrop\"]\n",
        "\n",
        "# -- CRITERTION\n",
        "reg = args[\"criterion\"][\"me_max\"]\n",
        "supervised_views = args[\"criterion\"][\"supervised_views\"]\n",
        "classes_per_batch = args[\"criterion\"][\"classes_per_batch\"]\n",
        "s_batch_size = args[\"criterion\"][\"supervised_imgs_per_class\"]\n",
        "u_batch_size = args[\"criterion\"][\"unsupervised_batch_size\"]\n",
        "temperature = args[\"criterion\"][\"temperature\"]\n",
        "sharpen = args[\"criterion\"][\"sharpen\"]\n",
        "\n",
        "# -- DATA\n",
        "unlabeled_frac = args[\"data\"][\"unlabeled_frac\"]\n",
        "color_jitter = args[\"data\"][\"color_jitter_strength\"]\n",
        "normalize = args[\"data\"][\"normalize\"]\n",
        "root_path = args[\"data\"][\"root_path\"]\n",
        "s_image_folder = args[\"data\"][\"s_image_folder\"]\n",
        "u_image_folder = args[\"data\"][\"u_image_folder\"]\n",
        "dataset_name = args[\"data\"][\"dataset\"]\n",
        "subset_path = args[\"data\"][\"subset_path\"]\n",
        "unique_classes = args[\"data\"][\"unique_classes_per_rank\"]\n",
        "label_smoothing = args[\"data\"][\"label_smoothing\"]\n",
        "data_seed = None\n",
        "\n",
        "copy_data = args[\"meta\"][\"copy_data\"]\n",
        "use_pred_head = args[\"meta\"][\"use_pred_head\"]\n",
        "\n",
        "use_fp16 = args[\"meta\"][\"use_fp16\"]\n",
        "\n",
        "# -- OPTIMIZATION\n",
        "wd = float(args[\"optimization\"][\"weight_decay\"])\n",
        "num_epochs = args[\"optimization\"][\"epochs\"]\n",
        "warmup = args[\"optimization\"][\"warmup\"]\n",
        "start_lr = args[\"optimization\"][\"start_lr\"]\n",
        "lr = args[\"optimization\"][\"lr\"]\n",
        "final_lr = args[\"optimization\"][\"final_lr\"]\n",
        "mom = args[\"optimization\"][\"momentum\"]\n",
        "nesterov = args[\"optimization\"][\"nesterov\"]\n",
        "\n",
        "\n",
        "# -- META\n",
        "load_model = args[\"meta\"][\"load_checkpoint\"]\n",
        "r_file = args[\"meta\"][\"read_checkpoint\"]\n",
        "\n",
        "\n",
        "# -- LOGGING\n",
        "folder = args[\"logging\"][\"folder\"]\n",
        "tag = args[\"logging\"][\"write_tag\"]\n",
        "# ----------------------------------------------------------------------- #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBzLKYbOUtYO"
      },
      "source": [
        "crop_scale = (0.14, 1.0) if multicrop > 0 else (0.08, 1.0)\n",
        "mc_scale = (0.05, 0.14)\n",
        "mc_size = 96"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7N60VarMvrC"
      },
      "source": [
        "import logging\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "import traceback\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    gpu_timer,\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule,\n",
        "    CSVLogger,\n",
        "    AverageMeter,\n",
        ")\n",
        "from src.losses import init_paws_loss, make_labels_matrix\n",
        "from src.data_manager import init_data, make_transforms, make_multicrop_transform\n",
        "from src.sgd import SGD\n",
        "from src.lars import LARS\n",
        "\n",
        "import torchvision.models as models\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "#import apex\n",
        "from torch.nn.parallel import DistributedDataParallel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCx_JdBzD05x"
      },
      "source": [
        "from src.paws_train import init_model\n",
        "from src.data_manager import ImageNet\n",
        "from src.data_manager import GaussianBlur"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX1hxqUQn47M"
      },
      "source": [
        "## PyTorch/XLA ResNet18/CIFAR10 (GPU or TPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJSWXG7FKF5n"
      },
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import time\n",
        "import gdown\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.serialization as xser\n",
        "import torch_xla.utils.utils as xu\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from src.utils import (\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule,\n",
        "    CSVLogger,\n",
        "    AverageMeter,\n",
        ")\n",
        "from src.utils import (\n",
        "    AllGather,\n",
        "    AllReduce\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyHKXfPULVP1"
      },
      "source": [
        "def download(data, url):\n",
        "    # Download dataset\n",
        "    import zipfile\n",
        "    url = url\n",
        "    output = \"{}.zip\".format(data)\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # Uncompress dataset\n",
        "    local_zip = '{}.zip'.format(data)\n",
        "    zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDhpxrcKLX7W"
      },
      "source": [
        "data_samples = {\n",
        "    \"sample@200\": \"https://drive.google.com/uc?id=1FfV7YyDJvNUCDP5r3-8iQfZ2-xJp_pgb\",\n",
        "    \"sample@500\": \"https://drive.google.com/uc?id=1dHwUqpmSogEdjAB9rwDUL-OKFRUcVXte\",\n",
        "    \"sample@1000\": \"https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\",\n",
        "    \"sample@2000\": \"https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\",\n",
        "    \"sample@3000\": \"https://drive.google.com/uc?id=1_yre5K9YYvJgSrT4xvrI8eD_htucIywA\",\n",
        "    \"sample@4000_images\": \"https://drive.google.com/uc?id=1dqVB8EozEpwWzyuU80AauoQmsiw3Gtm2\",\n",
        "    \"sample@20000\": \"https://drive.google.com/uc?id=1MTDpLzpmhSiZq2jSdmHx2UDPn9FC8gzO\",\n",
        "    \"val-voets-tf\": \"https://drive.google.com/uc?id=1VzVgMGTkBBPG2qbzLunD9HvLzH6tcyrv\",\n",
        "    \"train_voets\": \"https://drive.google.com/uc?id=1AmcFh1MOOZ6aqKm2eO7XEdgmIEqHKTZ5\",\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umuD5GhXawwo"
      },
      "source": [
        "multicrop=multicrop\n",
        "tau=temperature\n",
        "T=sharpen\n",
        "me_max=reg\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Make semi-supervised PAWS loss\n",
        "\n",
        ":param multicrop: number of small multi-crop views\n",
        ":param tau: cosine similarity temperature\n",
        ":param T: target sharpenning temperature\n",
        ":param me_max: whether to perform me-max regularization\n",
        "\"\"\"\n",
        "\n",
        "def sharpen_func(p):\n",
        "    sharp_p = p**(1./T)\n",
        "    sharp_p /= torch.sum(sharp_p, dim=1, keepdim=True)\n",
        "    return sharp_p\n",
        "\n",
        "def snn(query, supports, labels, tau):\n",
        "\n",
        "    softmax = torch.nn.Softmax(dim=1)\n",
        "    \"\"\" Soft Nearest Neighbours similarity classifier \"\"\"\n",
        "    # Step 1: normalize embeddings\n",
        "    query = torch.nn.functional.normalize(query)\n",
        "    supports = torch.nn.functional.normalize(supports)\n",
        "\n",
        "    # Step 2: gather embeddings from all workers\n",
        "    supports = AllGather.apply(supports)\n",
        "\n",
        "    # Step 3: compute similarlity between local embeddings\n",
        "\n",
        "    #result = softmax(query @ supports.T / tau) @ labels\n",
        "    result = torch.matmul(softmax(torch.matmul(query, supports.T / tau)), labels)\n",
        "\n",
        "    return result\n",
        "\n",
        "def my_loss_func(\n",
        "    anchor_views,\n",
        "    anchor_supports,\n",
        "    anchor_support_labels,\n",
        "    target_views,\n",
        "    target_supports,\n",
        "    target_support_labels,\n",
        "    sharpen=sharpen_func,\n",
        "    snn=snn\n",
        "):\n",
        "    # -- NOTE: num views of each unlabeled instance = 2+multicrop\n",
        "    batch_size = len(anchor_views) // (2+multicrop)\n",
        "\n",
        "    # Step 1: compute anchor predictions\n",
        "    probs = snn(anchor_views, anchor_supports, anchor_support_labels, tau)\n",
        "\n",
        "    # Step 2: compute targets for anchor predictions\n",
        "    with torch.no_grad():\n",
        "        targets = snn(target_views, target_supports, target_support_labels, tau)\n",
        "        targets = sharpen(targets)\n",
        "        if multicrop > 0:\n",
        "            mc_target = 0.5*(targets[:batch_size]+targets[batch_size:])\n",
        "            targets = torch.cat([targets, *[mc_target for _ in range(multicrop)]], dim=0)\n",
        "        targets[targets < 1e-4] *= 0  # numerical stability\n",
        "\n",
        "    # Step 3: compute cross-entropy loss H(targets, queries)\n",
        "    #loss = torch.mean(torch.sum(torch.log(probs**(-targets)), dim=1))\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    targets2 = targets.argmax(-1)\n",
        "    loss = criterion(probs, targets2)\n",
        "\n",
        "    # Step 4: compute me-max regularizer\n",
        "    rloss = 0.\n",
        "    if me_max:\n",
        "        avg_probs = AllReduce.apply(torch.mean(sharpen(probs), dim=0))\n",
        "        rloss -= torch.sum(torch.log(avg_probs**(-avg_probs)))\n",
        "\n",
        "    return loss, rloss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxQlRwv7TzBN"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG4xTLJxT0WA"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vMl96KLoCq8"
      },
      "source": [
        "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
        "# Only instantiate model weights once in memory.\n",
        "#WRAPPED_MODEL = xmp.MpModelWrapper(ResNet18())\n",
        "\n",
        "def train_resnet18():\n",
        "  torch.manual_seed(1)\n",
        "\n",
        "  ############# PAWS CODE ##################\n",
        "\n",
        "  device = xm.xla_device()\n",
        "\n",
        "  # -- init model\n",
        "  encoder = init_model(\n",
        "    device=device,\n",
        "    model_name=model_name,\n",
        "    use_pred=use_pred_head,\n",
        "    output_dim=output_dim,\n",
        "  )\n",
        "\n",
        "  # -- init losses\n",
        "  #paws = init_paws_loss(multicrop=multicrop, tau=temperature, T=sharpen, me_max=reg)\n",
        "  # -- assume support images are sampled with ClassStratifiedSampler\n",
        "\n",
        "  # 1. TO DO: Hacer el smooth de los labels Matrix.\n",
        "\n",
        "# -- make data transforms\n",
        "  transform, init_transform = make_transforms(\n",
        "    dataset_name=dataset_name,\n",
        "    subset_path=subset_path,\n",
        "    unlabeled_frac=unlabeled_frac,\n",
        "    training=True,\n",
        "    split_seed=data_seed,\n",
        "    crop_scale=crop_scale,\n",
        "    basic_augmentations=False,\n",
        "    color_jitter=color_jitter,\n",
        "    normalize=normalize,\n",
        "  )\n",
        "  multicrop_transform = (multicrop, None)\n",
        "  if multicrop > 0:\n",
        "    multicrop_transform = make_multicrop_transform(\n",
        "        dataset_name=dataset_name,\n",
        "        num_crops=multicrop,\n",
        "        size=mc_size,\n",
        "        crop_scale=mc_scale,\n",
        "        normalize=normalize,\n",
        "        color_distortion=color_jitter,\n",
        "    )\n",
        "\n",
        "# -- init data-loaders/samplers\n",
        "  (\n",
        "    unsupervised_loader,\n",
        "    unsupervised_sampler,\n",
        "    supervised_loader,\n",
        "    supervised_sampler,\n",
        ") = init_data(\n",
        "    dataset_name=dataset_name,\n",
        "    transform=transform,\n",
        "    init_transform=init_transform,\n",
        "    supervised_views=supervised_views,\n",
        "    u_batch_size=u_batch_size,\n",
        "    s_batch_size=s_batch_size,\n",
        "    unique_classes=unique_classes,\n",
        "    classes_per_batch=classes_per_batch,\n",
        "    multicrop_transform=multicrop_transform,\n",
        "    world_size=xm.xrt_world_size(),\n",
        "    rank=xm.get_ordinal(),\n",
        "    root_path=root_path,\n",
        "    s_image_folder=s_image_folder,\n",
        "    u_image_folder=u_image_folder,\n",
        "    training=True,\n",
        "    copy_data=copy_data,\n",
        "  )\n",
        "\n",
        "  #iter_supervised = None\n",
        "  ipe = len(unsupervised_loader)\n",
        "\n",
        "  logger.info(f\"iterations per epoch: {ipe}\")\n",
        "\n",
        "  # -- init optimizer and scheduler\n",
        "  #scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "  \n",
        "  # 2. TO DO: Optimizer Doble check learning rate\n",
        "  optimizer = torch.optim.Adam(encoder.parameters(), 0.0001, weight_decay=5e-4)\n",
        "\n",
        "  def train_loop_fn(supervised_loader, unsupervised_loader, epoch):\n",
        "      tracker = xm.RateTracker()\n",
        "      # -- TRAINING LOOP\n",
        "      best_loss = None\n",
        "\n",
        "      unsupervised_sampler.set_epoch(epoch)\n",
        "\n",
        "      loss_meter = AverageMeter()\n",
        "      ploss_meter = AverageMeter()\n",
        "      rloss_meter = AverageMeter()\n",
        "      time_meter = AverageMeter()\n",
        "      data_meter = AverageMeter()\n",
        "\n",
        "      for itr, udata in enumerate(unsupervised_loader):\n",
        "          def load_imgs(supervised_loader):\n",
        "              # -- unsupervised imgs\n",
        "              uimgs = [u.to(device, non_blocking=True) for u in udata[:-1]]\n",
        "              # -- supervised imgs\n",
        "              global iter_supervised\n",
        "              try:\n",
        "                  sdata = next(iter_supervised)\n",
        "              except Exception:\n",
        "                  iter_supervised = iter(supervised_loader)\n",
        "                  sdata = next(iter_supervised)\n",
        "              finally:\n",
        "                  idx = sdata[1].clone().detach()\n",
        "                  idx = idx.to(device)\n",
        "\n",
        "                  labels_matrix = torch.zeros(len(idx), idx.max()+1, device = device).scatter_(1, idx.unsqueeze(1), 1.)\n",
        "  \n",
        "                  labels_matrix = labels_matrix.to(device)\n",
        "                  labels = torch.cat([labels_matrix for _ in range(supervised_views)])\n",
        "                  simgs = [s.to(device, non_blocking=True) for s in sdata[:-1]]\n",
        "              # -- concatenate supervised imgs and unsupervised imgs\n",
        "              imgs = simgs + uimgs\n",
        "              return imgs, labels\n",
        "          \n",
        "          imgs, labels = load_imgs(supervised_loader)\n",
        "          \n",
        "          def train_step():\n",
        "\n",
        "              #with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # --\n",
        "              # h: representations of 'imgs' before head\n",
        "              # z: representations of 'imgs' after head\n",
        "              # -- If use_pred_head=False, then encoder.pred (prediction\n",
        "              #    head) is None, and _forward_head just returns the\n",
        "              #    identity, z=h\n",
        "              h, z = encoder(imgs, return_before_head=True)\n",
        "\n",
        "              # Compute paws loss in full precision\n",
        "              #with torch.cuda.amp.autocast(enabled=False):\n",
        "\n",
        "              # Step 1. convert representations to fp32\n",
        "              h, z = h.float(), z.float()\n",
        "\n",
        "              # Step 2. determine anchor views/supports and their\n",
        "              #         corresponding target views/supports\n",
        "              # --\n",
        "              num_support = (\n",
        "                  supervised_views * s_batch_size * classes_per_batch\n",
        "              )\n",
        "\n",
        "              # --\n",
        "              anchor_supports = z[:num_support]\n",
        "              anchor_views = z[num_support:]\n",
        "              # --\n",
        "              target_supports = h[:num_support].detach()\n",
        "              target_views = h[num_support:].detach()\n",
        "              target_views = torch.cat(\n",
        "                  [\n",
        "                      target_views[u_batch_size : 2 * u_batch_size],\n",
        "                      target_views[:u_batch_size],\n",
        "                  ],\n",
        "                  dim=0,\n",
        "              )\n",
        "\n",
        "              # Step 3. compute paws loss with me-max regularization\n",
        "              ploss, me_max = my_loss_func(\n",
        "                  anchor_views=anchor_views,\n",
        "                  anchor_supports=anchor_supports,\n",
        "                  anchor_support_labels=labels,\n",
        "                  target_views=target_views,\n",
        "                  target_supports=target_supports,\n",
        "                  target_support_labels=labels,\n",
        "              )\n",
        "\n",
        "              loss = ploss + me_max\n",
        "              loss.backward()\n",
        "\n",
        "              xm.optimizer_step(optimizer)\n",
        "\n",
        "              if itr % FLAGS.get(\"log_steps\") == 0:\n",
        "                  print(\n",
        "                      \"[xla:{}]({}) Loss={:.5f} Rate={:.2f} GlobalRate={:.2f} Time={}\".format(\n",
        "                          xm.get_ordinal(),\n",
        "                          itr,\n",
        "                          loss.item(),\n",
        "                          tracker.rate(),\n",
        "                          tracker.global_rate(),\n",
        "                          time.asctime(),\n",
        "                      ),\n",
        "                      flush=True,\n",
        "                  )\n",
        " \n",
        "              return (float(loss), float(ploss), float(me_max))\n",
        "\n",
        "          (loss, ploss, rloss) = train_step()\n",
        "          loss_meter.update(loss)\n",
        "          ploss_meter.update(ploss)\n",
        "          rloss_meter.update(rloss)\n",
        "\n",
        "  data, pred, target = None, None, None\n",
        "\n",
        "  start_epoch = 0\n",
        "  end_epoch = FLAGS.get(\"num_epochs\")\n",
        "\n",
        "  train_supervised_loader = pl.MpDeviceLoader(supervised_loader, device)\n",
        "  train_unsupervised_loader = pl.MpDeviceLoader(unsupervised_loader, device)\n",
        "\n",
        "  for epoch in range(start_epoch, end_epoch):\n",
        "      train_loop_fn(train_supervised_loader, train_unsupervised_loader, epoch)\n",
        "      xm.master_print(\"Finished training epoch {}\".format(epoch))\n",
        "  #return accuracy, data, pred, target\n",
        "  return 0, 0, 0, 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFXrf8Qd7V-E"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2nL4HmloEyl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f685ead-d454-43d2-bee2-ccfb26552af0"
      },
      "source": [
        "# Start training processes\n",
        "def _mp_fn(rank, flags):\n",
        "  global FLAGS\n",
        "  FLAGS = flags\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  accuracy, data, pred, target = train_resnet18()\n",
        "\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'], start_method='fork')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[xla:5](0) Loss=0.00413 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:45:42 2021\n",
            "[xla:3](0) Loss=-0.00526 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:45:51 2021\n",
            "[xla:7](0) Loss=0.16770 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:45:58 2021\n",
            "[xla:2](0) Loss=0.05073 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:45:58 2021\n",
            "[xla:1](0) Loss=0.00592 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:45:59 2021\n",
            "[xla:4](0) Loss=-0.00304 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:46:00 2021\n",
            "[xla:6](0) Loss=0.29993 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:46:02 2021\n",
            "[xla:0](0) Loss=-0.00944 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:46:04 2021\n",
            "[xla:3](20) Loss=0.02141 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:52:47 2021\n",
            "[xla:0](20) Loss=0.00342 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:52:47 2021\n",
            "[xla:5](20) Loss=0.00163 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:52:47 2021\n",
            "[xla:2](20) Loss=-0.01493 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:52:47 2021\n",
            "[xla:1](20) Loss=-0.00182 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:52:47 2021\n",
            "[xla:4](20) Loss=0.03034 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:53:00 2021\n",
            "[xla:7](20) Loss=0.00883 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:53:00 2021\n",
            "[xla:6](20) Loss=0.07193 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 19:53:00 2021\n",
            "[xla:5](40) Loss=-0.01364 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:13:06 2021\n",
            "[xla:1](40) Loss=0.03169 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:13:06 2021\n",
            "[xla:0](40) Loss=0.02912 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:13:06 2021\n",
            "[xla:2](40) Loss=0.04036 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:13:06 2021\n",
            "[xla:3](40) Loss=-0.00534 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:13:06 2021\n",
            "[xla:4](40) Loss=0.00068 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:13:06 2021\n",
            "[xla:7](40) Loss=0.01943 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:13:15 2021\n",
            "[xla:6](40) Loss=-0.01518 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:13:15 2021\n",
            "[xla:5](60) Loss=-0.00319 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:23:51 2021\n",
            "[xla:6](60) Loss=-0.03258 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:23:52 2021\n",
            "[xla:3](60) Loss=-0.01764 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:23:52 2021\n",
            "[xla:2](60) Loss=-0.03092 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:23:52 2021\n",
            "[xla:0](60) Loss=-0.08354 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:23:52 2021\n",
            "[xla:4](60) Loss=0.02050 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:23:52 2021\n",
            "[xla:1](60) Loss=0.03798 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:23:52 2021\n",
            "[xla:7](60) Loss=-0.02582 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:24:01 2021\n",
            "[xla:3](80) Loss=-0.02052 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:31:18 2021\n",
            "[xla:2](80) Loss=-0.02070 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:31:18 2021\n",
            "[xla:1](80) Loss=0.01049 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:31:18 2021\n",
            "[xla:5](80) Loss=0.00483 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:31:18 2021\n",
            "[xla:4](80) Loss=-0.03133 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:31:18 2021\n",
            "[xla:0](80) Loss=-0.04209 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:31:19 2021\n",
            "[xla:6](80) Loss=-0.02208 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:31:19 2021\n",
            "[xla:7](80) Loss=-0.05432 Rate=0.00 GlobalRate=0.00 Time=Sat Aug 21 20:31:19 2021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f5cfcdc99734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_resnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mp_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_cores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m         ready = multiprocessing.connection.wait(\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         )\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbuadnjxHi07"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}