{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine Tune SimCLR Pytorch XLA",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP0ELtTiF9pDpbX2I0P0e2Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/Fine_Tune_SimCLR_Pytorch_XLA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uT6Jrl1Tj3H",
        "outputId": "32952bd4-c992-457d-e65f-55981655bd47"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n",
            "Requirement already satisfied: torch-xla==1.8.1 from https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.30.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (20.9)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqgt-SPZs69T"
      },
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "from google.colab import auth, drive\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycMSo6gEs84s",
        "outputId": "f7755158-9394-4202-d961-99cfc6056876"
      },
      "source": [
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt0HysgJtDr-",
        "outputId": "54ee8ba4-3ff2-46c7-c3b3-350b6029a5ff"
      },
      "source": [
        "import torch_xla.utils.serialization as xser"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqTsJNBCaPgG"
      },
      "source": [
        "import gdown\n",
        "\n",
        "def download(data, url):\n",
        "    # Download dataset\n",
        "    import zipfile\n",
        "    url = url\n",
        "    output = \"{}.zip\".format(data)\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # Uncompress dataset\n",
        "    local_zip = '{}.zip'.format(data)\n",
        "    zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imFIHTdSayCb"
      },
      "source": [
        "data_samples = {\n",
        "    \"sample@200\": \"https://drive.google.com/uc?id=1FfV7YyDJvNUCDP5r3-8iQfZ2-xJp_pgb\",\n",
        "    \"sample@500\": \"https://drive.google.com/uc?id=1dHwUqpmSogEdjAB9rwDUL-OKFRUcVXte\",\n",
        "    \"sample@1000\": \"https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\",\n",
        "    \"sample@2000\": \"https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\",\n",
        "    \"sample@3000\": \"https://drive.google.com/uc?id=1_yre5K9YYvJgSrT4xvrI8eD_htucIywA\",\n",
        "    \"sample@4000_images\": \"https://drive.google.com/uc?id=1dqVB8EozEpwWzyuU80AauoQmsiw3Gtm2\",\n",
        "    \"sample@20000\": \"https://drive.google.com/uc?id=1MTDpLzpmhSiZq2jSdmHx2UDPn9FC8gzO\",\n",
        "    \"val-voets-tf\": \"https://drive.google.com/uc?id=1VzVgMGTkBBPG2qbzLunD9HvLzH6tcyrv\",\n",
        "    \"train_voets\": \"https://drive.google.com/uc?id=1AmcFh1MOOZ6aqKm2eO7XEdgmIEqHKTZ5\",\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jJgVayva20x"
      },
      "source": [
        "UNLABELED = 'sample@1000'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIQsaT_Ta75z",
        "outputId": "8d9e7227-6303-469e-a36e-be26581a8c52"
      },
      "source": [
        "URL_UNLABELED = data_samples[UNLABELED]\n",
        "download(UNLABELED, URL_UNLABELED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\n",
            "To: /content/sample@1000.zip\n",
            "108MB [00:00, 148MB/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYbCW5nqO66d"
      },
      "source": [
        "import args_parse\n",
        "\n",
        "SUPPORTED_MODELS = [\n",
        "    'alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201',\n",
        "    'inception_v3', 'resnet101', 'resnet152', 'resnet18', 'resnet34',\n",
        "    'resnet50', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13',\n",
        "    'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn'\n",
        "]\n",
        "\n",
        "MODEL_OPTS = {\n",
        "    '--model': {\n",
        "        'choices': SUPPORTED_MODELS,\n",
        "        'default': 'resnet50',\n",
        "    },\n",
        "    '--test_set_batch_size': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--lr_scheduler_type': {\n",
        "        'type': str,\n",
        "    },\n",
        "    '--lr_scheduler_divide_every_n_epochs': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--lr_scheduler_divisor': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--test_only_at_end': {\n",
        "        'action': 'store_true',\n",
        "    },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ggvTYidO9ZQ"
      },
      "source": [
        "FLAGS = args_parse.parse_common_options(\n",
        "    datadir=UNLABELED,\n",
        "    batch_size=None,\n",
        "    num_epochs=None,\n",
        "    momentum=None,\n",
        "    lr=None,\n",
        "    target_accuracy=None,\n",
        "    profiler_port=9012,\n",
        "    opts=MODEL_OPTS.items(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CSubsgJShgy"
      },
      "source": [
        "FLAGS.fake_data = False\n",
        "FLAGS.num_epochs = 200\n",
        "FLAGS.batch_size = 64\n",
        "FLAGS.log_steps = 100\n",
        "FLAGS.num_cores = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOH8ZjssOSd1"
      },
      "source": [
        "import os\n",
        "import schedulers\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch_xla\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.utils.utils as xu\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.test.test_utils as test_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SX0pnOwOxBP"
      },
      "source": [
        "DEFAULT_KWARGS = dict(\n",
        "    batch_size=128,\n",
        "    test_set_batch_size=64,\n",
        "    num_epochs=200,\n",
        "    momentum=0.9,\n",
        "    lr=0.05,\n",
        "    target_accuracy=0.0,\n",
        ")\n",
        "MODEL_SPECIFIC_DEFAULTS = {\n",
        "    # Override some of the args in DEFAULT_KWARGS, or add them to the dict\n",
        "    # if they don't exist.\n",
        "    'resnet50':\n",
        "        dict(\n",
        "            DEFAULT_KWARGS, **{\n",
        "                'lr': 0.05,\n",
        "                'lr_scheduler_divide_every_n_epochs': 20,\n",
        "                'lr_scheduler_divisor': 5,\n",
        "                'lr_scheduler_type': 'WarmupAndExponentialDecayScheduler',\n",
        "            })\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nad72u1lOyyh"
      },
      "source": [
        "# Set any args that were not explicitly given by the user.\n",
        "default_value_dict = MODEL_SPECIFIC_DEFAULTS.get(FLAGS.model, DEFAULT_KWARGS)\n",
        "for arg, value in default_value_dict.items():\n",
        "  if getattr(FLAGS, arg) is None:\n",
        "    setattr(FLAGS, arg, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDkym-NUUocK",
        "outputId": "d92a2dd7-7d85-4613-9b81-05693200dfb0"
      },
      "source": [
        "default_value_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 128,\n",
              " 'lr': 0.05,\n",
              " 'lr_scheduler_divide_every_n_epochs': 20,\n",
              " 'lr_scheduler_divisor': 5,\n",
              " 'lr_scheduler_type': 'WarmupAndExponentialDecayScheduler',\n",
              " 'momentum': 0.9,\n",
              " 'num_epochs': 200,\n",
              " 'target_accuracy': 0.0,\n",
              " 'test_set_batch_size': 64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaSFCSsHeVxY"
      },
      "source": [
        "def get_model_property(key):\n",
        "  default_model_property = {\n",
        "      'img_dim': 224,\n",
        "      'model_fn': getattr(torchvision.models, FLAGS.model)\n",
        "  }\n",
        "  model_properties = {\n",
        "      'inception_v3': {\n",
        "          'img_dim': 299,\n",
        "          'model_fn': lambda: torchvision.models.inception_v3(aux_logits=False)\n",
        "      },\n",
        "  }\n",
        "  model_fn = model_properties.get(FLAGS.model, default_model_property)[key]\n",
        "  return model_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4xo5QNANY_Q"
      },
      "source": [
        "def _train_update(device, step, loss, tracker, epoch, writer):\n",
        "  test_utils.print_training_update(\n",
        "      device,\n",
        "      step,\n",
        "      loss.item(),\n",
        "      tracker.rate(),\n",
        "      tracker.global_rate(),\n",
        "      epoch,\n",
        "      summary_writer=writer)\n",
        "\n",
        "\n",
        "def train_imagenet():\n",
        "  print('==> Preparing data..')\n",
        "  img_dim = get_model_property('img_dim')\n",
        "  if FLAGS.fake_data:\n",
        "    train_dataset_len = 1200000  # Roughly the size of Imagenet dataset.\n",
        "    train_loader = xu.SampleGenerator(\n",
        "        data=(torch.zeros(FLAGS.batch_size, 3, img_dim, img_dim),\n",
        "              torch.zeros(FLAGS.batch_size, dtype=torch.int64)),\n",
        "        sample_count=train_dataset_len // FLAGS.batch_size //\n",
        "        xm.xrt_world_size())\n",
        "    test_loader = xu.SampleGenerator(\n",
        "        data=(torch.zeros(FLAGS.test_set_batch_size, 3, img_dim, img_dim),\n",
        "              torch.zeros(FLAGS.test_set_batch_size, dtype=torch.int64)),\n",
        "        sample_count=50000 // FLAGS.batch_size // xm.xrt_world_size())\n",
        "  else:\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    train_dataset = torchvision.datasets.ImageFolder(\n",
        "        os.path.join(FLAGS.datadir, 'train'),\n",
        "        transforms.Compose([\n",
        "            transforms.RandomResizedCrop(img_dim),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "    train_dataset_len = len(train_dataset.imgs)\n",
        "    resize_dim = max(img_dim, 256)\n",
        "\n",
        "\n",
        "    train_sampler, test_sampler = None, None\n",
        "    if xm.xrt_world_size() > 1:\n",
        "      train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "          train_dataset,\n",
        "          num_replicas=xm.xrt_world_size(),\n",
        "          rank=xm.get_ordinal(),\n",
        "          shuffle=True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=FLAGS.batch_size,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=FLAGS.drop_last,\n",
        "        shuffle=False if train_sampler else True,\n",
        "        num_workers=FLAGS.num_workers)\n",
        "\n",
        "  torch.manual_seed(42)\n",
        "\n",
        "  device = xm.xla_device()\n",
        "  model = get_model_property('model_fn')().to(device)\n",
        "\n",
        "  model.fc = nn.Sequential(\n",
        "        nn.Linear(2048, 512),\n",
        "        nn.Linear(512, 1),\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  state_dict = xser.load('/content/drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR-70.pt')\n",
        "\n",
        "  for k in list(state_dict.keys()):\n",
        "\n",
        "    if k.startswith('backbone.'):\n",
        "      if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "        # remove prefix\n",
        "        state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "    del state_dict[k]\n",
        "\n",
        "  log = model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "  writer = None\n",
        "  if xm.is_master_ordinal():\n",
        "    writer = test_utils.get_summary_writer(FLAGS.logdir)\n",
        "  optimizer = optim.SGD(\n",
        "      model.parameters(),\n",
        "      lr=FLAGS.lr,\n",
        "      momentum=FLAGS.momentum,\n",
        "      weight_decay=1e-4)\n",
        "  num_training_steps_per_epoch = train_dataset_len // (\n",
        "      FLAGS.batch_size * xm.xrt_world_size())\n",
        "  lr_scheduler = schedulers.wrap_optimizer_with_scheduler(\n",
        "      optimizer,\n",
        "      scheduler_type=getattr(FLAGS, 'lr_scheduler_type', None),\n",
        "      scheduler_divisor=getattr(FLAGS, 'lr_scheduler_divisor', None),\n",
        "      scheduler_divide_every_n_epochs=getattr(\n",
        "          FLAGS, 'lr_scheduler_divide_every_n_epochs', None),\n",
        "      num_steps_per_epoch=num_training_steps_per_epoch,\n",
        "      summary_writer=writer)\n",
        "  \n",
        "\n",
        "  #loss_fn = nn.CrossEntropyLoss()\n",
        "  loss_fn = nn.BCELoss()\n",
        "\n",
        "  def train_loop_fn(loader, epoch):\n",
        "    tracker = xm.RateTracker()\n",
        "    model.train()\n",
        "    for step, (data, target) in enumerate(loader):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "\n",
        "      target = target.unsqueeze(1) ## YO\n",
        "      target = target.float() # YOO\n",
        "\n",
        "      loss = loss_fn(output, target)\n",
        "      loss.backward()\n",
        "      xm.optimizer_step(optimizer)\n",
        "      tracker.add(FLAGS.batch_size)\n",
        "      if lr_scheduler:\n",
        "        lr_scheduler.step()\n",
        "      if step % FLAGS.log_steps == 0:\n",
        "        xm.add_step_closure(\n",
        "            _train_update, args=(device, step, loss, tracker, epoch, writer))\n",
        "\n",
        "  train_device_loader = pl.MpDeviceLoader(train_loader, device)\n",
        "\n",
        "  for epoch in range(1, FLAGS.num_epochs + 1):\n",
        "    xm.master_print('Epoch {} train begin {}'.format(epoch, test_utils.now()))\n",
        "    train_loop_fn(train_device_loader, epoch)\n",
        "    xm.master_print('Epoch {} train end {}'.format(epoch, test_utils.now()))\n",
        "\n",
        "    if FLAGS.metrics_debug:\n",
        "      xm.master_print(met.metrics_report())\n",
        "\n",
        "  test_utils.close_summary_writer(writer)\n",
        "\n",
        "  xm.master_print(\"Finished training\")\n",
        "\n",
        "  xm.save(\n",
        "            model.state_dict(),\n",
        "            \"drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR-Finetuned-Test.pt\"\n",
        "        )\n",
        "\n",
        "  return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww2PE7HZOsGH"
      },
      "source": [
        "def _mp_fn(index, flags):\n",
        "  global FLAGS\n",
        "  FLAGS = flags\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  ans = train_imagenet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9h_SHYQUw82",
        "outputId": "1f3a1d14-7185-4bff-8eb2-5e50268a7f9f"
      },
      "source": [
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "Epoch 1 train begin 03:32:14\n",
            "| Training Device=xla:0/2 Epoch=1 Step=0 Loss=0.68646 Rate=4.74 GlobalRate=4.74 Time=03:32:32\n",
            "| Training Device=xla:0/5 Epoch=1 Step=0 Loss=0.69463 Rate=10.19 GlobalRate=10.19 Time=03:32:32\n",
            "| Training Device=xla:1/0 Epoch=1 Step=0 Loss=0.69235 Rate=3.58 GlobalRate=3.58 Time=03:32:32\n",
            "| Training Device=xla:0/3 Epoch=1 Step=0 Loss=0.69339 Rate=8.80 GlobalRate=8.80 Time=03:32:32\n",
            "| Training Device=xla:0/4 Epoch=1 Step=0 Loss=0.68110 Rate=7.35 GlobalRate=7.35 Time=03:32:32\n",
            "| Training Device=xla:0/6 Epoch=1 Step=0 Loss=0.68771 Rate=12.00 GlobalRate=12.00 Time=03:32:32\n",
            "| Training Device=xla:0/1 Epoch=1 Step=0 Loss=0.68265 Rate=18.89 GlobalRate=18.89 Time=03:32:32\n",
            "| Training Device=xla:0/7 Epoch=1 Step=0 Loss=0.68425 Rate=40.34 GlobalRate=40.34 Time=03:32:32\n",
            "Epoch 1 train end 03:32:33\n",
            "Epoch 2 train begin 03:32:33\n",
            "| Training Device=xla:0/4 Epoch=2 Step=0 Loss=0.67619 Rate=10.17 GlobalRate=10.17 Time=03:32:39\n",
            "| Training Device=xla:0/3 Epoch=2 Step=0 Loss=0.67810 Rate=10.17 GlobalRate=10.17 Time=03:32:39\n",
            "| Training Device=xla:1/0 Epoch=2 Step=0 Loss=0.68393 Rate=10.17 GlobalRate=10.17 Time=03:32:39\n",
            "| Training Device=xla:0/6 Epoch=2 Step=0 Loss=0.68243 Rate=10.16 GlobalRate=10.16 Time=03:32:39\n",
            "| Training Device=xla:0/5 Epoch=2 Step=0 Loss=0.68652 Rate=10.16 GlobalRate=10.16 Time=03:32:39\n",
            "| Training Device=xla:0/1 Epoch=2 Step=0 Loss=0.67621 Rate=10.16 GlobalRate=10.16 Time=03:32:39\n",
            "| Training Device=xla:0/2 Epoch=2 Step=0 Loss=0.68514 Rate=10.15 GlobalRate=10.15 Time=03:32:39\n",
            "| Training Device=xla:0/7 Epoch=2 Step=0 Loss=0.67292 Rate=10.14 GlobalRate=10.14 Time=03:32:39\n",
            "Epoch 2 train end 03:32:39\n",
            "Epoch 3 train begin 03:32:39\n",
            "| Training Device=xla:0/7 Epoch=3 Step=0 Loss=0.65260 Rate=10.44 GlobalRate=10.44 Time=03:32:45\n",
            "| Training Device=xla:0/2 Epoch=3 Step=0 Loss=0.67488 Rate=10.43 GlobalRate=10.43 Time=03:32:45\n",
            "| Training Device=xla:0/3 Epoch=3 Step=0 Loss=0.67243 Rate=10.43 GlobalRate=10.43 Time=03:32:45\n",
            "| Training Device=xla:0/6 Epoch=3 Step=0 Loss=0.66792 Rate=10.43 GlobalRate=10.43 Time=03:32:45\n",
            "| Training Device=xla:1/0 Epoch=3 Step=0 Loss=0.67458 Rate=10.44 GlobalRate=10.44 Time=03:32:45\n",
            "| Training Device=xla:0/4 Epoch=3 Step=0 Loss=0.65699 Rate=10.43 GlobalRate=10.43 Time=03:32:45\n",
            "| Training Device=xla:0/5 Epoch=3 Step=0 Loss=0.67107 Rate=10.42 GlobalRate=10.42 Time=03:32:45\n",
            "| Training Device=xla:0/1 Epoch=3 Step=0 Loss=0.65650 Rate=10.41 GlobalRate=10.41 Time=03:32:45\n",
            "Epoch 3 train end 03:32:45\n",
            "Epoch 4 train begin 03:32:45\n",
            "| Training Device=xla:1/0 Epoch=4 Step=0 Loss=0.66133 Rate=10.33 GlobalRate=10.33 Time=03:32:52\n",
            "| Training Device=xla:0/4 Epoch=4 Step=0 Loss=0.62226 Rate=10.33 GlobalRate=10.33 Time=03:32:52\n",
            "| Training Device=xla:0/5 Epoch=4 Step=0 Loss=0.64399 Rate=10.32 GlobalRate=10.32 Time=03:32:52\n",
            "| Training Device=xla:0/2 Epoch=4 Step=0 Loss=0.65466 Rate=10.32 GlobalRate=10.32 Time=03:32:52\n",
            "| Training Device=xla:0/6 Epoch=4 Step=0 Loss=0.64744 Rate=10.32 GlobalRate=10.32 Time=03:32:52\n",
            "| Training Device=xla:0/3 Epoch=4 Step=0 Loss=0.65795 Rate=10.32 GlobalRate=10.32 Time=03:32:52\n",
            "| Training Device=xla:0/7 Epoch=4 Step=0 Loss=0.62972 Rate=10.32 GlobalRate=10.32 Time=03:32:52\n",
            "| Training Device=xla:0/1 Epoch=4 Step=0 Loss=0.63216 Rate=10.32 GlobalRate=10.32 Time=03:32:52\n",
            "Epoch 4 train end 03:32:52\n",
            "Epoch 5 train begin 03:32:52\n",
            "| Training Device=xla:0/3 Epoch=5 Step=0 Loss=0.65149 Rate=10.43 GlobalRate=10.43 Time=03:32:58\n",
            "| Training Device=xla:0/7 Epoch=5 Step=0 Loss=0.61247 Rate=10.43 GlobalRate=10.43 Time=03:32:58\n",
            "| Training Device=xla:0/1 Epoch=5 Step=0 Loss=0.59852 Rate=10.43 GlobalRate=10.43 Time=03:32:58\n",
            "| Training Device=xla:0/2 Epoch=5 Step=0 Loss=0.62268 Rate=10.43 GlobalRate=10.43 Time=03:32:58\n",
            "| Training Device=xla:0/5 Epoch=5 Step=0 Loss=0.61442 Rate=10.43 GlobalRate=10.43 Time=03:32:58\n",
            "| Training Device=xla:0/4 Epoch=5 Step=0 Loss=0.58371 Rate=10.42 GlobalRate=10.42 Time=03:32:58\n",
            "| Training Device=xla:0/6 Epoch=5 Step=0 Loss=0.61690 Rate=10.42 GlobalRate=10.42 Time=03:32:58\n",
            "| Training Device=xla:1/0 Epoch=5 Step=0 Loss=0.64079 Rate=10.43 GlobalRate=10.43 Time=03:32:58\n",
            "Epoch 5 train end 03:32:58\n",
            "Epoch 6 train begin 03:32:58\n",
            "| Training Device=xla:1/0 Epoch=6 Step=0 Loss=0.61593 Rate=10.42 GlobalRate=10.42 Time=03:33:04\n",
            "| Training Device=xla:0/1 Epoch=6 Step=0 Loss=0.58707 Rate=10.42 GlobalRate=10.42 Time=03:33:04\n",
            "| Training Device=xla:0/7 Epoch=6 Step=0 Loss=0.57024 Rate=10.42 GlobalRate=10.42 Time=03:33:04\n",
            "| Training Device=xla:0/6 Epoch=6 Step=0 Loss=0.59883 Rate=10.41 GlobalRate=10.41 Time=03:33:04\n",
            "| Training Device=xla:0/4 Epoch=6 Step=0 Loss=0.52663 Rate=10.41 GlobalRate=10.41 Time=03:33:04\n",
            "| Training Device=xla:0/3 Epoch=6 Step=0 Loss=0.61889 Rate=10.41 GlobalRate=10.41 Time=03:33:04\n",
            "| Training Device=xla:0/5 Epoch=6 Step=0 Loss=0.57093 Rate=10.41 GlobalRate=10.41 Time=03:33:04\n",
            "| Training Device=xla:0/2 Epoch=6 Step=0 Loss=0.61570 Rate=10.41 GlobalRate=10.41 Time=03:33:04\n",
            "Epoch 6 train end 03:33:05\n",
            "Epoch 7 train begin 03:33:05\n",
            "| Training Device=xla:0/6 Epoch=7 Step=0 Loss=0.56450 Rate=10.37 GlobalRate=10.37 Time=03:33:11\n",
            "| Training Device=xla:0/2 Epoch=7 Step=0 Loss=0.56258 Rate=10.37 GlobalRate=10.37 Time=03:33:11\n",
            "| Training Device=xla:0/5 Epoch=7 Step=0 Loss=0.52811 Rate=10.37 GlobalRate=10.37 Time=03:33:11\n",
            "| Training Device=xla:0/7 Epoch=7 Step=0 Loss=0.51647 Rate=10.37 GlobalRate=10.37 Time=03:33:11\n",
            "| Training Device=xla:0/1 Epoch=7 Step=0 Loss=0.56931 Rate=10.37 GlobalRate=10.37 Time=03:33:11\n",
            "| Training Device=xla:0/4 Epoch=7 Step=0 Loss=0.48255 Rate=10.37 GlobalRate=10.37 Time=03:33:11\n",
            "| Training Device=xla:0/3 Epoch=7 Step=0 Loss=0.62926 Rate=10.37 GlobalRate=10.37 Time=03:33:11\n",
            "| Training Device=xla:1/0 Epoch=7 Step=0 Loss=0.58771 Rate=10.37 GlobalRate=10.37 Time=03:33:11\n",
            "Epoch 7 train end 03:33:11\n",
            "Epoch 8 train begin 03:33:11\n",
            "| Training Device=xla:0/7 Epoch=8 Step=0 Loss=0.49089 Rate=10.40 GlobalRate=10.40 Time=03:33:17\n",
            "| Training Device=xla:0/4 Epoch=8 Step=0 Loss=0.46482 Rate=10.40 GlobalRate=10.40 Time=03:33:17\n",
            "| Training Device=xla:0/2 Epoch=8 Step=0 Loss=0.52685 Rate=10.40 GlobalRate=10.40 Time=03:33:17\n",
            "| Training Device=xla:0/3 Epoch=8 Step=0 Loss=0.59942 Rate=10.40 GlobalRate=10.40 Time=03:33:17\n",
            "| Training Device=xla:0/1 Epoch=8 Step=0 Loss=0.50836 Rate=10.39 GlobalRate=10.39 Time=03:33:17\n",
            "| Training Device=xla:0/6 Epoch=8 Step=0 Loss=0.54769 Rate=10.39 GlobalRate=10.39 Time=03:33:17\n",
            "| Training Device=xla:1/0 Epoch=8 Step=0 Loss=0.56143 Rate=10.40 GlobalRate=10.40 Time=03:33:17\n",
            "| Training Device=xla:0/5 Epoch=8 Step=0 Loss=0.50507 Rate=10.39 GlobalRate=10.39 Time=03:33:17\n",
            "Epoch 8 train end 03:33:17\n",
            "Epoch 9 train begin 03:33:17\n",
            "| Training Device=xla:1/0 Epoch=9 Step=0 Loss=0.55567 Rate=10.37 GlobalRate=10.37 Time=03:33:24\n",
            "| Training Device=xla:0/3 Epoch=9 Step=0 Loss=0.57767 Rate=10.36 GlobalRate=10.36 Time=03:33:24\n",
            "| Training Device=xla:0/1 Epoch=9 Step=0 Loss=0.49442 Rate=10.36 GlobalRate=10.36 Time=03:33:24\n",
            "| Training Device=xla:0/5 Epoch=9 Step=0 Loss=0.42677 Rate=10.36 GlobalRate=10.36 Time=03:33:24\n",
            "| Training Device=xla:0/7 Epoch=9 Step=0 Loss=0.43085 Rate=10.36 GlobalRate=10.36 Time=03:33:24\n",
            "| Training Device=xla:0/4 Epoch=9 Step=0 Loss=0.40511 Rate=10.36 GlobalRate=10.36 Time=03:33:24\n",
            "| Training Device=xla:0/2 Epoch=9 Step=0 Loss=0.48350 Rate=10.36 GlobalRate=10.36 Time=03:33:24\n",
            "| Training Device=xla:0/6 Epoch=9 Step=0 Loss=0.57507 Rate=10.36 GlobalRate=10.36 Time=03:33:24\n",
            "Epoch 9 train end 03:33:24\n",
            "Epoch 10 train begin 03:33:24\n",
            "| Training Device=xla:0/6 Epoch=10 Step=0 Loss=0.51439 Rate=10.34 GlobalRate=10.34 Time=03:33:30\n",
            "| Training Device=xla:0/5 Epoch=10 Step=0 Loss=0.38008 Rate=10.34 GlobalRate=10.34 Time=03:33:30\n",
            "| Training Device=xla:0/7 Epoch=10 Step=0 Loss=0.42596 Rate=10.34 GlobalRate=10.34 Time=03:33:30\n",
            "| Training Device=xla:0/2 Epoch=10 Step=0 Loss=0.43335 Rate=10.34 GlobalRate=10.34 Time=03:33:30\n",
            "| Training Device=xla:0/1 Epoch=10 Step=0 Loss=0.45184 Rate=10.34 GlobalRate=10.34 Time=03:33:30\n",
            "| Training Device=xla:0/3 Epoch=10 Step=0 Loss=0.62547 Rate=10.34 GlobalRate=10.34 Time=03:33:30\n",
            "| Training Device=xla:0/4 Epoch=10 Step=0 Loss=0.42519 Rate=10.34 GlobalRate=10.34 Time=03:33:30\n",
            "| Training Device=xla:1/0 Epoch=10 Step=0 Loss=0.57241 Rate=10.34 GlobalRate=10.34 Time=03:33:30\n",
            "Epoch 10 train end 03:33:30\n",
            "Epoch 11 train begin 03:33:30\n",
            "| Training Device=xla:1/0 Epoch=11 Step=0 Loss=0.56960 Rate=10.27 GlobalRate=10.27 Time=03:33:37\n",
            "| Training Device=xla:0/5 Epoch=11 Step=0 Loss=0.36018 Rate=10.26 GlobalRate=10.26 Time=03:33:37\n",
            "| Training Device=xla:0/7 Epoch=11 Step=0 Loss=0.41125 Rate=10.26 GlobalRate=10.26 Time=03:33:37\n",
            "| Training Device=xla:0/3 Epoch=11 Step=0 Loss=0.66665 Rate=10.26 GlobalRate=10.26 Time=03:33:37\n",
            "| Training Device=xla:0/6 Epoch=11 Step=0 Loss=0.59190 Rate=10.26 GlobalRate=10.26 Time=03:33:37\n",
            "| Training Device=xla:0/1 Epoch=11 Step=0 Loss=0.36015 Rate=10.26 GlobalRate=10.26 Time=03:33:37\n",
            "| Training Device=xla:0/2 Epoch=11 Step=0 Loss=0.42560 Rate=10.26 GlobalRate=10.26 Time=03:33:37\n",
            "| Training Device=xla:0/4 Epoch=11 Step=0 Loss=0.42585 Rate=10.26 GlobalRate=10.26 Time=03:33:37\n",
            "Epoch 11 train end 03:33:37\n",
            "Epoch 12 train begin 03:33:37\n",
            "| Training Device=xla:0/1 Epoch=12 Step=0 Loss=0.31472 Rate=10.36 GlobalRate=10.36 Time=03:33:43\n",
            "| Training Device=xla:0/5 Epoch=12 Step=0 Loss=0.40915 Rate=10.37 GlobalRate=10.37 Time=03:33:43\n",
            "| Training Device=xla:0/4 Epoch=12 Step=0 Loss=0.37549 Rate=10.36 GlobalRate=10.36 Time=03:33:43\n",
            "| Training Device=xla:0/2 Epoch=12 Step=0 Loss=0.41027 Rate=10.36 GlobalRate=10.36 Time=03:33:43\n",
            "| Training Device=xla:0/3 Epoch=12 Step=0 Loss=0.56677 Rate=10.36 GlobalRate=10.36 Time=03:33:43\n",
            "| Training Device=xla:0/6 Epoch=12 Step=0 Loss=0.57429 Rate=10.36 GlobalRate=10.36 Time=03:33:43\n",
            "| Training Device=xla:0/7 Epoch=12 Step=0 Loss=0.39625 Rate=10.36 GlobalRate=10.36 Time=03:33:43\n",
            "| Training Device=xla:1/0 Epoch=12 Step=0 Loss=0.46047 Rate=10.36 GlobalRate=10.36 Time=03:33:43\n",
            "Epoch 12 train end 03:33:43\n",
            "Epoch 13 train begin 03:33:43\n",
            "| Training Device=xla:0/2 Epoch=13 Step=0 Loss=0.43971 Rate=10.39 GlobalRate=10.39 Time=03:33:49\n",
            "| Training Device=xla:0/1 Epoch=13 Step=0 Loss=0.40074 Rate=10.39 GlobalRate=10.39 Time=03:33:49\n",
            "| Training Device=xla:0/3 Epoch=13 Step=0 Loss=0.54589 Rate=10.39 GlobalRate=10.39 Time=03:33:49\n",
            "| Training Device=xla:0/4 Epoch=13 Step=0 Loss=0.35313 Rate=10.39 GlobalRate=10.39 Time=03:33:49\n",
            "| Training Device=xla:0/6 Epoch=13 Step=0 Loss=0.47988 Rate=10.39 GlobalRate=10.39 Time=03:33:49\n",
            "| Training Device=xla:0/5 Epoch=13 Step=0 Loss=0.31907 Rate=10.39 GlobalRate=10.39 Time=03:33:49\n",
            "| Training Device=xla:1/0 Epoch=13 Step=0 Loss=0.51726 Rate=10.38 GlobalRate=10.38 Time=03:33:49\n",
            "| Training Device=xla:0/7 Epoch=13 Step=0 Loss=0.34039 Rate=10.38 GlobalRate=10.38 Time=03:33:49\n",
            "Epoch 13 train end 03:33:50\n",
            "Epoch 14 train begin 03:33:50\n",
            "| Training Device=xla:1/0 Epoch=14 Step=0 Loss=0.48687 Rate=10.23 GlobalRate=10.23 Time=03:33:56\n",
            "| Training Device=xla:0/3 Epoch=14 Step=0 Loss=0.63011 Rate=10.23 GlobalRate=10.23 Time=03:33:56\n",
            "| Training Device=xla:0/4 Epoch=14 Step=0 Loss=0.33447 Rate=10.23 GlobalRate=10.23 Time=03:33:56\n",
            "| Training Device=xla:0/6 Epoch=14 Step=0 Loss=0.46437 Rate=10.23 GlobalRate=10.23 Time=03:33:56\n",
            "| Training Device=xla:0/2 Epoch=14 Step=0 Loss=0.40508 Rate=10.23 GlobalRate=10.23 Time=03:33:56\n",
            "| Training Device=xla:0/5 Epoch=14 Step=0 Loss=0.38058 Rate=10.23 GlobalRate=10.23 Time=03:33:56\n",
            "| Training Device=xla:0/7 Epoch=14 Step=0 Loss=0.37310 Rate=10.23 GlobalRate=10.23 Time=03:33:56\n",
            "| Training Device=xla:0/1 Epoch=14 Step=0 Loss=0.36468 Rate=10.22 GlobalRate=10.22 Time=03:33:56\n",
            "Epoch 14 train end 03:33:56\n",
            "Epoch 15 train begin 03:33:56\n",
            "| Training Device=xla:0/7 Epoch=15 Step=0 Loss=0.38425 Rate=10.22 GlobalRate=10.22 Time=03:34:02\n",
            "| Training Device=xla:0/5 Epoch=15 Step=0 Loss=0.32182 Rate=10.22 GlobalRate=10.22 Time=03:34:02\n",
            "| Training Device=xla:0/1 Epoch=15 Step=0 Loss=0.38259 Rate=10.22 GlobalRate=10.22 Time=03:34:02\n",
            "| Training Device=xla:0/2 Epoch=15 Step=0 Loss=0.41009 Rate=10.22 GlobalRate=10.22 Time=03:34:02\n",
            "| Training Device=xla:0/6 Epoch=15 Step=0 Loss=0.49696 Rate=10.22 GlobalRate=10.22 Time=03:34:02\n",
            "| Training Device=xla:1/0 Epoch=15 Step=0 Loss=0.49447 Rate=10.22 GlobalRate=10.22 Time=03:34:02\n",
            "| Training Device=xla:0/3 Epoch=15 Step=0 Loss=0.54479 Rate=10.22 GlobalRate=10.22 Time=03:34:02\n",
            "| Training Device=xla:0/4 Epoch=15 Step=0 Loss=0.39919 Rate=10.21 GlobalRate=10.21 Time=03:34:02\n",
            "Epoch 15 train end 03:34:03\n",
            "Epoch 16 train begin 03:34:03\n",
            "| Training Device=xla:0/4 Epoch=16 Step=0 Loss=0.29974 Rate=10.24 GlobalRate=10.24 Time=03:34:09\n",
            "| Training Device=xla:0/6 Epoch=16 Step=0 Loss=0.42983 Rate=10.24 GlobalRate=10.24 Time=03:34:09\n",
            "| Training Device=xla:0/5 Epoch=16 Step=0 Loss=0.35567 Rate=10.24 GlobalRate=10.24 Time=03:34:09\n",
            "| Training Device=xla:0/2 Epoch=16 Step=0 Loss=0.36770 Rate=10.24 GlobalRate=10.24 Time=03:34:09\n",
            "| Training Device=xla:0/7 Epoch=16 Step=0 Loss=0.36252 Rate=10.23 GlobalRate=10.23 Time=03:34:09\n",
            "| Training Device=xla:0/3 Epoch=16 Step=0 Loss=0.48742 Rate=10.23 GlobalRate=10.23 Time=03:34:09\n",
            "| Training Device=xla:0/1 Epoch=16 Step=0 Loss=0.47633 Rate=10.23 GlobalRate=10.23 Time=03:34:09\n",
            "| Training Device=xla:1/0 Epoch=16 Step=0 Loss=0.43580 Rate=10.23 GlobalRate=10.23 Time=03:34:09\n",
            "Epoch 16 train end 03:34:09\n",
            "Epoch 17 train begin 03:34:09\n",
            "| Training Device=xla:0/1 Epoch=17 Step=0 Loss=0.36801 Rate=10.31 GlobalRate=10.31 Time=03:34:15\n",
            "| Training Device=xla:0/5 Epoch=17 Step=0 Loss=0.35364 Rate=10.31 GlobalRate=10.31 Time=03:34:15\n",
            "| Training Device=xla:0/6 Epoch=17 Step=0 Loss=0.43682 Rate=10.31 GlobalRate=10.31 Time=03:34:15\n",
            "| Training Device=xla:0/3 Epoch=17 Step=0 Loss=0.47961 Rate=10.31 GlobalRate=10.31 Time=03:34:15\n",
            "| Training Device=xla:0/4 Epoch=17 Step=0 Loss=0.34308 Rate=10.31 GlobalRate=10.31 Time=03:34:15\n",
            "| Training Device=xla:1/0 Epoch=17 Step=0 Loss=0.44903 Rate=10.31 GlobalRate=10.31 Time=03:34:15\n",
            "| Training Device=xla:0/2 Epoch=17 Step=0 Loss=0.36385 Rate=10.31 GlobalRate=10.31 Time=03:34:15\n",
            "| Training Device=xla:0/7 Epoch=17 Step=0 Loss=0.37429 Rate=10.30 GlobalRate=10.30 Time=03:34:15\n",
            "Epoch 17 train end 03:34:15\n",
            "Epoch 18 train begin 03:34:15\n",
            "| Training Device=xla:0/4 Epoch=18 Step=0 Loss=0.28509 Rate=10.33 GlobalRate=10.33 Time=03:34:22\n",
            "| Training Device=xla:1/0 Epoch=18 Step=0 Loss=0.39980 Rate=10.33 GlobalRate=10.33 Time=03:34:22\n",
            "| Training Device=xla:0/1 Epoch=18 Step=0 Loss=0.35570 Rate=10.32 GlobalRate=10.32 Time=03:34:22\n",
            "| Training Device=xla:0/3 Epoch=18 Step=0 Loss=0.43365 Rate=10.32 GlobalRate=10.32 Time=03:34:22\n",
            "| Training Device=xla:0/2 Epoch=18 Step=0 Loss=0.39217 Rate=10.32 GlobalRate=10.32 Time=03:34:22\n",
            "| Training Device=xla:0/6 Epoch=18 Step=0 Loss=0.43386 Rate=10.32 GlobalRate=10.32 Time=03:34:22\n",
            "| Training Device=xla:0/5 Epoch=18 Step=0 Loss=0.33568 Rate=10.32 GlobalRate=10.32 Time=03:34:22\n",
            "| Training Device=xla:0/7 Epoch=18 Step=0 Loss=0.32286 Rate=10.32 GlobalRate=10.32 Time=03:34:22\n",
            "Epoch 18 train end 03:34:22\n",
            "Epoch 19 train begin 03:34:22\n",
            "| Training Device=xla:0/1 Epoch=19 Step=0 Loss=0.37130 Rate=10.42 GlobalRate=10.42 Time=03:34:28\n",
            "| Training Device=xla:0/7 Epoch=19 Step=0 Loss=0.36279 Rate=10.42 GlobalRate=10.42 Time=03:34:28\n",
            "| Training Device=xla:0/2 Epoch=19 Step=0 Loss=0.35199 Rate=10.42 GlobalRate=10.42 Time=03:34:28\n",
            "| Training Device=xla:0/6 Epoch=19 Step=0 Loss=0.40110 Rate=10.41 GlobalRate=10.41 Time=03:34:28\n",
            "| Training Device=xla:0/4 Epoch=19 Step=0 Loss=0.32649 Rate=10.42 GlobalRate=10.42 Time=03:34:28\n",
            "| Training Device=xla:1/0 Epoch=19 Step=0 Loss=0.42910 Rate=10.42 GlobalRate=10.42 Time=03:34:28\n",
            "| Training Device=xla:0/5 Epoch=19 Step=0 Loss=0.31655 Rate=10.41 GlobalRate=10.41 Time=03:34:28\n",
            "| Training Device=xla:0/3 Epoch=19 Step=0 Loss=0.48956 Rate=10.41 GlobalRate=10.41 Time=03:34:28\n",
            "Epoch 19 train end 03:34:28\n",
            "Epoch 20 train begin 03:34:28\n",
            "| Training Device=xla:0/5 Epoch=20 Step=0 Loss=0.28763 Rate=10.34 GlobalRate=10.34 Time=03:34:34\n",
            "| Training Device=xla:0/6 Epoch=20 Step=0 Loss=0.36879 Rate=10.33 GlobalRate=10.33 Time=03:34:34\n",
            "| Training Device=xla:0/3 Epoch=20 Step=0 Loss=0.46493 Rate=10.34 GlobalRate=10.34 Time=03:34:34\n",
            "| Training Device=xla:0/7 Epoch=20 Step=0 Loss=0.34036 Rate=10.34 GlobalRate=10.34 Time=03:34:34\n",
            "| Training Device=xla:1/0 Epoch=20 Step=0 Loss=0.41540 Rate=10.34 GlobalRate=10.34 Time=03:34:34\n",
            "| Training Device=xla:0/1 Epoch=20 Step=0 Loss=0.32829 Rate=10.33 GlobalRate=10.33 Time=03:34:34\n",
            "| Training Device=xla:0/4 Epoch=20 Step=0 Loss=0.31709 Rate=10.33 GlobalRate=10.33 Time=03:34:34\n",
            "| Training Device=xla:0/2 Epoch=20 Step=0 Loss=0.32507 Rate=10.33 GlobalRate=10.33 Time=03:34:34\n",
            "Epoch 20 train end 03:34:35\n",
            "Epoch 21 train begin 03:34:35\n",
            "| Training Device=xla:0/6 Epoch=21 Step=0 Loss=0.43321 Rate=10.41 GlobalRate=10.41 Time=03:34:41\n",
            "| Training Device=xla:1/0 Epoch=21 Step=0 Loss=0.33135 Rate=10.42 GlobalRate=10.42 Time=03:34:41\n",
            "| Training Device=xla:0/1 Epoch=21 Step=0 Loss=0.31284 Rate=10.41 GlobalRate=10.41 Time=03:34:41\n",
            "| Training Device=xla:0/7 Epoch=21 Step=0 Loss=0.30029 Rate=10.41 GlobalRate=10.41 Time=03:34:41\n",
            "| Training Device=xla:0/2 Epoch=21 Step=0 Loss=0.28787 Rate=10.41 GlobalRate=10.41 Time=03:34:41\n",
            "| Training Device=xla:0/4 Epoch=21 Step=0 Loss=0.37627 Rate=10.41 GlobalRate=10.41 Time=03:34:41\n",
            "| Training Device=xla:0/5 Epoch=21 Step=0 Loss=0.30856 Rate=10.41 GlobalRate=10.41 Time=03:34:41\n",
            "| Training Device=xla:0/3 Epoch=21 Step=0 Loss=0.46130 Rate=10.41 GlobalRate=10.41 Time=03:34:41\n",
            "Epoch 21 train end 03:34:41\n",
            "Epoch 22 train begin 03:34:41\n",
            "| Training Device=xla:0/3 Epoch=22 Step=0 Loss=0.43861 Rate=10.42 GlobalRate=10.42 Time=03:34:47\n",
            "| Training Device=xla:0/1 Epoch=22 Step=0 Loss=0.31356 Rate=10.42 GlobalRate=10.42 Time=03:34:47\n",
            "| Training Device=xla:0/6 Epoch=22 Step=0 Loss=0.43063 Rate=10.42 GlobalRate=10.42 Time=03:34:47\n",
            "| Training Device=xla:0/7 Epoch=22 Step=0 Loss=0.27069 Rate=10.42 GlobalRate=10.42 Time=03:34:47\n",
            "| Training Device=xla:0/5 Epoch=22 Step=0 Loss=0.30250 Rate=10.42 GlobalRate=10.42 Time=03:34:47\n",
            "| Training Device=xla:0/2 Epoch=22 Step=0 Loss=0.33046 Rate=10.41 GlobalRate=10.41 Time=03:34:47\n",
            "| Training Device=xla:1/0 Epoch=22 Step=0 Loss=0.30522 Rate=10.42 GlobalRate=10.42 Time=03:34:47\n",
            "| Training Device=xla:0/4 Epoch=22 Step=0 Loss=0.30986 Rate=10.41 GlobalRate=10.41 Time=03:34:47\n",
            "Epoch 22 train end 03:34:47\n",
            "Epoch 23 train begin 03:34:47\n",
            "| Training Device=xla:0/6 Epoch=23 Step=0 Loss=0.42004 Rate=10.36 GlobalRate=10.36 Time=03:34:54\n",
            "| Training Device=xla:0/3 Epoch=23 Step=0 Loss=0.47121 Rate=10.36 GlobalRate=10.36 Time=03:34:54\n",
            "| Training Device=xla:0/2 Epoch=23 Step=0 Loss=0.32035 Rate=10.36 GlobalRate=10.36 Time=03:34:54\n",
            "| Training Device=xla:1/0 Epoch=23 Step=0 Loss=0.34845 Rate=10.36 GlobalRate=10.36 Time=03:34:54\n",
            "| Training Device=xla:0/4 Epoch=23 Step=0 Loss=0.28362 Rate=10.36 GlobalRate=10.36 Time=03:34:54\n",
            "| Training Device=xla:0/1 Epoch=23 Step=0 Loss=0.31969 Rate=10.36 GlobalRate=10.36 Time=03:34:54\n",
            "| Training Device=xla:0/7 Epoch=23 Step=0 Loss=0.30626 Rate=10.36 GlobalRate=10.36 Time=03:34:54\n",
            "| Training Device=xla:0/5 Epoch=23 Step=0 Loss=0.30825 Rate=10.36 GlobalRate=10.36 Time=03:34:54\n",
            "Epoch 23 train end 03:34:54\n",
            "Epoch 24 train begin 03:34:54\n",
            "| Training Device=xla:0/7 Epoch=24 Step=0 Loss=0.27408 Rate=10.24 GlobalRate=10.24 Time=03:35:00\n",
            "| Training Device=xla:0/4 Epoch=24 Step=0 Loss=0.30844 Rate=10.24 GlobalRate=10.24 Time=03:35:00\n",
            "| Training Device=xla:0/2 Epoch=24 Step=0 Loss=0.35744 Rate=10.24 GlobalRate=10.24 Time=03:35:00\n",
            "| Training Device=xla:0/3 Epoch=24 Step=0 Loss=0.40796 Rate=10.24 GlobalRate=10.24 Time=03:35:00\n",
            "| Training Device=xla:0/6 Epoch=24 Step=0 Loss=0.46292 Rate=10.24 GlobalRate=10.24 Time=03:35:00\n",
            "| Training Device=xla:1/0 Epoch=24 Step=0 Loss=0.35558 Rate=10.25 GlobalRate=10.25 Time=03:35:00\n",
            "| Training Device=xla:0/1 Epoch=24 Step=0 Loss=0.28979 Rate=10.24 GlobalRate=10.24 Time=03:35:00\n",
            "| Training Device=xla:0/5 Epoch=24 Step=0 Loss=0.27761 Rate=10.23 GlobalRate=10.23 Time=03:35:00\n",
            "Epoch 24 train end 03:35:00\n",
            "Epoch 25 train begin 03:35:00\n",
            "| Training Device=xla:0/7 Epoch=25 Step=0 Loss=0.23208 Rate=10.33 GlobalRate=10.33 Time=03:35:07\n",
            "| Training Device=xla:0/1 Epoch=25 Step=0 Loss=0.29581 Rate=10.33 GlobalRate=10.33 Time=03:35:07\n",
            "| Training Device=xla:0/2 Epoch=25 Step=0 Loss=0.29151 Rate=10.33 GlobalRate=10.33 Time=03:35:07\n",
            "| Training Device=xla:0/6 Epoch=25 Step=0 Loss=0.36552 Rate=10.33 GlobalRate=10.33 Time=03:35:07\n",
            "| Training Device=xla:1/0 Epoch=25 Step=0 Loss=0.38496 Rate=10.33 GlobalRate=10.33 Time=03:35:07\n",
            "| Training Device=xla:0/5 Epoch=25 Step=0 Loss=0.34800 Rate=10.33 GlobalRate=10.33 Time=03:35:07\n",
            "| Training Device=xla:0/3 Epoch=25 Step=0 Loss=0.46462 Rate=10.33 GlobalRate=10.33 Time=03:35:07\n",
            "| Training Device=xla:0/4 Epoch=25 Step=0 Loss=0.26024 Rate=10.33 GlobalRate=10.33 Time=03:35:07\n",
            "Epoch 25 train end 03:35:07\n",
            "Epoch 26 train begin 03:35:07\n",
            "| Training Device=xla:0/5 Epoch=26 Step=0 Loss=0.31427 Rate=10.21 GlobalRate=10.21 Time=03:35:13\n",
            "| Training Device=xla:0/3 Epoch=26 Step=0 Loss=0.41736 Rate=10.21 GlobalRate=10.21 Time=03:35:13\n",
            "| Training Device=xla:0/6 Epoch=26 Step=0 Loss=0.33508 Rate=10.21 GlobalRate=10.21 Time=03:35:13\n",
            "| Training Device=xla:0/2 Epoch=26 Step=0 Loss=0.24600 Rate=10.21 GlobalRate=10.21 Time=03:35:13\n",
            "| Training Device=xla:0/7 Epoch=26 Step=0 Loss=0.25880 Rate=10.21 GlobalRate=10.21 Time=03:35:13\n",
            "| Training Device=xla:1/0 Epoch=26 Step=0 Loss=0.33391 Rate=10.22 GlobalRate=10.22 Time=03:35:13\n",
            "| Training Device=xla:0/1 Epoch=26 Step=0 Loss=0.25553 Rate=10.21 GlobalRate=10.21 Time=03:35:13\n",
            "| Training Device=xla:0/4 Epoch=26 Step=0 Loss=0.27903 Rate=10.21 GlobalRate=10.21 Time=03:35:13\n",
            "Epoch 26 train end 03:35:13\n",
            "Epoch 27 train begin 03:35:13\n",
            "| Training Device=xla:0/3 Epoch=27 Step=0 Loss=0.40596 Rate=10.29 GlobalRate=10.29 Time=03:35:20\n",
            "| Training Device=xla:1/0 Epoch=27 Step=0 Loss=0.32611 Rate=10.29 GlobalRate=10.29 Time=03:35:20\n",
            "| Training Device=xla:0/1 Epoch=27 Step=0 Loss=0.28219 Rate=10.29 GlobalRate=10.28 Time=03:35:20\n",
            "| Training Device=xla:0/7 Epoch=27 Step=0 Loss=0.26662 Rate=10.28 GlobalRate=10.28 Time=03:35:20\n",
            "| Training Device=xla:0/6 Epoch=27 Step=0 Loss=0.39038 Rate=10.28 GlobalRate=10.28 Time=03:35:20\n",
            "| Training Device=xla:0/4 Epoch=27 Step=0 Loss=0.25011 Rate=10.28 GlobalRate=10.28 Time=03:35:20\n",
            "| Training Device=xla:0/5 Epoch=27 Step=0 Loss=0.23795 Rate=10.28 GlobalRate=10.28 Time=03:35:20\n",
            "| Training Device=xla:0/2 Epoch=27 Step=0 Loss=0.27279 Rate=10.28 GlobalRate=10.28 Time=03:35:20\n",
            "Epoch 27 train end 03:35:20\n",
            "Epoch 28 train begin 03:35:20\n",
            "| Training Device=xla:0/2 Epoch=28 Step=0 Loss=0.34533 Rate=10.32 GlobalRate=10.32 Time=03:35:26\n",
            "| Training Device=xla:0/1 Epoch=28 Step=0 Loss=0.29751 Rate=10.32 GlobalRate=10.32 Time=03:35:26\n",
            "| Training Device=xla:0/4 Epoch=28 Step=0 Loss=0.29018 Rate=10.32 GlobalRate=10.32 Time=03:35:26\n",
            "| Training Device=xla:0/3 Epoch=28 Step=0 Loss=0.40533 Rate=10.32 GlobalRate=10.32 Time=03:35:26\n",
            "| Training Device=xla:0/6 Epoch=28 Step=0 Loss=0.39742 Rate=10.32 GlobalRate=10.32 Time=03:35:26\n",
            "| Training Device=xla:0/5 Epoch=28 Step=0 Loss=0.26609 Rate=10.32 GlobalRate=10.32 Time=03:35:26\n",
            "| Training Device=xla:0/7 Epoch=28 Step=0 Loss=0.31351 Rate=10.31 GlobalRate=10.31 Time=03:35:26\n",
            "| Training Device=xla:1/0 Epoch=28 Step=0 Loss=0.29978 Rate=10.32 GlobalRate=10.32 Time=03:35:26\n",
            "Epoch 28 train end 03:35:26\n",
            "Epoch 29 train begin 03:35:26\n",
            "| Training Device=xla:1/0 Epoch=29 Step=0 Loss=0.29076 Rate=10.23 GlobalRate=10.23 Time=03:35:32\n",
            "| Training Device=xla:0/3 Epoch=29 Step=0 Loss=0.41552 Rate=10.22 GlobalRate=10.22 Time=03:35:32\n",
            "| Training Device=xla:0/7 Epoch=29 Step=0 Loss=0.31327 Rate=10.22 GlobalRate=10.22 Time=03:35:32\n",
            "| Training Device=xla:0/5 Epoch=29 Step=0 Loss=0.31468 Rate=10.22 GlobalRate=10.22 Time=03:35:32\n",
            "| Training Device=xla:0/6 Epoch=29 Step=0 Loss=0.38328 Rate=10.22 GlobalRate=10.22 Time=03:35:32\n",
            "| Training Device=xla:0/2 Epoch=29 Step=0 Loss=0.30308 Rate=10.22 GlobalRate=10.22 Time=03:35:32\n",
            "| Training Device=xla:0/4 Epoch=29 Step=0 Loss=0.24996 Rate=10.22 GlobalRate=10.22 Time=03:35:32\n",
            "| Training Device=xla:0/1 Epoch=29 Step=0 Loss=0.31376 Rate=10.21 GlobalRate=10.21 Time=03:35:32\n",
            "Epoch 29 train end 03:35:33\n",
            "Epoch 30 train begin 03:35:33\n",
            "| Training Device=xla:0/2 Epoch=30 Step=0 Loss=0.28643 Rate=10.29 GlobalRate=10.29 Time=03:35:39\n",
            "| Training Device=xla:0/1 Epoch=30 Step=0 Loss=0.29324 Rate=10.29 GlobalRate=10.29 Time=03:35:39\n",
            "| Training Device=xla:0/7 Epoch=30 Step=0 Loss=0.30735 Rate=10.29 GlobalRate=10.29 Time=03:35:39\n",
            "| Training Device=xla:0/3 Epoch=30 Step=0 Loss=0.42945 Rate=10.29 GlobalRate=10.29 Time=03:35:39\n",
            "| Training Device=xla:0/5 Epoch=30 Step=0 Loss=0.26090 Rate=10.28 GlobalRate=10.28 Time=03:35:39\n",
            "| Training Device=xla:0/6 Epoch=30 Step=0 Loss=0.41944 Rate=10.29 GlobalRate=10.29 Time=03:35:39\n",
            "| Training Device=xla:0/4 Epoch=30 Step=0 Loss=0.33327 Rate=10.29 GlobalRate=10.29 Time=03:35:39\n",
            "| Training Device=xla:1/0 Epoch=30 Step=0 Loss=0.33459 Rate=10.29 GlobalRate=10.29 Time=03:35:39\n",
            "Epoch 30 train end 03:35:39\n",
            "Epoch 31 train begin 03:35:39\n",
            "| Training Device=xla:1/0 Epoch=31 Step=0 Loss=0.30548 Rate=10.33 GlobalRate=10.33 Time=03:35:45\n",
            "| Training Device=xla:0/3 Epoch=31 Step=0 Loss=0.41088 Rate=10.33 GlobalRate=10.33 Time=03:35:45\n",
            "| Training Device=xla:0/2 Epoch=31 Step=0 Loss=0.32186 Rate=10.33 GlobalRate=10.33 Time=03:35:45\n",
            "| Training Device=xla:0/6 Epoch=31 Step=0 Loss=0.43627 Rate=10.33 GlobalRate=10.33 Time=03:35:45\n",
            "| Training Device=xla:0/1 Epoch=31 Step=0 Loss=0.35350 Rate=10.33 GlobalRate=10.33 Time=03:35:45\n",
            "| Training Device=xla:0/7 Epoch=31 Step=0 Loss=0.28277 Rate=10.32 GlobalRate=10.32 Time=03:35:45\n",
            "| Training Device=xla:0/5 Epoch=31 Step=0 Loss=0.25130 Rate=10.32 GlobalRate=10.32 Time=03:35:45\n",
            "| Training Device=xla:0/4 Epoch=31 Step=0 Loss=0.25954 Rate=10.33 GlobalRate=10.33 Time=03:35:45\n",
            "Epoch 31 train end 03:35:46\n",
            "Epoch 32 train begin 03:35:46\n",
            "| Training Device=xla:0/2 Epoch=32 Step=0 Loss=0.27444 Rate=10.38 GlobalRate=10.38 Time=03:35:52\n",
            "| Training Device=xla:0/6 Epoch=32 Step=0 Loss=0.33462 Rate=10.38 GlobalRate=10.38 Time=03:35:52\n",
            "| Training Device=xla:1/0 Epoch=32 Step=0 Loss=0.36078 Rate=10.38 GlobalRate=10.38 Time=03:35:52\n",
            "| Training Device=xla:0/3 Epoch=32 Step=0 Loss=0.35464 Rate=10.37 GlobalRate=10.37 Time=03:35:52\n",
            "| Training Device=xla:0/1 Epoch=32 Step=0 Loss=0.29743 Rate=10.37 GlobalRate=10.37 Time=03:35:52\n",
            "| Training Device=xla:0/5 Epoch=32 Step=0 Loss=0.24134 Rate=10.37 GlobalRate=10.37 Time=03:35:52\n",
            "| Training Device=xla:0/4 Epoch=32 Step=0 Loss=0.28089 Rate=10.37 GlobalRate=10.37 Time=03:35:52\n",
            "| Training Device=xla:0/7 Epoch=32 Step=0 Loss=0.19565 Rate=10.37 GlobalRate=10.37 Time=03:35:52\n",
            "Epoch 32 train end 03:35:52\n",
            "Epoch 33 train begin 03:35:52\n",
            "| Training Device=xla:0/4 Epoch=33 Step=0 Loss=0.26827 Rate=10.38 GlobalRate=10.38 Time=03:35:58\n",
            "| Training Device=xla:0/3 Epoch=33 Step=0 Loss=0.41833 Rate=10.38 GlobalRate=10.38 Time=03:35:58\n",
            "| Training Device=xla:0/1 Epoch=33 Step=0 Loss=0.27715 Rate=10.38 GlobalRate=10.38 Time=03:35:58\n",
            "| Training Device=xla:0/7 Epoch=33 Step=0 Loss=0.27850 Rate=10.38 GlobalRate=10.38 Time=03:35:58\n",
            "| Training Device=xla:1/0 Epoch=33 Step=0 Loss=0.30996 Rate=10.39 GlobalRate=10.39 Time=03:35:58\n",
            "| Training Device=xla:0/2 Epoch=33 Step=0 Loss=0.29342 Rate=10.38 GlobalRate=10.38 Time=03:35:58\n",
            "| Training Device=xla:0/6 Epoch=33 Step=0 Loss=0.35141 Rate=10.38 GlobalRate=10.38 Time=03:35:58\n",
            "| Training Device=xla:0/5 Epoch=33 Step=0 Loss=0.29886 Rate=10.38 GlobalRate=10.38 Time=03:35:58\n",
            "Epoch 33 train end 03:35:58\n",
            "Epoch 34 train begin 03:35:58\n",
            "| Training Device=xla:0/2 Epoch=34 Step=0 Loss=0.22262 Rate=10.31 GlobalRate=10.31 Time=03:36:05\n",
            "| Training Device=xla:1/0 Epoch=34 Step=0 Loss=0.33703 Rate=10.31 GlobalRate=10.31 Time=03:36:05\n",
            "| Training Device=xla:0/3 Epoch=34 Step=0 Loss=0.32451 Rate=10.31 GlobalRate=10.31 Time=03:36:05\n",
            "| Training Device=xla:0/7 Epoch=34 Step=0 Loss=0.27881 Rate=10.31 GlobalRate=10.31 Time=03:36:05\n",
            "| Training Device=xla:0/5 Epoch=34 Step=0 Loss=0.28975 Rate=10.31 GlobalRate=10.31 Time=03:36:05\n",
            "| Training Device=xla:0/6 Epoch=34 Step=0 Loss=0.35167 Rate=10.31 GlobalRate=10.31 Time=03:36:05\n",
            "| Training Device=xla:0/1 Epoch=34 Step=0 Loss=0.29577 Rate=10.31 GlobalRate=10.31 Time=03:36:05\n",
            "| Training Device=xla:0/4 Epoch=34 Step=0 Loss=0.29202 Rate=10.31 GlobalRate=10.31 Time=03:36:05\n",
            "Epoch 34 train end 03:36:05\n",
            "Epoch 35 train begin 03:36:05\n",
            "| Training Device=xla:1/0 Epoch=35 Step=0 Loss=0.29690 Rate=10.28 GlobalRate=10.28 Time=03:36:11\n",
            "| Training Device=xla:0/3 Epoch=35 Step=0 Loss=0.37264 Rate=10.28 GlobalRate=10.28 Time=03:36:11\n",
            "| Training Device=xla:0/6 Epoch=35 Step=0 Loss=0.36778 Rate=10.28 GlobalRate=10.28 Time=03:36:11\n",
            "| Training Device=xla:0/1 Epoch=35 Step=0 Loss=0.26284 Rate=10.28 GlobalRate=10.28 Time=03:36:11\n",
            "| Training Device=xla:0/7 Epoch=35 Step=0 Loss=0.26094 Rate=10.28 GlobalRate=10.28 Time=03:36:11\n",
            "| Training Device=xla:0/4 Epoch=35 Step=0 Loss=0.29498 Rate=10.27 GlobalRate=10.27 Time=03:36:11\n",
            "| Training Device=xla:0/2 Epoch=35 Step=0 Loss=0.30282 Rate=10.28 GlobalRate=10.28 Time=03:36:11\n",
            "| Training Device=xla:0/5 Epoch=35 Step=0 Loss=0.32618 Rate=10.28 GlobalRate=10.28 Time=03:36:11\n",
            "Epoch 35 train end 03:36:11\n",
            "Epoch 36 train begin 03:36:11\n",
            "| Training Device=xla:0/1 Epoch=36 Step=0 Loss=0.36930 Rate=10.31 GlobalRate=10.31 Time=03:36:17\n",
            "| Training Device=xla:0/5 Epoch=36 Step=0 Loss=0.30910 Rate=10.31 GlobalRate=10.31 Time=03:36:17\n",
            "| Training Device=xla:0/4 Epoch=36 Step=0 Loss=0.29157 Rate=10.31 GlobalRate=10.31 Time=03:36:17\n",
            "| Training Device=xla:0/6 Epoch=36 Step=0 Loss=0.44757 Rate=10.31 GlobalRate=10.31 Time=03:36:17\n",
            "| Training Device=xla:0/2 Epoch=36 Step=0 Loss=0.36831 Rate=10.31 GlobalRate=10.31 Time=03:36:17\n",
            "| Training Device=xla:1/0 Epoch=36 Step=0 Loss=0.32898 Rate=10.32 GlobalRate=10.32 Time=03:36:17\n",
            "| Training Device=xla:0/7 Epoch=36 Step=0 Loss=0.29169 Rate=10.31 GlobalRate=10.31 Time=03:36:17\n",
            "| Training Device=xla:0/3 Epoch=36 Step=0 Loss=0.42303 Rate=10.31 GlobalRate=10.31 Time=03:36:17\n",
            "Epoch 36 train end 03:36:18\n",
            "Epoch 37 train begin 03:36:18\n",
            "| Training Device=xla:0/6 Epoch=37 Step=0 Loss=0.35569 Rate=10.29 GlobalRate=10.29 Time=03:36:24\n",
            "| Training Device=xla:0/5 Epoch=37 Step=0 Loss=0.23254 Rate=10.29 GlobalRate=10.29 Time=03:36:24\n",
            "| Training Device=xla:0/2 Epoch=37 Step=0 Loss=0.24454 Rate=10.29 GlobalRate=10.29 Time=03:36:24\n",
            "| Training Device=xla:0/7 Epoch=37 Step=0 Loss=0.32768 Rate=10.29 GlobalRate=10.29 Time=03:36:24\n",
            "| Training Device=xla:0/1 Epoch=37 Step=0 Loss=0.22423 Rate=10.29 GlobalRate=10.29 Time=03:36:24\n",
            "| Training Device=xla:1/0 Epoch=37 Step=0 Loss=0.27046 Rate=10.30 GlobalRate=10.30 Time=03:36:24\n",
            "| Training Device=xla:0/3 Epoch=37 Step=0 Loss=0.33964 Rate=10.29 GlobalRate=10.29 Time=03:36:24\n",
            "| Training Device=xla:0/4 Epoch=37 Step=0 Loss=0.23284 Rate=10.29 GlobalRate=10.29 Time=03:36:24\n",
            "Epoch 37 train end 03:36:24\n",
            "Epoch 38 train begin 03:36:24\n",
            "| Training Device=xla:0/5 Epoch=38 Step=0 Loss=0.26103 Rate=10.34 GlobalRate=10.34 Time=03:36:30\n",
            "| Training Device=xla:1/0 Epoch=38 Step=0 Loss=0.31454 Rate=10.34 GlobalRate=10.34 Time=03:36:30\n",
            "| Training Device=xla:0/6 Epoch=38 Step=0 Loss=0.37936 Rate=10.34 GlobalRate=10.34 Time=03:36:30\n",
            "| Training Device=xla:0/3 Epoch=38 Step=0 Loss=0.37311 Rate=10.34 GlobalRate=10.34 Time=03:36:30\n",
            "| Training Device=xla:0/4 Epoch=38 Step=0 Loss=0.27965 Rate=10.34 GlobalRate=10.34 Time=03:36:30\n",
            "| Training Device=xla:0/7 Epoch=38 Step=0 Loss=0.24407 Rate=10.34 GlobalRate=10.34 Time=03:36:30\n",
            "| Training Device=xla:0/2 Epoch=38 Step=0 Loss=0.26395 Rate=10.34 GlobalRate=10.34 Time=03:36:30\n",
            "| Training Device=xla:0/1 Epoch=38 Step=0 Loss=0.27468 Rate=10.33 GlobalRate=10.33 Time=03:36:30\n",
            "Epoch 38 train end 03:36:31\n",
            "Epoch 39 train begin 03:36:31\n",
            "| Training Device=xla:0/7 Epoch=39 Step=0 Loss=0.31883 Rate=10.26 GlobalRate=10.26 Time=03:36:37\n",
            "| Training Device=xla:0/2 Epoch=39 Step=0 Loss=0.30370 Rate=10.25 GlobalRate=10.25 Time=03:36:37\n",
            "| Training Device=xla:0/3 Epoch=39 Step=0 Loss=0.36271 Rate=10.25 GlobalRate=10.25 Time=03:36:37\n",
            "| Training Device=xla:1/0 Epoch=39 Step=0 Loss=0.36118 Rate=10.26 GlobalRate=10.26 Time=03:36:37\n",
            "| Training Device=xla:0/4 Epoch=39 Step=0 Loss=0.32194 Rate=10.25 GlobalRate=10.25 Time=03:36:37\n",
            "| Training Device=xla:0/1 Epoch=39 Step=0 Loss=0.26733 Rate=10.25 GlobalRate=10.25 Time=03:36:37\n",
            "| Training Device=xla:0/5 Epoch=39 Step=0 Loss=0.25447 Rate=10.25 GlobalRate=10.25 Time=03:36:37\n",
            "| Training Device=xla:0/6 Epoch=39 Step=0 Loss=0.30176 Rate=10.25 GlobalRate=10.25 Time=03:36:37\n",
            "Epoch 39 train end 03:36:37\n",
            "Epoch 40 train begin 03:36:37\n",
            "| Training Device=xla:1/0 Epoch=40 Step=0 Loss=0.32187 Rate=10.30 GlobalRate=10.30 Time=03:36:43\n",
            "| Training Device=xla:0/4 Epoch=40 Step=0 Loss=0.26456 Rate=10.29 GlobalRate=10.29 Time=03:36:43\n",
            "| Training Device=xla:0/2 Epoch=40 Step=0 Loss=0.26593 Rate=10.29 GlobalRate=10.29 Time=03:36:43\n",
            "| Training Device=xla:0/7 Epoch=40 Step=0 Loss=0.29381 Rate=10.29 GlobalRate=10.29 Time=03:36:43\n",
            "| Training Device=xla:0/1 Epoch=40 Step=0 Loss=0.25465 Rate=10.29 GlobalRate=10.29 Time=03:36:43\n",
            "| Training Device=xla:0/5 Epoch=40 Step=0 Loss=0.27697 Rate=10.29 GlobalRate=10.29 Time=03:36:43\n",
            "| Training Device=xla:0/3 Epoch=40 Step=0 Loss=0.38505 Rate=10.29 GlobalRate=10.29 Time=03:36:43\n",
            "| Training Device=xla:0/6 Epoch=40 Step=0 Loss=0.34172 Rate=10.29 GlobalRate=10.29 Time=03:36:43\n",
            "Epoch 40 train end 03:36:43\n",
            "Epoch 41 train begin 03:36:43\n",
            "| Training Device=xla:0/2 Epoch=41 Step=0 Loss=0.27460 Rate=10.32 GlobalRate=10.32 Time=03:36:50\n",
            "| Training Device=xla:0/6 Epoch=41 Step=0 Loss=0.41348 Rate=10.32 GlobalRate=10.32 Time=03:36:50\n",
            "| Training Device=xla:0/5 Epoch=41 Step=0 Loss=0.29816 Rate=10.32 GlobalRate=10.32 Time=03:36:50\n",
            "| Training Device=xla:0/7 Epoch=41 Step=0 Loss=0.35393 Rate=10.32 GlobalRate=10.32 Time=03:36:50\n",
            "| Training Device=xla:0/3 Epoch=41 Step=0 Loss=0.45161 Rate=10.32 GlobalRate=10.32 Time=03:36:50\n",
            "| Training Device=xla:0/1 Epoch=41 Step=0 Loss=0.24542 Rate=10.32 GlobalRate=10.32 Time=03:36:50\n",
            "| Training Device=xla:0/4 Epoch=41 Step=0 Loss=0.29378 Rate=10.32 GlobalRate=10.32 Time=03:36:50\n",
            "| Training Device=xla:1/0 Epoch=41 Step=0 Loss=0.30971 Rate=10.32 GlobalRate=10.32 Time=03:36:50\n",
            "Epoch 41 train end 03:36:50\n",
            "Epoch 42 train begin 03:36:50\n",
            "| Training Device=xla:0/4 Epoch=42 Step=0 Loss=0.26132 Rate=10.31 GlobalRate=10.31 Time=03:36:56\n",
            "| Training Device=xla:0/3 Epoch=42 Step=0 Loss=0.34874 Rate=10.32 GlobalRate=10.32 Time=03:36:56\n",
            "| Training Device=xla:0/6 Epoch=42 Step=0 Loss=0.35842 Rate=10.31 GlobalRate=10.31 Time=03:36:56\n",
            "| Training Device=xla:1/0 Epoch=42 Step=0 Loss=0.30588 Rate=10.32 GlobalRate=10.32 Time=03:36:56\n",
            "| Training Device=xla:0/7 Epoch=42 Step=0 Loss=0.24309 Rate=10.31 GlobalRate=10.31 Time=03:36:56\n",
            "| Training Device=xla:0/2 Epoch=42 Step=0 Loss=0.23836 Rate=10.31 GlobalRate=10.31 Time=03:36:56\n",
            "| Training Device=xla:0/1 Epoch=42 Step=0 Loss=0.27353 Rate=10.31 GlobalRate=10.31 Time=03:36:56\n",
            "| Training Device=xla:0/5 Epoch=42 Step=0 Loss=0.24305 Rate=10.31 GlobalRate=10.31 Time=03:36:56\n",
            "Epoch 42 train end 03:36:56\n",
            "Epoch 43 train begin 03:36:56\n",
            "| Training Device=xla:0/1 Epoch=43 Step=0 Loss=0.24611 Rate=10.32 GlobalRate=10.32 Time=03:37:03\n",
            "| Training Device=xla:0/5 Epoch=43 Step=0 Loss=0.23946 Rate=10.32 GlobalRate=10.32 Time=03:37:03\n",
            "| Training Device=xla:0/4 Epoch=43 Step=0 Loss=0.28856 Rate=10.32 GlobalRate=10.32 Time=03:37:03\n",
            "| Training Device=xla:1/0 Epoch=43 Step=0 Loss=0.44182 Rate=10.32 GlobalRate=10.32 Time=03:37:03\n",
            "| Training Device=xla:0/2 Epoch=43 Step=0 Loss=0.28400 Rate=10.32 GlobalRate=10.32 Time=03:37:03\n",
            "| Training Device=xla:0/3 Epoch=43 Step=0 Loss=0.35587 Rate=10.31 GlobalRate=10.31 Time=03:37:03\n",
            "| Training Device=xla:0/7 Epoch=43 Step=0 Loss=0.23229 Rate=10.32 GlobalRate=10.32 Time=03:37:03\n",
            "| Training Device=xla:0/6 Epoch=43 Step=0 Loss=0.33505 Rate=10.31 GlobalRate=10.31 Time=03:37:03\n",
            "Epoch 43 train end 03:37:03\n",
            "Epoch 44 train begin 03:37:03\n",
            "| Training Device=xla:0/2 Epoch=44 Step=0 Loss=0.27960 Rate=10.30 GlobalRate=10.30 Time=03:37:09\n",
            "| Training Device=xla:0/6 Epoch=44 Step=0 Loss=0.40826 Rate=10.30 GlobalRate=10.30 Time=03:37:09\n",
            "| Training Device=xla:0/3 Epoch=44 Step=0 Loss=0.39310 Rate=10.30 GlobalRate=10.30 Time=03:37:09\n",
            "| Training Device=xla:0/1 Epoch=44 Step=0 Loss=0.23255 Rate=10.30 GlobalRate=10.30 Time=03:37:09\n",
            "| Training Device=xla:0/7 Epoch=44 Step=0 Loss=0.24242 Rate=10.30 GlobalRate=10.30 Time=03:37:09\n",
            "| Training Device=xla:1/0 Epoch=44 Step=0 Loss=0.28391 Rate=10.31 GlobalRate=10.31 Time=03:37:09\n",
            "| Training Device=xla:0/5 Epoch=44 Step=0 Loss=0.23652 Rate=10.30 GlobalRate=10.30 Time=03:37:09\n",
            "| Training Device=xla:0/4 Epoch=44 Step=0 Loss=0.27535 Rate=10.30 GlobalRate=10.30 Time=03:37:09\n",
            "Epoch 44 train end 03:37:09\n",
            "Epoch 45 train begin 03:37:09\n",
            "| Training Device=xla:0/4 Epoch=45 Step=0 Loss=0.31434 Rate=10.35 GlobalRate=10.35 Time=03:37:15\n",
            "| Training Device=xla:0/1 Epoch=45 Step=0 Loss=0.28223 Rate=10.35 GlobalRate=10.35 Time=03:37:15\n",
            "| Training Device=xla:0/2 Epoch=45 Step=0 Loss=0.32005 Rate=10.35 GlobalRate=10.35 Time=03:37:15\n",
            "| Training Device=xla:0/3 Epoch=45 Step=0 Loss=0.43874 Rate=10.35 GlobalRate=10.35 Time=03:37:15\n",
            "| Training Device=xla:0/6 Epoch=45 Step=0 Loss=0.39211 Rate=10.35 GlobalRate=10.35 Time=03:37:15\n",
            "| Training Device=xla:0/7 Epoch=45 Step=0 Loss=0.31847 Rate=10.35 GlobalRate=10.35 Time=03:37:15\n",
            "| Training Device=xla:0/5 Epoch=45 Step=0 Loss=0.24269 Rate=10.35 GlobalRate=10.35 Time=03:37:15\n",
            "| Training Device=xla:1/0 Epoch=45 Step=0 Loss=0.38487 Rate=10.35 GlobalRate=10.35 Time=03:37:15\n",
            "Epoch 45 train end 03:37:16\n",
            "Epoch 46 train begin 03:37:16\n",
            "| Training Device=xla:0/2 Epoch=46 Step=0 Loss=0.18231 Rate=10.35 GlobalRate=10.35 Time=03:37:22\n",
            "| Training Device=xla:0/3 Epoch=46 Step=0 Loss=0.43219 Rate=10.35 GlobalRate=10.35 Time=03:37:22\n",
            "| Training Device=xla:0/6 Epoch=46 Step=0 Loss=0.35698 Rate=10.35 GlobalRate=10.35 Time=03:37:22\n",
            "| Training Device=xla:0/4 Epoch=46 Step=0 Loss=0.22959 Rate=10.34 GlobalRate=10.34 Time=03:37:22\n",
            "| Training Device=xla:0/5 Epoch=46 Step=0 Loss=0.29113 Rate=10.34 GlobalRate=10.34 Time=03:37:22\n",
            "| Training Device=xla:0/7 Epoch=46 Step=0 Loss=0.23358 Rate=10.34 GlobalRate=10.34 Time=03:37:22\n",
            "| Training Device=xla:0/1 Epoch=46 Step=0 Loss=0.26127 Rate=10.34 GlobalRate=10.34 Time=03:37:22\n",
            "| Training Device=xla:1/0 Epoch=46 Step=0 Loss=0.28714 Rate=10.34 GlobalRate=10.34 Time=03:37:22\n",
            "Epoch 46 train end 03:37:22\n",
            "Epoch 47 train begin 03:37:22\n",
            "| Training Device=xla:0/1 Epoch=47 Step=0 Loss=0.23677 Rate=10.35 GlobalRate=10.35 Time=03:37:28\n",
            "| Training Device=xla:0/4 Epoch=47 Step=0 Loss=0.28031 Rate=10.35 GlobalRate=10.35 Time=03:37:28\n",
            "| Training Device=xla:0/5 Epoch=47 Step=0 Loss=0.26811 Rate=10.35 GlobalRate=10.35 Time=03:37:28\n",
            "| Training Device=xla:0/2 Epoch=47 Step=0 Loss=0.27443 Rate=10.35 GlobalRate=10.35 Time=03:37:28\n",
            "| Training Device=xla:0/3 Epoch=47 Step=0 Loss=0.35797 Rate=10.35 GlobalRate=10.35 Time=03:37:28\n",
            "| Training Device=xla:1/0 Epoch=47 Step=0 Loss=0.31518 Rate=10.35 GlobalRate=10.35 Time=03:37:28\n",
            "| Training Device=xla:0/7 Epoch=47 Step=0 Loss=0.32877 Rate=10.35 GlobalRate=10.35 Time=03:37:28\n",
            "| Training Device=xla:0/6 Epoch=47 Step=0 Loss=0.32361 Rate=10.35 GlobalRate=10.35 Time=03:37:28\n",
            "Epoch 47 train end 03:37:28\n",
            "Epoch 48 train begin 03:37:28\n",
            "| Training Device=xla:0/4 Epoch=48 Step=0 Loss=0.25654 Rate=10.33 GlobalRate=10.33 Time=03:37:35\n",
            "| Training Device=xla:0/2 Epoch=48 Step=0 Loss=0.28695 Rate=10.32 GlobalRate=10.32 Time=03:37:35\n",
            "| Training Device=xla:1/0 Epoch=48 Step=0 Loss=0.28844 Rate=10.33 GlobalRate=10.33 Time=03:37:35\n",
            "| Training Device=xla:0/5 Epoch=48 Step=0 Loss=0.23636 Rate=10.32 GlobalRate=10.32 Time=03:37:35\n",
            "| Training Device=xla:0/3 Epoch=48 Step=0 Loss=0.35272 Rate=10.32 GlobalRate=10.32 Time=03:37:35\n",
            "| Training Device=xla:0/6 Epoch=48 Step=0 Loss=0.34562 Rate=10.33 GlobalRate=10.33 Time=03:37:35\n",
            "| Training Device=xla:0/7 Epoch=48 Step=0 Loss=0.22796 Rate=10.32 GlobalRate=10.32 Time=03:37:35\n",
            "| Training Device=xla:0/1 Epoch=48 Step=0 Loss=0.28444 Rate=10.32 GlobalRate=10.32 Time=03:37:35\n",
            "Epoch 48 train end 03:37:35\n",
            "Epoch 49 train begin 03:37:35\n",
            "| Training Device=xla:0/1 Epoch=49 Step=0 Loss=0.25878 Rate=10.34 GlobalRate=10.34 Time=03:37:41\n",
            "| Training Device=xla:0/3 Epoch=49 Step=0 Loss=0.40017 Rate=10.34 GlobalRate=10.34 Time=03:37:41\n",
            "| Training Device=xla:0/5 Epoch=49 Step=0 Loss=0.28276 Rate=10.34 GlobalRate=10.34 Time=03:37:41\n",
            "| Training Device=xla:0/2 Epoch=49 Step=0 Loss=0.31730 Rate=10.34 GlobalRate=10.34 Time=03:37:41\n",
            "| Training Device=xla:1/0 Epoch=49 Step=0 Loss=0.32077 Rate=10.34 GlobalRate=10.34 Time=03:37:41\n",
            "| Training Device=xla:0/7 Epoch=49 Step=0 Loss=0.23490 Rate=10.34 GlobalRate=10.34 Time=03:37:41\n",
            "| Training Device=xla:0/6 Epoch=49 Step=0 Loss=0.37680 Rate=10.34 GlobalRate=10.34 Time=03:37:41\n",
            "| Training Device=xla:0/4 Epoch=49 Step=0 Loss=0.26839 Rate=10.34 GlobalRate=10.34 Time=03:37:41\n",
            "Epoch 49 train end 03:37:41\n",
            "Epoch 50 train begin 03:37:41\n",
            "| Training Device=xla:1/0 Epoch=50 Step=0 Loss=0.37272 Rate=10.35 GlobalRate=10.35 Time=03:37:48\n",
            "| Training Device=xla:0/4 Epoch=50 Step=0 Loss=0.29303 Rate=10.35 GlobalRate=10.35 Time=03:37:48\n",
            "| Training Device=xla:0/5 Epoch=50 Step=0 Loss=0.28678 Rate=10.35 GlobalRate=10.35 Time=03:37:48\n",
            "| Training Device=xla:0/2 Epoch=50 Step=0 Loss=0.27017 Rate=10.35 GlobalRate=10.35 Time=03:37:48\n",
            "| Training Device=xla:0/1 Epoch=50 Step=0 Loss=0.31630 Rate=10.35 GlobalRate=10.35 Time=03:37:48\n",
            "| Training Device=xla:0/7 Epoch=50 Step=0 Loss=0.32437 Rate=10.35 GlobalRate=10.35 Time=03:37:48\n",
            "| Training Device=xla:0/6 Epoch=50 Step=0 Loss=0.37069 Rate=10.35 GlobalRate=10.35 Time=03:37:48\n",
            "| Training Device=xla:0/3 Epoch=50 Step=0 Loss=0.43391 Rate=10.35 GlobalRate=10.35 Time=03:37:48\n",
            "Epoch 50 train end 03:37:48\n",
            "Epoch 51 train begin 03:37:48\n",
            "| Training Device=xla:1/0 Epoch=51 Step=0 Loss=0.37492 Rate=10.24 GlobalRate=10.24 Time=03:37:54\n",
            "| Training Device=xla:0/5 Epoch=51 Step=0 Loss=0.22581 Rate=10.24 GlobalRate=10.24 Time=03:37:54\n",
            "| Training Device=xla:0/2 Epoch=51 Step=0 Loss=0.26679 Rate=10.24 GlobalRate=10.24 Time=03:37:54\n",
            "| Training Device=xla:0/6 Epoch=51 Step=0 Loss=0.31180 Rate=10.24 GlobalRate=10.24 Time=03:37:54\n",
            "| Training Device=xla:0/4 Epoch=51 Step=0 Loss=0.26989 Rate=10.24 GlobalRate=10.24 Time=03:37:54\n",
            "| Training Device=xla:0/7 Epoch=51 Step=0 Loss=0.26734 Rate=10.24 GlobalRate=10.24 Time=03:37:54\n",
            "| Training Device=xla:0/1 Epoch=51 Step=0 Loss=0.27074 Rate=10.24 GlobalRate=10.24 Time=03:37:54\n",
            "| Training Device=xla:0/3 Epoch=51 Step=0 Loss=0.40739 Rate=10.24 GlobalRate=10.24 Time=03:37:54\n",
            "Epoch 51 train end 03:37:54\n",
            "Epoch 52 train begin 03:37:54\n",
            "| Training Device=xla:0/3 Epoch=52 Step=0 Loss=0.37432 Rate=10.23 GlobalRate=10.23 Time=03:38:01\n",
            "| Training Device=xla:0/4 Epoch=52 Step=0 Loss=0.32124 Rate=10.23 GlobalRate=10.23 Time=03:38:01\n",
            "| Training Device=xla:0/7 Epoch=52 Step=0 Loss=0.21111 Rate=10.23 GlobalRate=10.23 Time=03:38:01\n",
            "| Training Device=xla:0/5 Epoch=52 Step=0 Loss=0.25339 Rate=10.22 GlobalRate=10.22 Time=03:38:01\n",
            "| Training Device=xla:0/1 Epoch=52 Step=0 Loss=0.26602 Rate=10.22 GlobalRate=10.22 Time=03:38:01\n",
            "| Training Device=xla:1/0 Epoch=52 Step=0 Loss=0.36346 Rate=10.23 GlobalRate=10.23 Time=03:38:01\n",
            "| Training Device=xla:0/2 Epoch=52 Step=0 Loss=0.26983 Rate=10.22 GlobalRate=10.22 Time=03:38:01\n",
            "| Training Device=xla:0/6 Epoch=52 Step=0 Loss=0.36791 Rate=10.23 GlobalRate=10.23 Time=03:38:01\n",
            "Epoch 52 train end 03:38:01\n",
            "Epoch 53 train begin 03:38:01\n",
            "| Training Device=xla:0/2 Epoch=53 Step=0 Loss=0.29107 Rate=10.23 GlobalRate=10.23 Time=03:38:07\n",
            "| Training Device=xla:0/5 Epoch=53 Step=0 Loss=0.31358 Rate=10.23 GlobalRate=10.23 Time=03:38:07\n",
            "| Training Device=xla:0/1 Epoch=53 Step=0 Loss=0.30697 Rate=10.23 GlobalRate=10.23 Time=03:38:07\n",
            "| Training Device=xla:0/3 Epoch=53 Step=0 Loss=0.40442 Rate=10.23 GlobalRate=10.23 Time=03:38:07\n",
            "| Training Device=xla:0/4 Epoch=53 Step=0 Loss=0.28869 Rate=10.23 GlobalRate=10.23 Time=03:38:07\n",
            "| Training Device=xla:0/6 Epoch=53 Step=0 Loss=0.37501 Rate=10.23 GlobalRate=10.23 Time=03:38:07\n",
            "| Training Device=xla:1/0 Epoch=53 Step=0 Loss=0.34616 Rate=10.23 GlobalRate=10.23 Time=03:38:07\n",
            "| Training Device=xla:0/7 Epoch=53 Step=0 Loss=0.29895 Rate=10.23 GlobalRate=10.23 Time=03:38:07\n",
            "Epoch 53 train end 03:38:07\n",
            "Epoch 54 train begin 03:38:07\n",
            "| Training Device=xla:0/3 Epoch=54 Step=0 Loss=0.32978 Rate=10.32 GlobalRate=10.32 Time=03:38:13\n",
            "| Training Device=xla:0/5 Epoch=54 Step=0 Loss=0.25642 Rate=10.32 GlobalRate=10.32 Time=03:38:13\n",
            "| Training Device=xla:0/4 Epoch=54 Step=0 Loss=0.26924 Rate=10.32 GlobalRate=10.32 Time=03:38:13\n",
            "| Training Device=xla:0/1 Epoch=54 Step=0 Loss=0.33690 Rate=10.32 GlobalRate=10.32 Time=03:38:13\n",
            "| Training Device=xla:0/7 Epoch=54 Step=0 Loss=0.24043 Rate=10.32 GlobalRate=10.32 Time=03:38:13\n",
            "| Training Device=xla:0/2 Epoch=54 Step=0 Loss=0.25930 Rate=10.32 GlobalRate=10.32 Time=03:38:13\n",
            "| Training Device=xla:0/6 Epoch=54 Step=0 Loss=0.32975 Rate=10.32 GlobalRate=10.32 Time=03:38:13\n",
            "| Training Device=xla:1/0 Epoch=54 Step=0 Loss=0.33127 Rate=10.33 GlobalRate=10.33 Time=03:38:13\n",
            "Epoch 54 train end 03:38:14\n",
            "Epoch 55 train begin 03:38:14\n",
            "| Training Device=xla:0/4 Epoch=55 Step=0 Loss=0.28522 Rate=10.34 GlobalRate=10.34 Time=03:38:20\n",
            "| Training Device=xla:0/5 Epoch=55 Step=0 Loss=0.29126 Rate=10.34 GlobalRate=10.34 Time=03:38:20\n",
            "| Training Device=xla:0/7 Epoch=55 Step=0 Loss=0.24730 Rate=10.34 GlobalRate=10.34 Time=03:38:20\n",
            "| Training Device=xla:0/3 Epoch=55 Step=0 Loss=0.38462 Rate=10.34 GlobalRate=10.34 Time=03:38:20\n",
            "| Training Device=xla:0/1 Epoch=55 Step=0 Loss=0.26625 Rate=10.33 GlobalRate=10.33 Time=03:38:20\n",
            "| Training Device=xla:0/2 Epoch=55 Step=0 Loss=0.32064 Rate=10.34 GlobalRate=10.34 Time=03:38:20\n",
            "| Training Device=xla:1/0 Epoch=55 Step=0 Loss=0.29194 Rate=10.34 GlobalRate=10.34 Time=03:38:20\n",
            "| Training Device=xla:0/6 Epoch=55 Step=0 Loss=0.36100 Rate=10.34 GlobalRate=10.34 Time=03:38:20\n",
            "Epoch 55 train end 03:38:20\n",
            "Epoch 56 train begin 03:38:20\n",
            "| Training Device=xla:0/6 Epoch=56 Step=0 Loss=0.37229 Rate=10.39 GlobalRate=10.39 Time=03:38:26\n",
            "| Training Device=xla:0/3 Epoch=56 Step=0 Loss=0.44257 Rate=10.38 GlobalRate=10.38 Time=03:38:26\n",
            "| Training Device=xla:0/4 Epoch=56 Step=0 Loss=0.23970 Rate=10.38 GlobalRate=10.38 Time=03:38:26\n",
            "| Training Device=xla:0/5 Epoch=56 Step=0 Loss=0.26772 Rate=10.38 GlobalRate=10.38 Time=03:38:26\n",
            "| Training Device=xla:0/7 Epoch=56 Step=0 Loss=0.26099 Rate=10.38 GlobalRate=10.38 Time=03:38:26\n",
            "| Training Device=xla:1/0 Epoch=56 Step=0 Loss=0.30593 Rate=10.38 GlobalRate=10.38 Time=03:38:26\n",
            "| Training Device=xla:0/1 Epoch=56 Step=0 Loss=0.29961 Rate=10.38 GlobalRate=10.38 Time=03:38:26\n",
            "| Training Device=xla:0/2 Epoch=56 Step=0 Loss=0.27165 Rate=10.38 GlobalRate=10.38 Time=03:38:26\n",
            "Epoch 56 train end 03:38:27\n",
            "Epoch 57 train begin 03:38:27\n",
            "| Training Device=xla:0/2 Epoch=57 Step=0 Loss=0.34286 Rate=10.39 GlobalRate=10.39 Time=03:38:33\n",
            "| Training Device=xla:0/7 Epoch=57 Step=0 Loss=0.29091 Rate=10.39 GlobalRate=10.39 Time=03:38:33\n",
            "| Training Device=xla:0/3 Epoch=57 Step=0 Loss=0.47402 Rate=10.39 GlobalRate=10.39 Time=03:38:33\n",
            "| Training Device=xla:1/0 Epoch=57 Step=0 Loss=0.31196 Rate=10.39 GlobalRate=10.39 Time=03:38:33\n",
            "| Training Device=xla:0/6 Epoch=57 Step=0 Loss=0.35809 Rate=10.39 GlobalRate=10.39 Time=03:38:33\n",
            "| Training Device=xla:0/4 Epoch=57 Step=0 Loss=0.29123 Rate=10.39 GlobalRate=10.39 Time=03:38:33\n",
            "| Training Device=xla:0/1 Epoch=57 Step=0 Loss=0.30629 Rate=10.39 GlobalRate=10.39 Time=03:38:33\n",
            "| Training Device=xla:0/5 Epoch=57 Step=0 Loss=0.31173 Rate=10.39 GlobalRate=10.39 Time=03:38:33\n",
            "Epoch 57 train end 03:38:33\n",
            "Epoch 58 train begin 03:38:33\n",
            "| Training Device=xla:0/7 Epoch=58 Step=0 Loss=0.26318 Rate=10.37 GlobalRate=10.37 Time=03:38:39\n",
            "| Training Device=xla:0/1 Epoch=58 Step=0 Loss=0.26347 Rate=10.37 GlobalRate=10.37 Time=03:38:39\n",
            "| Training Device=xla:0/6 Epoch=58 Step=0 Loss=0.39428 Rate=10.37 GlobalRate=10.37 Time=03:38:39\n",
            "| Training Device=xla:0/2 Epoch=58 Step=0 Loss=0.26539 Rate=10.37 GlobalRate=10.37 Time=03:38:39\n",
            "| Training Device=xla:0/3 Epoch=58 Step=0 Loss=0.44276 Rate=10.37 GlobalRate=10.37 Time=03:38:39\n",
            "| Training Device=xla:0/5 Epoch=58 Step=0 Loss=0.26482 Rate=10.37 GlobalRate=10.37 Time=03:38:39\n",
            "| Training Device=xla:0/4 Epoch=58 Step=0 Loss=0.27524 Rate=10.36 GlobalRate=10.36 Time=03:38:39\n",
            "| Training Device=xla:1/0 Epoch=58 Step=0 Loss=0.31183 Rate=10.37 GlobalRate=10.37 Time=03:38:39\n",
            "Epoch 58 train end 03:38:39\n",
            "Epoch 59 train begin 03:38:39\n",
            "| Training Device=xla:0/6 Epoch=59 Step=0 Loss=0.35473 Rate=10.37 GlobalRate=10.37 Time=03:38:46\n",
            "| Training Device=xla:1/0 Epoch=59 Step=0 Loss=0.30268 Rate=10.37 GlobalRate=10.37 Time=03:38:46\n",
            "| Training Device=xla:0/3 Epoch=59 Step=0 Loss=0.38193 Rate=10.37 GlobalRate=10.37 Time=03:38:46\n",
            "| Training Device=xla:0/2 Epoch=59 Step=0 Loss=0.26113 Rate=10.37 GlobalRate=10.37 Time=03:38:46\n",
            "| Training Device=xla:0/7 Epoch=59 Step=0 Loss=0.24579 Rate=10.37 GlobalRate=10.37 Time=03:38:46\n",
            "| Training Device=xla:0/1 Epoch=59 Step=0 Loss=0.23314 Rate=10.37 GlobalRate=10.37 Time=03:38:46\n",
            "| Training Device=xla:0/4 Epoch=59 Step=0 Loss=0.26978 Rate=10.36 GlobalRate=10.36 Time=03:38:46\n",
            "| Training Device=xla:0/5 Epoch=59 Step=0 Loss=0.20839 Rate=10.37 GlobalRate=10.37 Time=03:38:46\n",
            "Epoch 59 train end 03:38:46\n",
            "Epoch 60 train begin 03:38:46\n",
            "| Training Device=xla:0/7 Epoch=60 Step=0 Loss=0.25600 Rate=10.36 GlobalRate=10.36 Time=03:38:52\n",
            "| Training Device=xla:0/6 Epoch=60 Step=0 Loss=0.34817 Rate=10.36 GlobalRate=10.36 Time=03:38:52\n",
            "| Training Device=xla:0/2 Epoch=60 Step=0 Loss=0.24063 Rate=10.36 GlobalRate=10.36 Time=03:38:52\n",
            "| Training Device=xla:0/5 Epoch=60 Step=0 Loss=0.25625 Rate=10.36 GlobalRate=10.36 Time=03:38:52\n",
            "| Training Device=xla:0/3 Epoch=60 Step=0 Loss=0.41162 Rate=10.36 GlobalRate=10.36 Time=03:38:52\n",
            "| Training Device=xla:0/1 Epoch=60 Step=0 Loss=0.25240 Rate=10.35 GlobalRate=10.35 Time=03:38:52\n",
            "| Training Device=xla:0/4 Epoch=60 Step=0 Loss=0.27694 Rate=10.35 GlobalRate=10.35 Time=03:38:52\n",
            "| Training Device=xla:1/0 Epoch=60 Step=0 Loss=0.36471 Rate=10.36 GlobalRate=10.36 Time=03:38:52\n",
            "Epoch 60 train end 03:38:52\n",
            "Epoch 61 train begin 03:38:52\n",
            "| Training Device=xla:0/3 Epoch=61 Step=0 Loss=0.41189 Rate=10.41 GlobalRate=10.41 Time=03:38:58\n",
            "| Training Device=xla:0/6 Epoch=61 Step=0 Loss=0.39232 Rate=10.41 GlobalRate=10.41 Time=03:38:58\n",
            "| Training Device=xla:0/5 Epoch=61 Step=0 Loss=0.27396 Rate=10.41 GlobalRate=10.41 Time=03:38:58\n",
            "| Training Device=xla:1/0 Epoch=61 Step=0 Loss=0.29865 Rate=10.41 GlobalRate=10.41 Time=03:38:58\n",
            "| Training Device=xla:0/7 Epoch=61 Step=0 Loss=0.24170 Rate=10.41 GlobalRate=10.41 Time=03:38:58\n",
            "| Training Device=xla:0/2 Epoch=61 Step=0 Loss=0.29225 Rate=10.41 GlobalRate=10.41 Time=03:38:58\n",
            "| Training Device=xla:0/4 Epoch=61 Step=0 Loss=0.37115 Rate=10.41 GlobalRate=10.41 Time=03:38:58\n",
            "| Training Device=xla:0/1 Epoch=61 Step=0 Loss=0.33555 Rate=10.40 GlobalRate=10.40 Time=03:38:58\n",
            "Epoch 61 train end 03:38:59\n",
            "Epoch 62 train begin 03:38:59\n",
            "| Training Device=xla:0/1 Epoch=62 Step=0 Loss=0.27447 Rate=10.34 GlobalRate=10.34 Time=03:39:05\n",
            "| Training Device=xla:0/3 Epoch=62 Step=0 Loss=0.38421 Rate=10.34 GlobalRate=10.34 Time=03:39:05\n",
            "| Training Device=xla:0/2 Epoch=62 Step=0 Loss=0.29060 Rate=10.34 GlobalRate=10.34 Time=03:39:05\n",
            "| Training Device=xla:0/4 Epoch=62 Step=0 Loss=0.27006 Rate=10.34 GlobalRate=10.34 Time=03:39:05\n",
            "| Training Device=xla:0/7 Epoch=62 Step=0 Loss=0.30108 Rate=10.34 GlobalRate=10.34 Time=03:39:05\n",
            "| Training Device=xla:1/0 Epoch=62 Step=0 Loss=0.34362 Rate=10.34 GlobalRate=10.34 Time=03:39:05\n",
            "| Training Device=xla:0/6 Epoch=62 Step=0 Loss=0.38207 Rate=10.34 GlobalRate=10.34 Time=03:39:05\n",
            "| Training Device=xla:0/5 Epoch=62 Step=0 Loss=0.26154 Rate=10.34 GlobalRate=10.34 Time=03:39:05\n",
            "Epoch 62 train end 03:39:05\n",
            "Epoch 63 train begin 03:39:05\n",
            "| Training Device=xla:0/4 Epoch=63 Step=0 Loss=0.24163 Rate=10.43 GlobalRate=10.43 Time=03:39:11\n",
            "| Training Device=xla:1/0 Epoch=63 Step=0 Loss=0.34369 Rate=10.43 GlobalRate=10.43 Time=03:39:11\n",
            "| Training Device=xla:0/6 Epoch=63 Step=0 Loss=0.39793 Rate=10.42 GlobalRate=10.42 Time=03:39:11\n",
            "| Training Device=xla:0/1 Epoch=63 Step=0 Loss=0.29457 Rate=10.42 GlobalRate=10.42 Time=03:39:11\n",
            "| Training Device=xla:0/2 Epoch=63 Step=0 Loss=0.24590 Rate=10.42 GlobalRate=10.42 Time=03:39:11\n",
            "| Training Device=xla:0/7 Epoch=63 Step=0 Loss=0.26134 Rate=10.42 GlobalRate=10.42 Time=03:39:11\n",
            "| Training Device=xla:0/3 Epoch=63 Step=0 Loss=0.35574 Rate=10.42 GlobalRate=10.42 Time=03:39:11\n",
            "| Training Device=xla:0/5 Epoch=63 Step=0 Loss=0.24471 Rate=10.42 GlobalRate=10.42 Time=03:39:11\n",
            "Epoch 63 train end 03:39:11\n",
            "Epoch 64 train begin 03:39:11\n",
            "| Training Device=xla:0/3 Epoch=64 Step=0 Loss=0.33911 Rate=10.41 GlobalRate=10.41 Time=03:39:17\n",
            "| Training Device=xla:0/5 Epoch=64 Step=0 Loss=0.29373 Rate=10.40 GlobalRate=10.40 Time=03:39:17\n",
            "| Training Device=xla:0/4 Epoch=64 Step=0 Loss=0.28623 Rate=10.40 GlobalRate=10.40 Time=03:39:17\n",
            "| Training Device=xla:0/7 Epoch=64 Step=0 Loss=0.31172 Rate=10.40 GlobalRate=10.40 Time=03:39:17\n",
            "| Training Device=xla:0/6 Epoch=64 Step=0 Loss=0.38620 Rate=10.40 GlobalRate=10.40 Time=03:39:17\n",
            "| Training Device=xla:0/1 Epoch=64 Step=0 Loss=0.28979 Rate=10.40 GlobalRate=10.40 Time=03:39:17\n",
            "| Training Device=xla:0/2 Epoch=64 Step=0 Loss=0.24476 Rate=10.40 GlobalRate=10.40 Time=03:39:17\n",
            "| Training Device=xla:1/0 Epoch=64 Step=0 Loss=0.31857 Rate=10.41 GlobalRate=10.41 Time=03:39:17\n",
            "Epoch 64 train end 03:39:18\n",
            "Epoch 65 train begin 03:39:18\n",
            "| Training Device=xla:0/3 Epoch=65 Step=0 Loss=0.44696 Rate=10.40 GlobalRate=10.40 Time=03:39:24\n",
            "| Training Device=xla:0/6 Epoch=65 Step=0 Loss=0.39959 Rate=10.39 GlobalRate=10.39 Time=03:39:24\n",
            "| Training Device=xla:0/1 Epoch=65 Step=0 Loss=0.23454 Rate=10.39 GlobalRate=10.39 Time=03:39:24\n",
            "| Training Device=xla:1/0 Epoch=65 Step=0 Loss=0.29392 Rate=10.40 GlobalRate=10.40 Time=03:39:24\n",
            "| Training Device=xla:0/2 Epoch=65 Step=0 Loss=0.29935 Rate=10.39 GlobalRate=10.39 Time=03:39:24\n",
            "| Training Device=xla:0/7 Epoch=65 Step=0 Loss=0.25811 Rate=10.39 GlobalRate=10.39 Time=03:39:24\n",
            "| Training Device=xla:0/4 Epoch=65 Step=0 Loss=0.21351 Rate=10.39 GlobalRate=10.39 Time=03:39:24\n",
            "| Training Device=xla:0/5 Epoch=65 Step=0 Loss=0.26281 Rate=10.39 GlobalRate=10.39 Time=03:39:24\n",
            "Epoch 65 train end 03:39:24\n",
            "Epoch 66 train begin 03:39:24\n",
            "| Training Device=xla:0/6 Epoch=66 Step=0 Loss=0.31227 Rate=10.35 GlobalRate=10.35 Time=03:39:30\n",
            "| Training Device=xla:0/7 Epoch=66 Step=0 Loss=0.24225 Rate=10.35 GlobalRate=10.35 Time=03:39:30\n",
            "| Training Device=xla:0/3 Epoch=66 Step=0 Loss=0.42460 Rate=10.35 GlobalRate=10.35 Time=03:39:30\n",
            "| Training Device=xla:0/5 Epoch=66 Step=0 Loss=0.24234 Rate=10.35 GlobalRate=10.35 Time=03:39:30\n",
            "| Training Device=xla:0/2 Epoch=66 Step=0 Loss=0.20209 Rate=10.35 GlobalRate=10.35 Time=03:39:30\n",
            "| Training Device=xla:1/0 Epoch=66 Step=0 Loss=0.35645 Rate=10.35 GlobalRate=10.35 Time=03:39:30\n",
            "| Training Device=xla:0/1 Epoch=66 Step=0 Loss=0.27086 Rate=10.35 GlobalRate=10.35 Time=03:39:30\n",
            "| Training Device=xla:0/4 Epoch=66 Step=0 Loss=0.25914 Rate=10.35 GlobalRate=10.35 Time=03:39:30\n",
            "Epoch 66 train end 03:39:31\n",
            "Epoch 67 train begin 03:39:31\n",
            "| Training Device=xla:1/0 Epoch=67 Step=0 Loss=0.30861 Rate=10.39 GlobalRate=10.39 Time=03:39:37\n",
            "| Training Device=xla:0/1 Epoch=67 Step=0 Loss=0.24666 Rate=10.39 GlobalRate=10.39 Time=03:39:37\n",
            "| Training Device=xla:0/2 Epoch=67 Step=0 Loss=0.26534 Rate=10.39 GlobalRate=10.39 Time=03:39:37\n",
            "| Training Device=xla:0/6 Epoch=67 Step=0 Loss=0.38923 Rate=10.39 GlobalRate=10.39 Time=03:39:37\n",
            "| Training Device=xla:0/5 Epoch=67 Step=0 Loss=0.27401 Rate=10.39 GlobalRate=10.39 Time=03:39:37\n",
            "| Training Device=xla:0/4 Epoch=67 Step=0 Loss=0.28447 Rate=10.39 GlobalRate=10.39 Time=03:39:37\n",
            "| Training Device=xla:0/7 Epoch=67 Step=0 Loss=0.27068 Rate=10.39 GlobalRate=10.39 Time=03:39:37\n",
            "| Training Device=xla:0/3 Epoch=67 Step=0 Loss=0.39877 Rate=10.39 GlobalRate=10.39 Time=03:39:37\n",
            "Epoch 67 train end 03:39:37\n",
            "Epoch 68 train begin 03:39:37\n",
            "| Training Device=xla:0/3 Epoch=68 Step=0 Loss=0.37421 Rate=10.36 GlobalRate=10.36 Time=03:39:43\n",
            "| Training Device=xla:0/6 Epoch=68 Step=0 Loss=0.34060 Rate=10.35 GlobalRate=10.35 Time=03:39:43\n",
            "| Training Device=xla:0/7 Epoch=68 Step=0 Loss=0.33073 Rate=10.35 GlobalRate=10.35 Time=03:39:43\n",
            "| Training Device=xla:0/5 Epoch=68 Step=0 Loss=0.23553 Rate=10.35 GlobalRate=10.35 Time=03:39:43\n",
            "| Training Device=xla:1/0 Epoch=68 Step=0 Loss=0.34852 Rate=10.36 GlobalRate=10.36 Time=03:39:43\n",
            "| Training Device=xla:0/4 Epoch=68 Step=0 Loss=0.24120 Rate=10.35 GlobalRate=10.35 Time=03:39:43\n",
            "| Training Device=xla:0/1 Epoch=68 Step=0 Loss=0.24421 Rate=10.35 GlobalRate=10.35 Time=03:39:43\n",
            "| Training Device=xla:0/2 Epoch=68 Step=0 Loss=0.29869 Rate=10.35 GlobalRate=10.35 Time=03:39:43\n",
            "Epoch 68 train end 03:39:43\n",
            "Epoch 69 train begin 03:39:43\n",
            "| Training Device=xla:0/5 Epoch=69 Step=0 Loss=0.29614 Rate=10.38 GlobalRate=10.38 Time=03:39:49\n",
            "| Training Device=xla:0/7 Epoch=69 Step=0 Loss=0.26702 Rate=10.38 GlobalRate=10.38 Time=03:39:49\n",
            "| Training Device=xla:1/0 Epoch=69 Step=0 Loss=0.33814 Rate=10.39 GlobalRate=10.39 Time=03:39:49\n",
            "| Training Device=xla:0/1 Epoch=69 Step=0 Loss=0.27460 Rate=10.38 GlobalRate=10.38 Time=03:39:49\n",
            "| Training Device=xla:0/6 Epoch=69 Step=0 Loss=0.33357 Rate=10.38 GlobalRate=10.38 Time=03:39:49\n",
            "| Training Device=xla:0/2 Epoch=69 Step=0 Loss=0.30320 Rate=10.38 GlobalRate=10.38 Time=03:39:49\n",
            "| Training Device=xla:0/3 Epoch=69 Step=0 Loss=0.39896 Rate=10.38 GlobalRate=10.38 Time=03:39:49\n",
            "| Training Device=xla:0/4 Epoch=69 Step=0 Loss=0.25244 Rate=10.38 GlobalRate=10.38 Time=03:39:49\n",
            "Epoch 69 train end 03:39:50\n",
            "Epoch 70 train begin 03:39:50\n",
            "| Training Device=xla:1/0 Epoch=70 Step=0 Loss=0.31607 Rate=10.24 GlobalRate=10.24 Time=03:39:56\n",
            "| Training Device=xla:0/3 Epoch=70 Step=0 Loss=0.46117 Rate=10.24 GlobalRate=10.24 Time=03:39:56\n",
            "| Training Device=xla:0/4 Epoch=70 Step=0 Loss=0.27998 Rate=10.23 GlobalRate=10.23 Time=03:39:56\n",
            "| Training Device=xla:0/2 Epoch=70 Step=0 Loss=0.28448 Rate=10.24 GlobalRate=10.23 Time=03:39:56\n",
            "| Training Device=xla:0/7 Epoch=70 Step=0 Loss=0.27461 Rate=10.23 GlobalRate=10.23 Time=03:39:56\n",
            "| Training Device=xla:0/5 Epoch=70 Step=0 Loss=0.33521 Rate=10.23 GlobalRate=10.23 Time=03:39:56\n",
            "| Training Device=xla:0/1 Epoch=70 Step=0 Loss=0.30702 Rate=10.23 GlobalRate=10.23 Time=03:39:56\n",
            "| Training Device=xla:0/6 Epoch=70 Step=0 Loss=0.40768 Rate=10.23 GlobalRate=10.23 Time=03:39:56\n",
            "Epoch 70 train end 03:39:56\n",
            "Epoch 71 train begin 03:39:56\n",
            "| Training Device=xla:0/2 Epoch=71 Step=0 Loss=0.27397 Rate=10.33 GlobalRate=10.33 Time=03:40:02\n",
            "| Training Device=xla:0/5 Epoch=71 Step=0 Loss=0.25131 Rate=10.33 GlobalRate=10.33 Time=03:40:02\n",
            "| Training Device=xla:0/4 Epoch=71 Step=0 Loss=0.27598 Rate=10.33 GlobalRate=10.33 Time=03:40:02\n",
            "| Training Device=xla:0/7 Epoch=71 Step=0 Loss=0.19813 Rate=10.33 GlobalRate=10.33 Time=03:40:02\n",
            "| Training Device=xla:0/1 Epoch=71 Step=0 Loss=0.31125 Rate=10.33 GlobalRate=10.33 Time=03:40:02\n",
            "| Training Device=xla:0/3 Epoch=71 Step=0 Loss=0.45789 Rate=10.32 GlobalRate=10.32 Time=03:40:02\n",
            "| Training Device=xla:0/6 Epoch=71 Step=0 Loss=0.35020 Rate=10.33 GlobalRate=10.33 Time=03:40:02\n",
            "| Training Device=xla:1/0 Epoch=71 Step=0 Loss=0.33713 Rate=10.33 GlobalRate=10.33 Time=03:40:02\n",
            "Epoch 71 train end 03:40:03\n",
            "Epoch 72 train begin 03:40:03\n",
            "| Training Device=xla:0/2 Epoch=72 Step=0 Loss=0.32743 Rate=10.30 GlobalRate=10.30 Time=03:40:09\n",
            "| Training Device=xla:0/3 Epoch=72 Step=0 Loss=0.32113 Rate=10.31 GlobalRate=10.31 Time=03:40:09\n",
            "| Training Device=xla:0/6 Epoch=72 Step=0 Loss=0.31340 Rate=10.30 GlobalRate=10.30 Time=03:40:09\n",
            "| Training Device=xla:0/4 Epoch=72 Step=0 Loss=0.23946 Rate=10.30 GlobalRate=10.30 Time=03:40:09\n",
            "| Training Device=xla:0/5 Epoch=72 Step=0 Loss=0.28452 Rate=10.30 GlobalRate=10.30 Time=03:40:09\n",
            "| Training Device=xla:0/7 Epoch=72 Step=0 Loss=0.32661 Rate=10.30 GlobalRate=10.30 Time=03:40:09\n",
            "| Training Device=xla:0/1 Epoch=72 Step=0 Loss=0.32060 Rate=10.30 GlobalRate=10.30 Time=03:40:09\n",
            "| Training Device=xla:1/0 Epoch=72 Step=0 Loss=0.33455 Rate=10.31 GlobalRate=10.31 Time=03:40:09\n",
            "Epoch 72 train end 03:40:09\n",
            "Epoch 73 train begin 03:40:09\n",
            "| Training Device=xla:0/4 Epoch=73 Step=0 Loss=0.26668 Rate=10.37 GlobalRate=10.37 Time=03:40:15\n",
            "| Training Device=xla:0/1 Epoch=73 Step=0 Loss=0.34903 Rate=10.37 GlobalRate=10.37 Time=03:40:15\n",
            "| Training Device=xla:0/5 Epoch=73 Step=0 Loss=0.21864 Rate=10.37 GlobalRate=10.36 Time=03:40:15\n",
            "| Training Device=xla:0/3 Epoch=73 Step=0 Loss=0.43512 Rate=10.37 GlobalRate=10.37 Time=03:40:15\n",
            "| Training Device=xla:0/2 Epoch=73 Step=0 Loss=0.28862 Rate=10.37 GlobalRate=10.37 Time=03:40:15\n",
            "| Training Device=xla:0/6 Epoch=73 Step=0 Loss=0.34803 Rate=10.37 GlobalRate=10.37 Time=03:40:15\n",
            "| Training Device=xla:0/7 Epoch=73 Step=0 Loss=0.30995 Rate=10.37 GlobalRate=10.37 Time=03:40:15\n",
            "| Training Device=xla:1/0 Epoch=73 Step=0 Loss=0.35237 Rate=10.37 GlobalRate=10.37 Time=03:40:15\n",
            "Epoch 73 train end 03:40:16\n",
            "Epoch 74 train begin 03:40:16\n",
            "| Training Device=xla:0/2 Epoch=74 Step=0 Loss=0.29119 Rate=10.30 GlobalRate=10.30 Time=03:40:22\n",
            "| Training Device=xla:0/5 Epoch=74 Step=0 Loss=0.25093 Rate=10.30 GlobalRate=10.30 Time=03:40:22\n",
            "| Training Device=xla:0/4 Epoch=74 Step=0 Loss=0.35846 Rate=10.30 GlobalRate=10.30 Time=03:40:22\n",
            "| Training Device=xla:1/0 Epoch=74 Step=0 Loss=0.24698 Rate=10.30 GlobalRate=10.30 Time=03:40:22\n",
            "| Training Device=xla:0/3 Epoch=74 Step=0 Loss=0.30903 Rate=10.30 GlobalRate=10.30 Time=03:40:22\n",
            "| Training Device=xla:0/1 Epoch=74 Step=0 Loss=0.31581 Rate=10.30 GlobalRate=10.30 Time=03:40:22\n",
            "| Training Device=xla:0/6 Epoch=74 Step=0 Loss=0.41111 Rate=10.30 GlobalRate=10.30 Time=03:40:22\n",
            "| Training Device=xla:0/7 Epoch=74 Step=0 Loss=0.27746 Rate=10.30 GlobalRate=10.30 Time=03:40:22\n",
            "Epoch 74 train end 03:40:22\n",
            "Epoch 75 train begin 03:40:22\n",
            "| Training Device=xla:0/3 Epoch=75 Step=0 Loss=0.35061 Rate=10.28 GlobalRate=10.28 Time=03:40:28\n",
            "| Training Device=xla:0/5 Epoch=75 Step=0 Loss=0.24627 Rate=10.28 GlobalRate=10.28 Time=03:40:28\n",
            "| Training Device=xla:0/4 Epoch=75 Step=0 Loss=0.23472 Rate=10.28 GlobalRate=10.28 Time=03:40:28\n",
            "| Training Device=xla:0/7 Epoch=75 Step=0 Loss=0.31325 Rate=10.28 GlobalRate=10.28 Time=03:40:28\n",
            "| Training Device=xla:0/2 Epoch=75 Step=0 Loss=0.26930 Rate=10.28 GlobalRate=10.28 Time=03:40:28\n",
            "| Training Device=xla:0/1 Epoch=75 Step=0 Loss=0.28160 Rate=10.27 GlobalRate=10.27 Time=03:40:28\n",
            "| Training Device=xla:0/6 Epoch=75 Step=0 Loss=0.34567 Rate=10.28 GlobalRate=10.28 Time=03:40:28\n",
            "| Training Device=xla:1/0 Epoch=75 Step=0 Loss=0.33196 Rate=10.28 GlobalRate=10.28 Time=03:40:28\n",
            "Epoch 75 train end 03:40:28\n",
            "Epoch 76 train begin 03:40:28\n",
            "| Training Device=xla:0/4 Epoch=76 Step=0 Loss=0.22405 Rate=10.42 GlobalRate=10.42 Time=03:40:35\n",
            "| Training Device=xla:0/2 Epoch=76 Step=0 Loss=0.25104 Rate=10.43 GlobalRate=10.43 Time=03:40:35\n",
            "| Training Device=xla:0/6 Epoch=76 Step=0 Loss=0.36988 Rate=10.43 GlobalRate=10.43 Time=03:40:35\n",
            "| Training Device=xla:0/5 Epoch=76 Step=0 Loss=0.21323 Rate=10.43 GlobalRate=10.43 Time=03:40:35\n",
            "| Training Device=xla:0/3 Epoch=76 Step=0 Loss=0.34595 Rate=10.43 GlobalRate=10.43 Time=03:40:35\n",
            "| Training Device=xla:1/0 Epoch=76 Step=0 Loss=0.30916 Rate=10.43 GlobalRate=10.43 Time=03:40:35\n",
            "| Training Device=xla:0/1 Epoch=76 Step=0 Loss=0.26932 Rate=10.43 GlobalRate=10.43 Time=03:40:35\n",
            "| Training Device=xla:0/7 Epoch=76 Step=0 Loss=0.29632 Rate=10.42 GlobalRate=10.42 Time=03:40:35\n",
            "Epoch 76 train end 03:40:35\n",
            "Epoch 77 train begin 03:40:35\n",
            "| Training Device=xla:0/1 Epoch=77 Step=0 Loss=0.24809 Rate=10.39 GlobalRate=10.39 Time=03:40:41\n",
            "| Training Device=xla:0/7 Epoch=77 Step=0 Loss=0.27079 Rate=10.39 GlobalRate=10.39 Time=03:40:41\n",
            "| Training Device=xla:0/3 Epoch=77 Step=0 Loss=0.42132 Rate=10.39 GlobalRate=10.39 Time=03:40:41\n",
            "| Training Device=xla:0/2 Epoch=77 Step=0 Loss=0.26005 Rate=10.39 GlobalRate=10.39 Time=03:40:41\n",
            "| Training Device=xla:0/5 Epoch=77 Step=0 Loss=0.22877 Rate=10.39 GlobalRate=10.39 Time=03:40:41\n",
            "| Training Device=xla:0/4 Epoch=77 Step=0 Loss=0.26083 Rate=10.39 GlobalRate=10.39 Time=03:40:41\n",
            "| Training Device=xla:0/6 Epoch=77 Step=0 Loss=0.39658 Rate=10.39 GlobalRate=10.39 Time=03:40:41\n",
            "| Training Device=xla:1/0 Epoch=77 Step=0 Loss=0.25597 Rate=10.39 GlobalRate=10.39 Time=03:40:41\n",
            "Epoch 77 train end 03:40:41\n",
            "Epoch 78 train begin 03:40:41\n",
            "| Training Device=xla:0/5 Epoch=78 Step=0 Loss=0.29445 Rate=10.41 GlobalRate=10.41 Time=03:40:47\n",
            "| Training Device=xla:0/7 Epoch=78 Step=0 Loss=0.27174 Rate=10.41 GlobalRate=10.41 Time=03:40:47\n",
            "| Training Device=xla:0/1 Epoch=78 Step=0 Loss=0.29901 Rate=10.41 GlobalRate=10.41 Time=03:40:47\n",
            "| Training Device=xla:0/2 Epoch=78 Step=0 Loss=0.31445 Rate=10.41 GlobalRate=10.41 Time=03:40:47\n",
            "| Training Device=xla:1/0 Epoch=78 Step=0 Loss=0.36027 Rate=10.41 GlobalRate=10.41 Time=03:40:47\n",
            "| Training Device=xla:0/6 Epoch=78 Step=0 Loss=0.39409 Rate=10.41 GlobalRate=10.41 Time=03:40:47\n",
            "| Training Device=xla:0/3 Epoch=78 Step=0 Loss=0.42963 Rate=10.41 GlobalRate=10.41 Time=03:40:47\n",
            "| Training Device=xla:0/4 Epoch=78 Step=0 Loss=0.28909 Rate=10.41 GlobalRate=10.41 Time=03:40:47\n",
            "Epoch 78 train end 03:40:48\n",
            "Epoch 79 train begin 03:40:48\n",
            "| Training Device=xla:0/7 Epoch=79 Step=0 Loss=0.26836 Rate=10.35 GlobalRate=10.35 Time=03:40:54\n",
            "| Training Device=xla:0/3 Epoch=79 Step=0 Loss=0.41579 Rate=10.35 GlobalRate=10.35 Time=03:40:54\n",
            "| Training Device=xla:0/2 Epoch=79 Step=0 Loss=0.26494 Rate=10.34 GlobalRate=10.34 Time=03:40:54\n",
            "| Training Device=xla:0/6 Epoch=79 Step=0 Loss=0.43341 Rate=10.34 GlobalRate=10.34 Time=03:40:54\n",
            "| Training Device=xla:0/1 Epoch=79 Step=0 Loss=0.27851 Rate=10.34 GlobalRate=10.34 Time=03:40:54\n",
            "| Training Device=xla:0/5 Epoch=79 Step=0 Loss=0.29705 Rate=10.34 GlobalRate=10.34 Time=03:40:54\n",
            "| Training Device=xla:1/0 Epoch=79 Step=0 Loss=0.38042 Rate=10.35 GlobalRate=10.35 Time=03:40:54\n",
            "| Training Device=xla:0/4 Epoch=79 Step=0 Loss=0.30090 Rate=10.34 GlobalRate=10.34 Time=03:40:54\n",
            "Epoch 79 train end 03:40:54\n",
            "Epoch 80 train begin 03:40:54\n",
            "| Training Device=xla:0/7 Epoch=80 Step=0 Loss=0.24766 Rate=10.37 GlobalRate=10.37 Time=03:41:00\n",
            "| Training Device=xla:0/4 Epoch=80 Step=0 Loss=0.25991 Rate=10.37 GlobalRate=10.37 Time=03:41:00\n",
            "| Training Device=xla:0/1 Epoch=80 Step=0 Loss=0.25523 Rate=10.37 GlobalRate=10.37 Time=03:41:00\n",
            "| Training Device=xla:0/2 Epoch=80 Step=0 Loss=0.23617 Rate=10.37 GlobalRate=10.37 Time=03:41:00\n",
            "| Training Device=xla:0/3 Epoch=80 Step=0 Loss=0.39831 Rate=10.37 GlobalRate=10.37 Time=03:41:00\n",
            "| Training Device=xla:0/6 Epoch=80 Step=0 Loss=0.37622 Rate=10.37 GlobalRate=10.37 Time=03:41:00\n",
            "| Training Device=xla:1/0 Epoch=80 Step=0 Loss=0.40450 Rate=10.38 GlobalRate=10.38 Time=03:41:00\n",
            "| Training Device=xla:0/5 Epoch=80 Step=0 Loss=0.26580 Rate=10.37 GlobalRate=10.37 Time=03:41:00\n",
            "Epoch 80 train end 03:41:00\n",
            "Epoch 81 train begin 03:41:00\n",
            "| Training Device=xla:1/0 Epoch=81 Step=0 Loss=0.36332 Rate=10.36 GlobalRate=10.36 Time=03:41:07\n",
            "| Training Device=xla:0/4 Epoch=81 Step=0 Loss=0.30197 Rate=10.36 GlobalRate=10.36 Time=03:41:07\n",
            "| Training Device=xla:0/1 Epoch=81 Step=0 Loss=0.23807 Rate=10.35 GlobalRate=10.35 Time=03:41:07\n",
            "| Training Device=xla:0/2 Epoch=81 Step=0 Loss=0.32392 Rate=10.35 GlobalRate=10.35 Time=03:41:07\n",
            "| Training Device=xla:0/6 Epoch=81 Step=0 Loss=0.35857 Rate=10.36 GlobalRate=10.36 Time=03:41:07\n",
            "| Training Device=xla:0/5 Epoch=81 Step=0 Loss=0.28976 Rate=10.35 GlobalRate=10.35 Time=03:41:07\n",
            "| Training Device=xla:0/7 Epoch=81 Step=0 Loss=0.25265 Rate=10.35 GlobalRate=10.35 Time=03:41:07\n",
            "| Training Device=xla:0/3 Epoch=81 Step=0 Loss=0.39354 Rate=10.35 GlobalRate=10.35 Time=03:41:07\n",
            "Epoch 81 train end 03:41:07\n",
            "Epoch 82 train begin 03:41:07\n",
            "| Training Device=xla:0/2 Epoch=82 Step=0 Loss=0.28026 Rate=10.36 GlobalRate=10.36 Time=03:41:13\n",
            "| Training Device=xla:0/4 Epoch=82 Step=0 Loss=0.26803 Rate=10.36 GlobalRate=10.36 Time=03:41:13\n",
            "| Training Device=xla:0/3 Epoch=82 Step=0 Loss=0.41651 Rate=10.36 GlobalRate=10.36 Time=03:41:13\n",
            "| Training Device=xla:0/7 Epoch=82 Step=0 Loss=0.33532 Rate=10.36 GlobalRate=10.36 Time=03:41:13\n",
            "| Training Device=xla:0/6 Epoch=82 Step=0 Loss=0.35142 Rate=10.36 GlobalRate=10.36 Time=03:41:13\n",
            "| Training Device=xla:0/1 Epoch=82 Step=0 Loss=0.29219 Rate=10.36 GlobalRate=10.36 Time=03:41:13\n",
            "| Training Device=xla:0/5 Epoch=82 Step=0 Loss=0.24302 Rate=10.36 GlobalRate=10.36 Time=03:41:13\n",
            "| Training Device=xla:1/0 Epoch=82 Step=0 Loss=0.27680 Rate=10.36 GlobalRate=10.36 Time=03:41:13\n",
            "Epoch 82 train end 03:41:13\n",
            "Epoch 83 train begin 03:41:13\n",
            "| Training Device=xla:0/4 Epoch=83 Step=0 Loss=0.31036 Rate=10.27 GlobalRate=10.27 Time=03:41:19\n",
            "| Training Device=xla:0/1 Epoch=83 Step=0 Loss=0.28682 Rate=10.27 GlobalRate=10.27 Time=03:41:19\n",
            "| Training Device=xla:0/6 Epoch=83 Step=0 Loss=0.35929 Rate=10.27 GlobalRate=10.27 Time=03:41:19\n",
            "| Training Device=xla:0/5 Epoch=83 Step=0 Loss=0.26205 Rate=10.27 GlobalRate=10.27 Time=03:41:19\n",
            "| Training Device=xla:0/3 Epoch=83 Step=0 Loss=0.44456 Rate=10.27 GlobalRate=10.27 Time=03:41:19\n",
            "| Training Device=xla:0/7 Epoch=83 Step=0 Loss=0.29273 Rate=10.27 GlobalRate=10.27 Time=03:41:19\n",
            "| Training Device=xla:0/2 Epoch=83 Step=0 Loss=0.23614 Rate=10.27 GlobalRate=10.27 Time=03:41:19\n",
            "| Training Device=xla:1/0 Epoch=83 Step=0 Loss=0.30384 Rate=10.27 GlobalRate=10.27 Time=03:41:19\n",
            "Epoch 83 train end 03:41:20\n",
            "Epoch 84 train begin 03:41:20\n",
            "| Training Device=xla:0/6 Epoch=84 Step=0 Loss=0.35879 Rate=10.40 GlobalRate=10.40 Time=03:41:26\n",
            "| Training Device=xla:0/7 Epoch=84 Step=0 Loss=0.26425 Rate=10.40 GlobalRate=10.40 Time=03:41:26\n",
            "| Training Device=xla:0/3 Epoch=84 Step=0 Loss=0.40770 Rate=10.40 GlobalRate=10.40 Time=03:41:26\n",
            "| Training Device=xla:0/5 Epoch=84 Step=0 Loss=0.24458 Rate=10.39 GlobalRate=10.39 Time=03:41:26\n",
            "| Training Device=xla:0/1 Epoch=84 Step=0 Loss=0.27207 Rate=10.40 GlobalRate=10.40 Time=03:41:26\n",
            "| Training Device=xla:0/2 Epoch=84 Step=0 Loss=0.28976 Rate=10.40 GlobalRate=10.40 Time=03:41:26\n",
            "| Training Device=xla:1/0 Epoch=84 Step=0 Loss=0.34751 Rate=10.40 GlobalRate=10.40 Time=03:41:26\n",
            "| Training Device=xla:0/4 Epoch=84 Step=0 Loss=0.24260 Rate=10.40 GlobalRate=10.40 Time=03:41:26\n",
            "Epoch 84 train end 03:41:26\n",
            "Epoch 85 train begin 03:41:26\n",
            "| Training Device=xla:0/3 Epoch=85 Step=0 Loss=0.42552 Rate=10.33 GlobalRate=10.33 Time=03:41:32\n",
            "| Training Device=xla:0/1 Epoch=85 Step=0 Loss=0.25680 Rate=10.33 GlobalRate=10.33 Time=03:41:32\n",
            "| Training Device=xla:0/2 Epoch=85 Step=0 Loss=0.28386 Rate=10.33 GlobalRate=10.33 Time=03:41:32\n",
            "| Training Device=xla:0/5 Epoch=85 Step=0 Loss=0.26017 Rate=10.33 GlobalRate=10.33 Time=03:41:32\n",
            "| Training Device=xla:0/6 Epoch=85 Step=0 Loss=0.36185 Rate=10.33 GlobalRate=10.33 Time=03:41:32\n",
            "| Training Device=xla:0/4 Epoch=85 Step=0 Loss=0.22119 Rate=10.33 GlobalRate=10.33 Time=03:41:32\n",
            "| Training Device=xla:0/7 Epoch=85 Step=0 Loss=0.22773 Rate=10.33 GlobalRate=10.33 Time=03:41:32\n",
            "| Training Device=xla:1/0 Epoch=85 Step=0 Loss=0.32361 Rate=10.33 GlobalRate=10.33 Time=03:41:32\n",
            "Epoch 85 train end 03:41:33\n",
            "Epoch 86 train begin 03:41:33\n",
            "| Training Device=xla:0/6 Epoch=86 Step=0 Loss=0.30595 Rate=10.39 GlobalRate=10.39 Time=03:41:39\n",
            "| Training Device=xla:0/1 Epoch=86 Step=0 Loss=0.25265 Rate=10.38 GlobalRate=10.38 Time=03:41:39\n",
            "| Training Device=xla:0/3 Epoch=86 Step=0 Loss=0.37045 Rate=10.38 GlobalRate=10.38 Time=03:41:39\n",
            "| Training Device=xla:1/0 Epoch=86 Step=0 Loss=0.31663 Rate=10.39 GlobalRate=10.39 Time=03:41:39\n",
            "| Training Device=xla:0/5 Epoch=86 Step=0 Loss=0.25761 Rate=10.38 GlobalRate=10.38 Time=03:41:39\n",
            "| Training Device=xla:0/7 Epoch=86 Step=0 Loss=0.23770 Rate=10.38 GlobalRate=10.38 Time=03:41:39\n",
            "| Training Device=xla:0/2 Epoch=86 Step=0 Loss=0.27464 Rate=10.38 GlobalRate=10.38 Time=03:41:39\n",
            "| Training Device=xla:0/4 Epoch=86 Step=0 Loss=0.23367 Rate=10.38 GlobalRate=10.38 Time=03:41:39\n",
            "Epoch 86 train end 03:41:39\n",
            "Epoch 87 train begin 03:41:39\n",
            "| Training Device=xla:0/4 Epoch=87 Step=0 Loss=0.30132 Rate=10.37 GlobalRate=10.37 Time=03:41:45\n",
            "| Training Device=xla:0/7 Epoch=87 Step=0 Loss=0.25112 Rate=10.37 GlobalRate=10.37 Time=03:41:45\n",
            "| Training Device=xla:0/3 Epoch=87 Step=0 Loss=0.36229 Rate=10.37 GlobalRate=10.37 Time=03:41:45\n",
            "| Training Device=xla:0/6 Epoch=87 Step=0 Loss=0.36034 Rate=10.37 GlobalRate=10.37 Time=03:41:45\n",
            "| Training Device=xla:0/2 Epoch=87 Step=0 Loss=0.25054 Rate=10.37 GlobalRate=10.37 Time=03:41:45\n",
            "| Training Device=xla:0/5 Epoch=87 Step=0 Loss=0.21974 Rate=10.37 GlobalRate=10.37 Time=03:41:45\n",
            "| Training Device=xla:1/0 Epoch=87 Step=0 Loss=0.23228 Rate=10.37 GlobalRate=10.37 Time=03:41:45\n",
            "| Training Device=xla:0/1 Epoch=87 Step=0 Loss=0.19959 Rate=10.37 GlobalRate=10.37 Time=03:41:45\n",
            "Epoch 87 train end 03:41:45\n",
            "Epoch 88 train begin 03:41:45\n",
            "| Training Device=xla:0/3 Epoch=88 Step=0 Loss=0.42455 Rate=10.38 GlobalRate=10.38 Time=03:41:52\n",
            "| Training Device=xla:1/0 Epoch=88 Step=0 Loss=0.29119 Rate=10.38 GlobalRate=10.38 Time=03:41:52\n",
            "| Training Device=xla:0/2 Epoch=88 Step=0 Loss=0.31499 Rate=10.37 GlobalRate=10.37 Time=03:41:52\n",
            "| Training Device=xla:0/6 Epoch=88 Step=0 Loss=0.34956 Rate=10.38 GlobalRate=10.38 Time=03:41:52\n",
            "| Training Device=xla:0/5 Epoch=88 Step=0 Loss=0.26379 Rate=10.38 GlobalRate=10.38 Time=03:41:52\n",
            "| Training Device=xla:0/1 Epoch=88 Step=0 Loss=0.27784 Rate=10.37 GlobalRate=10.37 Time=03:41:52\n",
            "| Training Device=xla:0/7 Epoch=88 Step=0 Loss=0.26832 Rate=10.37 GlobalRate=10.37 Time=03:41:52\n",
            "| Training Device=xla:0/4 Epoch=88 Step=0 Loss=0.26422 Rate=10.37 GlobalRate=10.37 Time=03:41:52\n",
            "Epoch 88 train end 03:41:52\n",
            "Epoch 89 train begin 03:41:52\n",
            "| Training Device=xla:0/3 Epoch=89 Step=0 Loss=0.39736 Rate=10.29 GlobalRate=10.29 Time=03:41:58\n",
            "| Training Device=xla:0/5 Epoch=89 Step=0 Loss=0.32766 Rate=10.29 GlobalRate=10.29 Time=03:41:58\n",
            "| Training Device=xla:1/0 Epoch=89 Step=0 Loss=0.30961 Rate=10.29 GlobalRate=10.29 Time=03:41:58\n",
            "| Training Device=xla:0/2 Epoch=89 Step=0 Loss=0.31496 Rate=10.29 GlobalRate=10.29 Time=03:41:58\n",
            "| Training Device=xla:0/1 Epoch=89 Step=0 Loss=0.32505 Rate=10.28 GlobalRate=10.28 Time=03:41:58\n",
            "| Training Device=xla:0/7 Epoch=89 Step=0 Loss=0.31305 Rate=10.29 GlobalRate=10.29 Time=03:41:58\n",
            "| Training Device=xla:0/6 Epoch=89 Step=0 Loss=0.36028 Rate=10.28 GlobalRate=10.28 Time=03:41:58\n",
            "| Training Device=xla:0/4 Epoch=89 Step=0 Loss=0.29426 Rate=10.28 GlobalRate=10.28 Time=03:41:58\n",
            "Epoch 89 train end 03:41:58\n",
            "Epoch 90 train begin 03:41:58\n",
            "| Training Device=xla:0/4 Epoch=90 Step=0 Loss=0.23723 Rate=10.27 GlobalRate=10.27 Time=03:42:04\n",
            "| Training Device=xla:0/6 Epoch=90 Step=0 Loss=0.39428 Rate=10.27 GlobalRate=10.27 Time=03:42:04\n",
            "| Training Device=xla:0/2 Epoch=90 Step=0 Loss=0.28943 Rate=10.27 GlobalRate=10.27 Time=03:42:04\n",
            "| Training Device=xla:0/3 Epoch=90 Step=0 Loss=0.42841 Rate=10.27 GlobalRate=10.27 Time=03:42:04\n",
            "| Training Device=xla:0/1 Epoch=90 Step=0 Loss=0.23025 Rate=10.27 GlobalRate=10.27 Time=03:42:04\n",
            "| Training Device=xla:0/5 Epoch=90 Step=0 Loss=0.23010 Rate=10.27 GlobalRate=10.27 Time=03:42:04\n",
            "| Training Device=xla:0/7 Epoch=90 Step=0 Loss=0.23012 Rate=10.27 GlobalRate=10.27 Time=03:42:04\n",
            "| Training Device=xla:1/0 Epoch=90 Step=0 Loss=0.31890 Rate=10.27 GlobalRate=10.27 Time=03:42:04\n",
            "Epoch 90 train end 03:42:05\n",
            "Epoch 91 train begin 03:42:05\n",
            "| Training Device=xla:0/1 Epoch=91 Step=0 Loss=0.29934 Rate=10.27 GlobalRate=10.27 Time=03:42:11\n",
            "| Training Device=xla:0/4 Epoch=91 Step=0 Loss=0.29775 Rate=10.27 GlobalRate=10.27 Time=03:42:11\n",
            "| Training Device=xla:0/6 Epoch=91 Step=0 Loss=0.32494 Rate=10.27 GlobalRate=10.27 Time=03:42:11\n",
            "| Training Device=xla:0/3 Epoch=91 Step=0 Loss=0.38290 Rate=10.27 GlobalRate=10.27 Time=03:42:11\n",
            "| Training Device=xla:0/5 Epoch=91 Step=0 Loss=0.25895 Rate=10.27 GlobalRate=10.27 Time=03:42:11\n",
            "| Training Device=xla:1/0 Epoch=91 Step=0 Loss=0.45256 Rate=10.27 GlobalRate=10.27 Time=03:42:11\n",
            "| Training Device=xla:0/7 Epoch=91 Step=0 Loss=0.26466 Rate=10.27 GlobalRate=10.27 Time=03:42:11\n",
            "| Training Device=xla:0/2 Epoch=91 Step=0 Loss=0.28075 Rate=10.27 GlobalRate=10.27 Time=03:42:11\n",
            "Epoch 91 train end 03:42:11\n",
            "Epoch 92 train begin 03:42:11\n",
            "| Training Device=xla:1/0 Epoch=92 Step=0 Loss=0.32096 Rate=10.44 GlobalRate=10.44 Time=03:42:17\n",
            "| Training Device=xla:0/5 Epoch=92 Step=0 Loss=0.25147 Rate=10.43 GlobalRate=10.43 Time=03:42:17\n",
            "| Training Device=xla:0/3 Epoch=92 Step=0 Loss=0.33240 Rate=10.43 GlobalRate=10.43 Time=03:42:17\n",
            "| Training Device=xla:0/1 Epoch=92 Step=0 Loss=0.26943 Rate=10.43 GlobalRate=10.43 Time=03:42:17\n",
            "| Training Device=xla:0/7 Epoch=92 Step=0 Loss=0.29692 Rate=10.43 GlobalRate=10.43 Time=03:42:17\n",
            "| Training Device=xla:0/2 Epoch=92 Step=0 Loss=0.28421 Rate=10.43 GlobalRate=10.43 Time=03:42:17\n",
            "| Training Device=xla:0/6 Epoch=92 Step=0 Loss=0.34776 Rate=10.43 GlobalRate=10.43 Time=03:42:17\n",
            "| Training Device=xla:0/4 Epoch=92 Step=0 Loss=0.30115 Rate=10.43 GlobalRate=10.43 Time=03:42:17\n",
            "Epoch 92 train end 03:42:18\n",
            "Epoch 93 train begin 03:42:18\n",
            "| Training Device=xla:0/4 Epoch=93 Step=0 Loss=0.25413 Rate=10.37 GlobalRate=10.37 Time=03:42:24\n",
            "| Training Device=xla:0/6 Epoch=93 Step=0 Loss=0.36104 Rate=10.37 GlobalRate=10.37 Time=03:42:24\n",
            "| Training Device=xla:0/7 Epoch=93 Step=0 Loss=0.26095 Rate=10.37 GlobalRate=10.37 Time=03:42:24\n",
            "| Training Device=xla:0/3 Epoch=93 Step=0 Loss=0.36341 Rate=10.37 GlobalRate=10.37 Time=03:42:24\n",
            "| Training Device=xla:0/2 Epoch=93 Step=0 Loss=0.24405 Rate=10.36 GlobalRate=10.36 Time=03:42:24\n",
            "| Training Device=xla:0/1 Epoch=93 Step=0 Loss=0.26288 Rate=10.37 GlobalRate=10.37 Time=03:42:24\n",
            "| Training Device=xla:0/5 Epoch=93 Step=0 Loss=0.21653 Rate=10.37 GlobalRate=10.37 Time=03:42:24\n",
            "| Training Device=xla:1/0 Epoch=93 Step=0 Loss=0.35009 Rate=10.37 GlobalRate=10.37 Time=03:42:24\n",
            "Epoch 93 train end 03:42:24\n",
            "Epoch 94 train begin 03:42:24\n",
            "| Training Device=xla:0/2 Epoch=94 Step=0 Loss=0.34743 Rate=10.32 GlobalRate=10.32 Time=03:42:30\n",
            "| Training Device=xla:0/3 Epoch=94 Step=0 Loss=0.32877 Rate=10.32 GlobalRate=10.32 Time=03:42:30\n",
            "| Training Device=xla:1/0 Epoch=94 Step=0 Loss=0.27421 Rate=10.32 GlobalRate=10.32 Time=03:42:30\n",
            "| Training Device=xla:0/7 Epoch=94 Step=0 Loss=0.30088 Rate=10.32 GlobalRate=10.32 Time=03:42:30\n",
            "| Training Device=xla:0/6 Epoch=94 Step=0 Loss=0.37862 Rate=10.32 GlobalRate=10.32 Time=03:42:30\n",
            "| Training Device=xla:0/5 Epoch=94 Step=0 Loss=0.24191 Rate=10.32 GlobalRate=10.32 Time=03:42:30\n",
            "| Training Device=xla:0/4 Epoch=94 Step=0 Loss=0.29819 Rate=10.32 GlobalRate=10.32 Time=03:42:30\n",
            "| Training Device=xla:0/1 Epoch=94 Step=0 Loss=0.31742 Rate=10.32 GlobalRate=10.32 Time=03:42:30\n",
            "Epoch 94 train end 03:42:30\n",
            "Epoch 95 train begin 03:42:30\n",
            "| Training Device=xla:0/2 Epoch=95 Step=0 Loss=0.24996 Rate=10.31 GlobalRate=10.31 Time=03:42:37\n",
            "| Training Device=xla:0/7 Epoch=95 Step=0 Loss=0.26098 Rate=10.31 GlobalRate=10.31 Time=03:42:37\n",
            "| Training Device=xla:0/1 Epoch=95 Step=0 Loss=0.27997 Rate=10.31 GlobalRate=10.31 Time=03:42:37\n",
            "| Training Device=xla:0/6 Epoch=95 Step=0 Loss=0.32427 Rate=10.31 GlobalRate=10.31 Time=03:42:37\n",
            "| Training Device=xla:0/5 Epoch=95 Step=0 Loss=0.22240 Rate=10.31 GlobalRate=10.31 Time=03:42:37\n",
            "| Training Device=xla:0/3 Epoch=95 Step=0 Loss=0.32562 Rate=10.31 GlobalRate=10.31 Time=03:42:37\n",
            "| Training Device=xla:1/0 Epoch=95 Step=0 Loss=0.26621 Rate=10.32 GlobalRate=10.32 Time=03:42:37\n",
            "| Training Device=xla:0/4 Epoch=95 Step=0 Loss=0.23567 Rate=10.31 GlobalRate=10.31 Time=03:42:37\n",
            "Epoch 95 train end 03:42:37\n",
            "Epoch 96 train begin 03:42:37\n",
            "| Training Device=xla:0/7 Epoch=96 Step=0 Loss=0.27930 Rate=10.35 GlobalRate=10.35 Time=03:42:43\n",
            "| Training Device=xla:1/0 Epoch=96 Step=0 Loss=0.31649 Rate=10.36 GlobalRate=10.36 Time=03:42:43\n",
            "| Training Device=xla:0/3 Epoch=96 Step=0 Loss=0.40674 Rate=10.35 GlobalRate=10.35 Time=03:42:43\n",
            "| Training Device=xla:0/6 Epoch=96 Step=0 Loss=0.36369 Rate=10.35 GlobalRate=10.35 Time=03:42:43\n",
            "| Training Device=xla:0/1 Epoch=96 Step=0 Loss=0.32814 Rate=10.35 GlobalRate=10.35 Time=03:42:43\n",
            "| Training Device=xla:0/2 Epoch=96 Step=0 Loss=0.28021 Rate=10.35 GlobalRate=10.35 Time=03:42:43\n",
            "| Training Device=xla:0/4 Epoch=96 Step=0 Loss=0.27823 Rate=10.35 GlobalRate=10.35 Time=03:42:43\n",
            "| Training Device=xla:0/5 Epoch=96 Step=0 Loss=0.25193 Rate=10.35 GlobalRate=10.35 Time=03:42:43\n",
            "Epoch 96 train end 03:42:43\n",
            "Epoch 97 train begin 03:42:43\n",
            "| Training Device=xla:0/7 Epoch=97 Step=0 Loss=0.21621 Rate=10.36 GlobalRate=10.36 Time=03:42:49\n",
            "| Training Device=xla:0/3 Epoch=97 Step=0 Loss=0.41424 Rate=10.36 GlobalRate=10.36 Time=03:42:49\n",
            "| Training Device=xla:0/5 Epoch=97 Step=0 Loss=0.25444 Rate=10.36 GlobalRate=10.36 Time=03:42:49\n",
            "| Training Device=xla:0/1 Epoch=97 Step=0 Loss=0.26480 Rate=10.36 GlobalRate=10.36 Time=03:42:49\n",
            "| Training Device=xla:0/2 Epoch=97 Step=0 Loss=0.28763 Rate=10.36 GlobalRate=10.36 Time=03:42:49\n",
            "| Training Device=xla:0/4 Epoch=97 Step=0 Loss=0.31455 Rate=10.35 GlobalRate=10.35 Time=03:42:49\n",
            "| Training Device=xla:1/0 Epoch=97 Step=0 Loss=0.40500 Rate=10.36 GlobalRate=10.36 Time=03:42:49\n",
            "| Training Device=xla:0/6 Epoch=97 Step=0 Loss=0.38716 Rate=10.36 GlobalRate=10.36 Time=03:42:49\n",
            "Epoch 97 train end 03:42:50\n",
            "Epoch 98 train begin 03:42:50\n",
            "| Training Device=xla:0/2 Epoch=98 Step=0 Loss=0.22774 Rate=10.31 GlobalRate=10.31 Time=03:42:56\n",
            "| Training Device=xla:0/1 Epoch=98 Step=0 Loss=0.25571 Rate=10.31 GlobalRate=10.31 Time=03:42:56\n",
            "| Training Device=xla:0/5 Epoch=98 Step=0 Loss=0.28945 Rate=10.31 GlobalRate=10.31 Time=03:42:56\n",
            "| Training Device=xla:1/0 Epoch=98 Step=0 Loss=0.29393 Rate=10.31 GlobalRate=10.31 Time=03:42:56\n",
            "| Training Device=xla:0/4 Epoch=98 Step=0 Loss=0.23537 Rate=10.31 GlobalRate=10.31 Time=03:42:56\n",
            "| Training Device=xla:0/7 Epoch=98 Step=0 Loss=0.24505 Rate=10.31 GlobalRate=10.31 Time=03:42:56\n",
            "| Training Device=xla:0/6 Epoch=98 Step=0 Loss=0.37533 Rate=10.31 GlobalRate=10.31 Time=03:42:56\n",
            "| Training Device=xla:0/3 Epoch=98 Step=0 Loss=0.42209 Rate=10.31 GlobalRate=10.31 Time=03:42:56\n",
            "Epoch 98 train end 03:42:56\n",
            "Epoch 99 train begin 03:42:56\n",
            "| Training Device=xla:0/3 Epoch=99 Step=0 Loss=0.34348 Rate=10.25 GlobalRate=10.25 Time=03:43:02\n",
            "| Training Device=xla:0/4 Epoch=99 Step=0 Loss=0.26662 Rate=10.25 GlobalRate=10.25 Time=03:43:02\n",
            "| Training Device=xla:0/2 Epoch=99 Step=0 Loss=0.26033 Rate=10.24 GlobalRate=10.24 Time=03:43:02\n",
            "| Training Device=xla:0/7 Epoch=99 Step=0 Loss=0.27422 Rate=10.25 GlobalRate=10.25 Time=03:43:02\n",
            "| Training Device=xla:0/1 Epoch=99 Step=0 Loss=0.27702 Rate=10.25 GlobalRate=10.25 Time=03:43:02\n",
            "| Training Device=xla:0/5 Epoch=99 Step=0 Loss=0.30050 Rate=10.25 GlobalRate=10.25 Time=03:43:02\n",
            "| Training Device=xla:0/6 Epoch=99 Step=0 Loss=0.36498 Rate=10.25 GlobalRate=10.25 Time=03:43:02\n",
            "| Training Device=xla:1/0 Epoch=99 Step=0 Loss=0.30424 Rate=10.25 GlobalRate=10.25 Time=03:43:02\n",
            "Epoch 99 train end 03:43:03\n",
            "Epoch 100 train begin 03:43:03\n",
            "| Training Device=xla:0/6 Epoch=100 Step=0 Loss=0.42456 Rate=10.26 GlobalRate=10.26 Time=03:43:09\n",
            "| Training Device=xla:0/5 Epoch=100 Step=0 Loss=0.25139 Rate=10.26 GlobalRate=10.26 Time=03:43:09\n",
            "| Training Device=xla:0/3 Epoch=100 Step=0 Loss=0.39319 Rate=10.26 GlobalRate=10.26 Time=03:43:09\n",
            "| Training Device=xla:1/0 Epoch=100 Step=0 Loss=0.32428 Rate=10.26 GlobalRate=10.26 Time=03:43:09\n",
            "| Training Device=xla:0/1 Epoch=100 Step=0 Loss=0.27131 Rate=10.26 GlobalRate=10.26 Time=03:43:09\n",
            "| Training Device=xla:0/4 Epoch=100 Step=0 Loss=0.24053 Rate=10.26 GlobalRate=10.26 Time=03:43:09\n",
            "| Training Device=xla:0/2 Epoch=100 Step=0 Loss=0.28020 Rate=10.26 GlobalRate=10.26 Time=03:43:09\n",
            "| Training Device=xla:0/7 Epoch=100 Step=0 Loss=0.29967 Rate=10.25 GlobalRate=10.25 Time=03:43:09\n",
            "Epoch 100 train end 03:43:09\n",
            "Epoch 101 train begin 03:43:09\n",
            "| Training Device=xla:0/5 Epoch=101 Step=0 Loss=0.22793 Rate=10.19 GlobalRate=10.19 Time=03:43:15\n",
            "| Training Device=xla:0/2 Epoch=101 Step=0 Loss=0.24346 Rate=10.19 GlobalRate=10.19 Time=03:43:15\n",
            "| Training Device=xla:0/4 Epoch=101 Step=0 Loss=0.27301 Rate=10.19 GlobalRate=10.19 Time=03:43:15\n",
            "| Training Device=xla:0/6 Epoch=101 Step=0 Loss=0.33401 Rate=10.19 GlobalRate=10.19 Time=03:43:15\n",
            "| Training Device=xla:0/3 Epoch=101 Step=0 Loss=0.42369 Rate=10.19 GlobalRate=10.19 Time=03:43:15\n",
            "| Training Device=xla:0/7 Epoch=101 Step=0 Loss=0.21270 Rate=10.19 GlobalRate=10.19 Time=03:43:15\n",
            "| Training Device=xla:0/1 Epoch=101 Step=0 Loss=0.25820 Rate=10.19 GlobalRate=10.19 Time=03:43:15\n",
            "| Training Device=xla:1/0 Epoch=101 Step=0 Loss=0.34538 Rate=10.19 GlobalRate=10.19 Time=03:43:15\n",
            "Epoch 101 train end 03:43:16\n",
            "Epoch 102 train begin 03:43:16\n",
            "| Training Device=xla:0/5 Epoch=102 Step=0 Loss=0.23075 Rate=10.08 GlobalRate=10.08 Time=03:43:22\n",
            "| Training Device=xla:1/0 Epoch=102 Step=0 Loss=0.28805 Rate=10.09 GlobalRate=10.09 Time=03:43:22\n",
            "| Training Device=xla:0/1 Epoch=102 Step=0 Loss=0.27352 Rate=10.08 GlobalRate=10.08 Time=03:43:22\n",
            "| Training Device=xla:0/2 Epoch=102 Step=0 Loss=0.29499 Rate=10.08 GlobalRate=10.08 Time=03:43:22\n",
            "| Training Device=xla:0/4 Epoch=102 Step=0 Loss=0.29138 Rate=10.08 GlobalRate=10.08 Time=03:43:22\n",
            "| Training Device=xla:0/6 Epoch=102 Step=0 Loss=0.41929 Rate=10.08 GlobalRate=10.08 Time=03:43:22\n",
            "| Training Device=xla:0/7 Epoch=102 Step=0 Loss=0.26658 Rate=10.08 GlobalRate=10.08 Time=03:43:22\n",
            "| Training Device=xla:0/3 Epoch=102 Step=0 Loss=0.33375 Rate=10.08 GlobalRate=10.08 Time=03:43:22\n",
            "Epoch 102 train end 03:43:22\n",
            "Epoch 103 train begin 03:43:22\n",
            "| Training Device=xla:0/2 Epoch=103 Step=0 Loss=0.26575 Rate=10.17 GlobalRate=10.17 Time=03:43:28\n",
            "| Training Device=xla:0/3 Epoch=103 Step=0 Loss=0.37336 Rate=10.16 GlobalRate=10.16 Time=03:43:28\n",
            "| Training Device=xla:0/5 Epoch=103 Step=0 Loss=0.20351 Rate=10.17 GlobalRate=10.17 Time=03:43:28\n",
            "| Training Device=xla:0/7 Epoch=103 Step=0 Loss=0.29042 Rate=10.16 GlobalRate=10.16 Time=03:43:28\n",
            "| Training Device=xla:1/0 Epoch=103 Step=0 Loss=0.31211 Rate=10.17 GlobalRate=10.17 Time=03:43:28\n",
            "| Training Device=xla:0/1 Epoch=103 Step=0 Loss=0.29530 Rate=10.16 GlobalRate=10.16 Time=03:43:28\n",
            "| Training Device=xla:0/4 Epoch=103 Step=0 Loss=0.25317 Rate=10.16 GlobalRate=10.16 Time=03:43:28\n",
            "| Training Device=xla:0/6 Epoch=103 Step=0 Loss=0.32888 Rate=10.16 GlobalRate=10.16 Time=03:43:28\n",
            "Epoch 103 train end 03:43:29\n",
            "Epoch 104 train begin 03:43:29\n",
            "| Training Device=xla:0/6 Epoch=104 Step=0 Loss=0.38314 Rate=10.09 GlobalRate=10.09 Time=03:43:35\n",
            "| Training Device=xla:0/7 Epoch=104 Step=0 Loss=0.29451 Rate=10.09 GlobalRate=10.09 Time=03:43:35\n",
            "| Training Device=xla:0/3 Epoch=104 Step=0 Loss=0.41838 Rate=10.09 GlobalRate=10.09 Time=03:43:35\n",
            "| Training Device=xla:0/1 Epoch=104 Step=0 Loss=0.27000 Rate=10.09 GlobalRate=10.09 Time=03:43:35\n",
            "| Training Device=xla:0/2 Epoch=104 Step=0 Loss=0.23197 Rate=10.09 GlobalRate=10.09 Time=03:43:35\n",
            "| Training Device=xla:0/5 Epoch=104 Step=0 Loss=0.24533 Rate=10.09 GlobalRate=10.09 Time=03:43:35\n",
            "| Training Device=xla:0/4 Epoch=104 Step=0 Loss=0.31632 Rate=10.09 GlobalRate=10.09 Time=03:43:35\n",
            "| Training Device=xla:1/0 Epoch=104 Step=0 Loss=0.31322 Rate=10.10 GlobalRate=10.10 Time=03:43:35\n",
            "Epoch 104 train end 03:43:35\n",
            "Epoch 105 train begin 03:43:35\n",
            "| Training Device=xla:0/2 Epoch=105 Step=0 Loss=0.26615 Rate=10.18 GlobalRate=10.18 Time=03:43:42\n",
            "| Training Device=xla:0/3 Epoch=105 Step=0 Loss=0.33360 Rate=10.18 GlobalRate=10.18 Time=03:43:42\n",
            "| Training Device=xla:0/1 Epoch=105 Step=0 Loss=0.26490 Rate=10.18 GlobalRate=10.18 Time=03:43:42\n",
            "| Training Device=xla:0/5 Epoch=105 Step=0 Loss=0.21667 Rate=10.18 GlobalRate=10.18 Time=03:43:42\n",
            "| Training Device=xla:1/0 Epoch=105 Step=0 Loss=0.30776 Rate=10.18 GlobalRate=10.18 Time=03:43:42\n",
            "| Training Device=xla:0/4 Epoch=105 Step=0 Loss=0.24706 Rate=10.18 GlobalRate=10.18 Time=03:43:42\n",
            "| Training Device=xla:0/7 Epoch=105 Step=0 Loss=0.19501 Rate=10.18 GlobalRate=10.18 Time=03:43:42\n",
            "| Training Device=xla:0/6 Epoch=105 Step=0 Loss=0.32408 Rate=10.18 GlobalRate=10.18 Time=03:43:42\n",
            "Epoch 105 train end 03:43:42\n",
            "Epoch 106 train begin 03:43:42\n",
            "| Training Device=xla:0/5 Epoch=106 Step=0 Loss=0.24068 Rate=10.27 GlobalRate=10.27 Time=03:43:48\n",
            "| Training Device=xla:0/3 Epoch=106 Step=0 Loss=0.32452 Rate=10.27 GlobalRate=10.27 Time=03:43:48\n",
            "| Training Device=xla:0/2 Epoch=106 Step=0 Loss=0.28565 Rate=10.27 GlobalRate=10.27 Time=03:43:48\n",
            "| Training Device=xla:0/6 Epoch=106 Step=0 Loss=0.38123 Rate=10.27 GlobalRate=10.27 Time=03:43:48\n",
            "| Training Device=xla:0/7 Epoch=106 Step=0 Loss=0.26349 Rate=10.27 GlobalRate=10.27 Time=03:43:48\n",
            "| Training Device=xla:0/1 Epoch=106 Step=0 Loss=0.23726 Rate=10.27 GlobalRate=10.27 Time=03:43:48\n",
            "| Training Device=xla:0/4 Epoch=106 Step=0 Loss=0.27987 Rate=10.27 GlobalRate=10.27 Time=03:43:48\n",
            "| Training Device=xla:1/0 Epoch=106 Step=0 Loss=0.35051 Rate=10.27 GlobalRate=10.27 Time=03:43:48\n",
            "Epoch 106 train end 03:43:48\n",
            "Epoch 107 train begin 03:43:48\n",
            "| Training Device=xla:1/0 Epoch=107 Step=0 Loss=0.28425 Rate=10.38 GlobalRate=10.38 Time=03:43:54\n",
            "| Training Device=xla:0/2 Epoch=107 Step=0 Loss=0.26384 Rate=10.38 GlobalRate=10.38 Time=03:43:54\n",
            "| Training Device=xla:0/1 Epoch=107 Step=0 Loss=0.25002 Rate=10.38 GlobalRate=10.38 Time=03:43:54\n",
            "| Training Device=xla:0/5 Epoch=107 Step=0 Loss=0.26617 Rate=10.38 GlobalRate=10.38 Time=03:43:54\n",
            "| Training Device=xla:0/3 Epoch=107 Step=0 Loss=0.40862 Rate=10.38 GlobalRate=10.38 Time=03:43:54\n",
            "| Training Device=xla:0/6 Epoch=107 Step=0 Loss=0.37775 Rate=10.38 GlobalRate=10.38 Time=03:43:54\n",
            "| Training Device=xla:0/4 Epoch=107 Step=0 Loss=0.30162 Rate=10.38 GlobalRate=10.38 Time=03:43:54\n",
            "| Training Device=xla:0/7 Epoch=107 Step=0 Loss=0.30083 Rate=10.38 GlobalRate=10.38 Time=03:43:54\n",
            "Epoch 107 train end 03:43:55\n",
            "Epoch 108 train begin 03:43:55\n",
            "| Training Device=xla:0/2 Epoch=108 Step=0 Loss=0.27651 Rate=10.31 GlobalRate=10.31 Time=03:44:01\n",
            "| Training Device=xla:0/3 Epoch=108 Step=0 Loss=0.39189 Rate=10.30 GlobalRate=10.30 Time=03:44:01\n",
            "| Training Device=xla:0/5 Epoch=108 Step=0 Loss=0.27026 Rate=10.30 GlobalRate=10.30 Time=03:44:01\n",
            "| Training Device=xla:0/6 Epoch=108 Step=0 Loss=0.35186 Rate=10.30 GlobalRate=10.30 Time=03:44:01\n",
            "| Training Device=xla:0/7 Epoch=108 Step=0 Loss=0.25555 Rate=10.30 GlobalRate=10.30 Time=03:44:01\n",
            "| Training Device=xla:0/4 Epoch=108 Step=0 Loss=0.26254 Rate=10.30 GlobalRate=10.30 Time=03:44:01\n",
            "| Training Device=xla:1/0 Epoch=108 Step=0 Loss=0.34874 Rate=10.30 GlobalRate=10.30 Time=03:44:01\n",
            "| Training Device=xla:0/1 Epoch=108 Step=0 Loss=0.32389 Rate=10.30 GlobalRate=10.30 Time=03:44:01\n",
            "Epoch 108 train end 03:44:01\n",
            "Epoch 109 train begin 03:44:01\n",
            "| Training Device=xla:0/3 Epoch=109 Step=0 Loss=0.47806 Rate=10.05 GlobalRate=10.05 Time=03:44:07\n",
            "| Training Device=xla:0/4 Epoch=109 Step=0 Loss=0.25922 Rate=10.05 GlobalRate=10.05 Time=03:44:07\n",
            "| Training Device=xla:0/7 Epoch=109 Step=0 Loss=0.29099 Rate=10.06 GlobalRate=10.06 Time=03:44:07\n",
            "| Training Device=xla:0/2 Epoch=109 Step=0 Loss=0.32125 Rate=10.05 GlobalRate=10.05 Time=03:44:07\n",
            "| Training Device=xla:0/1 Epoch=109 Step=0 Loss=0.29221 Rate=10.05 GlobalRate=10.05 Time=03:44:07\n",
            "| Training Device=xla:0/6 Epoch=109 Step=0 Loss=0.38469 Rate=10.06 GlobalRate=10.06 Time=03:44:07\n",
            "| Training Device=xla:0/5 Epoch=109 Step=0 Loss=0.24879 Rate=10.05 GlobalRate=10.05 Time=03:44:07\n",
            "| Training Device=xla:1/0 Epoch=109 Step=0 Loss=0.34903 Rate=10.06 GlobalRate=10.06 Time=03:44:07\n",
            "Epoch 109 train end 03:44:08\n",
            "Epoch 110 train begin 03:44:08\n",
            "| Training Device=xla:0/3 Epoch=110 Step=0 Loss=0.43261 Rate=10.13 GlobalRate=10.13 Time=03:44:14\n",
            "| Training Device=xla:0/5 Epoch=110 Step=0 Loss=0.29197 Rate=10.13 GlobalRate=10.13 Time=03:44:14\n",
            "| Training Device=xla:0/6 Epoch=110 Step=0 Loss=0.35991 Rate=10.13 GlobalRate=10.13 Time=03:44:14\n",
            "| Training Device=xla:0/4 Epoch=110 Step=0 Loss=0.28145 Rate=10.13 GlobalRate=10.13 Time=03:44:14\n",
            "| Training Device=xla:0/7 Epoch=110 Step=0 Loss=0.28395 Rate=10.13 GlobalRate=10.13 Time=03:44:14\n",
            "| Training Device=xla:0/1 Epoch=110 Step=0 Loss=0.25455 Rate=10.13 GlobalRate=10.13 Time=03:44:14\n",
            "| Training Device=xla:1/0 Epoch=110 Step=0 Loss=0.44440 Rate=10.13 GlobalRate=10.13 Time=03:44:14\n",
            "| Training Device=xla:0/2 Epoch=110 Step=0 Loss=0.26795 Rate=10.13 GlobalRate=10.13 Time=03:44:14\n",
            "Epoch 110 train end 03:44:14\n",
            "Epoch 111 train begin 03:44:14\n",
            "| Training Device=xla:0/1 Epoch=111 Step=0 Loss=0.27293 Rate=10.13 GlobalRate=10.13 Time=03:44:21\n",
            "| Training Device=xla:0/2 Epoch=111 Step=0 Loss=0.28039 Rate=10.12 GlobalRate=10.12 Time=03:44:21\n",
            "| Training Device=xla:0/5 Epoch=111 Step=0 Loss=0.28373 Rate=10.12 GlobalRate=10.12 Time=03:44:21\n",
            "| Training Device=xla:1/0 Epoch=111 Step=0 Loss=0.33566 Rate=10.13 GlobalRate=10.13 Time=03:44:21\n",
            "| Training Device=xla:0/3 Epoch=111 Step=0 Loss=0.42605 Rate=10.13 GlobalRate=10.13 Time=03:44:21\n",
            "| Training Device=xla:0/4 Epoch=111 Step=0 Loss=0.27919 Rate=10.13 GlobalRate=10.13 Time=03:44:21\n",
            "| Training Device=xla:0/6 Epoch=111 Step=0 Loss=0.36226 Rate=10.12 GlobalRate=10.12 Time=03:44:21\n",
            "| Training Device=xla:0/7 Epoch=111 Step=0 Loss=0.28208 Rate=10.12 GlobalRate=10.12 Time=03:44:21\n",
            "Epoch 111 train end 03:44:21\n",
            "Epoch 112 train begin 03:44:21\n",
            "| Training Device=xla:0/7 Epoch=112 Step=0 Loss=0.25808 Rate=10.11 GlobalRate=10.11 Time=03:44:27\n",
            "| Training Device=xla:0/3 Epoch=112 Step=0 Loss=0.45120 Rate=10.11 GlobalRate=10.11 Time=03:44:27\n",
            "| Training Device=xla:0/2 Epoch=112 Step=0 Loss=0.27532 Rate=10.11 GlobalRate=10.11 Time=03:44:27\n",
            "| Training Device=xla:0/5 Epoch=112 Step=0 Loss=0.30088 Rate=10.11 GlobalRate=10.11 Time=03:44:27\n",
            "| Training Device=xla:0/1 Epoch=112 Step=0 Loss=0.28382 Rate=10.11 GlobalRate=10.11 Time=03:44:27\n",
            "| Training Device=xla:0/6 Epoch=112 Step=0 Loss=0.33744 Rate=10.11 GlobalRate=10.11 Time=03:44:27\n",
            "| Training Device=xla:0/4 Epoch=112 Step=0 Loss=0.29495 Rate=10.10 GlobalRate=10.10 Time=03:44:27\n",
            "| Training Device=xla:1/0 Epoch=112 Step=0 Loss=0.30850 Rate=10.11 GlobalRate=10.11 Time=03:44:27\n",
            "Epoch 112 train end 03:44:27\n",
            "Epoch 113 train begin 03:44:27\n",
            "| Training Device=xla:0/5 Epoch=113 Step=0 Loss=0.24982 Rate=10.17 GlobalRate=10.17 Time=03:44:34\n",
            "| Training Device=xla:0/2 Epoch=113 Step=0 Loss=0.26271 Rate=10.17 GlobalRate=10.17 Time=03:44:34\n",
            "| Training Device=xla:0/7 Epoch=113 Step=0 Loss=0.30804 Rate=10.17 GlobalRate=10.17 Time=03:44:34\n",
            "| Training Device=xla:0/3 Epoch=113 Step=0 Loss=0.39663 Rate=10.17 GlobalRate=10.17 Time=03:44:34\n",
            "| Training Device=xla:0/1 Epoch=113 Step=0 Loss=0.27737 Rate=10.17 GlobalRate=10.17 Time=03:44:34\n",
            "| Training Device=xla:0/4 Epoch=113 Step=0 Loss=0.27497 Rate=10.17 GlobalRate=10.17 Time=03:44:34\n",
            "| Training Device=xla:0/6 Epoch=113 Step=0 Loss=0.36362 Rate=10.17 GlobalRate=10.17 Time=03:44:34\n",
            "| Training Device=xla:1/0 Epoch=113 Step=0 Loss=0.34700 Rate=10.17 GlobalRate=10.17 Time=03:44:34\n",
            "Epoch 113 train end 03:44:34\n",
            "Epoch 114 train begin 03:44:34\n",
            "| Training Device=xla:0/4 Epoch=114 Step=0 Loss=0.23922 Rate=10.31 GlobalRate=10.31 Time=03:44:40\n",
            "| Training Device=xla:0/3 Epoch=114 Step=0 Loss=0.37514 Rate=10.31 GlobalRate=10.31 Time=03:44:40\n",
            "| Training Device=xla:1/0 Epoch=114 Step=0 Loss=0.31708 Rate=10.32 GlobalRate=10.32 Time=03:44:40\n",
            "| Training Device=xla:0/2 Epoch=114 Step=0 Loss=0.24567 Rate=10.31 GlobalRate=10.31 Time=03:44:40\n",
            "| Training Device=xla:0/6 Epoch=114 Step=0 Loss=0.34414 Rate=10.31 GlobalRate=10.31 Time=03:44:40\n",
            "| Training Device=xla:0/1 Epoch=114 Step=0 Loss=0.25380 Rate=10.31 GlobalRate=10.31 Time=03:44:40\n",
            "| Training Device=xla:0/7 Epoch=114 Step=0 Loss=0.26904 Rate=10.31 GlobalRate=10.31 Time=03:44:40\n",
            "| Training Device=xla:0/5 Epoch=114 Step=0 Loss=0.25102 Rate=10.31 GlobalRate=10.31 Time=03:44:40\n",
            "Epoch 114 train end 03:44:40\n",
            "Epoch 115 train begin 03:44:40\n",
            "| Training Device=xla:0/6 Epoch=115 Step=0 Loss=0.32268 Rate=10.34 GlobalRate=10.34 Time=03:44:47\n",
            "| Training Device=xla:0/2 Epoch=115 Step=0 Loss=0.26391 Rate=10.34 GlobalRate=10.34 Time=03:44:47\n",
            "| Training Device=xla:0/7 Epoch=115 Step=0 Loss=0.25948 Rate=10.34 GlobalRate=10.34 Time=03:44:47\n",
            "| Training Device=xla:0/1 Epoch=115 Step=0 Loss=0.24224 Rate=10.34 GlobalRate=10.34 Time=03:44:47\n",
            "| Training Device=xla:0/4 Epoch=115 Step=0 Loss=0.24569 Rate=10.34 GlobalRate=10.34 Time=03:44:47\n",
            "| Training Device=xla:1/0 Epoch=115 Step=0 Loss=0.33926 Rate=10.34 GlobalRate=10.34 Time=03:44:47\n",
            "| Training Device=xla:0/3 Epoch=115 Step=0 Loss=0.32004 Rate=10.34 GlobalRate=10.34 Time=03:44:47\n",
            "| Training Device=xla:0/5 Epoch=115 Step=0 Loss=0.28098 Rate=10.34 GlobalRate=10.34 Time=03:44:47\n",
            "Epoch 115 train end 03:44:47\n",
            "Epoch 116 train begin 03:44:47\n",
            "| Training Device=xla:0/4 Epoch=116 Step=0 Loss=0.24282 Rate=10.21 GlobalRate=10.21 Time=03:44:53\n",
            "| Training Device=xla:0/1 Epoch=116 Step=0 Loss=0.29905 Rate=10.21 GlobalRate=10.21 Time=03:44:53\n",
            "| Training Device=xla:0/6 Epoch=116 Step=0 Loss=0.38548 Rate=10.21 GlobalRate=10.21 Time=03:44:53\n",
            "| Training Device=xla:0/2 Epoch=116 Step=0 Loss=0.28614 Rate=10.21 GlobalRate=10.21 Time=03:44:53\n",
            "| Training Device=xla:0/5 Epoch=116 Step=0 Loss=0.28583 Rate=10.21 GlobalRate=10.21 Time=03:44:53\n",
            "| Training Device=xla:1/0 Epoch=116 Step=0 Loss=0.36470 Rate=10.21 GlobalRate=10.21 Time=03:44:53\n",
            "| Training Device=xla:0/7 Epoch=116 Step=0 Loss=0.26076 Rate=10.21 GlobalRate=10.21 Time=03:44:53\n",
            "| Training Device=xla:0/3 Epoch=116 Step=0 Loss=0.38241 Rate=10.21 GlobalRate=10.21 Time=03:44:53\n",
            "Epoch 116 train end 03:44:53\n",
            "Epoch 117 train begin 03:44:53\n",
            "| Training Device=xla:1/0 Epoch=117 Step=0 Loss=0.31208 Rate=10.22 GlobalRate=10.22 Time=03:45:00\n",
            "| Training Device=xla:0/3 Epoch=117 Step=0 Loss=0.41867 Rate=10.22 GlobalRate=10.22 Time=03:45:00\n",
            "| Training Device=xla:0/1 Epoch=117 Step=0 Loss=0.22350 Rate=10.21 GlobalRate=10.21 Time=03:45:00\n",
            "| Training Device=xla:0/2 Epoch=117 Step=0 Loss=0.29573 Rate=10.22 GlobalRate=10.22 Time=03:45:00\n",
            "| Training Device=xla:0/5 Epoch=117 Step=0 Loss=0.30781 Rate=10.22 GlobalRate=10.22 Time=03:45:00\n",
            "| Training Device=xla:0/7 Epoch=117 Step=0 Loss=0.28634 Rate=10.22 GlobalRate=10.22 Time=03:45:00\n",
            "| Training Device=xla:0/6 Epoch=117 Step=0 Loss=0.34799 Rate=10.22 GlobalRate=10.22 Time=03:45:00\n",
            "| Training Device=xla:0/4 Epoch=117 Step=0 Loss=0.21925 Rate=10.22 GlobalRate=10.22 Time=03:45:00\n",
            "Epoch 117 train end 03:45:00\n",
            "Epoch 118 train begin 03:45:00\n",
            "| Training Device=xla:1/0 Epoch=118 Step=0 Loss=0.30379 Rate=10.26 GlobalRate=10.26 Time=03:45:06\n",
            "| Training Device=xla:0/2 Epoch=118 Step=0 Loss=0.28817 Rate=10.25 GlobalRate=10.25 Time=03:45:06\n",
            "| Training Device=xla:0/1 Epoch=118 Step=0 Loss=0.28497 Rate=10.25 GlobalRate=10.25 Time=03:45:06\n",
            "| Training Device=xla:0/5 Epoch=118 Step=0 Loss=0.25469 Rate=10.25 GlobalRate=10.25 Time=03:45:06\n",
            "| Training Device=xla:0/4 Epoch=118 Step=0 Loss=0.28556 Rate=10.25 GlobalRate=10.25 Time=03:45:06\n",
            "| Training Device=xla:0/6 Epoch=118 Step=0 Loss=0.39052 Rate=10.25 GlobalRate=10.25 Time=03:45:06\n",
            "| Training Device=xla:0/7 Epoch=118 Step=0 Loss=0.30005 Rate=10.25 GlobalRate=10.25 Time=03:45:06\n",
            "| Training Device=xla:0/3 Epoch=118 Step=0 Loss=0.37087 Rate=10.25 GlobalRate=10.25 Time=03:45:06\n",
            "Epoch 118 train end 03:45:06\n",
            "Epoch 119 train begin 03:45:06\n",
            "| Training Device=xla:0/4 Epoch=119 Step=0 Loss=0.24610 Rate=10.25 GlobalRate=10.25 Time=03:45:13\n",
            "| Training Device=xla:0/3 Epoch=119 Step=0 Loss=0.34591 Rate=10.24 GlobalRate=10.24 Time=03:45:13\n",
            "| Training Device=xla:0/5 Epoch=119 Step=0 Loss=0.26376 Rate=10.24 GlobalRate=10.24 Time=03:45:13\n",
            "| Training Device=xla:1/0 Epoch=119 Step=0 Loss=0.35431 Rate=10.25 GlobalRate=10.25 Time=03:45:13\n",
            "| Training Device=xla:0/7 Epoch=119 Step=0 Loss=0.30078 Rate=10.24 GlobalRate=10.24 Time=03:45:13\n",
            "| Training Device=xla:0/2 Epoch=119 Step=0 Loss=0.22077 Rate=10.24 GlobalRate=10.24 Time=03:45:13\n",
            "| Training Device=xla:0/1 Epoch=119 Step=0 Loss=0.25011 Rate=10.24 GlobalRate=10.24 Time=03:45:13\n",
            "| Training Device=xla:0/6 Epoch=119 Step=0 Loss=0.34595 Rate=10.24 GlobalRate=10.24 Time=03:45:13\n",
            "Epoch 119 train end 03:45:13\n",
            "Epoch 120 train begin 03:45:13\n",
            "| Training Device=xla:0/6 Epoch=120 Step=0 Loss=0.31997 Rate=10.13 GlobalRate=10.13 Time=03:45:19\n",
            "| Training Device=xla:0/3 Epoch=120 Step=0 Loss=0.34668 Rate=10.13 GlobalRate=10.13 Time=03:45:19\n",
            "| Training Device=xla:0/4 Epoch=120 Step=0 Loss=0.29991 Rate=10.13 GlobalRate=10.13 Time=03:45:19\n",
            "| Training Device=xla:0/5 Epoch=120 Step=0 Loss=0.29115 Rate=10.13 GlobalRate=10.13 Time=03:45:19\n",
            "| Training Device=xla:1/0 Epoch=120 Step=0 Loss=0.38687 Rate=10.14 GlobalRate=10.14 Time=03:45:19\n",
            "| Training Device=xla:0/7 Epoch=120 Step=0 Loss=0.30449 Rate=10.13 GlobalRate=10.13 Time=03:45:19\n",
            "| Training Device=xla:0/1 Epoch=120 Step=0 Loss=0.26648 Rate=10.13 GlobalRate=10.13 Time=03:45:19\n",
            "| Training Device=xla:0/2 Epoch=120 Step=0 Loss=0.30533 Rate=10.13 GlobalRate=10.13 Time=03:45:19\n",
            "Epoch 120 train end 03:45:19\n",
            "Epoch 121 train begin 03:45:19\n",
            "| Training Device=xla:0/3 Epoch=121 Step=0 Loss=0.36727 Rate=10.34 GlobalRate=10.34 Time=03:45:26\n",
            "| Training Device=xla:0/6 Epoch=121 Step=0 Loss=0.36399 Rate=10.34 GlobalRate=10.34 Time=03:45:26\n",
            "| Training Device=xla:0/5 Epoch=121 Step=0 Loss=0.31719 Rate=10.33 GlobalRate=10.33 Time=03:45:26\n",
            "| Training Device=xla:1/0 Epoch=121 Step=0 Loss=0.32184 Rate=10.34 GlobalRate=10.34 Time=03:45:26\n",
            "| Training Device=xla:0/7 Epoch=121 Step=0 Loss=0.30001 Rate=10.33 GlobalRate=10.33 Time=03:45:26\n",
            "| Training Device=xla:0/4 Epoch=121 Step=0 Loss=0.30508 Rate=10.33 GlobalRate=10.33 Time=03:45:26\n",
            "| Training Device=xla:0/2 Epoch=121 Step=0 Loss=0.35080 Rate=10.33 GlobalRate=10.33 Time=03:45:26\n",
            "| Training Device=xla:0/1 Epoch=121 Step=0 Loss=0.28363 Rate=10.33 GlobalRate=10.33 Time=03:45:26\n",
            "Epoch 121 train end 03:45:26\n",
            "Epoch 122 train begin 03:45:26\n",
            "| Training Device=xla:0/1 Epoch=122 Step=0 Loss=0.28967 Rate=10.31 GlobalRate=10.31 Time=03:45:32\n",
            "| Training Device=xla:0/4 Epoch=122 Step=0 Loss=0.25962 Rate=10.31 GlobalRate=10.31 Time=03:45:32\n",
            "| Training Device=xla:0/6 Epoch=122 Step=0 Loss=0.39210 Rate=10.30 GlobalRate=10.30 Time=03:45:32\n",
            "| Training Device=xla:0/3 Epoch=122 Step=0 Loss=0.41639 Rate=10.30 GlobalRate=10.30 Time=03:45:32\n",
            "| Training Device=xla:0/2 Epoch=122 Step=0 Loss=0.27149 Rate=10.30 GlobalRate=10.30 Time=03:45:32\n",
            "| Training Device=xla:0/5 Epoch=122 Step=0 Loss=0.27223 Rate=10.30 GlobalRate=10.30 Time=03:45:32\n",
            "| Training Device=xla:0/7 Epoch=122 Step=0 Loss=0.26605 Rate=10.30 GlobalRate=10.30 Time=03:45:32\n",
            "| Training Device=xla:1/0 Epoch=122 Step=0 Loss=0.30033 Rate=10.31 GlobalRate=10.31 Time=03:45:32\n",
            "Epoch 122 train end 03:45:32\n",
            "Epoch 123 train begin 03:45:32\n",
            "| Training Device=xla:0/6 Epoch=123 Step=0 Loss=0.29755 Rate=10.23 GlobalRate=10.23 Time=03:45:38\n",
            "| Training Device=xla:0/4 Epoch=123 Step=0 Loss=0.26516 Rate=10.23 GlobalRate=10.23 Time=03:45:38\n",
            "| Training Device=xla:0/3 Epoch=123 Step=0 Loss=0.34497 Rate=10.23 GlobalRate=10.23 Time=03:45:38\n",
            "| Training Device=xla:0/1 Epoch=123 Step=0 Loss=0.23046 Rate=10.23 GlobalRate=10.23 Time=03:45:38\n",
            "| Training Device=xla:1/0 Epoch=123 Step=0 Loss=0.28005 Rate=10.24 GlobalRate=10.24 Time=03:45:38\n",
            "| Training Device=xla:0/5 Epoch=123 Step=0 Loss=0.26823 Rate=10.23 GlobalRate=10.23 Time=03:45:38\n",
            "| Training Device=xla:0/7 Epoch=123 Step=0 Loss=0.25100 Rate=10.23 GlobalRate=10.23 Time=03:45:38\n",
            "| Training Device=xla:0/2 Epoch=123 Step=0 Loss=0.28963 Rate=10.23 GlobalRate=10.23 Time=03:45:38\n",
            "Epoch 123 train end 03:45:39\n",
            "Epoch 124 train begin 03:45:39\n",
            "| Training Device=xla:0/1 Epoch=124 Step=0 Loss=0.26831 Rate=10.33 GlobalRate=10.33 Time=03:45:45\n",
            "| Training Device=xla:0/3 Epoch=124 Step=0 Loss=0.36943 Rate=10.33 GlobalRate=10.33 Time=03:45:45\n",
            "| Training Device=xla:0/5 Epoch=124 Step=0 Loss=0.29585 Rate=10.33 GlobalRate=10.33 Time=03:45:45\n",
            "| Training Device=xla:0/6 Epoch=124 Step=0 Loss=0.34393 Rate=10.33 GlobalRate=10.33 Time=03:45:45\n",
            "| Training Device=xla:0/7 Epoch=124 Step=0 Loss=0.25698 Rate=10.33 GlobalRate=10.33 Time=03:45:45\n",
            "| Training Device=xla:0/4 Epoch=124 Step=0 Loss=0.25962 Rate=10.33 GlobalRate=10.33 Time=03:45:45\n",
            "| Training Device=xla:0/2 Epoch=124 Step=0 Loss=0.32511 Rate=10.33 GlobalRate=10.33 Time=03:45:45\n",
            "| Training Device=xla:1/0 Epoch=124 Step=0 Loss=0.31892 Rate=10.33 GlobalRate=10.33 Time=03:45:45\n",
            "Epoch 124 train end 03:45:45\n",
            "Epoch 125 train begin 03:45:45\n",
            "| Training Device=xla:1/0 Epoch=125 Step=0 Loss=0.29389 Rate=10.33 GlobalRate=10.33 Time=03:45:51\n",
            "| Training Device=xla:0/5 Epoch=125 Step=0 Loss=0.28442 Rate=10.33 GlobalRate=10.33 Time=03:45:51\n",
            "| Training Device=xla:0/7 Epoch=125 Step=0 Loss=0.30451 Rate=10.33 GlobalRate=10.33 Time=03:45:51\n",
            "| Training Device=xla:0/3 Epoch=125 Step=0 Loss=0.44006 Rate=10.33 GlobalRate=10.33 Time=03:45:51\n",
            "| Training Device=xla:0/1 Epoch=125 Step=0 Loss=0.25145 Rate=10.33 GlobalRate=10.33 Time=03:45:51\n",
            "| Training Device=xla:0/4 Epoch=125 Step=0 Loss=0.23522 Rate=10.33 GlobalRate=10.33 Time=03:45:51\n",
            "| Training Device=xla:0/6 Epoch=125 Step=0 Loss=0.32669 Rate=10.33 GlobalRate=10.33 Time=03:45:51\n",
            "| Training Device=xla:0/2 Epoch=125 Step=0 Loss=0.32008 Rate=10.33 GlobalRate=10.33 Time=03:45:51\n",
            "Epoch 125 train end 03:45:52\n",
            "Epoch 126 train begin 03:45:52\n",
            "| Training Device=xla:0/6 Epoch=126 Step=0 Loss=0.37564 Rate=10.34 GlobalRate=10.34 Time=03:45:58\n",
            "| Training Device=xla:0/2 Epoch=126 Step=0 Loss=0.28094 Rate=10.34 GlobalRate=10.34 Time=03:45:58\n",
            "| Training Device=xla:0/5 Epoch=126 Step=0 Loss=0.25070 Rate=10.34 GlobalRate=10.34 Time=03:45:58\n",
            "| Training Device=xla:0/4 Epoch=126 Step=0 Loss=0.25355 Rate=10.34 GlobalRate=10.34 Time=03:45:58\n",
            "| Training Device=xla:0/3 Epoch=126 Step=0 Loss=0.31388 Rate=10.34 GlobalRate=10.34 Time=03:45:58\n",
            "| Training Device=xla:0/1 Epoch=126 Step=0 Loss=0.28610 Rate=10.34 GlobalRate=10.34 Time=03:45:58\n",
            "| Training Device=xla:0/7 Epoch=126 Step=0 Loss=0.23306 Rate=10.34 GlobalRate=10.34 Time=03:45:58\n",
            "| Training Device=xla:1/0 Epoch=126 Step=0 Loss=0.34417 Rate=10.34 GlobalRate=10.34 Time=03:45:58\n",
            "Epoch 126 train end 03:45:58\n",
            "Epoch 127 train begin 03:45:58\n",
            "| Training Device=xla:0/2 Epoch=127 Step=0 Loss=0.32287 Rate=10.34 GlobalRate=10.34 Time=03:46:04\n",
            "| Training Device=xla:0/4 Epoch=127 Step=0 Loss=0.28368 Rate=10.34 GlobalRate=10.34 Time=03:46:04\n",
            "| Training Device=xla:0/6 Epoch=127 Step=0 Loss=0.42885 Rate=10.34 GlobalRate=10.34 Time=03:46:04\n",
            "| Training Device=xla:0/5 Epoch=127 Step=0 Loss=0.27754 Rate=10.34 GlobalRate=10.34 Time=03:46:04\n",
            "| Training Device=xla:0/7 Epoch=127 Step=0 Loss=0.27776 Rate=10.33 GlobalRate=10.33 Time=03:46:04\n",
            "| Training Device=xla:0/3 Epoch=127 Step=0 Loss=0.37500 Rate=10.34 GlobalRate=10.34 Time=03:46:04\n",
            "| Training Device=xla:0/1 Epoch=127 Step=0 Loss=0.29622 Rate=10.34 GlobalRate=10.34 Time=03:46:04\n",
            "| Training Device=xla:1/0 Epoch=127 Step=0 Loss=0.34319 Rate=10.34 GlobalRate=10.34 Time=03:46:04\n",
            "Epoch 127 train end 03:46:04\n",
            "Epoch 128 train begin 03:46:04\n",
            "| Training Device=xla:0/7 Epoch=128 Step=0 Loss=0.24441 Rate=10.38 GlobalRate=10.38 Time=03:46:11\n",
            "| Training Device=xla:0/5 Epoch=128 Step=0 Loss=0.26750 Rate=10.38 GlobalRate=10.38 Time=03:46:11\n",
            "| Training Device=xla:0/4 Epoch=128 Step=0 Loss=0.27285 Rate=10.38 GlobalRate=10.38 Time=03:46:11\n",
            "| Training Device=xla:0/1 Epoch=128 Step=0 Loss=0.27425 Rate=10.38 GlobalRate=10.38 Time=03:46:11\n",
            "| Training Device=xla:0/2 Epoch=128 Step=0 Loss=0.29566 Rate=10.38 GlobalRate=10.38 Time=03:46:11\n",
            "| Training Device=xla:0/3 Epoch=128 Step=0 Loss=0.36855 Rate=10.38 GlobalRate=10.38 Time=03:46:11\n",
            "| Training Device=xla:0/6 Epoch=128 Step=0 Loss=0.33819 Rate=10.38 GlobalRate=10.38 Time=03:46:11\n",
            "| Training Device=xla:1/0 Epoch=128 Step=0 Loss=0.33958 Rate=10.38 GlobalRate=10.38 Time=03:46:11\n",
            "Epoch 128 train end 03:46:11\n",
            "Epoch 129 train begin 03:46:11\n",
            "| Training Device=xla:0/2 Epoch=129 Step=0 Loss=0.30884 Rate=10.32 GlobalRate=10.32 Time=03:46:17\n",
            "| Training Device=xla:1/0 Epoch=129 Step=0 Loss=0.35079 Rate=10.33 GlobalRate=10.33 Time=03:46:17\n",
            "| Training Device=xla:0/3 Epoch=129 Step=0 Loss=0.35881 Rate=10.32 GlobalRate=10.32 Time=03:46:17\n",
            "| Training Device=xla:0/1 Epoch=129 Step=0 Loss=0.25196 Rate=10.32 GlobalRate=10.32 Time=03:46:17\n",
            "| Training Device=xla:0/6 Epoch=129 Step=0 Loss=0.32753 Rate=10.32 GlobalRate=10.32 Time=03:46:17\n",
            "| Training Device=xla:0/5 Epoch=129 Step=0 Loss=0.23275 Rate=10.32 GlobalRate=10.32 Time=03:46:17\n",
            "| Training Device=xla:0/4 Epoch=129 Step=0 Loss=0.33340 Rate=10.32 GlobalRate=10.32 Time=03:46:17\n",
            "| Training Device=xla:0/7 Epoch=129 Step=0 Loss=0.25514 Rate=10.32 GlobalRate=10.32 Time=03:46:17\n",
            "Epoch 129 train end 03:46:17\n",
            "Epoch 130 train begin 03:46:17\n",
            "| Training Device=xla:0/2 Epoch=130 Step=0 Loss=0.23611 Rate=10.36 GlobalRate=10.36 Time=03:46:23\n",
            "| Training Device=xla:0/5 Epoch=130 Step=0 Loss=0.24763 Rate=10.36 GlobalRate=10.36 Time=03:46:23\n",
            "| Training Device=xla:0/7 Epoch=130 Step=0 Loss=0.21185 Rate=10.36 GlobalRate=10.36 Time=03:46:23\n",
            "| Training Device=xla:0/6 Epoch=130 Step=0 Loss=0.35675 Rate=10.36 GlobalRate=10.36 Time=03:46:23\n",
            "| Training Device=xla:1/0 Epoch=130 Step=0 Loss=0.34867 Rate=10.36 GlobalRate=10.36 Time=03:46:23\n",
            "| Training Device=xla:0/4 Epoch=130 Step=0 Loss=0.30686 Rate=10.36 GlobalRate=10.36 Time=03:46:23\n",
            "| Training Device=xla:0/3 Epoch=130 Step=0 Loss=0.37375 Rate=10.36 GlobalRate=10.36 Time=03:46:23\n",
            "| Training Device=xla:0/1 Epoch=130 Step=0 Loss=0.26370 Rate=10.36 GlobalRate=10.36 Time=03:46:23\n",
            "Epoch 130 train end 03:46:24\n",
            "Epoch 131 train begin 03:46:24\n",
            "| Training Device=xla:0/4 Epoch=131 Step=0 Loss=0.29605 Rate=10.38 GlobalRate=10.38 Time=03:46:30\n",
            "| Training Device=xla:0/5 Epoch=131 Step=0 Loss=0.23062 Rate=10.38 GlobalRate=10.38 Time=03:46:30\n",
            "| Training Device=xla:0/7 Epoch=131 Step=0 Loss=0.21418 Rate=10.38 GlobalRate=10.38 Time=03:46:30\n",
            "| Training Device=xla:0/3 Epoch=131 Step=0 Loss=0.39904 Rate=10.38 GlobalRate=10.38 Time=03:46:30\n",
            "| Training Device=xla:0/1 Epoch=131 Step=0 Loss=0.23838 Rate=10.38 GlobalRate=10.38 Time=03:46:30\n",
            "| Training Device=xla:0/6 Epoch=131 Step=0 Loss=0.33107 Rate=10.38 GlobalRate=10.38 Time=03:46:30\n",
            "| Training Device=xla:0/2 Epoch=131 Step=0 Loss=0.30178 Rate=10.38 GlobalRate=10.38 Time=03:46:30\n",
            "| Training Device=xla:1/0 Epoch=131 Step=0 Loss=0.34381 Rate=10.38 GlobalRate=10.38 Time=03:46:30\n",
            "Epoch 131 train end 03:46:30\n",
            "Epoch 132 train begin 03:46:30\n",
            "| Training Device=xla:0/6 Epoch=132 Step=0 Loss=0.35049 Rate=10.39 GlobalRate=10.39 Time=03:46:36\n",
            "| Training Device=xla:1/0 Epoch=132 Step=0 Loss=0.38854 Rate=10.40 GlobalRate=10.40 Time=03:46:36\n",
            "| Training Device=xla:0/2 Epoch=132 Step=0 Loss=0.23439 Rate=10.39 GlobalRate=10.39 Time=03:46:36\n",
            "| Training Device=xla:0/5 Epoch=132 Step=0 Loss=0.20173 Rate=10.39 GlobalRate=10.39 Time=03:46:36\n",
            "| Training Device=xla:0/7 Epoch=132 Step=0 Loss=0.25803 Rate=10.39 GlobalRate=10.39 Time=03:46:36\n",
            "| Training Device=xla:0/4 Epoch=132 Step=0 Loss=0.26103 Rate=10.39 GlobalRate=10.39 Time=03:46:36\n",
            "| Training Device=xla:0/1 Epoch=132 Step=0 Loss=0.26382 Rate=10.39 GlobalRate=10.39 Time=03:46:36\n",
            "| Training Device=xla:0/3 Epoch=132 Step=0 Loss=0.35593 Rate=10.39 GlobalRate=10.39 Time=03:46:36\n",
            "Epoch 132 train end 03:46:36\n",
            "Epoch 133 train begin 03:46:36\n",
            "| Training Device=xla:0/5 Epoch=133 Step=0 Loss=0.28528 Rate=10.40 GlobalRate=10.40 Time=03:46:43\n",
            "| Training Device=xla:0/3 Epoch=133 Step=0 Loss=0.38763 Rate=10.40 GlobalRate=10.40 Time=03:46:43\n",
            "| Training Device=xla:0/1 Epoch=133 Step=0 Loss=0.27307 Rate=10.39 GlobalRate=10.39 Time=03:46:43\n",
            "| Training Device=xla:0/2 Epoch=133 Step=0 Loss=0.30648 Rate=10.40 GlobalRate=10.40 Time=03:46:43\n",
            "| Training Device=xla:0/4 Epoch=133 Step=0 Loss=0.27622 Rate=10.40 GlobalRate=10.40 Time=03:46:43\n",
            "| Training Device=xla:0/7 Epoch=133 Step=0 Loss=0.27391 Rate=10.40 GlobalRate=10.40 Time=03:46:43\n",
            "| Training Device=xla:0/6 Epoch=133 Step=0 Loss=0.48786 Rate=10.40 GlobalRate=10.40 Time=03:46:43\n",
            "| Training Device=xla:1/0 Epoch=133 Step=0 Loss=0.31921 Rate=10.40 GlobalRate=10.40 Time=03:46:43\n",
            "Epoch 133 train end 03:46:43\n",
            "Epoch 134 train begin 03:46:43\n",
            "| Training Device=xla:0/4 Epoch=134 Step=0 Loss=0.28912 Rate=10.31 GlobalRate=10.31 Time=03:46:49\n",
            "| Training Device=xla:0/6 Epoch=134 Step=0 Loss=0.35478 Rate=10.31 GlobalRate=10.31 Time=03:46:49\n",
            "| Training Device=xla:0/5 Epoch=134 Step=0 Loss=0.24214 Rate=10.31 GlobalRate=10.31 Time=03:46:49\n",
            "| Training Device=xla:1/0 Epoch=134 Step=0 Loss=0.34489 Rate=10.32 GlobalRate=10.32 Time=03:46:49\n",
            "| Training Device=xla:0/2 Epoch=134 Step=0 Loss=0.26565 Rate=10.31 GlobalRate=10.31 Time=03:46:49\n",
            "| Training Device=xla:0/3 Epoch=134 Step=0 Loss=0.44824 Rate=10.31 GlobalRate=10.31 Time=03:46:49\n",
            "| Training Device=xla:0/7 Epoch=134 Step=0 Loss=0.27889 Rate=10.31 GlobalRate=10.31 Time=03:46:49\n",
            "| Training Device=xla:0/1 Epoch=134 Step=0 Loss=0.30619 Rate=10.31 GlobalRate=10.31 Time=03:46:49\n",
            "Epoch 134 train end 03:46:49\n",
            "Epoch 135 train begin 03:46:49\n",
            "| Training Device=xla:0/3 Epoch=135 Step=0 Loss=0.38746 Rate=10.25 GlobalRate=10.25 Time=03:46:56\n",
            "| Training Device=xla:0/4 Epoch=135 Step=0 Loss=0.29514 Rate=10.25 GlobalRate=10.25 Time=03:46:56\n",
            "| Training Device=xla:0/1 Epoch=135 Step=0 Loss=0.33442 Rate=10.25 GlobalRate=10.25 Time=03:46:56\n",
            "| Training Device=xla:1/0 Epoch=135 Step=0 Loss=0.32348 Rate=10.26 GlobalRate=10.26 Time=03:46:56\n",
            "| Training Device=xla:0/7 Epoch=135 Step=0 Loss=0.25200 Rate=10.25 GlobalRate=10.25 Time=03:46:56\n",
            "| Training Device=xla:0/5 Epoch=135 Step=0 Loss=0.25092 Rate=10.25 GlobalRate=10.25 Time=03:46:56\n",
            "| Training Device=xla:0/2 Epoch=135 Step=0 Loss=0.27190 Rate=10.25 GlobalRate=10.25 Time=03:46:56\n",
            "| Training Device=xla:0/6 Epoch=135 Step=0 Loss=0.34252 Rate=10.25 GlobalRate=10.25 Time=03:46:56\n",
            "Epoch 135 train end 03:46:56\n",
            "Epoch 136 train begin 03:46:56\n",
            "| Training Device=xla:0/5 Epoch=136 Step=0 Loss=0.30254 Rate=10.26 GlobalRate=10.26 Time=03:47:02\n",
            "| Training Device=xla:0/6 Epoch=136 Step=0 Loss=0.35283 Rate=10.26 GlobalRate=10.26 Time=03:47:02\n",
            "| Training Device=xla:0/2 Epoch=136 Step=0 Loss=0.28040 Rate=10.26 GlobalRate=10.26 Time=03:47:02\n",
            "| Training Device=xla:0/1 Epoch=136 Step=0 Loss=0.30938 Rate=10.26 GlobalRate=10.26 Time=03:47:02\n",
            "| Training Device=xla:0/3 Epoch=136 Step=0 Loss=0.36047 Rate=10.26 GlobalRate=10.26 Time=03:47:02\n",
            "| Training Device=xla:0/4 Epoch=136 Step=0 Loss=0.26826 Rate=10.26 GlobalRate=10.26 Time=03:47:02\n",
            "| Training Device=xla:0/7 Epoch=136 Step=0 Loss=0.28764 Rate=10.26 GlobalRate=10.26 Time=03:47:02\n",
            "| Training Device=xla:1/0 Epoch=136 Step=0 Loss=0.36386 Rate=10.26 GlobalRate=10.26 Time=03:47:02\n",
            "Epoch 136 train end 03:47:02\n",
            "Epoch 137 train begin 03:47:02\n",
            "| Training Device=xla:0/6 Epoch=137 Step=0 Loss=0.32665 Rate=10.29 GlobalRate=10.29 Time=03:47:08\n",
            "| Training Device=xla:0/5 Epoch=137 Step=0 Loss=0.26798 Rate=10.29 GlobalRate=10.29 Time=03:47:08\n",
            "| Training Device=xla:1/0 Epoch=137 Step=0 Loss=0.33298 Rate=10.30 GlobalRate=10.30 Time=03:47:08\n",
            "| Training Device=xla:0/7 Epoch=137 Step=0 Loss=0.27662 Rate=10.29 GlobalRate=10.29 Time=03:47:08\n",
            "| Training Device=xla:0/4 Epoch=137 Step=0 Loss=0.23343 Rate=10.29 GlobalRate=10.29 Time=03:47:08\n",
            "| Training Device=xla:0/1 Epoch=137 Step=0 Loss=0.25565 Rate=10.29 GlobalRate=10.29 Time=03:47:08\n",
            "| Training Device=xla:0/3 Epoch=137 Step=0 Loss=0.39642 Rate=10.29 GlobalRate=10.29 Time=03:47:08\n",
            "| Training Device=xla:0/2 Epoch=137 Step=0 Loss=0.22485 Rate=10.29 GlobalRate=10.29 Time=03:47:08\n",
            "Epoch 137 train end 03:47:09\n",
            "Epoch 138 train begin 03:47:09\n",
            "| Training Device=xla:1/0 Epoch=138 Step=0 Loss=0.31872 Rate=10.31 GlobalRate=10.31 Time=03:47:15\n",
            "| Training Device=xla:0/3 Epoch=138 Step=0 Loss=0.34586 Rate=10.31 GlobalRate=10.31 Time=03:47:15\n",
            "| Training Device=xla:0/4 Epoch=138 Step=0 Loss=0.26299 Rate=10.31 GlobalRate=10.31 Time=03:47:15\n",
            "| Training Device=xla:0/1 Epoch=138 Step=0 Loss=0.24372 Rate=10.31 GlobalRate=10.31 Time=03:47:15\n",
            "| Training Device=xla:0/6 Epoch=138 Step=0 Loss=0.38070 Rate=10.30 GlobalRate=10.30 Time=03:47:15\n",
            "| Training Device=xla:0/5 Epoch=138 Step=0 Loss=0.25859 Rate=10.30 GlobalRate=10.30 Time=03:47:15\n",
            "| Training Device=xla:0/2 Epoch=138 Step=0 Loss=0.23013 Rate=10.30 GlobalRate=10.30 Time=03:47:15\n",
            "| Training Device=xla:0/7 Epoch=138 Step=0 Loss=0.21424 Rate=10.30 GlobalRate=10.30 Time=03:47:15\n",
            "Epoch 138 train end 03:47:15\n",
            "Epoch 139 train begin 03:47:15\n",
            "| Training Device=xla:0/4 Epoch=139 Step=0 Loss=0.26114 Rate=10.32 GlobalRate=10.32 Time=03:47:21\n",
            "| Training Device=xla:0/3 Epoch=139 Step=0 Loss=0.34355 Rate=10.32 GlobalRate=10.32 Time=03:47:21\n",
            "| Training Device=xla:0/2 Epoch=139 Step=0 Loss=0.30177 Rate=10.32 GlobalRate=10.32 Time=03:47:21\n",
            "| Training Device=xla:0/6 Epoch=139 Step=0 Loss=0.34665 Rate=10.32 GlobalRate=10.32 Time=03:47:21\n",
            "| Training Device=xla:0/7 Epoch=139 Step=0 Loss=0.26536 Rate=10.32 GlobalRate=10.32 Time=03:47:21\n",
            "| Training Device=xla:0/1 Epoch=139 Step=0 Loss=0.25360 Rate=10.32 GlobalRate=10.32 Time=03:47:21\n",
            "| Training Device=xla:0/5 Epoch=139 Step=0 Loss=0.23370 Rate=10.32 GlobalRate=10.32 Time=03:47:21\n",
            "| Training Device=xla:1/0 Epoch=139 Step=0 Loss=0.35378 Rate=10.32 GlobalRate=10.32 Time=03:47:21\n",
            "Epoch 139 train end 03:47:22\n",
            "Epoch 140 train begin 03:47:22\n",
            "| Training Device=xla:0/7 Epoch=140 Step=0 Loss=0.28840 Rate=10.27 GlobalRate=10.27 Time=03:47:28\n",
            "| Training Device=xla:0/5 Epoch=140 Step=0 Loss=0.24529 Rate=10.27 GlobalRate=10.27 Time=03:47:28\n",
            "| Training Device=xla:0/2 Epoch=140 Step=0 Loss=0.28429 Rate=10.27 GlobalRate=10.27 Time=03:47:28\n",
            "| Training Device=xla:0/6 Epoch=140 Step=0 Loss=0.43764 Rate=10.27 GlobalRate=10.27 Time=03:47:28\n",
            "| Training Device=xla:0/3 Epoch=140 Step=0 Loss=0.42528 Rate=10.27 GlobalRate=10.27 Time=03:47:28\n",
            "| Training Device=xla:0/4 Epoch=140 Step=0 Loss=0.29863 Rate=10.27 GlobalRate=10.27 Time=03:47:28\n",
            "| Training Device=xla:1/0 Epoch=140 Step=0 Loss=0.32089 Rate=10.27 GlobalRate=10.27 Time=03:47:28\n",
            "| Training Device=xla:0/1 Epoch=140 Step=0 Loss=0.32225 Rate=10.27 GlobalRate=10.27 Time=03:47:28\n",
            "Epoch 140 train end 03:47:28\n",
            "Epoch 141 train begin 03:47:28\n",
            "| Training Device=xla:0/4 Epoch=141 Step=0 Loss=0.29406 Rate=10.33 GlobalRate=10.33 Time=03:47:34\n",
            "| Training Device=xla:0/6 Epoch=141 Step=0 Loss=0.39747 Rate=10.33 GlobalRate=10.33 Time=03:47:34\n",
            "| Training Device=xla:0/1 Epoch=141 Step=0 Loss=0.26404 Rate=10.33 GlobalRate=10.33 Time=03:47:34\n",
            "| Training Device=xla:0/5 Epoch=141 Step=0 Loss=0.27584 Rate=10.33 GlobalRate=10.33 Time=03:47:34\n",
            "| Training Device=xla:0/7 Epoch=141 Step=0 Loss=0.24646 Rate=10.33 GlobalRate=10.33 Time=03:47:34\n",
            "| Training Device=xla:0/3 Epoch=141 Step=0 Loss=0.41626 Rate=10.33 GlobalRate=10.33 Time=03:47:34\n",
            "| Training Device=xla:0/2 Epoch=141 Step=0 Loss=0.23591 Rate=10.33 GlobalRate=10.33 Time=03:47:34\n",
            "| Training Device=xla:1/0 Epoch=141 Step=0 Loss=0.37047 Rate=10.33 GlobalRate=10.33 Time=03:47:34\n",
            "Epoch 141 train end 03:47:34\n",
            "Epoch 142 train begin 03:47:34\n",
            "| Training Device=xla:0/7 Epoch=142 Step=0 Loss=0.27281 Rate=10.27 GlobalRate=10.27 Time=03:47:41\n",
            "| Training Device=xla:0/4 Epoch=142 Step=0 Loss=0.29990 Rate=10.27 GlobalRate=10.27 Time=03:47:41\n",
            "| Training Device=xla:0/6 Epoch=142 Step=0 Loss=0.40251 Rate=10.26 GlobalRate=10.26 Time=03:47:41\n",
            "| Training Device=xla:0/1 Epoch=142 Step=0 Loss=0.30402 Rate=10.26 GlobalRate=10.26 Time=03:47:41\n",
            "| Training Device=xla:0/5 Epoch=142 Step=0 Loss=0.29183 Rate=10.27 GlobalRate=10.27 Time=03:47:41\n",
            "| Training Device=xla:1/0 Epoch=142 Step=0 Loss=0.29825 Rate=10.27 GlobalRate=10.27 Time=03:47:41\n",
            "| Training Device=xla:0/3 Epoch=142 Step=0 Loss=0.39889 Rate=10.26 GlobalRate=10.26 Time=03:47:41\n",
            "| Training Device=xla:0/2 Epoch=142 Step=0 Loss=0.26809 Rate=10.26 GlobalRate=10.26 Time=03:47:41\n",
            "Epoch 142 train end 03:47:41\n",
            "Epoch 143 train begin 03:47:41\n",
            "| Training Device=xla:0/3 Epoch=143 Step=0 Loss=0.37324 Rate=10.30 GlobalRate=10.30 Time=03:47:47\n",
            "| Training Device=xla:0/5 Epoch=143 Step=0 Loss=0.25922 Rate=10.31 GlobalRate=10.31 Time=03:47:47\n",
            "| Training Device=xla:0/2 Epoch=143 Step=0 Loss=0.29723 Rate=10.30 GlobalRate=10.30 Time=03:47:47\n",
            "| Training Device=xla:0/1 Epoch=143 Step=0 Loss=0.24443 Rate=10.30 GlobalRate=10.30 Time=03:47:47\n",
            "| Training Device=xla:0/4 Epoch=143 Step=0 Loss=0.25793 Rate=10.30 GlobalRate=10.30 Time=03:47:47\n",
            "| Training Device=xla:0/7 Epoch=143 Step=0 Loss=0.29856 Rate=10.30 GlobalRate=10.30 Time=03:47:47\n",
            "| Training Device=xla:0/6 Epoch=143 Step=0 Loss=0.43233 Rate=10.30 GlobalRate=10.30 Time=03:47:47\n",
            "| Training Device=xla:1/0 Epoch=143 Step=0 Loss=0.34447 Rate=10.30 GlobalRate=10.30 Time=03:47:47\n",
            "Epoch 143 train end 03:47:47\n",
            "Epoch 144 train begin 03:47:47\n",
            "| Training Device=xla:0/2 Epoch=144 Step=0 Loss=0.22941 Rate=10.29 GlobalRate=10.29 Time=03:47:54\n",
            "| Training Device=xla:0/5 Epoch=144 Step=0 Loss=0.23283 Rate=10.29 GlobalRate=10.29 Time=03:47:54\n",
            "| Training Device=xla:0/1 Epoch=144 Step=0 Loss=0.27505 Rate=10.29 GlobalRate=10.29 Time=03:47:54\n",
            "| Training Device=xla:1/0 Epoch=144 Step=0 Loss=0.34788 Rate=10.29 GlobalRate=10.29 Time=03:47:54\n",
            "| Training Device=xla:0/3 Epoch=144 Step=0 Loss=0.35154 Rate=10.29 GlobalRate=10.29 Time=03:47:54\n",
            "| Training Device=xla:0/6 Epoch=144 Step=0 Loss=0.40406 Rate=10.29 GlobalRate=10.29 Time=03:47:54\n",
            "| Training Device=xla:0/4 Epoch=144 Step=0 Loss=0.25444 Rate=10.29 GlobalRate=10.29 Time=03:47:54\n",
            "| Training Device=xla:0/7 Epoch=144 Step=0 Loss=0.23118 Rate=10.29 GlobalRate=10.29 Time=03:47:54\n",
            "Epoch 144 train end 03:47:54\n",
            "Epoch 145 train begin 03:47:54\n",
            "| Training Device=xla:0/2 Epoch=145 Step=0 Loss=0.19733 Rate=10.30 GlobalRate=10.30 Time=03:48:00\n",
            "| Training Device=xla:1/0 Epoch=145 Step=0 Loss=0.35766 Rate=10.30 GlobalRate=10.30 Time=03:48:00\n",
            "| Training Device=xla:0/1 Epoch=145 Step=0 Loss=0.29166 Rate=10.30 GlobalRate=10.30 Time=03:48:00\n",
            "| Training Device=xla:0/5 Epoch=145 Step=0 Loss=0.23379 Rate=10.29 GlobalRate=10.29 Time=03:48:00\n",
            "| Training Device=xla:0/6 Epoch=145 Step=0 Loss=0.38454 Rate=10.29 GlobalRate=10.29 Time=03:48:00\n",
            "| Training Device=xla:0/4 Epoch=145 Step=0 Loss=0.25853 Rate=10.29 GlobalRate=10.29 Time=03:48:00\n",
            "| Training Device=xla:0/7 Epoch=145 Step=0 Loss=0.25544 Rate=10.29 GlobalRate=10.29 Time=03:48:00\n",
            "| Training Device=xla:0/3 Epoch=145 Step=0 Loss=0.37347 Rate=10.29 GlobalRate=10.29 Time=03:48:00\n",
            "Epoch 145 train end 03:48:00\n",
            "Epoch 146 train begin 03:48:00\n",
            "| Training Device=xla:0/1 Epoch=146 Step=0 Loss=0.31464 Rate=10.36 GlobalRate=10.36 Time=03:48:06\n",
            "| Training Device=xla:0/6 Epoch=146 Step=0 Loss=0.37585 Rate=10.35 GlobalRate=10.35 Time=03:48:06\n",
            "| Training Device=xla:0/3 Epoch=146 Step=0 Loss=0.44511 Rate=10.35 GlobalRate=10.35 Time=03:48:06\n",
            "| Training Device=xla:0/7 Epoch=146 Step=0 Loss=0.28521 Rate=10.35 GlobalRate=10.35 Time=03:48:06\n",
            "| Training Device=xla:0/5 Epoch=146 Step=0 Loss=0.24762 Rate=10.35 GlobalRate=10.35 Time=03:48:06\n",
            "| Training Device=xla:0/2 Epoch=146 Step=0 Loss=0.26769 Rate=10.35 GlobalRate=10.35 Time=03:48:06\n",
            "| Training Device=xla:0/4 Epoch=146 Step=0 Loss=0.27826 Rate=10.35 GlobalRate=10.35 Time=03:48:06\n",
            "| Training Device=xla:1/0 Epoch=146 Step=0 Loss=0.34997 Rate=10.35 GlobalRate=10.35 Time=03:48:06\n",
            "Epoch 146 train end 03:48:07\n",
            "Epoch 147 train begin 03:48:07\n",
            "| Training Device=xla:0/1 Epoch=147 Step=0 Loss=0.29259 Rate=10.26 GlobalRate=10.26 Time=03:48:13\n",
            "| Training Device=xla:0/3 Epoch=147 Step=0 Loss=0.38776 Rate=10.26 GlobalRate=10.26 Time=03:48:13\n",
            "| Training Device=xla:0/7 Epoch=147 Step=0 Loss=0.27301 Rate=10.26 GlobalRate=10.26 Time=03:48:13\n",
            "| Training Device=xla:0/5 Epoch=147 Step=0 Loss=0.19593 Rate=10.26 GlobalRate=10.26 Time=03:48:13\n",
            "| Training Device=xla:0/6 Epoch=147 Step=0 Loss=0.35625 Rate=10.25 GlobalRate=10.25 Time=03:48:13\n",
            "| Training Device=xla:0/4 Epoch=147 Step=0 Loss=0.28888 Rate=10.26 GlobalRate=10.26 Time=03:48:13\n",
            "| Training Device=xla:1/0 Epoch=147 Step=0 Loss=0.28941 Rate=10.26 GlobalRate=10.26 Time=03:48:13\n",
            "| Training Device=xla:0/2 Epoch=147 Step=0 Loss=0.30671 Rate=10.25 GlobalRate=10.25 Time=03:48:13\n",
            "Epoch 147 train end 03:48:13\n",
            "Epoch 148 train begin 03:48:13\n",
            "| Training Device=xla:0/2 Epoch=148 Step=0 Loss=0.28119 Rate=10.38 GlobalRate=10.38 Time=03:48:19\n",
            "| Training Device=xla:0/3 Epoch=148 Step=0 Loss=0.38508 Rate=10.38 GlobalRate=10.38 Time=03:48:19\n",
            "| Training Device=xla:0/5 Epoch=148 Step=0 Loss=0.35625 Rate=10.38 GlobalRate=10.38 Time=03:48:19\n",
            "| Training Device=xla:0/1 Epoch=148 Step=0 Loss=0.34220 Rate=10.38 GlobalRate=10.38 Time=03:48:19\n",
            "| Training Device=xla:0/6 Epoch=148 Step=0 Loss=0.37191 Rate=10.38 GlobalRate=10.38 Time=03:48:19\n",
            "| Training Device=xla:0/7 Epoch=148 Step=0 Loss=0.23896 Rate=10.38 GlobalRate=10.38 Time=03:48:19\n",
            "| Training Device=xla:0/4 Epoch=148 Step=0 Loss=0.24054 Rate=10.38 GlobalRate=10.38 Time=03:48:19\n",
            "| Training Device=xla:1/0 Epoch=148 Step=0 Loss=0.40765 Rate=10.38 GlobalRate=10.38 Time=03:48:19\n",
            "Epoch 148 train end 03:48:20\n",
            "Epoch 149 train begin 03:48:20\n",
            "| Training Device=xla:0/3 Epoch=149 Step=0 Loss=0.40453 Rate=10.35 GlobalRate=10.35 Time=03:48:26\n",
            "| Training Device=xla:0/2 Epoch=149 Step=0 Loss=0.26768 Rate=10.34 GlobalRate=10.34 Time=03:48:26\n",
            "| Training Device=xla:0/6 Epoch=149 Step=0 Loss=0.33043 Rate=10.34 GlobalRate=10.34 Time=03:48:26\n",
            "| Training Device=xla:0/1 Epoch=149 Step=0 Loss=0.21992 Rate=10.35 GlobalRate=10.35 Time=03:48:26\n",
            "| Training Device=xla:0/7 Epoch=149 Step=0 Loss=0.25328 Rate=10.34 GlobalRate=10.34 Time=03:48:26\n",
            "| Training Device=xla:0/4 Epoch=149 Step=0 Loss=0.24295 Rate=10.34 GlobalRate=10.34 Time=03:48:26\n",
            "| Training Device=xla:0/5 Epoch=149 Step=0 Loss=0.26167 Rate=10.34 GlobalRate=10.34 Time=03:48:26\n",
            "| Training Device=xla:1/0 Epoch=149 Step=0 Loss=0.38485 Rate=10.35 GlobalRate=10.35 Time=03:48:26\n",
            "Epoch 149 train end 03:48:26\n",
            "Epoch 150 train begin 03:48:26\n",
            "| Training Device=xla:0/2 Epoch=150 Step=0 Loss=0.28257 Rate=10.36 GlobalRate=10.36 Time=03:48:32\n",
            "| Training Device=xla:0/4 Epoch=150 Step=0 Loss=0.23768 Rate=10.36 GlobalRate=10.36 Time=03:48:32\n",
            "| Training Device=xla:0/7 Epoch=150 Step=0 Loss=0.25063 Rate=10.36 GlobalRate=10.36 Time=03:48:32\n",
            "| Training Device=xla:0/5 Epoch=150 Step=0 Loss=0.29029 Rate=10.36 GlobalRate=10.36 Time=03:48:32\n",
            "| Training Device=xla:0/1 Epoch=150 Step=0 Loss=0.22917 Rate=10.36 GlobalRate=10.36 Time=03:48:32\n",
            "| Training Device=xla:0/6 Epoch=150 Step=0 Loss=0.30676 Rate=10.36 GlobalRate=10.36 Time=03:48:32\n",
            "| Training Device=xla:1/0 Epoch=150 Step=0 Loss=0.34708 Rate=10.36 GlobalRate=10.36 Time=03:48:32\n",
            "| Training Device=xla:0/3 Epoch=150 Step=0 Loss=0.38031 Rate=10.36 GlobalRate=10.36 Time=03:48:32\n",
            "Epoch 150 train end 03:48:32\n",
            "Epoch 151 train begin 03:48:32\n",
            "| Training Device=xla:0/2 Epoch=151 Step=0 Loss=0.20470 Rate=10.31 GlobalRate=10.31 Time=03:48:39\n",
            "| Training Device=xla:0/3 Epoch=151 Step=0 Loss=0.42228 Rate=10.31 GlobalRate=10.31 Time=03:48:39\n",
            "| Training Device=xla:0/5 Epoch=151 Step=0 Loss=0.25335 Rate=10.31 GlobalRate=10.31 Time=03:48:39\n",
            "| Training Device=xla:0/4 Epoch=151 Step=0 Loss=0.29957 Rate=10.31 GlobalRate=10.31 Time=03:48:39\n",
            "| Training Device=xla:0/7 Epoch=151 Step=0 Loss=0.27491 Rate=10.31 GlobalRate=10.31 Time=03:48:39\n",
            "| Training Device=xla:1/0 Epoch=151 Step=0 Loss=0.32961 Rate=10.31 GlobalRate=10.31 Time=03:48:39\n",
            "| Training Device=xla:0/6 Epoch=151 Step=0 Loss=0.34452 Rate=10.31 GlobalRate=10.31 Time=03:48:39\n",
            "| Training Device=xla:0/1 Epoch=151 Step=0 Loss=0.27225 Rate=10.31 GlobalRate=10.31 Time=03:48:39\n",
            "Epoch 151 train end 03:48:39\n",
            "Epoch 152 train begin 03:48:39\n",
            "| Training Device=xla:0/3 Epoch=152 Step=0 Loss=0.44971 Rate=10.35 GlobalRate=10.35 Time=03:48:45\n",
            "| Training Device=xla:0/2 Epoch=152 Step=0 Loss=0.32187 Rate=10.35 GlobalRate=10.35 Time=03:48:45\n",
            "| Training Device=xla:0/5 Epoch=152 Step=0 Loss=0.27341 Rate=10.35 GlobalRate=10.35 Time=03:48:45\n",
            "| Training Device=xla:1/0 Epoch=152 Step=0 Loss=0.33564 Rate=10.35 GlobalRate=10.35 Time=03:48:45\n",
            "| Training Device=xla:0/7 Epoch=152 Step=0 Loss=0.26858 Rate=10.35 GlobalRate=10.35 Time=03:48:45\n",
            "| Training Device=xla:0/1 Epoch=152 Step=0 Loss=0.22202 Rate=10.35 GlobalRate=10.35 Time=03:48:45\n",
            "| Training Device=xla:0/6 Epoch=152 Step=0 Loss=0.35621 Rate=10.35 GlobalRate=10.35 Time=03:48:45\n",
            "| Training Device=xla:0/4 Epoch=152 Step=0 Loss=0.29695 Rate=10.35 GlobalRate=10.35 Time=03:48:45\n",
            "Epoch 152 train end 03:48:45\n",
            "Epoch 153 train begin 03:48:45\n",
            "| Training Device=xla:0/7 Epoch=153 Step=0 Loss=0.29708 Rate=10.28 GlobalRate=10.28 Time=03:48:52\n",
            "| Training Device=xla:0/5 Epoch=153 Step=0 Loss=0.30579 Rate=10.28 GlobalRate=10.28 Time=03:48:52\n",
            "| Training Device=xla:0/2 Epoch=153 Step=0 Loss=0.23219 Rate=10.28 GlobalRate=10.28 Time=03:48:52\n",
            "| Training Device=xla:0/1 Epoch=153 Step=0 Loss=0.28349 Rate=10.28 GlobalRate=10.28 Time=03:48:52\n",
            "| Training Device=xla:0/6 Epoch=153 Step=0 Loss=0.32329 Rate=10.28 GlobalRate=10.28 Time=03:48:52\n",
            "| Training Device=xla:0/3 Epoch=153 Step=0 Loss=0.41221 Rate=10.28 GlobalRate=10.28 Time=03:48:52\n",
            "| Training Device=xla:1/0 Epoch=153 Step=0 Loss=0.34685 Rate=10.28 GlobalRate=10.28 Time=03:48:52\n",
            "| Training Device=xla:0/4 Epoch=153 Step=0 Loss=0.27603 Rate=10.28 GlobalRate=10.28 Time=03:48:52\n",
            "Epoch 153 train end 03:48:52\n",
            "Epoch 154 train begin 03:48:52\n",
            "| Training Device=xla:0/2 Epoch=154 Step=0 Loss=0.34315 Rate=10.34 GlobalRate=10.34 Time=03:48:58\n",
            "| Training Device=xla:0/3 Epoch=154 Step=0 Loss=0.41856 Rate=10.34 GlobalRate=10.34 Time=03:48:58\n",
            "| Training Device=xla:0/5 Epoch=154 Step=0 Loss=0.27644 Rate=10.34 GlobalRate=10.34 Time=03:48:58\n",
            "| Training Device=xla:1/0 Epoch=154 Step=0 Loss=0.31208 Rate=10.34 GlobalRate=10.34 Time=03:48:58\n",
            "| Training Device=xla:0/1 Epoch=154 Step=0 Loss=0.28746 Rate=10.34 GlobalRate=10.34 Time=03:48:58\n",
            "| Training Device=xla:0/6 Epoch=154 Step=0 Loss=0.37392 Rate=10.34 GlobalRate=10.34 Time=03:48:58\n",
            "| Training Device=xla:0/4 Epoch=154 Step=0 Loss=0.24296 Rate=10.33 GlobalRate=10.33 Time=03:48:58\n",
            "| Training Device=xla:0/7 Epoch=154 Step=0 Loss=0.27046 Rate=10.33 GlobalRate=10.33 Time=03:48:58\n",
            "Epoch 154 train end 03:48:58\n",
            "Epoch 155 train begin 03:48:58\n",
            "| Training Device=xla:0/1 Epoch=155 Step=0 Loss=0.26184 Rate=10.29 GlobalRate=10.29 Time=03:49:04\n",
            "| Training Device=xla:0/7 Epoch=155 Step=0 Loss=0.27275 Rate=10.29 GlobalRate=10.29 Time=03:49:04\n",
            "| Training Device=xla:0/2 Epoch=155 Step=0 Loss=0.33167 Rate=10.29 GlobalRate=10.29 Time=03:49:04\n",
            "| Training Device=xla:0/5 Epoch=155 Step=0 Loss=0.28278 Rate=10.29 GlobalRate=10.29 Time=03:49:04\n",
            "| Training Device=xla:0/4 Epoch=155 Step=0 Loss=0.22932 Rate=10.29 GlobalRate=10.29 Time=03:49:04\n",
            "| Training Device=xla:0/3 Epoch=155 Step=0 Loss=0.39220 Rate=10.29 GlobalRate=10.29 Time=03:49:04\n",
            "| Training Device=xla:1/0 Epoch=155 Step=0 Loss=0.31796 Rate=10.29 GlobalRate=10.29 Time=03:49:04\n",
            "| Training Device=xla:0/6 Epoch=155 Step=0 Loss=0.39011 Rate=10.28 GlobalRate=10.28 Time=03:49:04\n",
            "Epoch 155 train end 03:49:05\n",
            "Epoch 156 train begin 03:49:05\n",
            "| Training Device=xla:0/5 Epoch=156 Step=0 Loss=0.25073 Rate=10.30 GlobalRate=10.30 Time=03:49:11\n",
            "| Training Device=xla:0/2 Epoch=156 Step=0 Loss=0.30732 Rate=10.30 GlobalRate=10.30 Time=03:49:11\n",
            "| Training Device=xla:0/3 Epoch=156 Step=0 Loss=0.35094 Rate=10.30 GlobalRate=10.30 Time=03:49:11\n",
            "| Training Device=xla:1/0 Epoch=156 Step=0 Loss=0.31347 Rate=10.30 GlobalRate=10.30 Time=03:49:11\n",
            "| Training Device=xla:0/6 Epoch=156 Step=0 Loss=0.36612 Rate=10.30 GlobalRate=10.30 Time=03:49:11\n",
            "| Training Device=xla:0/4 Epoch=156 Step=0 Loss=0.27153 Rate=10.30 GlobalRate=10.30 Time=03:49:11\n",
            "| Training Device=xla:0/1 Epoch=156 Step=0 Loss=0.28109 Rate=10.30 GlobalRate=10.30 Time=03:49:11\n",
            "| Training Device=xla:0/7 Epoch=156 Step=0 Loss=0.22561 Rate=10.30 GlobalRate=10.30 Time=03:49:11\n",
            "Epoch 156 train end 03:49:11\n",
            "Epoch 157 train begin 03:49:11\n",
            "| Training Device=xla:1/0 Epoch=157 Step=0 Loss=0.29345 Rate=10.40 GlobalRate=10.40 Time=03:49:17\n",
            "| Training Device=xla:0/3 Epoch=157 Step=0 Loss=0.32479 Rate=10.40 GlobalRate=10.40 Time=03:49:17\n",
            "| Training Device=xla:0/1 Epoch=157 Step=0 Loss=0.28205 Rate=10.40 GlobalRate=10.40 Time=03:49:17\n",
            "| Training Device=xla:0/7 Epoch=157 Step=0 Loss=0.21957 Rate=10.40 GlobalRate=10.40 Time=03:49:17\n",
            "| Training Device=xla:0/5 Epoch=157 Step=0 Loss=0.23299 Rate=10.40 GlobalRate=10.40 Time=03:49:17\n",
            "| Training Device=xla:0/4 Epoch=157 Step=0 Loss=0.22743 Rate=10.40 GlobalRate=10.40 Time=03:49:17\n",
            "| Training Device=xla:0/6 Epoch=157 Step=0 Loss=0.32692 Rate=10.39 GlobalRate=10.39 Time=03:49:17\n",
            "| Training Device=xla:0/2 Epoch=157 Step=0 Loss=0.21664 Rate=10.40 GlobalRate=10.40 Time=03:49:17\n",
            "Epoch 157 train end 03:49:17\n",
            "Epoch 158 train begin 03:49:17\n",
            "| Training Device=xla:0/6 Epoch=158 Step=0 Loss=0.31921 Rate=10.38 GlobalRate=10.38 Time=03:49:24\n",
            "| Training Device=xla:0/2 Epoch=158 Step=0 Loss=0.33012 Rate=10.38 GlobalRate=10.38 Time=03:49:24\n",
            "| Training Device=xla:1/0 Epoch=158 Step=0 Loss=0.36647 Rate=10.38 GlobalRate=10.38 Time=03:49:24\n",
            "| Training Device=xla:0/7 Epoch=158 Step=0 Loss=0.26136 Rate=10.38 GlobalRate=10.38 Time=03:49:24\n",
            "| Training Device=xla:0/1 Epoch=158 Step=0 Loss=0.32275 Rate=10.38 GlobalRate=10.38 Time=03:49:24\n",
            "| Training Device=xla:0/5 Epoch=158 Step=0 Loss=0.21538 Rate=10.38 GlobalRate=10.38 Time=03:49:24\n",
            "| Training Device=xla:0/4 Epoch=158 Step=0 Loss=0.22710 Rate=10.38 GlobalRate=10.38 Time=03:49:24\n",
            "| Training Device=xla:0/3 Epoch=158 Step=0 Loss=0.39159 Rate=10.37 GlobalRate=10.37 Time=03:49:24\n",
            "Epoch 158 train end 03:49:24\n",
            "Epoch 159 train begin 03:49:24\n",
            "| Training Device=xla:0/3 Epoch=159 Step=0 Loss=0.32336 Rate=10.32 GlobalRate=10.32 Time=03:49:30\n",
            "| Training Device=xla:0/2 Epoch=159 Step=0 Loss=0.26913 Rate=10.32 GlobalRate=10.32 Time=03:49:30\n",
            "| Training Device=xla:1/0 Epoch=159 Step=0 Loss=0.27445 Rate=10.33 GlobalRate=10.33 Time=03:49:30\n",
            "| Training Device=xla:0/6 Epoch=159 Step=0 Loss=0.48776 Rate=10.32 GlobalRate=10.32 Time=03:49:30\n",
            "| Training Device=xla:0/4 Epoch=159 Step=0 Loss=0.30922 Rate=10.32 GlobalRate=10.32 Time=03:49:30\n",
            "| Training Device=xla:0/7 Epoch=159 Step=0 Loss=0.26661 Rate=10.32 GlobalRate=10.32 Time=03:49:30\n",
            "| Training Device=xla:0/1 Epoch=159 Step=0 Loss=0.26513 Rate=10.32 GlobalRate=10.32 Time=03:49:30\n",
            "| Training Device=xla:0/5 Epoch=159 Step=0 Loss=0.25246 Rate=10.32 GlobalRate=10.32 Time=03:49:30\n",
            "Epoch 159 train end 03:49:30\n",
            "Epoch 160 train begin 03:49:30\n",
            "| Training Device=xla:0/2 Epoch=160 Step=0 Loss=0.26975 Rate=10.35 GlobalRate=10.35 Time=03:49:37\n",
            "| Training Device=xla:0/1 Epoch=160 Step=0 Loss=0.29915 Rate=10.35 GlobalRate=10.35 Time=03:49:37\n",
            "| Training Device=xla:0/6 Epoch=160 Step=0 Loss=0.39876 Rate=10.35 GlobalRate=10.35 Time=03:49:37\n",
            "| Training Device=xla:0/7 Epoch=160 Step=0 Loss=0.28341 Rate=10.35 GlobalRate=10.35 Time=03:49:37\n",
            "| Training Device=xla:0/4 Epoch=160 Step=0 Loss=0.26547 Rate=10.35 GlobalRate=10.35 Time=03:49:37\n",
            "| Training Device=xla:0/5 Epoch=160 Step=0 Loss=0.28619 Rate=10.35 GlobalRate=10.35 Time=03:49:37\n",
            "| Training Device=xla:0/3 Epoch=160 Step=0 Loss=0.36810 Rate=10.35 GlobalRate=10.35 Time=03:49:37\n",
            "| Training Device=xla:1/0 Epoch=160 Step=0 Loss=0.34557 Rate=10.35 GlobalRate=10.35 Time=03:49:37\n",
            "Epoch 160 train end 03:49:37\n",
            "Epoch 161 train begin 03:49:37\n",
            "| Training Device=xla:0/2 Epoch=161 Step=0 Loss=0.23135 Rate=10.31 GlobalRate=10.31 Time=03:49:43\n",
            "| Training Device=xla:0/6 Epoch=161 Step=0 Loss=0.37810 Rate=10.31 GlobalRate=10.31 Time=03:49:43\n",
            "| Training Device=xla:0/7 Epoch=161 Step=0 Loss=0.31382 Rate=10.31 GlobalRate=10.31 Time=03:49:43\n",
            "| Training Device=xla:0/4 Epoch=161 Step=0 Loss=0.26687 Rate=10.31 GlobalRate=10.31 Time=03:49:43\n",
            "| Training Device=xla:0/1 Epoch=161 Step=0 Loss=0.24400 Rate=10.31 GlobalRate=10.31 Time=03:49:43\n",
            "| Training Device=xla:0/3 Epoch=161 Step=0 Loss=0.42675 Rate=10.31 GlobalRate=10.31 Time=03:49:43\n",
            "| Training Device=xla:0/5 Epoch=161 Step=0 Loss=0.22805 Rate=10.31 GlobalRate=10.31 Time=03:49:43\n",
            "| Training Device=xla:1/0 Epoch=161 Step=0 Loss=0.26459 Rate=10.31 GlobalRate=10.31 Time=03:49:43\n",
            "Epoch 161 train end 03:49:43\n",
            "Epoch 162 train begin 03:49:43\n",
            "| Training Device=xla:0/4 Epoch=162 Step=0 Loss=0.26602 Rate=10.28 GlobalRate=10.28 Time=03:49:49\n",
            "| Training Device=xla:1/0 Epoch=162 Step=0 Loss=0.31556 Rate=10.28 GlobalRate=10.28 Time=03:49:49\n",
            "| Training Device=xla:0/6 Epoch=162 Step=0 Loss=0.40433 Rate=10.28 GlobalRate=10.28 Time=03:49:49\n",
            "| Training Device=xla:0/7 Epoch=162 Step=0 Loss=0.27461 Rate=10.28 GlobalRate=10.28 Time=03:49:49\n",
            "| Training Device=xla:0/2 Epoch=162 Step=0 Loss=0.27778 Rate=10.27 GlobalRate=10.27 Time=03:49:49\n",
            "| Training Device=xla:0/5 Epoch=162 Step=0 Loss=0.22236 Rate=10.27 GlobalRate=10.27 Time=03:49:49\n",
            "| Training Device=xla:0/1 Epoch=162 Step=0 Loss=0.25312 Rate=10.27 GlobalRate=10.27 Time=03:49:49\n",
            "| Training Device=xla:0/3 Epoch=162 Step=0 Loss=0.38534 Rate=10.27 GlobalRate=10.27 Time=03:49:49\n",
            "Epoch 162 train end 03:49:50\n",
            "Epoch 163 train begin 03:49:50\n",
            "| Training Device=xla:0/1 Epoch=163 Step=0 Loss=0.30271 Rate=10.27 GlobalRate=10.27 Time=03:49:56\n",
            "| Training Device=xla:0/3 Epoch=163 Step=0 Loss=0.42067 Rate=10.26 GlobalRate=10.26 Time=03:49:56\n",
            "| Training Device=xla:0/5 Epoch=163 Step=0 Loss=0.24763 Rate=10.27 GlobalRate=10.27 Time=03:49:56\n",
            "| Training Device=xla:0/6 Epoch=163 Step=0 Loss=0.36030 Rate=10.27 GlobalRate=10.27 Time=03:49:56\n",
            "| Training Device=xla:0/7 Epoch=163 Step=0 Loss=0.26385 Rate=10.27 GlobalRate=10.27 Time=03:49:56\n",
            "| Training Device=xla:0/4 Epoch=163 Step=0 Loss=0.28129 Rate=10.27 GlobalRate=10.27 Time=03:49:56\n",
            "| Training Device=xla:0/2 Epoch=163 Step=0 Loss=0.33908 Rate=10.27 GlobalRate=10.27 Time=03:49:56\n",
            "| Training Device=xla:1/0 Epoch=163 Step=0 Loss=0.39543 Rate=10.27 GlobalRate=10.27 Time=03:49:56\n",
            "Epoch 163 train end 03:49:56\n",
            "Epoch 164 train begin 03:49:56\n",
            "| Training Device=xla:0/6 Epoch=164 Step=0 Loss=0.44007 Rate=10.39 GlobalRate=10.39 Time=03:50:02\n",
            "| Training Device=xla:0/5 Epoch=164 Step=0 Loss=0.24683 Rate=10.39 GlobalRate=10.39 Time=03:50:02\n",
            "| Training Device=xla:0/1 Epoch=164 Step=0 Loss=0.28938 Rate=10.39 GlobalRate=10.39 Time=03:50:02\n",
            "| Training Device=xla:0/2 Epoch=164 Step=0 Loss=0.33462 Rate=10.38 GlobalRate=10.38 Time=03:50:02\n",
            "| Training Device=xla:0/7 Epoch=164 Step=0 Loss=0.27784 Rate=10.38 GlobalRate=10.38 Time=03:50:02\n",
            "| Training Device=xla:0/3 Epoch=164 Step=0 Loss=0.41660 Rate=10.38 GlobalRate=10.38 Time=03:50:02\n",
            "| Training Device=xla:0/4 Epoch=164 Step=0 Loss=0.31166 Rate=10.38 GlobalRate=10.38 Time=03:50:02\n",
            "| Training Device=xla:1/0 Epoch=164 Step=0 Loss=0.28972 Rate=10.39 GlobalRate=10.39 Time=03:50:02\n",
            "Epoch 164 train end 03:50:03\n",
            "Epoch 165 train begin 03:50:03\n",
            "| Training Device=xla:0/4 Epoch=165 Step=0 Loss=0.32651 Rate=10.34 GlobalRate=10.34 Time=03:50:09\n",
            "| Training Device=xla:0/5 Epoch=165 Step=0 Loss=0.31839 Rate=10.33 GlobalRate=10.33 Time=03:50:09\n",
            "| Training Device=xla:0/3 Epoch=165 Step=0 Loss=0.40968 Rate=10.33 GlobalRate=10.33 Time=03:50:09\n",
            "| Training Device=xla:0/2 Epoch=165 Step=0 Loss=0.29715 Rate=10.33 GlobalRate=10.33 Time=03:50:09\n",
            "| Training Device=xla:0/1 Epoch=165 Step=0 Loss=0.29270 Rate=10.33 GlobalRate=10.33 Time=03:50:09\n",
            "| Training Device=xla:0/7 Epoch=165 Step=0 Loss=0.24248 Rate=10.33 GlobalRate=10.33 Time=03:50:09\n",
            "| Training Device=xla:0/6 Epoch=165 Step=0 Loss=0.36892 Rate=10.33 GlobalRate=10.33 Time=03:50:09\n",
            "| Training Device=xla:1/0 Epoch=165 Step=0 Loss=0.28286 Rate=10.33 GlobalRate=10.33 Time=03:50:09\n",
            "Epoch 165 train end 03:50:09\n",
            "Epoch 166 train begin 03:50:09\n",
            "| Training Device=xla:0/2 Epoch=166 Step=0 Loss=0.29293 Rate=10.28 GlobalRate=10.28 Time=03:50:15\n",
            "| Training Device=xla:0/6 Epoch=166 Step=0 Loss=0.28111 Rate=10.28 GlobalRate=10.28 Time=03:50:15\n",
            "| Training Device=xla:0/7 Epoch=166 Step=0 Loss=0.26021 Rate=10.28 GlobalRate=10.28 Time=03:50:15\n",
            "| Training Device=xla:0/1 Epoch=166 Step=0 Loss=0.29690 Rate=10.28 GlobalRate=10.28 Time=03:50:15\n",
            "| Training Device=xla:0/3 Epoch=166 Step=0 Loss=0.38725 Rate=10.28 GlobalRate=10.28 Time=03:50:15\n",
            "| Training Device=xla:0/5 Epoch=166 Step=0 Loss=0.21740 Rate=10.28 GlobalRate=10.28 Time=03:50:15\n",
            "| Training Device=xla:0/4 Epoch=166 Step=0 Loss=0.24258 Rate=10.28 GlobalRate=10.28 Time=03:50:15\n",
            "| Training Device=xla:1/0 Epoch=166 Step=0 Loss=0.31059 Rate=10.29 GlobalRate=10.29 Time=03:50:15\n",
            "Epoch 166 train end 03:50:15\n",
            "Epoch 167 train begin 03:50:15\n",
            "| Training Device=xla:0/4 Epoch=167 Step=0 Loss=0.28137 Rate=10.31 GlobalRate=10.31 Time=03:50:22\n",
            "| Training Device=xla:0/3 Epoch=167 Step=0 Loss=0.42716 Rate=10.31 GlobalRate=10.31 Time=03:50:22\n",
            "| Training Device=xla:0/5 Epoch=167 Step=0 Loss=0.22925 Rate=10.31 GlobalRate=10.31 Time=03:50:22\n",
            "| Training Device=xla:0/7 Epoch=167 Step=0 Loss=0.29044 Rate=10.31 GlobalRate=10.31 Time=03:50:22\n",
            "| Training Device=xla:0/1 Epoch=167 Step=0 Loss=0.28689 Rate=10.31 GlobalRate=10.31 Time=03:50:22\n",
            "| Training Device=xla:0/2 Epoch=167 Step=0 Loss=0.24861 Rate=10.31 GlobalRate=10.31 Time=03:50:22\n",
            "| Training Device=xla:0/6 Epoch=167 Step=0 Loss=0.35998 Rate=10.31 GlobalRate=10.31 Time=03:50:22\n",
            "| Training Device=xla:1/0 Epoch=167 Step=0 Loss=0.30729 Rate=10.31 GlobalRate=10.31 Time=03:50:22\n",
            "Epoch 167 train end 03:50:22\n",
            "Epoch 168 train begin 03:50:22\n",
            "| Training Device=xla:0/3 Epoch=168 Step=0 Loss=0.34857 Rate=10.31 GlobalRate=10.31 Time=03:50:28\n",
            "| Training Device=xla:0/6 Epoch=168 Step=0 Loss=0.33634 Rate=10.31 GlobalRate=10.31 Time=03:50:28\n",
            "| Training Device=xla:1/0 Epoch=168 Step=0 Loss=0.29642 Rate=10.31 GlobalRate=10.31 Time=03:50:28\n",
            "| Training Device=xla:0/5 Epoch=168 Step=0 Loss=0.27934 Rate=10.31 GlobalRate=10.31 Time=03:50:28\n",
            "| Training Device=xla:0/7 Epoch=168 Step=0 Loss=0.23883 Rate=10.31 GlobalRate=10.31 Time=03:50:28\n",
            "| Training Device=xla:0/1 Epoch=168 Step=0 Loss=0.25963 Rate=10.30 GlobalRate=10.30 Time=03:50:28\n",
            "| Training Device=xla:0/4 Epoch=168 Step=0 Loss=0.27349 Rate=10.31 GlobalRate=10.31 Time=03:50:28\n",
            "| Training Device=xla:0/2 Epoch=168 Step=0 Loss=0.25703 Rate=10.31 GlobalRate=10.31 Time=03:50:28\n",
            "Epoch 168 train end 03:50:28\n",
            "Epoch 169 train begin 03:50:28\n",
            "| Training Device=xla:1/0 Epoch=169 Step=0 Loss=0.32040 Rate=10.32 GlobalRate=10.32 Time=03:50:34\n",
            "| Training Device=xla:0/1 Epoch=169 Step=0 Loss=0.29387 Rate=10.32 GlobalRate=10.32 Time=03:50:34\n",
            "| Training Device=xla:0/7 Epoch=169 Step=0 Loss=0.25863 Rate=10.32 GlobalRate=10.32 Time=03:50:34\n",
            "| Training Device=xla:0/6 Epoch=169 Step=0 Loss=0.35304 Rate=10.32 GlobalRate=10.32 Time=03:50:34\n",
            "| Training Device=xla:0/2 Epoch=169 Step=0 Loss=0.23169 Rate=10.32 GlobalRate=10.32 Time=03:50:34\n",
            "| Training Device=xla:0/4 Epoch=169 Step=0 Loss=0.22959 Rate=10.32 GlobalRate=10.32 Time=03:50:34\n",
            "| Training Device=xla:0/3 Epoch=169 Step=0 Loss=0.35622 Rate=10.32 GlobalRate=10.32 Time=03:50:34\n",
            "| Training Device=xla:0/5 Epoch=169 Step=0 Loss=0.24177 Rate=10.32 GlobalRate=10.32 Time=03:50:34\n",
            "Epoch 169 train end 03:50:35\n",
            "Epoch 170 train begin 03:50:35\n",
            "| Training Device=xla:0/1 Epoch=170 Step=0 Loss=0.27559 Rate=10.18 GlobalRate=10.18 Time=03:50:41\n",
            "| Training Device=xla:0/5 Epoch=170 Step=0 Loss=0.22574 Rate=10.18 GlobalRate=10.18 Time=03:50:41\n",
            "| Training Device=xla:0/2 Epoch=170 Step=0 Loss=0.26284 Rate=10.18 GlobalRate=10.18 Time=03:50:41\n",
            "| Training Device=xla:0/3 Epoch=170 Step=0 Loss=0.31150 Rate=10.18 GlobalRate=10.18 Time=03:50:41\n",
            "| Training Device=xla:0/7 Epoch=170 Step=0 Loss=0.24922 Rate=10.18 GlobalRate=10.18 Time=03:50:41\n",
            "| Training Device=xla:0/6 Epoch=170 Step=0 Loss=0.36013 Rate=10.18 GlobalRate=10.18 Time=03:50:41\n",
            "| Training Device=xla:0/4 Epoch=170 Step=0 Loss=0.23636 Rate=10.18 GlobalRate=10.18 Time=03:50:41\n",
            "| Training Device=xla:1/0 Epoch=170 Step=0 Loss=0.34782 Rate=10.18 GlobalRate=10.18 Time=03:50:41\n",
            "Epoch 170 train end 03:50:41\n",
            "Epoch 171 train begin 03:50:41\n",
            "| Training Device=xla:0/1 Epoch=171 Step=0 Loss=0.28437 Rate=10.15 GlobalRate=10.15 Time=03:50:48\n",
            "| Training Device=xla:0/3 Epoch=171 Step=0 Loss=0.37747 Rate=10.15 GlobalRate=10.15 Time=03:50:48\n",
            "| Training Device=xla:0/2 Epoch=171 Step=0 Loss=0.26354 Rate=10.15 GlobalRate=10.15 Time=03:50:48\n",
            "| Training Device=xla:0/6 Epoch=171 Step=0 Loss=0.35456 Rate=10.15 GlobalRate=10.15 Time=03:50:48\n",
            "| Training Device=xla:0/5 Epoch=171 Step=0 Loss=0.22956 Rate=10.15 GlobalRate=10.15 Time=03:50:48\n",
            "| Training Device=xla:0/4 Epoch=171 Step=0 Loss=0.26774 Rate=10.15 GlobalRate=10.15 Time=03:50:48\n",
            "| Training Device=xla:1/0 Epoch=171 Step=0 Loss=0.31561 Rate=10.16 GlobalRate=10.16 Time=03:50:48\n",
            "| Training Device=xla:0/7 Epoch=171 Step=0 Loss=0.22805 Rate=10.15 GlobalRate=10.15 Time=03:50:48\n",
            "Epoch 171 train end 03:50:48\n",
            "Epoch 172 train begin 03:50:48\n",
            "| Training Device=xla:0/2 Epoch=172 Step=0 Loss=0.26632 Rate=10.19 GlobalRate=10.19 Time=03:50:54\n",
            "| Training Device=xla:0/5 Epoch=172 Step=0 Loss=0.29947 Rate=10.19 GlobalRate=10.19 Time=03:50:54\n",
            "| Training Device=xla:0/7 Epoch=172 Step=0 Loss=0.27132 Rate=10.19 GlobalRate=10.19 Time=03:50:54\n",
            "| Training Device=xla:0/1 Epoch=172 Step=0 Loss=0.20847 Rate=10.19 GlobalRate=10.19 Time=03:50:54\n",
            "| Training Device=xla:0/4 Epoch=172 Step=0 Loss=0.28252 Rate=10.19 GlobalRate=10.19 Time=03:50:54\n",
            "| Training Device=xla:1/0 Epoch=172 Step=0 Loss=0.32864 Rate=10.20 GlobalRate=10.20 Time=03:50:54\n",
            "| Training Device=xla:0/6 Epoch=172 Step=0 Loss=0.36805 Rate=10.19 GlobalRate=10.19 Time=03:50:54\n",
            "| Training Device=xla:0/3 Epoch=172 Step=0 Loss=0.38561 Rate=10.19 GlobalRate=10.19 Time=03:50:54\n",
            "Epoch 172 train end 03:50:54\n",
            "Epoch 173 train begin 03:50:54\n",
            "| Training Device=xla:0/3 Epoch=173 Step=0 Loss=0.42993 Rate=10.31 GlobalRate=10.31 Time=03:51:00\n",
            "| Training Device=xla:0/4 Epoch=173 Step=0 Loss=0.25764 Rate=10.31 GlobalRate=10.31 Time=03:51:00\n",
            "| Training Device=xla:0/7 Epoch=173 Step=0 Loss=0.22838 Rate=10.31 GlobalRate=10.31 Time=03:51:01\n",
            "| Training Device=xla:0/6 Epoch=173 Step=0 Loss=0.33663 Rate=10.31 GlobalRate=10.31 Time=03:51:01\n",
            "| Training Device=xla:0/2 Epoch=173 Step=0 Loss=0.31607 Rate=10.31 GlobalRate=10.31 Time=03:51:01\n",
            "| Training Device=xla:0/5 Epoch=173 Step=0 Loss=0.25761 Rate=10.31 GlobalRate=10.31 Time=03:51:01\n",
            "| Training Device=xla:0/1 Epoch=173 Step=0 Loss=0.30126 Rate=10.31 GlobalRate=10.31 Time=03:51:01\n",
            "| Training Device=xla:1/0 Epoch=173 Step=0 Loss=0.30201 Rate=10.31 GlobalRate=10.31 Time=03:51:01\n",
            "Epoch 173 train end 03:51:01\n",
            "Epoch 174 train begin 03:51:01\n",
            "| Training Device=xla:0/4 Epoch=174 Step=0 Loss=0.40187 Rate=10.30 GlobalRate=10.30 Time=03:51:07\n",
            "| Training Device=xla:0/2 Epoch=174 Step=0 Loss=0.29457 Rate=10.30 GlobalRate=10.30 Time=03:51:07\n",
            "| Training Device=xla:0/5 Epoch=174 Step=0 Loss=0.20719 Rate=10.30 GlobalRate=10.30 Time=03:51:07\n",
            "| Training Device=xla:0/1 Epoch=174 Step=0 Loss=0.26488 Rate=10.30 GlobalRate=10.30 Time=03:51:07\n",
            "| Training Device=xla:0/6 Epoch=174 Step=0 Loss=0.33056 Rate=10.30 GlobalRate=10.30 Time=03:51:07\n",
            "| Training Device=xla:0/7 Epoch=174 Step=0 Loss=0.24803 Rate=10.30 GlobalRate=10.30 Time=03:51:07\n",
            "| Training Device=xla:0/3 Epoch=174 Step=0 Loss=0.43038 Rate=10.30 GlobalRate=10.30 Time=03:51:07\n",
            "| Training Device=xla:1/0 Epoch=174 Step=0 Loss=0.32537 Rate=10.30 GlobalRate=10.30 Time=03:51:07\n",
            "Epoch 174 train end 03:51:07\n",
            "Epoch 175 train begin 03:51:07\n",
            "| Training Device=xla:0/5 Epoch=175 Step=0 Loss=0.27228 Rate=10.35 GlobalRate=10.35 Time=03:51:13\n",
            "| Training Device=xla:0/4 Epoch=175 Step=0 Loss=0.27128 Rate=10.35 GlobalRate=10.35 Time=03:51:13\n",
            "| Training Device=xla:0/2 Epoch=175 Step=0 Loss=0.27088 Rate=10.35 GlobalRate=10.35 Time=03:51:13\n",
            "| Training Device=xla:0/7 Epoch=175 Step=0 Loss=0.26791 Rate=10.35 GlobalRate=10.35 Time=03:51:13\n",
            "| Training Device=xla:0/6 Epoch=175 Step=0 Loss=0.34603 Rate=10.35 GlobalRate=10.35 Time=03:51:13\n",
            "| Training Device=xla:1/0 Epoch=175 Step=0 Loss=0.31927 Rate=10.36 GlobalRate=10.36 Time=03:51:13\n",
            "| Training Device=xla:0/3 Epoch=175 Step=0 Loss=0.39114 Rate=10.35 GlobalRate=10.35 Time=03:51:13\n",
            "| Training Device=xla:0/1 Epoch=175 Step=0 Loss=0.26307 Rate=10.35 GlobalRate=10.35 Time=03:51:13\n",
            "Epoch 175 train end 03:51:14\n",
            "Epoch 176 train begin 03:51:14\n",
            "| Training Device=xla:0/2 Epoch=176 Step=0 Loss=0.31321 Rate=10.28 GlobalRate=10.28 Time=03:51:20\n",
            "| Training Device=xla:0/4 Epoch=176 Step=0 Loss=0.29191 Rate=10.28 GlobalRate=10.28 Time=03:51:20\n",
            "| Training Device=xla:0/1 Epoch=176 Step=0 Loss=0.22935 Rate=10.28 GlobalRate=10.28 Time=03:51:20\n",
            "| Training Device=xla:0/7 Epoch=176 Step=0 Loss=0.25976 Rate=10.28 GlobalRate=10.28 Time=03:51:20\n",
            "| Training Device=xla:0/3 Epoch=176 Step=0 Loss=0.40699 Rate=10.28 GlobalRate=10.28 Time=03:51:20\n",
            "| Training Device=xla:0/6 Epoch=176 Step=0 Loss=0.35970 Rate=10.28 GlobalRate=10.28 Time=03:51:20\n",
            "| Training Device=xla:0/5 Epoch=176 Step=0 Loss=0.22938 Rate=10.28 GlobalRate=10.28 Time=03:51:20\n",
            "| Training Device=xla:1/0 Epoch=176 Step=0 Loss=0.31350 Rate=10.28 GlobalRate=10.28 Time=03:51:20\n",
            "Epoch 176 train end 03:51:20\n",
            "Epoch 177 train begin 03:51:20\n",
            "| Training Device=xla:1/0 Epoch=177 Step=0 Loss=0.33946 Rate=10.38 GlobalRate=10.38 Time=03:51:26\n",
            "| Training Device=xla:0/7 Epoch=177 Step=0 Loss=0.27099 Rate=10.37 GlobalRate=10.37 Time=03:51:26\n",
            "| Training Device=xla:0/4 Epoch=177 Step=0 Loss=0.28677 Rate=10.37 GlobalRate=10.37 Time=03:51:26\n",
            "| Training Device=xla:0/1 Epoch=177 Step=0 Loss=0.22671 Rate=10.37 GlobalRate=10.37 Time=03:51:26\n",
            "| Training Device=xla:0/5 Epoch=177 Step=0 Loss=0.26808 Rate=10.37 GlobalRate=10.37 Time=03:51:26\n",
            "| Training Device=xla:0/2 Epoch=177 Step=0 Loss=0.34322 Rate=10.37 GlobalRate=10.37 Time=03:51:26\n",
            "| Training Device=xla:0/6 Epoch=177 Step=0 Loss=0.36855 Rate=10.37 GlobalRate=10.37 Time=03:51:26\n",
            "| Training Device=xla:0/3 Epoch=177 Step=0 Loss=0.38987 Rate=10.37 GlobalRate=10.37 Time=03:51:26\n",
            "Epoch 177 train end 03:51:26\n",
            "Epoch 178 train begin 03:51:26\n",
            "| Training Device=xla:0/3 Epoch=178 Step=0 Loss=0.37354 Rate=10.31 GlobalRate=10.31 Time=03:51:33\n",
            "| Training Device=xla:0/1 Epoch=178 Step=0 Loss=0.25500 Rate=10.31 GlobalRate=10.31 Time=03:51:33\n",
            "| Training Device=xla:0/6 Epoch=178 Step=0 Loss=0.34129 Rate=10.31 GlobalRate=10.31 Time=03:51:33\n",
            "| Training Device=xla:0/5 Epoch=178 Step=0 Loss=0.25033 Rate=10.31 GlobalRate=10.31 Time=03:51:33\n",
            "| Training Device=xla:0/4 Epoch=178 Step=0 Loss=0.32475 Rate=10.31 GlobalRate=10.31 Time=03:51:33\n",
            "| Training Device=xla:0/7 Epoch=178 Step=0 Loss=0.26333 Rate=10.31 GlobalRate=10.31 Time=03:51:33\n",
            "| Training Device=xla:0/2 Epoch=178 Step=0 Loss=0.28002 Rate=10.31 GlobalRate=10.31 Time=03:51:33\n",
            "| Training Device=xla:1/0 Epoch=178 Step=0 Loss=0.27749 Rate=10.31 GlobalRate=10.31 Time=03:51:33\n",
            "Epoch 178 train end 03:51:33\n",
            "Epoch 179 train begin 03:51:33\n",
            "| Training Device=xla:0/7 Epoch=179 Step=0 Loss=0.29005 Rate=10.34 GlobalRate=10.34 Time=03:51:39\n",
            "| Training Device=xla:0/6 Epoch=179 Step=0 Loss=0.39651 Rate=10.35 GlobalRate=10.35 Time=03:51:39\n",
            "| Training Device=xla:0/1 Epoch=179 Step=0 Loss=0.23302 Rate=10.34 GlobalRate=10.34 Time=03:51:39\n",
            "| Training Device=xla:0/3 Epoch=179 Step=0 Loss=0.40960 Rate=10.34 GlobalRate=10.34 Time=03:51:39\n",
            "| Training Device=xla:0/2 Epoch=179 Step=0 Loss=0.28101 Rate=10.34 GlobalRate=10.34 Time=03:51:39\n",
            "| Training Device=xla:0/5 Epoch=179 Step=0 Loss=0.26756 Rate=10.34 GlobalRate=10.34 Time=03:51:39\n",
            "| Training Device=xla:0/4 Epoch=179 Step=0 Loss=0.26402 Rate=10.34 GlobalRate=10.34 Time=03:51:39\n",
            "| Training Device=xla:1/0 Epoch=179 Step=0 Loss=0.26574 Rate=10.35 GlobalRate=10.35 Time=03:51:39\n",
            "Epoch 179 train end 03:51:39\n",
            "Epoch 180 train begin 03:51:39\n",
            "| Training Device=xla:1/0 Epoch=180 Step=0 Loss=0.38106 Rate=10.34 GlobalRate=10.34 Time=03:51:46\n",
            "| Training Device=xla:0/3 Epoch=180 Step=0 Loss=0.41147 Rate=10.34 GlobalRate=10.34 Time=03:51:46\n",
            "| Training Device=xla:0/5 Epoch=180 Step=0 Loss=0.23479 Rate=10.34 GlobalRate=10.34 Time=03:51:46\n",
            "| Training Device=xla:0/2 Epoch=180 Step=0 Loss=0.26230 Rate=10.34 GlobalRate=10.34 Time=03:51:46\n",
            "| Training Device=xla:0/1 Epoch=180 Step=0 Loss=0.22949 Rate=10.34 GlobalRate=10.34 Time=03:51:46\n",
            "| Training Device=xla:0/6 Epoch=180 Step=0 Loss=0.35259 Rate=10.34 GlobalRate=10.34 Time=03:51:46\n",
            "| Training Device=xla:0/7 Epoch=180 Step=0 Loss=0.30195 Rate=10.34 GlobalRate=10.34 Time=03:51:46\n",
            "| Training Device=xla:0/4 Epoch=180 Step=0 Loss=0.29799 Rate=10.34 GlobalRate=10.34 Time=03:51:46\n",
            "Epoch 180 train end 03:51:46\n",
            "Epoch 181 train begin 03:51:46\n",
            "| Training Device=xla:0/1 Epoch=181 Step=0 Loss=0.25419 Rate=10.39 GlobalRate=10.39 Time=03:51:52\n",
            "| Training Device=xla:1/0 Epoch=181 Step=0 Loss=0.35932 Rate=10.39 GlobalRate=10.39 Time=03:51:52\n",
            "| Training Device=xla:0/2 Epoch=181 Step=0 Loss=0.31152 Rate=10.38 GlobalRate=10.38 Time=03:51:52\n",
            "| Training Device=xla:0/4 Epoch=181 Step=0 Loss=0.26684 Rate=10.38 GlobalRate=10.38 Time=03:51:52\n",
            "| Training Device=xla:0/5 Epoch=181 Step=0 Loss=0.24941 Rate=10.38 GlobalRate=10.38 Time=03:51:52\n",
            "| Training Device=xla:0/3 Epoch=181 Step=0 Loss=0.38332 Rate=10.38 GlobalRate=10.38 Time=03:51:52\n",
            "| Training Device=xla:0/6 Epoch=181 Step=0 Loss=0.36943 Rate=10.38 GlobalRate=10.38 Time=03:51:52\n",
            "| Training Device=xla:0/7 Epoch=181 Step=0 Loss=0.23111 Rate=10.38 GlobalRate=10.38 Time=03:51:52\n",
            "Epoch 181 train end 03:51:52\n",
            "Epoch 182 train begin 03:51:52\n",
            "| Training Device=xla:0/5 Epoch=182 Step=0 Loss=0.22203 Rate=10.30 GlobalRate=10.30 Time=03:51:58\n",
            "| Training Device=xla:0/4 Epoch=182 Step=0 Loss=0.23237 Rate=10.30 GlobalRate=10.30 Time=03:51:58\n",
            "| Training Device=xla:0/2 Epoch=182 Step=0 Loss=0.26160 Rate=10.30 GlobalRate=10.30 Time=03:51:58\n",
            "| Training Device=xla:0/3 Epoch=182 Step=0 Loss=0.41197 Rate=10.30 GlobalRate=10.30 Time=03:51:58\n",
            "| Training Device=xla:0/6 Epoch=182 Step=0 Loss=0.37177 Rate=10.30 GlobalRate=10.30 Time=03:51:58\n",
            "| Training Device=xla:1/0 Epoch=182 Step=0 Loss=0.32449 Rate=10.31 GlobalRate=10.31 Time=03:51:58\n",
            "| Training Device=xla:0/1 Epoch=182 Step=0 Loss=0.22647 Rate=10.30 GlobalRate=10.30 Time=03:51:58\n",
            "| Training Device=xla:0/7 Epoch=182 Step=0 Loss=0.27609 Rate=10.30 GlobalRate=10.30 Time=03:51:58\n",
            "Epoch 182 train end 03:51:59\n",
            "Epoch 183 train begin 03:51:59\n",
            "| Training Device=xla:0/1 Epoch=183 Step=0 Loss=0.28769 Rate=10.34 GlobalRate=10.34 Time=03:52:05\n",
            "| Training Device=xla:0/5 Epoch=183 Step=0 Loss=0.21725 Rate=10.34 GlobalRate=10.34 Time=03:52:05\n",
            "| Training Device=xla:0/6 Epoch=183 Step=0 Loss=0.39341 Rate=10.34 GlobalRate=10.34 Time=03:52:05\n",
            "| Training Device=xla:0/2 Epoch=183 Step=0 Loss=0.23674 Rate=10.34 GlobalRate=10.34 Time=03:52:05\n",
            "| Training Device=xla:0/4 Epoch=183 Step=0 Loss=0.32487 Rate=10.34 GlobalRate=10.34 Time=03:52:05\n",
            "| Training Device=xla:0/7 Epoch=183 Step=0 Loss=0.28868 Rate=10.34 GlobalRate=10.34 Time=03:52:05\n",
            "| Training Device=xla:1/0 Epoch=183 Step=0 Loss=0.27572 Rate=10.34 GlobalRate=10.34 Time=03:52:05\n",
            "| Training Device=xla:0/3 Epoch=183 Step=0 Loss=0.40169 Rate=10.34 GlobalRate=10.34 Time=03:52:05\n",
            "Epoch 183 train end 03:52:05\n",
            "Epoch 184 train begin 03:52:05\n",
            "| Training Device=xla:0/6 Epoch=184 Step=0 Loss=0.31858 Rate=10.29 GlobalRate=10.29 Time=03:52:11\n",
            "| Training Device=xla:0/4 Epoch=184 Step=0 Loss=0.22341 Rate=10.29 GlobalRate=10.29 Time=03:52:11\n",
            "| Training Device=xla:0/3 Epoch=184 Step=0 Loss=0.38798 Rate=10.29 GlobalRate=10.29 Time=03:52:11\n",
            "| Training Device=xla:0/2 Epoch=184 Step=0 Loss=0.24635 Rate=10.29 GlobalRate=10.29 Time=03:52:11\n",
            "| Training Device=xla:0/7 Epoch=184 Step=0 Loss=0.26494 Rate=10.29 GlobalRate=10.29 Time=03:52:11\n",
            "| Training Device=xla:0/1 Epoch=184 Step=0 Loss=0.27196 Rate=10.29 GlobalRate=10.29 Time=03:52:11\n",
            "| Training Device=xla:0/5 Epoch=184 Step=0 Loss=0.24471 Rate=10.29 GlobalRate=10.29 Time=03:52:11\n",
            "| Training Device=xla:1/0 Epoch=184 Step=0 Loss=0.32076 Rate=10.29 GlobalRate=10.29 Time=03:52:11\n",
            "Epoch 184 train end 03:52:11\n",
            "Epoch 185 train begin 03:52:11\n",
            "| Training Device=xla:0/5 Epoch=185 Step=0 Loss=0.26451 Rate=10.32 GlobalRate=10.32 Time=03:52:18\n",
            "| Training Device=xla:0/4 Epoch=185 Step=0 Loss=0.28235 Rate=10.32 GlobalRate=10.32 Time=03:52:18\n",
            "| Training Device=xla:0/6 Epoch=185 Step=0 Loss=0.32994 Rate=10.32 GlobalRate=10.32 Time=03:52:18\n",
            "| Training Device=xla:0/1 Epoch=185 Step=0 Loss=0.26320 Rate=10.32 GlobalRate=10.32 Time=03:52:18\n",
            "| Training Device=xla:0/2 Epoch=185 Step=0 Loss=0.26729 Rate=10.32 GlobalRate=10.32 Time=03:52:18\n",
            "| Training Device=xla:0/3 Epoch=185 Step=0 Loss=0.37087 Rate=10.32 GlobalRate=10.32 Time=03:52:18\n",
            "| Training Device=xla:0/7 Epoch=185 Step=0 Loss=0.27767 Rate=10.32 GlobalRate=10.32 Time=03:52:18\n",
            "| Training Device=xla:1/0 Epoch=185 Step=0 Loss=0.30124 Rate=10.33 GlobalRate=10.33 Time=03:52:18\n",
            "Epoch 185 train end 03:52:18\n",
            "Epoch 186 train begin 03:52:18\n",
            "| Training Device=xla:0/5 Epoch=186 Step=0 Loss=0.25679 Rate=10.34 GlobalRate=10.34 Time=03:52:24\n",
            "| Training Device=xla:0/4 Epoch=186 Step=0 Loss=0.25176 Rate=10.34 GlobalRate=10.34 Time=03:52:24\n",
            "| Training Device=xla:1/0 Epoch=186 Step=0 Loss=0.30465 Rate=10.34 GlobalRate=10.34 Time=03:52:24\n",
            "| Training Device=xla:0/7 Epoch=186 Step=0 Loss=0.23449 Rate=10.34 GlobalRate=10.34 Time=03:52:24\n",
            "| Training Device=xla:0/3 Epoch=186 Step=0 Loss=0.37584 Rate=10.34 GlobalRate=10.34 Time=03:52:24\n",
            "| Training Device=xla:0/2 Epoch=186 Step=0 Loss=0.26761 Rate=10.34 GlobalRate=10.34 Time=03:52:24\n",
            "| Training Device=xla:0/6 Epoch=186 Step=0 Loss=0.33113 Rate=10.33 GlobalRate=10.33 Time=03:52:24\n",
            "| Training Device=xla:0/1 Epoch=186 Step=0 Loss=0.30219 Rate=10.33 GlobalRate=10.33 Time=03:52:24\n",
            "Epoch 186 train end 03:52:24\n",
            "Epoch 187 train begin 03:52:24\n",
            "| Training Device=xla:0/5 Epoch=187 Step=0 Loss=0.25625 Rate=10.34 GlobalRate=10.34 Time=03:52:31\n",
            "| Training Device=xla:0/2 Epoch=187 Step=0 Loss=0.24502 Rate=10.33 GlobalRate=10.33 Time=03:52:31\n",
            "| Training Device=xla:0/6 Epoch=187 Step=0 Loss=0.35960 Rate=10.33 GlobalRate=10.33 Time=03:52:31\n",
            "| Training Device=xla:0/4 Epoch=187 Step=0 Loss=0.32588 Rate=10.33 GlobalRate=10.33 Time=03:52:31\n",
            "| Training Device=xla:0/7 Epoch=187 Step=0 Loss=0.28499 Rate=10.33 GlobalRate=10.33 Time=03:52:31\n",
            "| Training Device=xla:1/0 Epoch=187 Step=0 Loss=0.34214 Rate=10.34 GlobalRate=10.34 Time=03:52:31\n",
            "| Training Device=xla:0/3 Epoch=187 Step=0 Loss=0.43640 Rate=10.33 GlobalRate=10.33 Time=03:52:31\n",
            "| Training Device=xla:0/1 Epoch=187 Step=0 Loss=0.25709 Rate=10.33 GlobalRate=10.33 Time=03:52:31\n",
            "Epoch 187 train end 03:52:31\n",
            "Epoch 188 train begin 03:52:31\n",
            "| Training Device=xla:0/2 Epoch=188 Step=0 Loss=0.22835 Rate=10.25 GlobalRate=10.25 Time=03:52:37\n",
            "| Training Device=xla:0/7 Epoch=188 Step=0 Loss=0.23644 Rate=10.26 GlobalRate=10.26 Time=03:52:37\n",
            "| Training Device=xla:0/3 Epoch=188 Step=0 Loss=0.39489 Rate=10.25 GlobalRate=10.25 Time=03:52:37\n",
            "| Training Device=xla:0/5 Epoch=188 Step=0 Loss=0.26140 Rate=10.25 GlobalRate=10.25 Time=03:52:37\n",
            "| Training Device=xla:0/4 Epoch=188 Step=0 Loss=0.24459 Rate=10.25 GlobalRate=10.25 Time=03:52:37\n",
            "| Training Device=xla:0/1 Epoch=188 Step=0 Loss=0.27658 Rate=10.25 GlobalRate=10.25 Time=03:52:37\n",
            "| Training Device=xla:0/6 Epoch=188 Step=0 Loss=0.35069 Rate=10.25 GlobalRate=10.25 Time=03:52:37\n",
            "| Training Device=xla:1/0 Epoch=188 Step=0 Loss=0.30877 Rate=10.26 GlobalRate=10.26 Time=03:52:37\n",
            "Epoch 188 train end 03:52:37\n",
            "Epoch 189 train begin 03:52:37\n",
            "| Training Device=xla:0/2 Epoch=189 Step=0 Loss=0.21518 Rate=10.29 GlobalRate=10.29 Time=03:52:43\n",
            "| Training Device=xla:0/4 Epoch=189 Step=0 Loss=0.27096 Rate=10.29 GlobalRate=10.29 Time=03:52:43\n",
            "| Training Device=xla:0/6 Epoch=189 Step=0 Loss=0.37864 Rate=10.29 GlobalRate=10.29 Time=03:52:43\n",
            "| Training Device=xla:0/5 Epoch=189 Step=0 Loss=0.29054 Rate=10.29 GlobalRate=10.29 Time=03:52:43\n",
            "| Training Device=xla:0/7 Epoch=189 Step=0 Loss=0.27343 Rate=10.29 GlobalRate=10.29 Time=03:52:43\n",
            "| Training Device=xla:0/3 Epoch=189 Step=0 Loss=0.35264 Rate=10.28 GlobalRate=10.28 Time=03:52:43\n",
            "| Training Device=xla:0/1 Epoch=189 Step=0 Loss=0.29722 Rate=10.28 GlobalRate=10.28 Time=03:52:43\n",
            "| Training Device=xla:1/0 Epoch=189 Step=0 Loss=0.29811 Rate=10.29 GlobalRate=10.29 Time=03:52:43\n",
            "Epoch 189 train end 03:52:44\n",
            "Epoch 190 train begin 03:52:44\n",
            "| Training Device=xla:0/3 Epoch=190 Step=0 Loss=0.40538 Rate=10.36 GlobalRate=10.36 Time=03:52:50\n",
            "| Training Device=xla:0/2 Epoch=190 Step=0 Loss=0.26504 Rate=10.36 GlobalRate=10.36 Time=03:52:50\n",
            "| Training Device=xla:1/0 Epoch=190 Step=0 Loss=0.44977 Rate=10.37 GlobalRate=10.37 Time=03:52:50\n",
            "| Training Device=xla:0/4 Epoch=190 Step=0 Loss=0.23251 Rate=10.36 GlobalRate=10.36 Time=03:52:50\n",
            "| Training Device=xla:0/7 Epoch=190 Step=0 Loss=0.27483 Rate=10.36 GlobalRate=10.36 Time=03:52:50\n",
            "| Training Device=xla:0/1 Epoch=190 Step=0 Loss=0.23848 Rate=10.36 GlobalRate=10.36 Time=03:52:50\n",
            "| Training Device=xla:0/5 Epoch=190 Step=0 Loss=0.23688 Rate=10.36 GlobalRate=10.36 Time=03:52:50\n",
            "| Training Device=xla:0/6 Epoch=190 Step=0 Loss=0.36227 Rate=10.36 GlobalRate=10.36 Time=03:52:50\n",
            "Epoch 190 train end 03:52:50\n",
            "Epoch 191 train begin 03:52:50\n",
            "| Training Device=xla:0/7 Epoch=191 Step=0 Loss=0.26588 Rate=10.29 GlobalRate=10.29 Time=03:52:56\n",
            "| Training Device=xla:1/0 Epoch=191 Step=0 Loss=0.34275 Rate=10.29 GlobalRate=10.29 Time=03:52:56\n",
            "| Training Device=xla:0/2 Epoch=191 Step=0 Loss=0.26918 Rate=10.28 GlobalRate=10.28 Time=03:52:56\n",
            "| Training Device=xla:0/3 Epoch=191 Step=0 Loss=0.36885 Rate=10.28 GlobalRate=10.28 Time=03:52:56\n",
            "| Training Device=xla:0/6 Epoch=191 Step=0 Loss=0.34554 Rate=10.28 GlobalRate=10.28 Time=03:52:56\n",
            "| Training Device=xla:0/5 Epoch=191 Step=0 Loss=0.22562 Rate=10.28 GlobalRate=10.28 Time=03:52:56\n",
            "| Training Device=xla:0/1 Epoch=191 Step=0 Loss=0.30463 Rate=10.28 GlobalRate=10.28 Time=03:52:56\n",
            "| Training Device=xla:0/4 Epoch=191 Step=0 Loss=0.28188 Rate=10.28 GlobalRate=10.28 Time=03:52:56\n",
            "Epoch 191 train end 03:52:57\n",
            "Epoch 192 train begin 03:52:57\n",
            "| Training Device=xla:0/2 Epoch=192 Step=0 Loss=0.27486 Rate=10.31 GlobalRate=10.31 Time=03:53:03\n",
            "| Training Device=xla:0/4 Epoch=192 Step=0 Loss=0.25058 Rate=10.31 GlobalRate=10.31 Time=03:53:03\n",
            "| Training Device=xla:0/3 Epoch=192 Step=0 Loss=0.41468 Rate=10.30 GlobalRate=10.30 Time=03:53:03\n",
            "| Training Device=xla:0/1 Epoch=192 Step=0 Loss=0.28269 Rate=10.31 GlobalRate=10.31 Time=03:53:03\n",
            "| Training Device=xla:1/0 Epoch=192 Step=0 Loss=0.29680 Rate=10.31 GlobalRate=10.31 Time=03:53:03\n",
            "| Training Device=xla:0/7 Epoch=192 Step=0 Loss=0.31810 Rate=10.30 GlobalRate=10.30 Time=03:53:03\n",
            "| Training Device=xla:0/6 Epoch=192 Step=0 Loss=0.37592 Rate=10.31 GlobalRate=10.31 Time=03:53:03\n",
            "| Training Device=xla:0/5 Epoch=192 Step=0 Loss=0.25624 Rate=10.30 GlobalRate=10.30 Time=03:53:03\n",
            "Epoch 192 train end 03:53:03\n",
            "Epoch 193 train begin 03:53:03\n",
            "| Training Device=xla:1/0 Epoch=193 Step=0 Loss=0.36434 Rate=10.39 GlobalRate=10.39 Time=03:53:09\n",
            "| Training Device=xla:0/7 Epoch=193 Step=0 Loss=0.33872 Rate=10.39 GlobalRate=10.39 Time=03:53:09\n",
            "| Training Device=xla:0/2 Epoch=193 Step=0 Loss=0.26352 Rate=10.39 GlobalRate=10.39 Time=03:53:09\n",
            "| Training Device=xla:0/4 Epoch=193 Step=0 Loss=0.30130 Rate=10.39 GlobalRate=10.39 Time=03:53:09\n",
            "| Training Device=xla:0/6 Epoch=193 Step=0 Loss=0.36764 Rate=10.39 GlobalRate=10.39 Time=03:53:09\n",
            "| Training Device=xla:0/5 Epoch=193 Step=0 Loss=0.30646 Rate=10.39 GlobalRate=10.39 Time=03:53:09\n",
            "| Training Device=xla:0/3 Epoch=193 Step=0 Loss=0.42375 Rate=10.39 GlobalRate=10.39 Time=03:53:09\n",
            "| Training Device=xla:0/1 Epoch=193 Step=0 Loss=0.25585 Rate=10.39 GlobalRate=10.39 Time=03:53:09\n",
            "Epoch 193 train end 03:53:09\n",
            "Epoch 194 train begin 03:53:09\n",
            "| Training Device=xla:0/7 Epoch=194 Step=0 Loss=0.25410 Rate=10.36 GlobalRate=10.36 Time=03:53:16\n",
            "| Training Device=xla:0/1 Epoch=194 Step=0 Loss=0.33420 Rate=10.36 GlobalRate=10.36 Time=03:53:16\n",
            "| Training Device=xla:0/3 Epoch=194 Step=0 Loss=0.42359 Rate=10.36 GlobalRate=10.36 Time=03:53:16\n",
            "| Training Device=xla:0/5 Epoch=194 Step=0 Loss=0.19173 Rate=10.36 GlobalRate=10.36 Time=03:53:16\n",
            "| Training Device=xla:0/4 Epoch=194 Step=0 Loss=0.27806 Rate=10.36 GlobalRate=10.36 Time=03:53:16\n",
            "| Training Device=xla:1/0 Epoch=194 Step=0 Loss=0.29771 Rate=10.36 GlobalRate=10.36 Time=03:53:16\n",
            "| Training Device=xla:0/2 Epoch=194 Step=0 Loss=0.28895 Rate=10.36 GlobalRate=10.36 Time=03:53:16\n",
            "| Training Device=xla:0/6 Epoch=194 Step=0 Loss=0.37112 Rate=10.36 GlobalRate=10.36 Time=03:53:16\n",
            "Epoch 194 train end 03:53:16\n",
            "Epoch 195 train begin 03:53:16\n",
            "| Training Device=xla:0/4 Epoch=195 Step=0 Loss=0.28004 Rate=10.25 GlobalRate=10.25 Time=03:53:22\n",
            "| Training Device=xla:0/7 Epoch=195 Step=0 Loss=0.21195 Rate=10.25 GlobalRate=10.25 Time=03:53:22\n",
            "| Training Device=xla:0/3 Epoch=195 Step=0 Loss=0.39641 Rate=10.25 GlobalRate=10.25 Time=03:53:22\n",
            "| Training Device=xla:0/6 Epoch=195 Step=0 Loss=0.43916 Rate=10.25 GlobalRate=10.25 Time=03:53:22\n",
            "| Training Device=xla:0/5 Epoch=195 Step=0 Loss=0.21611 Rate=10.25 GlobalRate=10.25 Time=03:53:22\n",
            "| Training Device=xla:0/2 Epoch=195 Step=0 Loss=0.27988 Rate=10.25 GlobalRate=10.25 Time=03:53:22\n",
            "| Training Device=xla:0/1 Epoch=195 Step=0 Loss=0.28906 Rate=10.25 GlobalRate=10.25 Time=03:53:22\n",
            "| Training Device=xla:1/0 Epoch=195 Step=0 Loss=0.30200 Rate=10.25 GlobalRate=10.25 Time=03:53:22\n",
            "Epoch 195 train end 03:53:22\n",
            "Epoch 196 train begin 03:53:22\n",
            "| Training Device=xla:1/0 Epoch=196 Step=0 Loss=0.29398 Rate=10.29 GlobalRate=10.29 Time=03:53:28\n",
            "| Training Device=xla:0/3 Epoch=196 Step=0 Loss=0.40090 Rate=10.28 GlobalRate=10.28 Time=03:53:28\n",
            "| Training Device=xla:0/1 Epoch=196 Step=0 Loss=0.24395 Rate=10.29 GlobalRate=10.29 Time=03:53:28\n",
            "| Training Device=xla:0/5 Epoch=196 Step=0 Loss=0.24970 Rate=10.28 GlobalRate=10.28 Time=03:53:28\n",
            "| Training Device=xla:0/2 Epoch=196 Step=0 Loss=0.25498 Rate=10.28 GlobalRate=10.28 Time=03:53:28\n",
            "| Training Device=xla:0/7 Epoch=196 Step=0 Loss=0.29379 Rate=10.29 GlobalRate=10.29 Time=03:53:28\n",
            "| Training Device=xla:0/6 Epoch=196 Step=0 Loss=0.30504 Rate=10.28 GlobalRate=10.28 Time=03:53:28\n",
            "| Training Device=xla:0/4 Epoch=196 Step=0 Loss=0.26371 Rate=10.28 GlobalRate=10.28 Time=03:53:28\n",
            "Epoch 196 train end 03:53:29\n",
            "Epoch 197 train begin 03:53:29\n",
            "| Training Device=xla:0/1 Epoch=197 Step=0 Loss=0.22036 Rate=10.31 GlobalRate=10.31 Time=03:53:35\n",
            "| Training Device=xla:1/0 Epoch=197 Step=0 Loss=0.32113 Rate=10.32 GlobalRate=10.32 Time=03:53:35\n",
            "| Training Device=xla:0/6 Epoch=197 Step=0 Loss=0.32008 Rate=10.31 GlobalRate=10.31 Time=03:53:35\n",
            "| Training Device=xla:0/3 Epoch=197 Step=0 Loss=0.37530 Rate=10.31 GlobalRate=10.31 Time=03:53:35\n",
            "| Training Device=xla:0/5 Epoch=197 Step=0 Loss=0.24396 Rate=10.31 GlobalRate=10.31 Time=03:53:35\n",
            "| Training Device=xla:0/2 Epoch=197 Step=0 Loss=0.25119 Rate=10.31 GlobalRate=10.31 Time=03:53:35\n",
            "| Training Device=xla:0/7 Epoch=197 Step=0 Loss=0.32000 Rate=10.31 GlobalRate=10.31 Time=03:53:35\n",
            "| Training Device=xla:0/4 Epoch=197 Step=0 Loss=0.27815 Rate=10.31 GlobalRate=10.31 Time=03:53:35\n",
            "Epoch 197 train end 03:53:35\n",
            "Epoch 198 train begin 03:53:35\n",
            "| Training Device=xla:0/3 Epoch=198 Step=0 Loss=0.31891 Rate=10.34 GlobalRate=10.34 Time=03:53:41\n",
            "| Training Device=xla:0/4 Epoch=198 Step=0 Loss=0.23911 Rate=10.34 GlobalRate=10.34 Time=03:53:41\n",
            "| Training Device=xla:0/6 Epoch=198 Step=0 Loss=0.37832 Rate=10.34 GlobalRate=10.34 Time=03:53:41\n",
            "| Training Device=xla:0/1 Epoch=198 Step=0 Loss=0.26044 Rate=10.34 GlobalRate=10.34 Time=03:53:41\n",
            "| Training Device=xla:0/7 Epoch=198 Step=0 Loss=0.22551 Rate=10.34 GlobalRate=10.34 Time=03:53:41\n",
            "| Training Device=xla:1/0 Epoch=198 Step=0 Loss=0.28892 Rate=10.34 GlobalRate=10.34 Time=03:53:41\n",
            "| Training Device=xla:0/2 Epoch=198 Step=0 Loss=0.27072 Rate=10.34 GlobalRate=10.34 Time=03:53:41\n",
            "| Training Device=xla:0/5 Epoch=198 Step=0 Loss=0.22962 Rate=10.34 GlobalRate=10.34 Time=03:53:41\n",
            "Epoch 198 train end 03:53:42\n",
            "Epoch 199 train begin 03:53:42\n",
            "| Training Device=xla:0/5 Epoch=199 Step=0 Loss=0.29151 Rate=10.31 GlobalRate=10.31 Time=03:53:48\n",
            "| Training Device=xla:0/2 Epoch=199 Step=0 Loss=0.34519 Rate=10.31 GlobalRate=10.31 Time=03:53:48\n",
            "| Training Device=xla:0/6 Epoch=199 Step=0 Loss=0.36999 Rate=10.31 GlobalRate=10.31 Time=03:53:48\n",
            "| Training Device=xla:0/4 Epoch=199 Step=0 Loss=0.32003 Rate=10.31 GlobalRate=10.31 Time=03:53:48\n",
            "| Training Device=xla:0/7 Epoch=199 Step=0 Loss=0.27417 Rate=10.31 GlobalRate=10.31 Time=03:53:48\n",
            "| Training Device=xla:0/1 Epoch=199 Step=0 Loss=0.25799 Rate=10.31 GlobalRate=10.31 Time=03:53:48\n",
            "| Training Device=xla:0/3 Epoch=199 Step=0 Loss=0.44501 Rate=10.31 GlobalRate=10.31 Time=03:53:48\n",
            "| Training Device=xla:1/0 Epoch=199 Step=0 Loss=0.29451 Rate=10.31 GlobalRate=10.31 Time=03:53:48\n",
            "Epoch 199 train end 03:53:48\n",
            "Epoch 200 train begin 03:53:48\n",
            "| Training Device=xla:0/6 Epoch=200 Step=0 Loss=0.30467 Rate=10.24 GlobalRate=10.24 Time=03:53:54\n",
            "| Training Device=xla:0/7 Epoch=200 Step=0 Loss=0.26345 Rate=10.24 GlobalRate=10.24 Time=03:53:54\n",
            "| Training Device=xla:0/5 Epoch=200 Step=0 Loss=0.27888 Rate=10.24 GlobalRate=10.24 Time=03:53:54\n",
            "| Training Device=xla:0/3 Epoch=200 Step=0 Loss=0.37148 Rate=10.24 GlobalRate=10.24 Time=03:53:54\n",
            "| Training Device=xla:0/2 Epoch=200 Step=0 Loss=0.28538 Rate=10.23 GlobalRate=10.23 Time=03:53:54\n",
            "| Training Device=xla:0/1 Epoch=200 Step=0 Loss=0.26437 Rate=10.23 GlobalRate=10.23 Time=03:53:54\n",
            "| Training Device=xla:0/4 Epoch=200 Step=0 Loss=0.24405 Rate=10.23 GlobalRate=10.23 Time=03:53:54\n",
            "| Training Device=xla:1/0 Epoch=200 Step=0 Loss=0.33738 Rate=10.24 GlobalRate=10.24 Time=03:53:54\n",
            "Epoch 200 train end 03:53:55\n",
            "Finished training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJB7S4MlSCHr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJm4ZDyVSD7z"
      },
      "source": [
        "## Test SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BeMrdacT6c9"
      },
      "source": [
        "device = xm.xla_device()\n",
        "model = get_model_property('model_fn')().to(device)\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 512),\n",
        "    nn.Linear(512, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b7voDQHT_dO"
      },
      "source": [
        "state_dict = xser.load('/content/drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR-Finetuned-Test.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ0t8T0EUAQR",
        "outputId": "919b0623-7768-4ed2-eda9-aae548a34f2f"
      },
      "source": [
        "state_dict.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7mSzyjETOtu"
      },
      "source": [
        "for k in list(state_dict.keys()):\n",
        "    if k.startswith('backbone.'):\n",
        "        if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "            # remove prefix\n",
        "            state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "del state_dict[k]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC-x2AVGTl0r"
      },
      "source": [
        "log = model.load_state_dict(state_dict, strict=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFaRBi4xTre5",
        "outputId": "efea700c-c11f-49d4-f0a9-cb07d6135186"
      },
      "source": [
        "log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['fc.1.bias'], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GHP7D0VSCom"
      },
      "source": [
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftq2MFAHSFjS"
      },
      "source": [
        "test_data = {\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\",\n",
        "    \"messidor2\": \"https://drive.google.com/uc?id=1HaUAxDtN4BNj0hpH8QYGmiX39Va-Ke8p\",\n",
        "}\n",
        "\n",
        "TEST_DATASET = 'messidor2'\n",
        "URL_TEST_DATASET = test_data[TEST_DATASET]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m1XHql2SKTw",
        "outputId": "aba760d6-e83c-4b3e-c148-91fa5b46fd8a"
      },
      "source": [
        "!gdown $URL_TEST_DATASET"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HaUAxDtN4BNj0hpH8QYGmiX39Va-Ke8p\n",
            "To: /content/messidor2.zip\n",
            "106MB [00:00, 116MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5ZUz1-WSMWB"
      },
      "source": [
        "local_zip = '{}.zip'.format(TEST_DATASET)\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWAX0N6hSOx9"
      },
      "source": [
        "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
        "cifar10_std = (0.2471, 0.2435, 0.2616)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZfoKcb-SQsO"
      },
      "source": [
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=cifar10_mean, std=cifar10_std)  # What happens if I change This \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A7qhuYFSRsE"
      },
      "source": [
        "test_dataset = datasets.ImageFolder(root=\"messidor2\", transform=transform_val) # root: test/messidor2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsuwZuBpSTC1"
      },
      "source": [
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    num_workers=1,\n",
        "    shuffle=False)\n",
        "\n",
        "loader = test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGMMogMMSaL_",
        "outputId": "ae958108-412b-41ed-f851-2f87fc7a979c"
      },
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    with tqdm(total=len(loader)) as pbar:\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "\n",
        "            output = output.to(device)\n",
        "\n",
        "            # Yo le agrege esto\n",
        "            y_true.append(targets.cpu().detach().numpy()[0])\n",
        "            y_pred.append(output.cpu().detach().numpy()[0][0])\n",
        "\n",
        "            pbar.update(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 1748/1748 [01:02<00:00, 27.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBmiwR_MVmnw",
        "outputId": "4915c0be-04cb-4dc8-bfed-42d07543ef6b"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
        "metrics.auc(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8628097106802094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90LPlaoWVo9K",
        "outputId": "b6b2465e-3b6c-4368-fb84-5b2cb89989fc"
      },
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from mlxtend.plotting import plot_confusion_matrix \n",
        "# %matplotlib inline\n",
        "\n",
        "#cm=metrics.confusion_matrix(y_true, y_pred)\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "#print('AUC: %.3f' % auc)\n",
        "#print('Accuracy: {}'.format(accuracy_score(y_true, y_pred)))\n",
        "\n",
        "# Plot ROC curve\n",
        "lw = 2\n",
        "sns.set_style({'axes.grid' : False})\n",
        "sns.set_style(\"darkgrid\")\n",
        "ax1 = sns.lineplot(fpr, tpr, color='darkorange',\n",
        "        lw=lw, label='AUC = %0.2f' % auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "ax1.set_title('Receiver operating characteristic')\n",
        "ax1.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}