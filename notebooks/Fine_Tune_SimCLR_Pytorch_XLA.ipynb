{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine Tune SimCLR Pytorch XLA",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPGWojyTVPTTW5G5pPuM/MC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/Fine_Tune_SimCLR_Pytorch_XLA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj5ZiBEIDFm5",
        "outputId": "7fbf5533-29e7-4d00-ae43-50febf88d366"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==1.8.1 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl tensorboard-plugin-profile"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-xla==1.8.1\n",
            "  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl (145.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 145.0 MB 12 kB/s \n",
            "\u001b[?25hCollecting cloud-tpu-client==0.10\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting torch==1.8.1\n",
            "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1 MB 2.4 kB/s \n",
            "\u001b[?25hCollecting tensorboard-plugin-profile\n",
            "  Downloading tensorboard_plugin_profile-2.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 61.1 MB/s \n",
            "\u001b[?25hCollecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.34.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Collecting gviz-api>=1.9.0\n",
            "  Downloading gviz_api-1.9.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile) (1.0.1)\n",
            "Installing collected packages: gviz-api, google-api-python-client, torch-xla, torch, tensorboard-plugin-profile, cloud-tpu-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "earthengine-api 0.1.278 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0 gviz-api-1.9.0 tensorboard-plugin-profile-2.5.0 torch-1.8.1 torch-xla-1.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k151pjHTcAMs",
        "outputId": "b20671e3-34fa-43e4-cada-b68043c7201a"
      },
      "source": [
        "!pip uninstall torch -y\n",
        "!pip install torch==1.8.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 1.8.1\n",
            "Uninstalling torch-1.8.1:\n",
            "  Successfully uninstalled torch-1.8.1\n",
            "Collecting torch==1.8.1\n",
            "  Using cached torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqgt-SPZs69T"
      },
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "from google.colab import auth, drive\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt0HysgJtDr-",
        "outputId": "f3c82c39-8a44-4ba1-9b63-a8f204d19dbb"
      },
      "source": [
        "import torch_xla.utils.serialization as xser"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.8.1...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.8.1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycMSo6gEs84s",
        "outputId": "d74397ba-b04b-4b22-ac55-ea95c1c78e5f"
      },
      "source": [
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqTsJNBCaPgG"
      },
      "source": [
        "import gdown\n",
        "\n",
        "def download(data, url):\n",
        "    # Download dataset\n",
        "    import zipfile\n",
        "    url = url\n",
        "    output = \"{}.zip\".format(data)\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # Uncompress dataset\n",
        "    local_zip = '{}.zip'.format(data)\n",
        "    zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imFIHTdSayCb"
      },
      "source": [
        "data_samples = {\n",
        "    \"sample@200\": \"https://drive.google.com/uc?id=1FfV7YyDJvNUCDP5r3-8iQfZ2-xJp_pgb\",\n",
        "    \"sample@500\": \"https://drive.google.com/uc?id=1dHwUqpmSogEdjAB9rwDUL-OKFRUcVXte\",\n",
        "    \"sample@1000\": \"https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\",\n",
        "    \"sample@2000\": \"https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\",\n",
        "    \"sample@3000\": \"https://drive.google.com/uc?id=1_yre5K9YYvJgSrT4xvrI8eD_htucIywA\",\n",
        "    \"sample@4000_images\": \"https://drive.google.com/uc?id=1dqVB8EozEpwWzyuU80AauoQmsiw3Gtm2\",\n",
        "    \"sample@20000\": \"https://drive.google.com/uc?id=1MTDpLzpmhSiZq2jSdmHx2UDPn9FC8gzO\",\n",
        "    \"val-voets-tf\": \"https://drive.google.com/uc?id=1VzVgMGTkBBPG2qbzLunD9HvLzH6tcyrv\",\n",
        "    \"train_voets\": \"https://drive.google.com/uc?id=1AmcFh1MOOZ6aqKm2eO7XEdgmIEqHKTZ5\",\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\"\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jJgVayva20x"
      },
      "source": [
        "LABELED = 'sample@1000'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIQsaT_Ta75z",
        "outputId": "4aafca8b-f732-4613-aaa3-2b4151b1c81e"
      },
      "source": [
        "URL_LABELED = data_samples[LABELED]\n",
        "download(LABELED, URL_LABELED)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\n",
            "To: /content/sample@1000.zip\n",
            "108MB [00:00, 109MB/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCO3Y6dlELcr"
      },
      "source": [
        "Upload file argparse from https://raw.githubusercontent.com/pytorch/xla/master/test/args_parse.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfNVM3RMRIl1",
        "outputId": "83d7fb9e-70c6-4d5e-a835-43b94eed5b81"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/pytorch/xla/master/test/args_parse.py\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-22 14:30:29--  https://raw.githubusercontent.com/pytorch/xla/master/test/args_parse.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2036 (2.0K) [text/plain]\n",
            "Saving to: ‘args_parse.py’\n",
            "\n",
            "\rargs_parse.py         0%[                    ]       0  --.-KB/s               \rargs_parse.py       100%[===================>]   1.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-22 14:30:29 (40.1 MB/s) - ‘args_parse.py’ saved [2036/2036]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYbCW5nqO66d"
      },
      "source": [
        "import args_parse\n",
        "\n",
        "SUPPORTED_MODELS = [\n",
        "    'alexnet', 'densenet121', 'densenet161', 'densenet169', 'densenet201',\n",
        "    'inception_v3', 'resnet101', 'resnet152', 'resnet18', 'resnet34',\n",
        "    'resnet50', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13',\n",
        "    'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn'\n",
        "]\n",
        "\n",
        "MODEL_OPTS = {\n",
        "    '--model': {\n",
        "        'choices': SUPPORTED_MODELS,\n",
        "        'default': 'resnet50',\n",
        "    },\n",
        "    '--test_set_batch_size': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--lr_scheduler_type': {\n",
        "        'type': str,\n",
        "    },\n",
        "    '--lr_scheduler_divide_every_n_epochs': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--lr_scheduler_divisor': {\n",
        "        'type': int,\n",
        "    },\n",
        "    '--test_only_at_end': {\n",
        "        'action': 'store_true',\n",
        "    },\n",
        "}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ggvTYidO9ZQ"
      },
      "source": [
        "FLAGS = args_parse.parse_common_options(\n",
        "    datadir=LABELED,\n",
        "    batch_size=None,\n",
        "    num_epochs=None,\n",
        "    momentum=None,\n",
        "    lr=None,\n",
        "    target_accuracy=None,\n",
        "    profiler_port=9012,\n",
        "    opts=MODEL_OPTS.items(),\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAjhjw4AgIZg"
      },
      "source": [
        "EPOCHS = 200"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CSubsgJShgy"
      },
      "source": [
        "FLAGS.fake_data = False\n",
        "FLAGS.num_epochs = EPOCHS\n",
        "FLAGS.batch_size = 64\n",
        "FLAGS.log_steps = 100\n",
        "FLAGS.num_cores = 8"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWDZngg-EgJx"
      },
      "source": [
        "Import schedulers from https://github.com/pytorch/xla/blob/master/test/schedulers.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C07yPHSMRVY7",
        "outputId": "f03365d7-830e-41ac-926b-fe0f5c57c184"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/pytorch/xla/master/test/schedulers.py"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-22 14:30:57--  https://raw.githubusercontent.com/pytorch/xla/master/test/schedulers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6083 (5.9K) [text/plain]\n",
            "Saving to: ‘schedulers.py’\n",
            "\n",
            "\rschedulers.py         0%[                    ]       0  --.-KB/s               \rschedulers.py       100%[===================>]   5.94K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-22 14:30:57 (90.8 MB/s) - ‘schedulers.py’ saved [6083/6083]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOH8ZjssOSd1"
      },
      "source": [
        "import os\n",
        "import schedulers\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch_xla\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.utils.utils as xu\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.test.test_utils as test_utils"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SX0pnOwOxBP"
      },
      "source": [
        "DEFAULT_KWARGS = dict(\n",
        "    batch_size=128,\n",
        "    test_set_batch_size=64,\n",
        "    num_epochs=200,\n",
        "    momentum=0.9,\n",
        "    lr=0.05,\n",
        "    target_accuracy=0.0,\n",
        ")\n",
        "MODEL_SPECIFIC_DEFAULTS = {\n",
        "    # Override some of the args in DEFAULT_KWARGS, or add them to the dict\n",
        "    # if they don't exist.\n",
        "    'resnet50':\n",
        "        dict(\n",
        "            DEFAULT_KWARGS, **{\n",
        "                'lr': 0.05,\n",
        "                'lr_scheduler_divide_every_n_epochs': 20,\n",
        "                'lr_scheduler_divisor': 5,\n",
        "                'lr_scheduler_type': 'WarmupAndExponentialDecayScheduler',\n",
        "            })\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nad72u1lOyyh"
      },
      "source": [
        "# Set any args that were not explicitly given by the user.\n",
        "default_value_dict = MODEL_SPECIFIC_DEFAULTS.get(FLAGS.model, DEFAULT_KWARGS)\n",
        "for arg, value in default_value_dict.items():\n",
        "  if getattr(FLAGS, arg) is None:\n",
        "    setattr(FLAGS, arg, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDkym-NUUocK",
        "outputId": "d4fb123f-8409-4efc-8d63-0f6e6d866baf"
      },
      "source": [
        "default_value_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 128,\n",
              " 'lr': 0.05,\n",
              " 'lr_scheduler_divide_every_n_epochs': 20,\n",
              " 'lr_scheduler_divisor': 5,\n",
              " 'lr_scheduler_type': 'WarmupAndExponentialDecayScheduler',\n",
              " 'momentum': 0.9,\n",
              " 'num_epochs': 200,\n",
              " 'target_accuracy': 0.0,\n",
              " 'test_set_batch_size': 64}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaSFCSsHeVxY"
      },
      "source": [
        "def get_model_property(key):\n",
        "  default_model_property = {\n",
        "      'img_dim': 224,\n",
        "      'model_fn': getattr(torchvision.models, FLAGS.model)\n",
        "  }\n",
        "  model_properties = {\n",
        "      'inception_v3': {\n",
        "          'img_dim': 299,\n",
        "          'model_fn': lambda: torchvision.models.inception_v3(aux_logits=False)\n",
        "      },\n",
        "  }\n",
        "  model_fn = model_properties.get(FLAGS.model, default_model_property)[key]\n",
        "  return model_fn"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4xo5QNANY_Q"
      },
      "source": [
        "def _train_update(device, step, loss, tracker, epoch, writer):\n",
        "  test_utils.print_training_update(\n",
        "      device,\n",
        "      step,\n",
        "      loss.item(),\n",
        "      tracker.rate(),\n",
        "      tracker.global_rate(),\n",
        "      epoch,\n",
        "      summary_writer=writer)\n",
        "\n",
        "\n",
        "def train_imagenet():\n",
        "  print('==> Preparing data..')\n",
        "  img_dim = get_model_property('img_dim')\n",
        "  if FLAGS.fake_data:\n",
        "    train_dataset_len = 1200000  # Roughly the size of Imagenet dataset.\n",
        "    train_loader = xu.SampleGenerator(\n",
        "        data=(torch.zeros(FLAGS.batch_size, 3, img_dim, img_dim),\n",
        "              torch.zeros(FLAGS.batch_size, dtype=torch.int64)),\n",
        "        sample_count=train_dataset_len // FLAGS.batch_size //\n",
        "        xm.xrt_world_size())\n",
        "    test_loader = xu.SampleGenerator(\n",
        "        data=(torch.zeros(FLAGS.test_set_batch_size, 3, img_dim, img_dim),\n",
        "              torch.zeros(FLAGS.test_set_batch_size, dtype=torch.int64)),\n",
        "        sample_count=50000 // FLAGS.batch_size // xm.xrt_world_size())\n",
        "  else:\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    train_dataset = torchvision.datasets.ImageFolder(\n",
        "        os.path.join(FLAGS.datadir, 'train'),\n",
        "        transforms.Compose([\n",
        "            transforms.RandomResizedCrop(img_dim),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "    train_dataset_len = len(train_dataset.imgs)\n",
        "    resize_dim = max(img_dim, 256)\n",
        "\n",
        "\n",
        "    train_sampler, test_sampler = None, None\n",
        "    if xm.xrt_world_size() > 1:\n",
        "      train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "          train_dataset,\n",
        "          num_replicas=xm.xrt_world_size(),\n",
        "          rank=xm.get_ordinal(),\n",
        "          shuffle=True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=FLAGS.batch_size,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=FLAGS.drop_last,\n",
        "        shuffle=False if train_sampler else True,\n",
        "        num_workers=FLAGS.num_workers)\n",
        "\n",
        "  torch.manual_seed(42)\n",
        "\n",
        "  device = xm.xla_device()\n",
        "  model = get_model_property('model_fn')().to(device)\n",
        "\n",
        "  model.fc = nn.Sequential(\n",
        "        nn.Linear(2048, 512),\n",
        "        nn.Linear(512, 1),\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  state_dict = xser.load('/content/drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR-epoch-100.pt')\n",
        "  #state_dict = xser.load('/content/drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR-70.pt')\n",
        "\n",
        "  for k in list(state_dict.keys()):\n",
        "    if k.startswith('backbone.'):\n",
        "      if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "        # remove prefix\n",
        "        state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "    del state_dict[k]\n",
        "\n",
        "  log = model.load_state_dict(state_dict, strict=False)\n",
        "  print(log)\n",
        "\n",
        "  writer = None\n",
        "  if xm.is_master_ordinal():\n",
        "    writer = test_utils.get_summary_writer(FLAGS.logdir)\n",
        "\n",
        "\n",
        "  optimizer = optim.SGD(\n",
        "      model.parameters(),\n",
        "      lr=FLAGS.lr,\n",
        "      momentum=FLAGS.momentum,\n",
        "      weight_decay=1e-4)\n",
        "\n",
        "  num_training_steps_per_epoch = train_dataset_len // (\n",
        "      FLAGS.batch_size * xm.xrt_world_size())\n",
        "  lr_scheduler = schedulers.wrap_optimizer_with_scheduler(\n",
        "      optimizer,\n",
        "      scheduler_type=getattr(FLAGS, 'lr_scheduler_type', None),\n",
        "      scheduler_divisor=getattr(FLAGS, 'lr_scheduler_divisor', None),\n",
        "      scheduler_divide_every_n_epochs=getattr(\n",
        "          FLAGS, 'lr_scheduler_divide_every_n_epochs', None),\n",
        "      num_steps_per_epoch=num_training_steps_per_epoch,\n",
        "      summary_writer=writer)\n",
        "  \n",
        "\n",
        "  #loss_fn = nn.CrossEntropyLoss()\n",
        "  loss_fn = nn.BCELoss()\n",
        "\n",
        "  def train_loop_fn(loader, epoch):\n",
        "    tracker = xm.RateTracker()\n",
        "    model.train()\n",
        "    for step, (data, target) in enumerate(loader):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "\n",
        "      target = target.unsqueeze(1) ## YO\n",
        "      target = target.float() # YOO\n",
        "\n",
        "      loss = loss_fn(output, target)\n",
        "      loss.backward()\n",
        "      xm.optimizer_step(optimizer)\n",
        "      tracker.add(FLAGS.batch_size)\n",
        "      if lr_scheduler:\n",
        "        lr_scheduler.step()\n",
        "      if step % FLAGS.log_steps == 0:\n",
        "        xm.add_step_closure(\n",
        "            _train_update, args=(device, step, loss, tracker, epoch, writer))\n",
        "\n",
        "  train_device_loader = pl.MpDeviceLoader(train_loader, device)\n",
        "\n",
        "  for epoch in range(1, FLAGS.num_epochs + 1):\n",
        "    xm.master_print('Epoch {} train begin {}'.format(epoch, test_utils.now()))\n",
        "    train_loop_fn(train_device_loader, epoch)\n",
        "    xm.master_print('Epoch {} train end {}'.format(epoch, test_utils.now()))\n",
        "\n",
        "    if FLAGS.metrics_debug:\n",
        "      xm.master_print(met.metrics_report())\n",
        "\n",
        "  test_utils.close_summary_writer(writer)\n",
        "\n",
        "  xm.master_print(\"Finished training\")\n",
        "\n",
        "  xm.save(\n",
        "            model.state_dict(),\n",
        "            \"drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR-Finetuned-Test-{}.pt\".format(LABELED)\n",
        "        )\n",
        "\n",
        "  return 0"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww2PE7HZOsGH"
      },
      "source": [
        "def _mp_fn(index, flags):\n",
        "  global FLAGS\n",
        "  FLAGS = flags\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  ans = train_imagenet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9h_SHYQUw82",
        "outputId": "c702e385-e1c9-4e05-a1e4-280094cf820a"
      },
      "source": [
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "==> Preparing data..\n",
            "_IncompatibleKeys(missing_keys=['fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias'], unexpected_keys=[])\n",
            "Epoch 1 train begin 22:39:37\n",
            "_IncompatibleKeys(missing_keys=['fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias'], unexpected_keys=[])\n",
            "_IncompatibleKeys(missing_keys=['fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias'], unexpected_keys=[])\n",
            "_IncompatibleKeys(missing_keys=['fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias'], unexpected_keys=[])\n",
            "_IncompatibleKeys(missing_keys=['fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias'], unexpected_keys=[])\n",
            "_IncompatibleKeys(missing_keys=['fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias'], unexpected_keys=[])\n",
            "_IncompatibleKeys(missing_keys=['fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias'], unexpected_keys=[])\n",
            "_IncompatibleKeys(missing_keys=['fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias'], unexpected_keys=[])\n",
            "| Training Device=xla:0/3 Epoch=1 Step=0 Loss=0.69564 Rate=10.79 GlobalRate=10.79 Time=22:39:51\n",
            "| Training Device=xla:0/7 Epoch=1 Step=0 Loss=0.69202 Rate=6.75 GlobalRate=6.75 Time=22:39:51\n",
            "| Training Device=xla:1/0 Epoch=1 Step=0 Loss=0.69051 Rate=4.64 GlobalRate=4.64 Time=22:39:51\n",
            "| Training Device=xla:0/5 Epoch=1 Step=0 Loss=0.68819 Rate=26.84 GlobalRate=26.84 Time=22:39:51\n",
            "| Training Device=xla:0/2 Epoch=1 Step=0 Loss=0.68597 Rate=7.23 GlobalRate=7.23 Time=22:39:51\n",
            "| Training Device=xla:0/1 Epoch=1 Step=0 Loss=0.69081 Rate=11.25 GlobalRate=11.25 Time=22:39:51\n",
            "| Training Device=xla:0/6 Epoch=1 Step=0 Loss=0.68648 Rate=21.81 GlobalRate=21.81 Time=22:39:51\n",
            "| Training Device=xla:0/4 Epoch=1 Step=0 Loss=0.68148 Rate=21.24 GlobalRate=21.24 Time=22:39:51\n",
            "Epoch 1 train end 22:39:51\n",
            "Epoch 2 train begin 22:39:51\n",
            "| Training Device=xla:0/1 Epoch=2 Step=0 Loss=0.68636 Rate=10.04 GlobalRate=10.04 Time=22:39:58\n",
            "| Training Device=xla:0/7 Epoch=2 Step=0 Loss=0.68494 Rate=10.04 GlobalRate=10.04 Time=22:39:58\n",
            "| Training Device=xla:0/2 Epoch=2 Step=0 Loss=0.68582 Rate=10.04 GlobalRate=10.04 Time=22:39:58\n",
            "| Training Device=xla:0/3 Epoch=2 Step=0 Loss=0.68825 Rate=10.04 GlobalRate=10.04 Time=22:39:58\n",
            "| Training Device=xla:0/5 Epoch=2 Step=0 Loss=0.68468 Rate=10.03 GlobalRate=10.03 Time=22:39:58\n",
            "| Training Device=xla:0/4 Epoch=2 Step=0 Loss=0.68039 Rate=10.04 GlobalRate=10.04 Time=22:39:58\n",
            "| Training Device=xla:1/0 Epoch=2 Step=0 Loss=0.68667 Rate=10.02 GlobalRate=10.02 Time=22:39:58\n",
            "| Training Device=xla:0/6 Epoch=2 Step=0 Loss=0.68450 Rate=10.01 GlobalRate=10.01 Time=22:39:58\n",
            "Epoch 2 train end 22:39:58\n",
            "Epoch 3 train begin 22:39:58\n",
            "| Training Device=xla:0/3 Epoch=3 Step=0 Loss=0.67871 Rate=10.22 GlobalRate=10.22 Time=22:40:04\n",
            "| Training Device=xla:0/5 Epoch=3 Step=0 Loss=0.67788 Rate=10.22 GlobalRate=10.22 Time=22:40:04\n",
            "| Training Device=xla:0/7 Epoch=3 Step=0 Loss=0.67034 Rate=10.21 GlobalRate=10.21 Time=22:40:04\n",
            "| Training Device=xla:1/0 Epoch=3 Step=0 Loss=0.68103 Rate=10.22 GlobalRate=10.22 Time=22:40:04\n",
            "| Training Device=xla:0/6 Epoch=3 Step=0 Loss=0.67862 Rate=10.21 GlobalRate=10.21 Time=22:40:04\n",
            "| Training Device=xla:0/1 Epoch=3 Step=0 Loss=0.67905 Rate=10.21 GlobalRate=10.21 Time=22:40:04\n",
            "| Training Device=xla:0/4 Epoch=3 Step=0 Loss=0.67045 Rate=10.21 GlobalRate=10.21 Time=22:40:04\n",
            "| Training Device=xla:0/2 Epoch=3 Step=0 Loss=0.67833 Rate=10.19 GlobalRate=10.19 Time=22:40:04\n",
            "Epoch 3 train end 22:40:04\n",
            "Epoch 4 train begin 22:40:04\n",
            "| Training Device=xla:0/7 Epoch=4 Step=0 Loss=0.65712 Rate=10.17 GlobalRate=10.17 Time=22:40:11\n",
            "| Training Device=xla:0/1 Epoch=4 Step=0 Loss=0.66037 Rate=10.17 GlobalRate=10.17 Time=22:40:11\n",
            "| Training Device=xla:1/0 Epoch=4 Step=0 Loss=0.67338 Rate=10.17 GlobalRate=10.17 Time=22:40:11\n",
            "| Training Device=xla:0/5 Epoch=4 Step=0 Loss=0.66152 Rate=10.17 GlobalRate=10.17 Time=22:40:11\n",
            "| Training Device=xla:0/6 Epoch=4 Step=0 Loss=0.66674 Rate=10.17 GlobalRate=10.17 Time=22:40:11\n",
            "| Training Device=xla:0/4 Epoch=4 Step=0 Loss=0.65139 Rate=10.16 GlobalRate=10.16 Time=22:40:11\n",
            "| Training Device=xla:0/2 Epoch=4 Step=0 Loss=0.67032 Rate=10.17 GlobalRate=10.17 Time=22:40:11\n",
            "| Training Device=xla:0/3 Epoch=4 Step=0 Loss=0.66687 Rate=10.14 GlobalRate=10.14 Time=22:40:11\n",
            "Epoch 4 train end 22:40:11\n",
            "Epoch 5 train begin 22:40:11\n",
            "| Training Device=xla:0/5 Epoch=5 Step=0 Loss=0.64987 Rate=10.16 GlobalRate=10.16 Time=22:40:17\n",
            "| Training Device=xla:0/4 Epoch=5 Step=0 Loss=0.62257 Rate=10.16 GlobalRate=10.16 Time=22:40:17\n",
            "| Training Device=xla:1/0 Epoch=5 Step=0 Loss=0.66044 Rate=10.16 GlobalRate=10.16 Time=22:40:17\n",
            "| Training Device=xla:0/3 Epoch=5 Step=0 Loss=0.66600 Rate=10.15 GlobalRate=10.15 Time=22:40:17\n",
            "| Training Device=xla:0/2 Epoch=5 Step=0 Loss=0.64704 Rate=10.15 GlobalRate=10.15 Time=22:40:17\n",
            "| Training Device=xla:0/7 Epoch=5 Step=0 Loss=0.64530 Rate=10.15 GlobalRate=10.15 Time=22:40:17\n",
            "| Training Device=xla:0/6 Epoch=5 Step=0 Loss=0.64674 Rate=10.15 GlobalRate=10.15 Time=22:40:17\n",
            "| Training Device=xla:0/1 Epoch=5 Step=0 Loss=0.63772 Rate=10.15 GlobalRate=10.15 Time=22:40:17\n",
            "Epoch 5 train end 22:40:18\n",
            "Epoch 6 train begin 22:40:18\n",
            "| Training Device=xla:0/1 Epoch=6 Step=0 Loss=0.62371 Rate=10.13 GlobalRate=10.13 Time=22:40:24\n",
            "| Training Device=xla:0/4 Epoch=6 Step=0 Loss=0.58403 Rate=10.13 GlobalRate=10.13 Time=22:40:24\n",
            "| Training Device=xla:0/6 Epoch=6 Step=0 Loss=0.62738 Rate=10.13 GlobalRate=10.13 Time=22:40:24\n",
            "| Training Device=xla:0/3 Epoch=6 Step=0 Loss=0.65142 Rate=10.13 GlobalRate=10.13 Time=22:40:24\n",
            "| Training Device=xla:0/5 Epoch=6 Step=0 Loss=0.61664 Rate=10.12 GlobalRate=10.12 Time=22:40:24\n",
            "| Training Device=xla:1/0 Epoch=6 Step=0 Loss=0.64791 Rate=10.13 GlobalRate=10.12 Time=22:40:24\n",
            "| Training Device=xla:0/2 Epoch=6 Step=0 Loss=0.63350 Rate=10.12 GlobalRate=10.12 Time=22:40:24\n",
            "| Training Device=xla:0/7 Epoch=6 Step=0 Loss=0.62678 Rate=10.12 GlobalRate=10.12 Time=22:40:24\n",
            "Epoch 6 train end 22:40:24\n",
            "Epoch 7 train begin 22:40:24\n",
            "| Training Device=xla:0/1 Epoch=7 Step=0 Loss=0.61512 Rate=10.17 GlobalRate=10.17 Time=22:40:30\n",
            "| Training Device=xla:0/7 Epoch=7 Step=0 Loss=0.58431 Rate=10.17 GlobalRate=10.17 Time=22:40:30\n",
            "| Training Device=xla:0/5 Epoch=7 Step=0 Loss=0.58535 Rate=10.17 GlobalRate=10.17 Time=22:40:30\n",
            "| Training Device=xla:0/4 Epoch=7 Step=0 Loss=0.55899 Rate=10.17 GlobalRate=10.17 Time=22:40:30\n",
            "| Training Device=xla:0/6 Epoch=7 Step=0 Loss=0.60065 Rate=10.17 GlobalRate=10.17 Time=22:40:30\n",
            "| Training Device=xla:0/2 Epoch=7 Step=0 Loss=0.59899 Rate=10.17 GlobalRate=10.17 Time=22:40:30\n",
            "| Training Device=xla:0/3 Epoch=7 Step=0 Loss=0.64566 Rate=10.16 GlobalRate=10.16 Time=22:40:30\n",
            "| Training Device=xla:1/0 Epoch=7 Step=0 Loss=0.61682 Rate=10.17 GlobalRate=10.17 Time=22:40:30\n",
            "Epoch 7 train end 22:40:31\n",
            "Epoch 8 train begin 22:40:31\n",
            "| Training Device=xla:0/2 Epoch=8 Step=0 Loss=0.57511 Rate=10.21 GlobalRate=10.21 Time=22:40:37\n",
            "| Training Device=xla:0/7 Epoch=8 Step=0 Loss=0.56905 Rate=10.21 GlobalRate=10.21 Time=22:40:37\n",
            "| Training Device=xla:0/5 Epoch=8 Step=0 Loss=0.54563 Rate=10.21 GlobalRate=10.21 Time=22:40:37\n",
            "| Training Device=xla:0/3 Epoch=8 Step=0 Loss=0.62278 Rate=10.21 GlobalRate=10.21 Time=22:40:37\n",
            "| Training Device=xla:1/0 Epoch=8 Step=0 Loss=0.59506 Rate=10.21 GlobalRate=10.21 Time=22:40:37\n",
            "| Training Device=xla:0/4 Epoch=8 Step=0 Loss=0.51855 Rate=10.20 GlobalRate=10.20 Time=22:40:37\n",
            "| Training Device=xla:0/6 Epoch=8 Step=0 Loss=0.58158 Rate=10.20 GlobalRate=10.20 Time=22:40:37\n",
            "| Training Device=xla:0/1 Epoch=8 Step=0 Loss=0.55829 Rate=10.20 GlobalRate=10.20 Time=22:40:37\n",
            "Epoch 8 train end 22:40:37\n",
            "Epoch 9 train begin 22:40:37\n",
            "| Training Device=xla:0/6 Epoch=9 Step=0 Loss=0.58568 Rate=10.16 GlobalRate=10.16 Time=22:40:43\n",
            "| Training Device=xla:0/5 Epoch=9 Step=0 Loss=0.47737 Rate=10.16 GlobalRate=10.16 Time=22:40:43\n",
            "| Training Device=xla:0/4 Epoch=9 Step=0 Loss=0.46968 Rate=10.16 GlobalRate=10.16 Time=22:40:43\n",
            "| Training Device=xla:0/2 Epoch=9 Step=0 Loss=0.53476 Rate=10.16 GlobalRate=10.16 Time=22:40:43\n",
            "| Training Device=xla:0/7 Epoch=9 Step=0 Loss=0.49899 Rate=10.15 GlobalRate=10.15 Time=22:40:43\n",
            "| Training Device=xla:1/0 Epoch=9 Step=0 Loss=0.57631 Rate=10.16 GlobalRate=10.16 Time=22:40:43\n",
            "| Training Device=xla:0/3 Epoch=9 Step=0 Loss=0.59711 Rate=10.16 GlobalRate=10.16 Time=22:40:43\n",
            "| Training Device=xla:0/1 Epoch=9 Step=0 Loss=0.53442 Rate=10.16 GlobalRate=10.16 Time=22:40:43\n",
            "Epoch 9 train end 22:40:44\n",
            "Epoch 10 train begin 22:40:44\n",
            "| Training Device=xla:0/3 Epoch=10 Step=0 Loss=0.61924 Rate=10.16 GlobalRate=10.16 Time=22:40:50\n",
            "| Training Device=xla:0/7 Epoch=10 Step=0 Loss=0.48120 Rate=10.16 GlobalRate=10.16 Time=22:40:50\n",
            "| Training Device=xla:0/6 Epoch=10 Step=0 Loss=0.55796 Rate=10.16 GlobalRate=10.16 Time=22:40:50\n",
            "| Training Device=xla:0/1 Epoch=10 Step=0 Loss=0.49806 Rate=10.16 GlobalRate=10.16 Time=22:40:50\n",
            "| Training Device=xla:0/2 Epoch=10 Step=0 Loss=0.50385 Rate=10.16 GlobalRate=10.16 Time=22:40:50\n",
            "| Training Device=xla:0/5 Epoch=10 Step=0 Loss=0.44661 Rate=10.16 GlobalRate=10.16 Time=22:40:50\n",
            "| Training Device=xla:1/0 Epoch=10 Step=0 Loss=0.60949 Rate=10.16 GlobalRate=10.16 Time=22:40:50\n",
            "| Training Device=xla:0/4 Epoch=10 Step=0 Loss=0.44721 Rate=10.15 GlobalRate=10.15 Time=22:40:50\n",
            "Epoch 10 train end 22:40:50\n",
            "Epoch 11 train begin 22:40:50\n",
            "| Training Device=xla:0/2 Epoch=11 Step=0 Loss=0.44895 Rate=10.19 GlobalRate=10.19 Time=22:40:57\n",
            "| Training Device=xla:1/0 Epoch=11 Step=0 Loss=0.54930 Rate=10.20 GlobalRate=10.20 Time=22:40:57\n",
            "| Training Device=xla:0/6 Epoch=11 Step=0 Loss=0.59010 Rate=10.19 GlobalRate=10.19 Time=22:40:57\n",
            "| Training Device=xla:0/4 Epoch=11 Step=0 Loss=0.45635 Rate=10.19 GlobalRate=10.19 Time=22:40:57\n",
            "| Training Device=xla:0/3 Epoch=11 Step=0 Loss=0.63323 Rate=10.19 GlobalRate=10.19 Time=22:40:57\n",
            "| Training Device=xla:0/5 Epoch=11 Step=0 Loss=0.45512 Rate=10.18 GlobalRate=10.18 Time=22:40:57\n",
            "| Training Device=xla:0/7 Epoch=11 Step=0 Loss=0.42894 Rate=10.19 GlobalRate=10.19 Time=22:40:57\n",
            "| Training Device=xla:0/1 Epoch=11 Step=0 Loss=0.42306 Rate=10.19 GlobalRate=10.19 Time=22:40:57\n",
            "Epoch 11 train end 22:40:57\n",
            "Epoch 12 train begin 22:40:57\n",
            "| Training Device=xla:0/3 Epoch=12 Step=0 Loss=0.55868 Rate=10.21 GlobalRate=10.21 Time=22:41:03\n",
            "| Training Device=xla:1/0 Epoch=12 Step=0 Loss=0.48772 Rate=10.22 GlobalRate=10.22 Time=22:41:03\n",
            "| Training Device=xla:0/5 Epoch=12 Step=0 Loss=0.44896 Rate=10.21 GlobalRate=10.21 Time=22:41:03\n",
            "| Training Device=xla:0/4 Epoch=12 Step=0 Loss=0.40670 Rate=10.21 GlobalRate=10.21 Time=22:41:03\n",
            "| Training Device=xla:0/2 Epoch=12 Step=0 Loss=0.44221 Rate=10.21 GlobalRate=10.21 Time=22:41:03\n",
            "| Training Device=xla:0/1 Epoch=12 Step=0 Loss=0.40094 Rate=10.20 GlobalRate=10.20 Time=22:41:03\n",
            "| Training Device=xla:0/7 Epoch=12 Step=0 Loss=0.42118 Rate=10.20 GlobalRate=10.20 Time=22:41:03\n",
            "| Training Device=xla:0/6 Epoch=12 Step=0 Loss=0.61768 Rate=10.20 GlobalRate=10.20 Time=22:41:03\n",
            "Epoch 12 train end 22:41:03\n",
            "Epoch 13 train begin 22:41:03\n",
            "| Training Device=xla:0/1 Epoch=13 Step=0 Loss=0.44144 Rate=10.14 GlobalRate=10.14 Time=22:41:10\n",
            "| Training Device=xla:0/4 Epoch=13 Step=0 Loss=0.40216 Rate=10.14 GlobalRate=10.14 Time=22:41:10\n",
            "| Training Device=xla:0/3 Epoch=13 Step=0 Loss=0.57617 Rate=10.14 GlobalRate=10.14 Time=22:41:10\n",
            "| Training Device=xla:0/2 Epoch=13 Step=0 Loss=0.44119 Rate=10.14 GlobalRate=10.14 Time=22:41:10\n",
            "| Training Device=xla:0/7 Epoch=13 Step=0 Loss=0.39281 Rate=10.14 GlobalRate=10.14 Time=22:41:10\n",
            "| Training Device=xla:0/6 Epoch=13 Step=0 Loss=0.51820 Rate=10.14 GlobalRate=10.14 Time=22:41:10\n",
            "| Training Device=xla:0/5 Epoch=13 Step=0 Loss=0.39015 Rate=10.13 GlobalRate=10.13 Time=22:41:10\n",
            "| Training Device=xla:1/0 Epoch=13 Step=0 Loss=0.49390 Rate=10.14 GlobalRate=10.14 Time=22:41:10\n",
            "Epoch 13 train end 22:41:10\n",
            "Epoch 14 train begin 22:41:10\n",
            "| Training Device=xla:0/4 Epoch=14 Step=0 Loss=0.40158 Rate=10.21 GlobalRate=10.21 Time=22:41:16\n",
            "| Training Device=xla:0/7 Epoch=14 Step=0 Loss=0.40746 Rate=10.21 GlobalRate=10.21 Time=22:41:16\n",
            "| Training Device=xla:0/5 Epoch=14 Step=0 Loss=0.46468 Rate=10.21 GlobalRate=10.21 Time=22:41:16\n",
            "| Training Device=xla:0/6 Epoch=14 Step=0 Loss=0.52095 Rate=10.21 GlobalRate=10.21 Time=22:41:16\n",
            "| Training Device=xla:0/1 Epoch=14 Step=0 Loss=0.44060 Rate=10.21 GlobalRate=10.21 Time=22:41:16\n",
            "| Training Device=xla:0/2 Epoch=14 Step=0 Loss=0.47061 Rate=10.21 GlobalRate=10.21 Time=22:41:16\n",
            "| Training Device=xla:1/0 Epoch=14 Step=0 Loss=0.52085 Rate=10.21 GlobalRate=10.21 Time=22:41:16\n",
            "| Training Device=xla:0/3 Epoch=14 Step=0 Loss=0.60417 Rate=10.20 GlobalRate=10.20 Time=22:41:16\n",
            "Epoch 14 train end 22:41:16\n",
            "Epoch 15 train begin 22:41:16\n",
            "| Training Device=xla:0/1 Epoch=15 Step=0 Loss=0.40614 Rate=10.23 GlobalRate=10.23 Time=22:41:23\n",
            "| Training Device=xla:0/3 Epoch=15 Step=0 Loss=0.58939 Rate=10.23 GlobalRate=10.23 Time=22:41:23\n",
            "| Training Device=xla:0/5 Epoch=15 Step=0 Loss=0.36314 Rate=10.23 GlobalRate=10.23 Time=22:41:23\n",
            "| Training Device=xla:0/7 Epoch=15 Step=0 Loss=0.39504 Rate=10.23 GlobalRate=10.23 Time=22:41:23\n",
            "| Training Device=xla:0/6 Epoch=15 Step=0 Loss=0.46723 Rate=10.23 GlobalRate=10.23 Time=22:41:23\n",
            "| Training Device=xla:0/4 Epoch=15 Step=0 Loss=0.39342 Rate=10.23 GlobalRate=10.23 Time=22:41:23\n",
            "| Training Device=xla:1/0 Epoch=15 Step=0 Loss=0.52148 Rate=10.24 GlobalRate=10.24 Time=22:41:23\n",
            "| Training Device=xla:0/2 Epoch=15 Step=0 Loss=0.40579 Rate=10.23 GlobalRate=10.23 Time=22:41:23\n",
            "Epoch 15 train end 22:41:23\n",
            "Epoch 16 train begin 22:41:23\n",
            "| Training Device=xla:0/6 Epoch=16 Step=0 Loss=0.46858 Rate=10.16 GlobalRate=10.16 Time=22:41:29\n",
            "| Training Device=xla:0/3 Epoch=16 Step=0 Loss=0.54541 Rate=10.16 GlobalRate=10.16 Time=22:41:29\n",
            "| Training Device=xla:0/2 Epoch=16 Step=0 Loss=0.38242 Rate=10.16 GlobalRate=10.16 Time=22:41:29\n",
            "| Training Device=xla:0/5 Epoch=16 Step=0 Loss=0.39068 Rate=10.16 GlobalRate=10.16 Time=22:41:29\n",
            "| Training Device=xla:1/0 Epoch=16 Step=0 Loss=0.45883 Rate=10.16 GlobalRate=10.16 Time=22:41:29\n",
            "| Training Device=xla:0/7 Epoch=16 Step=0 Loss=0.38356 Rate=10.16 GlobalRate=10.16 Time=22:41:29\n",
            "| Training Device=xla:0/4 Epoch=16 Step=0 Loss=0.39445 Rate=10.16 GlobalRate=10.16 Time=22:41:29\n",
            "| Training Device=xla:0/1 Epoch=16 Step=0 Loss=0.45486 Rate=10.15 GlobalRate=10.15 Time=22:41:29\n",
            "Epoch 16 train end 22:41:29\n",
            "Epoch 17 train begin 22:41:29\n",
            "| Training Device=xla:0/2 Epoch=17 Step=0 Loss=0.42392 Rate=10.18 GlobalRate=10.18 Time=22:41:36\n",
            "| Training Device=xla:0/1 Epoch=17 Step=0 Loss=0.38049 Rate=10.18 GlobalRate=10.18 Time=22:41:36\n",
            "| Training Device=xla:0/4 Epoch=17 Step=0 Loss=0.36500 Rate=10.18 GlobalRate=10.18 Time=22:41:36\n",
            "| Training Device=xla:0/7 Epoch=17 Step=0 Loss=0.38868 Rate=10.18 GlobalRate=10.18 Time=22:41:36\n",
            "| Training Device=xla:1/0 Epoch=17 Step=0 Loss=0.47079 Rate=10.18 GlobalRate=10.18 Time=22:41:36\n",
            "| Training Device=xla:0/3 Epoch=17 Step=0 Loss=0.53475 Rate=10.17 GlobalRate=10.17 Time=22:41:36\n",
            "| Training Device=xla:0/6 Epoch=17 Step=0 Loss=0.43929 Rate=10.17 GlobalRate=10.17 Time=22:41:36\n",
            "| Training Device=xla:0/5 Epoch=17 Step=0 Loss=0.35013 Rate=10.17 GlobalRate=10.17 Time=22:41:36\n",
            "Epoch 17 train end 22:41:36\n",
            "Epoch 18 train begin 22:41:36\n",
            "| Training Device=xla:0/1 Epoch=18 Step=0 Loss=0.41315 Rate=10.22 GlobalRate=10.22 Time=22:41:42\n",
            "| Training Device=xla:0/4 Epoch=18 Step=0 Loss=0.34283 Rate=10.22 GlobalRate=10.22 Time=22:41:42\n",
            "| Training Device=xla:0/6 Epoch=18 Step=0 Loss=0.46949 Rate=10.22 GlobalRate=10.22 Time=22:41:42\n",
            "| Training Device=xla:0/2 Epoch=18 Step=0 Loss=0.42964 Rate=10.22 GlobalRate=10.22 Time=22:41:42\n",
            "| Training Device=xla:0/7 Epoch=18 Step=0 Loss=0.35967 Rate=10.22 GlobalRate=10.22 Time=22:41:42\n",
            "| Training Device=xla:0/5 Epoch=18 Step=0 Loss=0.38674 Rate=10.22 GlobalRate=10.22 Time=22:41:42\n",
            "| Training Device=xla:0/3 Epoch=18 Step=0 Loss=0.47159 Rate=10.22 GlobalRate=10.22 Time=22:41:42\n",
            "| Training Device=xla:1/0 Epoch=18 Step=0 Loss=0.44882 Rate=10.23 GlobalRate=10.23 Time=22:41:42\n",
            "Epoch 18 train end 22:41:42\n",
            "Epoch 19 train begin 22:41:42\n",
            "| Training Device=xla:0/5 Epoch=19 Step=0 Loss=0.34931 Rate=10.13 GlobalRate=10.13 Time=22:41:49\n",
            "| Training Device=xla:0/2 Epoch=19 Step=0 Loss=0.40255 Rate=10.13 GlobalRate=10.13 Time=22:41:49\n",
            "| Training Device=xla:1/0 Epoch=19 Step=0 Loss=0.44779 Rate=10.14 GlobalRate=10.14 Time=22:41:49\n",
            "| Training Device=xla:0/1 Epoch=19 Step=0 Loss=0.39112 Rate=10.13 GlobalRate=10.13 Time=22:41:49\n",
            "| Training Device=xla:0/3 Epoch=19 Step=0 Loss=0.51908 Rate=10.13 GlobalRate=10.13 Time=22:41:49\n",
            "| Training Device=xla:0/6 Epoch=19 Step=0 Loss=0.44684 Rate=10.13 GlobalRate=10.13 Time=22:41:49\n",
            "| Training Device=xla:0/7 Epoch=19 Step=0 Loss=0.32714 Rate=10.13 GlobalRate=10.13 Time=22:41:49\n",
            "| Training Device=xla:0/4 Epoch=19 Step=0 Loss=0.36035 Rate=10.13 GlobalRate=10.13 Time=22:41:49\n",
            "Epoch 19 train end 22:41:49\n",
            "Epoch 20 train begin 22:41:49\n",
            "| Training Device=xla:0/3 Epoch=20 Step=0 Loss=0.49490 Rate=10.13 GlobalRate=10.13 Time=22:41:55\n",
            "| Training Device=xla:0/2 Epoch=20 Step=0 Loss=0.36650 Rate=10.13 GlobalRate=10.13 Time=22:41:55\n",
            "| Training Device=xla:0/5 Epoch=20 Step=0 Loss=0.32455 Rate=10.13 GlobalRate=10.13 Time=22:41:55\n",
            "| Training Device=xla:0/6 Epoch=20 Step=0 Loss=0.42878 Rate=10.13 GlobalRate=10.13 Time=22:41:55\n",
            "| Training Device=xla:0/1 Epoch=20 Step=0 Loss=0.35926 Rate=10.13 GlobalRate=10.13 Time=22:41:55\n",
            "| Training Device=xla:0/4 Epoch=20 Step=0 Loss=0.33079 Rate=10.13 GlobalRate=10.13 Time=22:41:55\n",
            "| Training Device=xla:1/0 Epoch=20 Step=0 Loss=0.41519 Rate=10.14 GlobalRate=10.14 Time=22:41:55\n",
            "| Training Device=xla:0/7 Epoch=20 Step=0 Loss=0.39722 Rate=10.13 GlobalRate=10.13 Time=22:41:55\n",
            "Epoch 20 train end 22:41:56\n",
            "Epoch 21 train begin 22:41:56\n",
            "| Training Device=xla:0/4 Epoch=21 Step=0 Loss=0.40851 Rate=10.21 GlobalRate=10.21 Time=22:42:02\n",
            "| Training Device=xla:0/7 Epoch=21 Step=0 Loss=0.32388 Rate=10.21 GlobalRate=10.21 Time=22:42:02\n",
            "| Training Device=xla:0/3 Epoch=21 Step=0 Loss=0.46008 Rate=10.21 GlobalRate=10.21 Time=22:42:02\n",
            "| Training Device=xla:0/6 Epoch=21 Step=0 Loss=0.50143 Rate=10.21 GlobalRate=10.21 Time=22:42:02\n",
            "| Training Device=xla:0/5 Epoch=21 Step=0 Loss=0.35813 Rate=10.21 GlobalRate=10.21 Time=22:42:02\n",
            "| Training Device=xla:1/0 Epoch=21 Step=0 Loss=0.38894 Rate=10.21 GlobalRate=10.21 Time=22:42:02\n",
            "| Training Device=xla:0/1 Epoch=21 Step=0 Loss=0.36460 Rate=10.21 GlobalRate=10.21 Time=22:42:02\n",
            "| Training Device=xla:0/2 Epoch=21 Step=0 Loss=0.36232 Rate=10.21 GlobalRate=10.21 Time=22:42:02\n",
            "Epoch 21 train end 22:42:02\n",
            "Epoch 22 train begin 22:42:02\n",
            "| Training Device=xla:0/5 Epoch=22 Step=0 Loss=0.35095 Rate=10.15 GlobalRate=10.15 Time=22:42:08\n",
            "| Training Device=xla:0/1 Epoch=22 Step=0 Loss=0.36625 Rate=10.15 GlobalRate=10.15 Time=22:42:08\n",
            "| Training Device=xla:0/7 Epoch=22 Step=0 Loss=0.34267 Rate=10.15 GlobalRate=10.15 Time=22:42:08\n",
            "| Training Device=xla:0/6 Epoch=22 Step=0 Loss=0.48166 Rate=10.15 GlobalRate=10.15 Time=22:42:08\n",
            "| Training Device=xla:0/2 Epoch=22 Step=0 Loss=0.40917 Rate=10.15 GlobalRate=10.15 Time=22:42:08\n",
            "| Training Device=xla:1/0 Epoch=22 Step=0 Loss=0.32649 Rate=10.15 GlobalRate=10.15 Time=22:42:08\n",
            "| Training Device=xla:0/3 Epoch=22 Step=0 Loss=0.48499 Rate=10.14 GlobalRate=10.14 Time=22:42:08\n",
            "| Training Device=xla:0/4 Epoch=22 Step=0 Loss=0.34653 Rate=10.14 GlobalRate=10.14 Time=22:42:08\n",
            "Epoch 22 train end 22:42:09\n",
            "Epoch 23 train begin 22:42:09\n",
            "| Training Device=xla:1/0 Epoch=23 Step=0 Loss=0.39450 Rate=10.31 GlobalRate=10.31 Time=22:42:15\n",
            "| Training Device=xla:0/2 Epoch=23 Step=0 Loss=0.36419 Rate=10.31 GlobalRate=10.31 Time=22:42:15\n",
            "| Training Device=xla:0/3 Epoch=23 Step=0 Loss=0.45642 Rate=10.30 GlobalRate=10.30 Time=22:42:15\n",
            "| Training Device=xla:0/4 Epoch=23 Step=0 Loss=0.33411 Rate=10.30 GlobalRate=10.30 Time=22:42:15\n",
            "| Training Device=xla:0/1 Epoch=23 Step=0 Loss=0.39700 Rate=10.31 GlobalRate=10.31 Time=22:42:15\n",
            "| Training Device=xla:0/5 Epoch=23 Step=0 Loss=0.35088 Rate=10.31 GlobalRate=10.31 Time=22:42:15\n",
            "| Training Device=xla:0/6 Epoch=23 Step=0 Loss=0.41613 Rate=10.30 GlobalRate=10.30 Time=22:42:15\n",
            "| Training Device=xla:0/7 Epoch=23 Step=0 Loss=0.32657 Rate=10.30 GlobalRate=10.30 Time=22:42:15\n",
            "Epoch 23 train end 22:42:15\n",
            "Epoch 24 train begin 22:42:15\n",
            "| Training Device=xla:0/1 Epoch=24 Step=0 Loss=0.35154 Rate=10.22 GlobalRate=10.22 Time=22:42:21\n",
            "| Training Device=xla:0/3 Epoch=24 Step=0 Loss=0.49340 Rate=10.21 GlobalRate=10.21 Time=22:42:21\n",
            "| Training Device=xla:0/6 Epoch=24 Step=0 Loss=0.46158 Rate=10.21 GlobalRate=10.21 Time=22:42:21\n",
            "| Training Device=xla:0/2 Epoch=24 Step=0 Loss=0.34302 Rate=10.21 GlobalRate=10.21 Time=22:42:21\n",
            "| Training Device=xla:0/5 Epoch=24 Step=0 Loss=0.33120 Rate=10.21 GlobalRate=10.21 Time=22:42:21\n",
            "| Training Device=xla:0/4 Epoch=24 Step=0 Loss=0.35900 Rate=10.21 GlobalRate=10.21 Time=22:42:21\n",
            "| Training Device=xla:0/7 Epoch=24 Step=0 Loss=0.32069 Rate=10.21 GlobalRate=10.21 Time=22:42:21\n",
            "| Training Device=xla:1/0 Epoch=24 Step=0 Loss=0.35864 Rate=10.21 GlobalRate=10.21 Time=22:42:21\n",
            "Epoch 24 train end 22:42:21\n",
            "Epoch 25 train begin 22:42:21\n",
            "| Training Device=xla:0/1 Epoch=25 Step=0 Loss=0.37205 Rate=10.16 GlobalRate=10.16 Time=22:42:28\n",
            "| Training Device=xla:0/2 Epoch=25 Step=0 Loss=0.34240 Rate=10.15 GlobalRate=10.15 Time=22:42:28\n",
            "| Training Device=xla:0/7 Epoch=25 Step=0 Loss=0.30094 Rate=10.15 GlobalRate=10.15 Time=22:42:28\n",
            "| Training Device=xla:0/4 Epoch=25 Step=0 Loss=0.30842 Rate=10.15 GlobalRate=10.15 Time=22:42:28\n",
            "| Training Device=xla:0/3 Epoch=25 Step=0 Loss=0.48840 Rate=10.15 GlobalRate=10.15 Time=22:42:28\n",
            "| Training Device=xla:0/5 Epoch=25 Step=0 Loss=0.32785 Rate=10.15 GlobalRate=10.15 Time=22:42:28\n",
            "| Training Device=xla:0/6 Epoch=25 Step=0 Loss=0.38855 Rate=10.15 GlobalRate=10.15 Time=22:42:28\n",
            "| Training Device=xla:1/0 Epoch=25 Step=0 Loss=0.46087 Rate=10.16 GlobalRate=10.16 Time=22:42:28\n",
            "Epoch 25 train end 22:42:28\n",
            "Epoch 26 train begin 22:42:28\n",
            "| Training Device=xla:0/3 Epoch=26 Step=0 Loss=0.46347 Rate=10.12 GlobalRate=10.12 Time=22:42:34\n",
            "| Training Device=xla:0/4 Epoch=26 Step=0 Loss=0.34433 Rate=10.12 GlobalRate=10.12 Time=22:42:34\n",
            "| Training Device=xla:0/6 Epoch=26 Step=0 Loss=0.37874 Rate=10.12 GlobalRate=10.12 Time=22:42:34\n",
            "| Training Device=xla:0/5 Epoch=26 Step=0 Loss=0.33746 Rate=10.12 GlobalRate=10.12 Time=22:42:34\n",
            "| Training Device=xla:0/7 Epoch=26 Step=0 Loss=0.30245 Rate=10.12 GlobalRate=10.12 Time=22:42:34\n",
            "| Training Device=xla:0/1 Epoch=26 Step=0 Loss=0.33389 Rate=10.12 GlobalRate=10.12 Time=22:42:34\n",
            "| Training Device=xla:1/0 Epoch=26 Step=0 Loss=0.37636 Rate=10.12 GlobalRate=10.12 Time=22:42:34\n",
            "| Training Device=xla:0/2 Epoch=26 Step=0 Loss=0.33855 Rate=10.11 GlobalRate=10.11 Time=22:42:34\n",
            "Epoch 26 train end 22:42:35\n",
            "Epoch 27 train begin 22:42:35\n",
            "| Training Device=xla:0/1 Epoch=27 Step=0 Loss=0.32608 Rate=10.18 GlobalRate=10.18 Time=22:42:41\n",
            "| Training Device=xla:0/3 Epoch=27 Step=0 Loss=0.45443 Rate=10.18 GlobalRate=10.18 Time=22:42:41\n",
            "| Training Device=xla:0/7 Epoch=27 Step=0 Loss=0.28438 Rate=10.18 GlobalRate=10.18 Time=22:42:41\n",
            "| Training Device=xla:0/2 Epoch=27 Step=0 Loss=0.33704 Rate=10.18 GlobalRate=10.18 Time=22:42:41\n",
            "| Training Device=xla:0/6 Epoch=27 Step=0 Loss=0.39990 Rate=10.18 GlobalRate=10.18 Time=22:42:41\n",
            "| Training Device=xla:1/0 Epoch=27 Step=0 Loss=0.36248 Rate=10.19 GlobalRate=10.19 Time=22:42:41\n",
            "| Training Device=xla:0/5 Epoch=27 Step=0 Loss=0.27996 Rate=10.18 GlobalRate=10.18 Time=22:42:41\n",
            "| Training Device=xla:0/4 Epoch=27 Step=0 Loss=0.31353 Rate=10.18 GlobalRate=10.18 Time=22:42:41\n",
            "Epoch 27 train end 22:42:41\n",
            "Epoch 28 train begin 22:42:41\n",
            "| Training Device=xla:0/4 Epoch=28 Step=0 Loss=0.34161 Rate=10.19 GlobalRate=10.19 Time=22:42:47\n",
            "| Training Device=xla:0/7 Epoch=28 Step=0 Loss=0.37185 Rate=10.19 GlobalRate=10.19 Time=22:42:47\n",
            "| Training Device=xla:0/2 Epoch=28 Step=0 Loss=0.39648 Rate=10.19 GlobalRate=10.19 Time=22:42:47\n",
            "| Training Device=xla:0/3 Epoch=28 Step=0 Loss=0.44157 Rate=10.19 GlobalRate=10.19 Time=22:42:47\n",
            "| Training Device=xla:1/0 Epoch=28 Step=0 Loss=0.33459 Rate=10.20 GlobalRate=10.20 Time=22:42:47\n",
            "| Training Device=xla:0/1 Epoch=28 Step=0 Loss=0.33501 Rate=10.19 GlobalRate=10.19 Time=22:42:47\n",
            "| Training Device=xla:0/6 Epoch=28 Step=0 Loss=0.44272 Rate=10.19 GlobalRate=10.19 Time=22:42:47\n",
            "| Training Device=xla:0/5 Epoch=28 Step=0 Loss=0.29967 Rate=10.19 GlobalRate=10.19 Time=22:42:47\n",
            "Epoch 28 train end 22:42:48\n",
            "Epoch 29 train begin 22:42:48\n",
            "| Training Device=xla:0/7 Epoch=29 Step=0 Loss=0.36063 Rate=10.26 GlobalRate=10.26 Time=22:42:54\n",
            "| Training Device=xla:0/3 Epoch=29 Step=0 Loss=0.48474 Rate=10.26 GlobalRate=10.26 Time=22:42:54\n",
            "| Training Device=xla:1/0 Epoch=29 Step=0 Loss=0.32181 Rate=10.26 GlobalRate=10.26 Time=22:42:54\n",
            "| Training Device=xla:0/4 Epoch=29 Step=0 Loss=0.29333 Rate=10.26 GlobalRate=10.26 Time=22:42:54\n",
            "| Training Device=xla:0/6 Epoch=29 Step=0 Loss=0.40962 Rate=10.25 GlobalRate=10.25 Time=22:42:54\n",
            "| Training Device=xla:0/5 Epoch=29 Step=0 Loss=0.33866 Rate=10.25 GlobalRate=10.25 Time=22:42:54\n",
            "| Training Device=xla:0/2 Epoch=29 Step=0 Loss=0.36512 Rate=10.25 GlobalRate=10.25 Time=22:42:54\n",
            "| Training Device=xla:0/1 Epoch=29 Step=0 Loss=0.29809 Rate=10.25 GlobalRate=10.25 Time=22:42:54\n",
            "Epoch 29 train end 22:42:54\n",
            "Epoch 30 train begin 22:42:54\n",
            "| Training Device=xla:0/2 Epoch=30 Step=0 Loss=0.35979 Rate=10.23 GlobalRate=10.23 Time=22:43:00\n",
            "| Training Device=xla:0/4 Epoch=30 Step=0 Loss=0.37312 Rate=10.23 GlobalRate=10.23 Time=22:43:00\n",
            "| Training Device=xla:0/5 Epoch=30 Step=0 Loss=0.28653 Rate=10.23 GlobalRate=10.23 Time=22:43:00\n",
            "| Training Device=xla:0/6 Epoch=30 Step=0 Loss=0.44655 Rate=10.23 GlobalRate=10.23 Time=22:43:00\n",
            "| Training Device=xla:0/7 Epoch=30 Step=0 Loss=0.34535 Rate=10.23 GlobalRate=10.23 Time=22:43:00\n",
            "| Training Device=xla:0/3 Epoch=30 Step=0 Loss=0.46305 Rate=10.23 GlobalRate=10.23 Time=22:43:00\n",
            "| Training Device=xla:0/1 Epoch=30 Step=0 Loss=0.30947 Rate=10.23 GlobalRate=10.23 Time=22:43:00\n",
            "| Training Device=xla:1/0 Epoch=30 Step=0 Loss=0.38644 Rate=10.23 GlobalRate=10.23 Time=22:43:00\n",
            "Epoch 30 train end 22:43:01\n",
            "Epoch 31 train begin 22:43:01\n",
            "| Training Device=xla:0/3 Epoch=31 Step=0 Loss=0.45173 Rate=10.14 GlobalRate=10.14 Time=22:43:07\n",
            "| Training Device=xla:0/5 Epoch=31 Step=0 Loss=0.29390 Rate=10.15 GlobalRate=10.15 Time=22:43:07\n",
            "| Training Device=xla:0/2 Epoch=31 Step=0 Loss=0.35755 Rate=10.14 GlobalRate=10.14 Time=22:43:07\n",
            "| Training Device=xla:0/6 Epoch=31 Step=0 Loss=0.43986 Rate=10.14 GlobalRate=10.14 Time=22:43:07\n",
            "| Training Device=xla:1/0 Epoch=31 Step=0 Loss=0.35797 Rate=10.15 GlobalRate=10.15 Time=22:43:07\n",
            "| Training Device=xla:0/1 Epoch=31 Step=0 Loss=0.44547 Rate=10.14 GlobalRate=10.14 Time=22:43:07\n",
            "| Training Device=xla:0/4 Epoch=31 Step=0 Loss=0.28880 Rate=10.14 GlobalRate=10.14 Time=22:43:07\n",
            "| Training Device=xla:0/7 Epoch=31 Step=0 Loss=0.34777 Rate=10.14 GlobalRate=10.14 Time=22:43:07\n",
            "Epoch 31 train end 22:43:07\n",
            "Epoch 32 train begin 22:43:07\n",
            "| Training Device=xla:0/2 Epoch=32 Step=0 Loss=0.34863 Rate=10.18 GlobalRate=10.18 Time=22:43:13\n",
            "| Training Device=xla:0/7 Epoch=32 Step=0 Loss=0.26938 Rate=10.18 GlobalRate=10.18 Time=22:43:13\n",
            "| Training Device=xla:0/3 Epoch=32 Step=0 Loss=0.42675 Rate=10.18 GlobalRate=10.18 Time=22:43:13\n",
            "| Training Device=xla:0/4 Epoch=32 Step=0 Loss=0.29152 Rate=10.18 GlobalRate=10.18 Time=22:43:13\n",
            "| Training Device=xla:0/1 Epoch=32 Step=0 Loss=0.38187 Rate=10.18 GlobalRate=10.18 Time=22:43:13\n",
            "| Training Device=xla:0/5 Epoch=32 Step=0 Loss=0.28734 Rate=10.18 GlobalRate=10.18 Time=22:43:13\n",
            "| Training Device=xla:1/0 Epoch=32 Step=0 Loss=0.40478 Rate=10.18 GlobalRate=10.18 Time=22:43:13\n",
            "| Training Device=xla:0/6 Epoch=32 Step=0 Loss=0.38903 Rate=10.18 GlobalRate=10.18 Time=22:43:13\n",
            "Epoch 32 train end 22:43:14\n",
            "Epoch 33 train begin 22:43:14\n",
            "| Training Device=xla:0/1 Epoch=33 Step=0 Loss=0.29773 Rate=10.24 GlobalRate=10.24 Time=22:43:20\n",
            "| Training Device=xla:0/6 Epoch=33 Step=0 Loss=0.38843 Rate=10.24 GlobalRate=10.24 Time=22:43:20\n",
            "| Training Device=xla:0/4 Epoch=33 Step=0 Loss=0.32485 Rate=10.24 GlobalRate=10.24 Time=22:43:20\n",
            "| Training Device=xla:0/7 Epoch=33 Step=0 Loss=0.30989 Rate=10.24 GlobalRate=10.24 Time=22:43:20\n",
            "| Training Device=xla:0/2 Epoch=33 Step=0 Loss=0.32906 Rate=10.24 GlobalRate=10.24 Time=22:43:20\n",
            "| Training Device=xla:0/3 Epoch=33 Step=0 Loss=0.44909 Rate=10.24 GlobalRate=10.24 Time=22:43:20\n",
            "| Training Device=xla:0/5 Epoch=33 Step=0 Loss=0.32034 Rate=10.24 GlobalRate=10.24 Time=22:43:20\n",
            "| Training Device=xla:1/0 Epoch=33 Step=0 Loss=0.37156 Rate=10.24 GlobalRate=10.24 Time=22:43:20\n",
            "Epoch 33 train end 22:43:20\n",
            "Epoch 34 train begin 22:43:20\n",
            "| Training Device=xla:1/0 Epoch=34 Step=0 Loss=0.40080 Rate=10.15 GlobalRate=10.15 Time=22:43:26\n",
            "| Training Device=xla:0/7 Epoch=34 Step=0 Loss=0.31312 Rate=10.15 GlobalRate=10.15 Time=22:43:26\n",
            "| Training Device=xla:0/4 Epoch=34 Step=0 Loss=0.32679 Rate=10.15 GlobalRate=10.15 Time=22:43:26\n",
            "| Training Device=xla:0/6 Epoch=34 Step=0 Loss=0.38948 Rate=10.15 GlobalRate=10.15 Time=22:43:26\n",
            "| Training Device=xla:0/1 Epoch=34 Step=0 Loss=0.34360 Rate=10.14 GlobalRate=10.14 Time=22:43:26\n",
            "| Training Device=xla:0/2 Epoch=34 Step=0 Loss=0.31319 Rate=10.15 GlobalRate=10.15 Time=22:43:26\n",
            "| Training Device=xla:0/5 Epoch=34 Step=0 Loss=0.35067 Rate=10.15 GlobalRate=10.15 Time=22:43:26\n",
            "| Training Device=xla:0/3 Epoch=34 Step=0 Loss=0.38663 Rate=10.14 GlobalRate=10.14 Time=22:43:26\n",
            "Epoch 34 train end 22:43:27\n",
            "Epoch 35 train begin 22:43:27\n",
            "| Training Device=xla:0/1 Epoch=35 Step=0 Loss=0.32039 Rate=10.25 GlobalRate=10.25 Time=22:43:33\n",
            "| Training Device=xla:0/7 Epoch=35 Step=0 Loss=0.32401 Rate=10.24 GlobalRate=10.24 Time=22:43:33\n",
            "| Training Device=xla:0/3 Epoch=35 Step=0 Loss=0.43089 Rate=10.25 GlobalRate=10.24 Time=22:43:33\n",
            "| Training Device=xla:0/6 Epoch=35 Step=0 Loss=0.39173 Rate=10.24 GlobalRate=10.24 Time=22:43:33\n",
            "| Training Device=xla:0/5 Epoch=35 Step=0 Loss=0.33563 Rate=10.24 GlobalRate=10.24 Time=22:43:33\n",
            "| Training Device=xla:0/2 Epoch=35 Step=0 Loss=0.34870 Rate=10.24 GlobalRate=10.24 Time=22:43:33\n",
            "| Training Device=xla:1/0 Epoch=35 Step=0 Loss=0.35294 Rate=10.25 GlobalRate=10.25 Time=22:43:33\n",
            "| Training Device=xla:0/4 Epoch=35 Step=0 Loss=0.30234 Rate=10.24 GlobalRate=10.24 Time=22:43:33\n",
            "Epoch 35 train end 22:43:33\n",
            "Epoch 36 train begin 22:43:33\n",
            "| Training Device=xla:0/4 Epoch=36 Step=0 Loss=0.33550 Rate=10.28 GlobalRate=10.28 Time=22:43:39\n",
            "| Training Device=xla:0/5 Epoch=36 Step=0 Loss=0.32528 Rate=10.28 GlobalRate=10.28 Time=22:43:39\n",
            "| Training Device=xla:0/3 Epoch=36 Step=0 Loss=0.50326 Rate=10.28 GlobalRate=10.28 Time=22:43:39\n",
            "| Training Device=xla:0/2 Epoch=36 Step=0 Loss=0.36417 Rate=10.28 GlobalRate=10.28 Time=22:43:39\n",
            "| Training Device=xla:0/1 Epoch=36 Step=0 Loss=0.39644 Rate=10.28 GlobalRate=10.28 Time=22:43:39\n",
            "| Training Device=xla:0/7 Epoch=36 Step=0 Loss=0.31325 Rate=10.28 GlobalRate=10.28 Time=22:43:39\n",
            "| Training Device=xla:1/0 Epoch=36 Step=0 Loss=0.37648 Rate=10.28 GlobalRate=10.28 Time=22:43:39\n",
            "| Training Device=xla:0/6 Epoch=36 Step=0 Loss=0.46468 Rate=10.28 GlobalRate=10.28 Time=22:43:39\n",
            "Epoch 36 train end 22:43:40\n",
            "Epoch 37 train begin 22:43:40\n",
            "| Training Device=xla:0/4 Epoch=37 Step=0 Loss=0.25877 Rate=10.23 GlobalRate=10.23 Time=22:43:46\n",
            "| Training Device=xla:0/5 Epoch=37 Step=0 Loss=0.26406 Rate=10.23 GlobalRate=10.23 Time=22:43:46\n",
            "| Training Device=xla:0/2 Epoch=37 Step=0 Loss=0.30975 Rate=10.22 GlobalRate=10.22 Time=22:43:46\n",
            "| Training Device=xla:0/1 Epoch=37 Step=0 Loss=0.31847 Rate=10.22 GlobalRate=10.22 Time=22:43:46\n",
            "| Training Device=xla:0/3 Epoch=37 Step=0 Loss=0.43242 Rate=10.22 GlobalRate=10.22 Time=22:43:46\n",
            "| Training Device=xla:0/6 Epoch=37 Step=0 Loss=0.40917 Rate=10.22 GlobalRate=10.22 Time=22:43:46\n",
            "| Training Device=xla:0/7 Epoch=37 Step=0 Loss=0.34188 Rate=10.22 GlobalRate=10.22 Time=22:43:46\n",
            "| Training Device=xla:1/0 Epoch=37 Step=0 Loss=0.34652 Rate=10.23 GlobalRate=10.23 Time=22:43:46\n",
            "Epoch 37 train end 22:43:46\n",
            "Epoch 38 train begin 22:43:46\n",
            "| Training Device=xla:0/3 Epoch=38 Step=0 Loss=0.45291 Rate=10.20 GlobalRate=10.20 Time=22:43:52\n",
            "| Training Device=xla:0/1 Epoch=38 Step=0 Loss=0.31246 Rate=10.20 GlobalRate=10.20 Time=22:43:52\n",
            "| Training Device=xla:0/7 Epoch=38 Step=0 Loss=0.29296 Rate=10.20 GlobalRate=10.20 Time=22:43:52\n",
            "| Training Device=xla:0/6 Epoch=38 Step=0 Loss=0.45455 Rate=10.20 GlobalRate=10.20 Time=22:43:52\n",
            "| Training Device=xla:0/2 Epoch=38 Step=0 Loss=0.31451 Rate=10.20 GlobalRate=10.20 Time=22:43:52\n",
            "| Training Device=xla:1/0 Epoch=38 Step=0 Loss=0.38103 Rate=10.20 GlobalRate=10.20 Time=22:43:52\n",
            "| Training Device=xla:0/5 Epoch=38 Step=0 Loss=0.28052 Rate=10.20 GlobalRate=10.20 Time=22:43:52\n",
            "| Training Device=xla:0/4 Epoch=38 Step=0 Loss=0.26355 Rate=10.20 GlobalRate=10.20 Time=22:43:52\n",
            "Epoch 38 train end 22:43:53\n",
            "Epoch 39 train begin 22:43:53\n",
            "| Training Device=xla:0/3 Epoch=39 Step=0 Loss=0.40434 Rate=10.25 GlobalRate=10.25 Time=22:43:59\n",
            "| Training Device=xla:0/1 Epoch=39 Step=0 Loss=0.32306 Rate=10.25 GlobalRate=10.25 Time=22:43:59\n",
            "| Training Device=xla:0/6 Epoch=39 Step=0 Loss=0.38897 Rate=10.24 GlobalRate=10.24 Time=22:43:59\n",
            "| Training Device=xla:0/5 Epoch=39 Step=0 Loss=0.26656 Rate=10.24 GlobalRate=10.24 Time=22:43:59\n",
            "| Training Device=xla:0/7 Epoch=39 Step=0 Loss=0.31815 Rate=10.24 GlobalRate=10.24 Time=22:43:59\n",
            "| Training Device=xla:0/4 Epoch=39 Step=0 Loss=0.34246 Rate=10.25 GlobalRate=10.25 Time=22:43:59\n",
            "| Training Device=xla:0/2 Epoch=39 Step=0 Loss=0.34499 Rate=10.25 GlobalRate=10.25 Time=22:43:59\n",
            "| Training Device=xla:1/0 Epoch=39 Step=0 Loss=0.37471 Rate=10.25 GlobalRate=10.25 Time=22:43:59\n",
            "Epoch 39 train end 22:43:59\n",
            "Epoch 40 train begin 22:43:59\n",
            "| Training Device=xla:0/3 Epoch=40 Step=0 Loss=0.44111 Rate=10.20 GlobalRate=10.20 Time=22:44:05\n",
            "| Training Device=xla:0/6 Epoch=40 Step=0 Loss=0.38855 Rate=10.19 GlobalRate=10.19 Time=22:44:05\n",
            "| Training Device=xla:0/5 Epoch=40 Step=0 Loss=0.31567 Rate=10.19 GlobalRate=10.19 Time=22:44:05\n",
            "| Training Device=xla:0/4 Epoch=40 Step=0 Loss=0.27460 Rate=10.19 GlobalRate=10.19 Time=22:44:05\n",
            "| Training Device=xla:0/1 Epoch=40 Step=0 Loss=0.32864 Rate=10.19 GlobalRate=10.19 Time=22:44:05\n",
            "| Training Device=xla:0/7 Epoch=40 Step=0 Loss=0.28926 Rate=10.19 GlobalRate=10.19 Time=22:44:05\n",
            "| Training Device=xla:0/2 Epoch=40 Step=0 Loss=0.31914 Rate=10.19 GlobalRate=10.19 Time=22:44:05\n",
            "| Training Device=xla:1/0 Epoch=40 Step=0 Loss=0.37016 Rate=10.19 GlobalRate=10.19 Time=22:44:05\n",
            "Epoch 40 train end 22:44:06\n",
            "Epoch 41 train begin 22:44:06\n",
            "| Training Device=xla:0/3 Epoch=41 Step=0 Loss=0.46386 Rate=10.27 GlobalRate=10.27 Time=22:44:12\n",
            "| Training Device=xla:0/1 Epoch=41 Step=0 Loss=0.30404 Rate=10.27 GlobalRate=10.27 Time=22:44:12\n",
            "| Training Device=xla:0/6 Epoch=41 Step=0 Loss=0.43210 Rate=10.27 GlobalRate=10.27 Time=22:44:12\n",
            "| Training Device=xla:0/7 Epoch=41 Step=0 Loss=0.32171 Rate=10.27 GlobalRate=10.27 Time=22:44:12\n",
            "| Training Device=xla:1/0 Epoch=41 Step=0 Loss=0.34078 Rate=10.27 GlobalRate=10.27 Time=22:44:12\n",
            "| Training Device=xla:0/2 Epoch=41 Step=0 Loss=0.33587 Rate=10.27 GlobalRate=10.27 Time=22:44:12\n",
            "| Training Device=xla:0/5 Epoch=41 Step=0 Loss=0.32539 Rate=10.26 GlobalRate=10.26 Time=22:44:12\n",
            "| Training Device=xla:0/4 Epoch=41 Step=0 Loss=0.34691 Rate=10.27 GlobalRate=10.27 Time=22:44:12\n",
            "Epoch 41 train end 22:44:12\n",
            "Epoch 42 train begin 22:44:12\n",
            "| Training Device=xla:0/2 Epoch=42 Step=0 Loss=0.34379 Rate=10.21 GlobalRate=10.21 Time=22:44:18\n",
            "| Training Device=xla:0/6 Epoch=42 Step=0 Loss=0.39201 Rate=10.21 GlobalRate=10.21 Time=22:44:18\n",
            "| Training Device=xla:1/0 Epoch=42 Step=0 Loss=0.36579 Rate=10.21 GlobalRate=10.21 Time=22:44:18\n",
            "| Training Device=xla:0/5 Epoch=42 Step=0 Loss=0.28376 Rate=10.21 GlobalRate=10.21 Time=22:44:18\n",
            "| Training Device=xla:0/1 Epoch=42 Step=0 Loss=0.35139 Rate=10.21 GlobalRate=10.21 Time=22:44:18\n",
            "| Training Device=xla:0/3 Epoch=42 Step=0 Loss=0.40068 Rate=10.20 GlobalRate=10.20 Time=22:44:18\n",
            "| Training Device=xla:0/7 Epoch=42 Step=0 Loss=0.27240 Rate=10.21 GlobalRate=10.21 Time=22:44:18\n",
            "| Training Device=xla:0/4 Epoch=42 Step=0 Loss=0.27345 Rate=10.20 GlobalRate=10.20 Time=22:44:18\n",
            "Epoch 42 train end 22:44:19\n",
            "Epoch 43 train begin 22:44:19\n",
            "| Training Device=xla:0/4 Epoch=43 Step=0 Loss=0.31135 Rate=10.21 GlobalRate=10.21 Time=22:44:25\n",
            "| Training Device=xla:0/5 Epoch=43 Step=0 Loss=0.28744 Rate=10.21 GlobalRate=10.21 Time=22:44:25\n",
            "| Training Device=xla:1/0 Epoch=43 Step=0 Loss=0.44633 Rate=10.21 GlobalRate=10.21 Time=22:44:25\n",
            "| Training Device=xla:0/1 Epoch=43 Step=0 Loss=0.33173 Rate=10.20 GlobalRate=10.20 Time=22:44:25\n",
            "| Training Device=xla:0/3 Epoch=43 Step=0 Loss=0.39946 Rate=10.21 GlobalRate=10.21 Time=22:44:25\n",
            "| Training Device=xla:0/2 Epoch=43 Step=0 Loss=0.32313 Rate=10.21 GlobalRate=10.21 Time=22:44:25\n",
            "| Training Device=xla:0/7 Epoch=43 Step=0 Loss=0.27552 Rate=10.21 GlobalRate=10.21 Time=22:44:25\n",
            "| Training Device=xla:0/6 Epoch=43 Step=0 Loss=0.38600 Rate=10.21 GlobalRate=10.21 Time=22:44:25\n",
            "Epoch 43 train end 22:44:25\n",
            "Epoch 44 train begin 22:44:25\n",
            "| Training Device=xla:0/3 Epoch=44 Step=0 Loss=0.43689 Rate=10.21 GlobalRate=10.21 Time=22:44:31\n",
            "| Training Device=xla:0/5 Epoch=44 Step=0 Loss=0.26314 Rate=10.22 GlobalRate=10.22 Time=22:44:31\n",
            "| Training Device=xla:0/4 Epoch=44 Step=0 Loss=0.29442 Rate=10.21 GlobalRate=10.21 Time=22:44:31\n",
            "| Training Device=xla:0/6 Epoch=44 Step=0 Loss=0.41460 Rate=10.21 GlobalRate=10.21 Time=22:44:31\n",
            "| Training Device=xla:0/2 Epoch=44 Step=0 Loss=0.34568 Rate=10.21 GlobalRate=10.21 Time=22:44:31\n",
            "| Training Device=xla:0/1 Epoch=44 Step=0 Loss=0.29697 Rate=10.21 GlobalRate=10.21 Time=22:44:31\n",
            "| Training Device=xla:0/7 Epoch=44 Step=0 Loss=0.27254 Rate=10.21 GlobalRate=10.21 Time=22:44:31\n",
            "| Training Device=xla:1/0 Epoch=44 Step=0 Loss=0.32881 Rate=10.22 GlobalRate=10.22 Time=22:44:31\n",
            "Epoch 44 train end 22:44:32\n",
            "Epoch 45 train begin 22:44:32\n",
            "| Training Device=xla:0/3 Epoch=45 Step=0 Loss=0.46905 Rate=10.14 GlobalRate=10.14 Time=22:44:38\n",
            "| Training Device=xla:0/2 Epoch=45 Step=0 Loss=0.39005 Rate=10.14 GlobalRate=10.14 Time=22:44:38\n",
            "| Training Device=xla:0/6 Epoch=45 Step=0 Loss=0.40957 Rate=10.14 GlobalRate=10.14 Time=22:44:38\n",
            "| Training Device=xla:0/4 Epoch=45 Step=0 Loss=0.32023 Rate=10.14 GlobalRate=10.14 Time=22:44:38\n",
            "| Training Device=xla:0/5 Epoch=45 Step=0 Loss=0.26539 Rate=10.14 GlobalRate=10.14 Time=22:44:38\n",
            "| Training Device=xla:0/7 Epoch=45 Step=0 Loss=0.31100 Rate=10.14 GlobalRate=10.14 Time=22:44:38\n",
            "| Training Device=xla:1/0 Epoch=45 Step=0 Loss=0.37370 Rate=10.14 GlobalRate=10.14 Time=22:44:38\n",
            "| Training Device=xla:0/1 Epoch=45 Step=0 Loss=0.33336 Rate=10.14 GlobalRate=10.14 Time=22:44:38\n",
            "Epoch 45 train end 22:44:38\n",
            "Epoch 46 train begin 22:44:38\n",
            "| Training Device=xla:1/0 Epoch=46 Step=0 Loss=0.31075 Rate=10.16 GlobalRate=10.16 Time=22:44:45\n",
            "| Training Device=xla:0/5 Epoch=46 Step=0 Loss=0.33338 Rate=10.16 GlobalRate=10.16 Time=22:44:45\n",
            "| Training Device=xla:0/1 Epoch=46 Step=0 Loss=0.30911 Rate=10.16 GlobalRate=10.16 Time=22:44:45\n",
            "| Training Device=xla:0/7 Epoch=46 Step=0 Loss=0.26081 Rate=10.15 GlobalRate=10.15 Time=22:44:45\n",
            "| Training Device=xla:0/6 Epoch=46 Step=0 Loss=0.40781 Rate=10.15 GlobalRate=10.15 Time=22:44:45\n",
            "| Training Device=xla:0/4 Epoch=46 Step=0 Loss=0.24194 Rate=10.15 GlobalRate=10.15 Time=22:44:45\n",
            "| Training Device=xla:0/2 Epoch=46 Step=0 Loss=0.26471 Rate=10.15 GlobalRate=10.15 Time=22:44:45\n",
            "| Training Device=xla:0/3 Epoch=46 Step=0 Loss=0.44632 Rate=10.15 GlobalRate=10.15 Time=22:44:45\n",
            "Epoch 46 train end 22:44:45\n",
            "Epoch 47 train begin 22:44:45\n",
            "| Training Device=xla:0/5 Epoch=47 Step=0 Loss=0.28436 Rate=10.16 GlobalRate=10.16 Time=22:44:51\n",
            "| Training Device=xla:0/3 Epoch=47 Step=0 Loss=0.43051 Rate=10.16 GlobalRate=10.16 Time=22:44:51\n",
            "| Training Device=xla:0/2 Epoch=47 Step=0 Loss=0.31698 Rate=10.16 GlobalRate=10.16 Time=22:44:51\n",
            "| Training Device=xla:0/1 Epoch=47 Step=0 Loss=0.30892 Rate=10.16 GlobalRate=10.16 Time=22:44:51\n",
            "| Training Device=xla:0/7 Epoch=47 Step=0 Loss=0.34337 Rate=10.15 GlobalRate=10.15 Time=22:44:51\n",
            "| Training Device=xla:0/6 Epoch=47 Step=0 Loss=0.34773 Rate=10.15 GlobalRate=10.15 Time=22:44:51\n",
            "| Training Device=xla:0/4 Epoch=47 Step=0 Loss=0.29569 Rate=10.15 GlobalRate=10.15 Time=22:44:51\n",
            "| Training Device=xla:1/0 Epoch=47 Step=0 Loss=0.36588 Rate=10.16 GlobalRate=10.16 Time=22:44:51\n",
            "Epoch 47 train end 22:44:51\n",
            "Epoch 48 train begin 22:44:51\n",
            "| Training Device=xla:0/1 Epoch=48 Step=0 Loss=0.33405 Rate=10.25 GlobalRate=10.25 Time=22:44:58\n",
            "| Training Device=xla:0/3 Epoch=48 Step=0 Loss=0.37959 Rate=10.25 GlobalRate=10.25 Time=22:44:58\n",
            "| Training Device=xla:0/2 Epoch=48 Step=0 Loss=0.29815 Rate=10.25 GlobalRate=10.25 Time=22:44:58\n",
            "| Training Device=xla:0/7 Epoch=48 Step=0 Loss=0.26692 Rate=10.25 GlobalRate=10.25 Time=22:44:58\n",
            "| Training Device=xla:0/6 Epoch=48 Step=0 Loss=0.40084 Rate=10.24 GlobalRate=10.24 Time=22:44:58\n",
            "| Training Device=xla:1/0 Epoch=48 Step=0 Loss=0.31742 Rate=10.25 GlobalRate=10.25 Time=22:44:58\n",
            "| Training Device=xla:0/4 Epoch=48 Step=0 Loss=0.30948 Rate=10.24 GlobalRate=10.24 Time=22:44:58\n",
            "| Training Device=xla:0/5 Epoch=48 Step=0 Loss=0.29161 Rate=10.24 GlobalRate=10.24 Time=22:44:58\n",
            "Epoch 48 train end 22:44:58\n",
            "Epoch 49 train begin 22:44:58\n",
            "| Training Device=xla:0/3 Epoch=49 Step=0 Loss=0.44462 Rate=10.13 GlobalRate=10.13 Time=22:45:04\n",
            "| Training Device=xla:0/1 Epoch=49 Step=0 Loss=0.31596 Rate=10.12 GlobalRate=10.12 Time=22:45:04\n",
            "| Training Device=xla:0/2 Epoch=49 Step=0 Loss=0.35912 Rate=10.12 GlobalRate=10.12 Time=22:45:04\n",
            "| Training Device=xla:0/6 Epoch=49 Step=0 Loss=0.40909 Rate=10.12 GlobalRate=10.12 Time=22:45:04\n",
            "| Training Device=xla:1/0 Epoch=49 Step=0 Loss=0.37069 Rate=10.13 GlobalRate=10.13 Time=22:45:04\n",
            "| Training Device=xla:0/7 Epoch=49 Step=0 Loss=0.28894 Rate=10.12 GlobalRate=10.12 Time=22:45:04\n",
            "| Training Device=xla:0/5 Epoch=49 Step=0 Loss=0.30883 Rate=10.12 GlobalRate=10.12 Time=22:45:04\n",
            "| Training Device=xla:0/4 Epoch=49 Step=0 Loss=0.30809 Rate=10.12 GlobalRate=10.12 Time=22:45:04\n",
            "Epoch 49 train end 22:45:04\n",
            "Epoch 50 train begin 22:45:04\n",
            "| Training Device=xla:0/2 Epoch=50 Step=0 Loss=0.31163 Rate=10.15 GlobalRate=10.15 Time=22:45:11\n",
            "| Training Device=xla:0/3 Epoch=50 Step=0 Loss=0.43414 Rate=10.15 GlobalRate=10.15 Time=22:45:11\n",
            "| Training Device=xla:0/1 Epoch=50 Step=0 Loss=0.36554 Rate=10.14 GlobalRate=10.14 Time=22:45:11\n",
            "| Training Device=xla:0/4 Epoch=50 Step=0 Loss=0.33062 Rate=10.14 GlobalRate=10.14 Time=22:45:11\n",
            "| Training Device=xla:0/7 Epoch=50 Step=0 Loss=0.35864 Rate=10.15 GlobalRate=10.15 Time=22:45:11\n",
            "| Training Device=xla:0/6 Epoch=50 Step=0 Loss=0.39571 Rate=10.14 GlobalRate=10.14 Time=22:45:11\n",
            "| Training Device=xla:0/5 Epoch=50 Step=0 Loss=0.32148 Rate=10.14 GlobalRate=10.14 Time=22:45:11\n",
            "| Training Device=xla:1/0 Epoch=50 Step=0 Loss=0.39957 Rate=10.15 GlobalRate=10.15 Time=22:45:11\n",
            "Epoch 50 train end 22:45:11\n",
            "Epoch 51 train begin 22:45:11\n",
            "| Training Device=xla:0/6 Epoch=51 Step=0 Loss=0.36634 Rate=10.18 GlobalRate=10.18 Time=22:45:17\n",
            "| Training Device=xla:0/5 Epoch=51 Step=0 Loss=0.28070 Rate=10.18 GlobalRate=10.18 Time=22:45:17\n",
            "| Training Device=xla:0/3 Epoch=51 Step=0 Loss=0.43224 Rate=10.18 GlobalRate=10.18 Time=22:45:17\n",
            "| Training Device=xla:0/1 Epoch=51 Step=0 Loss=0.30896 Rate=10.18 GlobalRate=10.18 Time=22:45:17\n",
            "| Training Device=xla:1/0 Epoch=51 Step=0 Loss=0.39137 Rate=10.18 GlobalRate=10.18 Time=22:45:17\n",
            "| Training Device=xla:0/2 Epoch=51 Step=0 Loss=0.30827 Rate=10.18 GlobalRate=10.18 Time=22:45:17\n",
            "| Training Device=xla:0/4 Epoch=51 Step=0 Loss=0.31711 Rate=10.18 GlobalRate=10.18 Time=22:45:17\n",
            "| Training Device=xla:0/7 Epoch=51 Step=0 Loss=0.29878 Rate=10.18 GlobalRate=10.18 Time=22:45:17\n",
            "Epoch 51 train end 22:45:17\n",
            "Epoch 52 train begin 22:45:17\n",
            "| Training Device=xla:1/0 Epoch=52 Step=0 Loss=0.37203 Rate=10.17 GlobalRate=10.17 Time=22:45:24\n",
            "| Training Device=xla:0/6 Epoch=52 Step=0 Loss=0.40410 Rate=10.16 GlobalRate=10.16 Time=22:45:24\n",
            "| Training Device=xla:0/4 Epoch=52 Step=0 Loss=0.32947 Rate=10.16 GlobalRate=10.16 Time=22:45:24\n",
            "| Training Device=xla:0/7 Epoch=52 Step=0 Loss=0.26385 Rate=10.17 GlobalRate=10.17 Time=22:45:24\n",
            "| Training Device=xla:0/1 Epoch=52 Step=0 Loss=0.32610 Rate=10.16 GlobalRate=10.16 Time=22:45:24\n",
            "| Training Device=xla:0/2 Epoch=52 Step=0 Loss=0.30230 Rate=10.16 GlobalRate=10.16 Time=22:45:24\n",
            "| Training Device=xla:0/5 Epoch=52 Step=0 Loss=0.27732 Rate=10.16 GlobalRate=10.16 Time=22:45:24\n",
            "| Training Device=xla:0/3 Epoch=52 Step=0 Loss=0.45039 Rate=10.17 GlobalRate=10.17 Time=22:45:24\n",
            "Epoch 52 train end 22:45:24\n",
            "Epoch 53 train begin 22:45:24\n",
            "| Training Device=xla:0/3 Epoch=53 Step=0 Loss=0.44655 Rate=10.14 GlobalRate=10.14 Time=22:45:30\n",
            "| Training Device=xla:0/2 Epoch=53 Step=0 Loss=0.35436 Rate=10.13 GlobalRate=10.13 Time=22:45:30\n",
            "| Training Device=xla:0/1 Epoch=53 Step=0 Loss=0.34475 Rate=10.13 GlobalRate=10.13 Time=22:45:30\n",
            "| Training Device=xla:0/6 Epoch=53 Step=0 Loss=0.37959 Rate=10.13 GlobalRate=10.13 Time=22:45:30\n",
            "| Training Device=xla:1/0 Epoch=53 Step=0 Loss=0.36969 Rate=10.14 GlobalRate=10.14 Time=22:45:30\n",
            "| Training Device=xla:0/7 Epoch=53 Step=0 Loss=0.30630 Rate=10.13 GlobalRate=10.13 Time=22:45:30\n",
            "| Training Device=xla:0/5 Epoch=53 Step=0 Loss=0.35151 Rate=10.13 GlobalRate=10.13 Time=22:45:30\n",
            "| Training Device=xla:0/4 Epoch=53 Step=0 Loss=0.31514 Rate=10.13 GlobalRate=10.13 Time=22:45:30\n",
            "Epoch 53 train end 22:45:31\n",
            "Epoch 54 train begin 22:45:31\n",
            "| Training Device=xla:0/6 Epoch=54 Step=0 Loss=0.37123 Rate=10.14 GlobalRate=10.14 Time=22:45:37\n",
            "| Training Device=xla:0/7 Epoch=54 Step=0 Loss=0.29539 Rate=10.15 GlobalRate=10.15 Time=22:45:37\n",
            "| Training Device=xla:0/4 Epoch=54 Step=0 Loss=0.28747 Rate=10.14 GlobalRate=10.14 Time=22:45:37\n",
            "| Training Device=xla:0/3 Epoch=54 Step=0 Loss=0.39673 Rate=10.14 GlobalRate=10.14 Time=22:45:37\n",
            "| Training Device=xla:0/5 Epoch=54 Step=0 Loss=0.26287 Rate=10.14 GlobalRate=10.14 Time=22:45:37\n",
            "| Training Device=xla:0/2 Epoch=54 Step=0 Loss=0.33695 Rate=10.14 GlobalRate=10.14 Time=22:45:37\n",
            "| Training Device=xla:0/1 Epoch=54 Step=0 Loss=0.42191 Rate=10.14 GlobalRate=10.14 Time=22:45:37\n",
            "| Training Device=xla:1/0 Epoch=54 Step=0 Loss=0.35839 Rate=10.15 GlobalRate=10.15 Time=22:45:37\n",
            "Epoch 54 train end 22:45:37\n",
            "Epoch 55 train begin 22:45:37\n",
            "| Training Device=xla:0/6 Epoch=55 Step=0 Loss=0.41287 Rate=10.16 GlobalRate=10.16 Time=22:45:43\n",
            "| Training Device=xla:0/7 Epoch=55 Step=0 Loss=0.26274 Rate=10.16 GlobalRate=10.16 Time=22:45:43\n",
            "| Training Device=xla:0/2 Epoch=55 Step=0 Loss=0.33052 Rate=10.16 GlobalRate=10.16 Time=22:45:43\n",
            "| Training Device=xla:0/5 Epoch=55 Step=0 Loss=0.34253 Rate=10.16 GlobalRate=10.16 Time=22:45:43\n",
            "| Training Device=xla:0/4 Epoch=55 Step=0 Loss=0.28808 Rate=10.16 GlobalRate=10.16 Time=22:45:43\n",
            "| Training Device=xla:0/3 Epoch=55 Step=0 Loss=0.41815 Rate=10.16 GlobalRate=10.16 Time=22:45:43\n",
            "| Training Device=xla:1/0 Epoch=55 Step=0 Loss=0.32330 Rate=10.17 GlobalRate=10.17 Time=22:45:43\n",
            "| Training Device=xla:0/1 Epoch=55 Step=0 Loss=0.33369 Rate=10.16 GlobalRate=10.16 Time=22:45:43\n",
            "Epoch 55 train end 22:45:44\n",
            "Epoch 56 train begin 22:45:44\n",
            "| Training Device=xla:0/4 Epoch=56 Step=0 Loss=0.27511 Rate=10.18 GlobalRate=10.18 Time=22:45:50\n",
            "| Training Device=xla:0/3 Epoch=56 Step=0 Loss=0.46025 Rate=10.18 GlobalRate=10.18 Time=22:45:50\n",
            "| Training Device=xla:0/6 Epoch=56 Step=0 Loss=0.41750 Rate=10.18 GlobalRate=10.18 Time=22:45:50\n",
            "| Training Device=xla:0/1 Epoch=56 Step=0 Loss=0.37159 Rate=10.17 GlobalRate=10.17 Time=22:45:50\n",
            "| Training Device=xla:0/7 Epoch=56 Step=0 Loss=0.27796 Rate=10.18 GlobalRate=10.18 Time=22:45:50\n",
            "| Training Device=xla:0/2 Epoch=56 Step=0 Loss=0.30727 Rate=10.18 GlobalRate=10.18 Time=22:45:50\n",
            "| Training Device=xla:0/5 Epoch=56 Step=0 Loss=0.27915 Rate=10.18 GlobalRate=10.18 Time=22:45:50\n",
            "| Training Device=xla:1/0 Epoch=56 Step=0 Loss=0.35369 Rate=10.18 GlobalRate=10.18 Time=22:45:50\n",
            "Epoch 56 train end 22:45:50\n",
            "Epoch 57 train begin 22:45:50\n",
            "| Training Device=xla:0/2 Epoch=57 Step=0 Loss=0.34065 Rate=10.23 GlobalRate=10.23 Time=22:45:56\n",
            "| Training Device=xla:1/0 Epoch=57 Step=0 Loss=0.34863 Rate=10.23 GlobalRate=10.23 Time=22:45:56\n",
            "| Training Device=xla:0/4 Epoch=57 Step=0 Loss=0.35085 Rate=10.23 GlobalRate=10.23 Time=22:45:56\n",
            "| Training Device=xla:0/7 Epoch=57 Step=0 Loss=0.28695 Rate=10.23 GlobalRate=10.23 Time=22:45:56\n",
            "| Training Device=xla:0/5 Epoch=57 Step=0 Loss=0.31994 Rate=10.22 GlobalRate=10.22 Time=22:45:56\n",
            "| Training Device=xla:0/6 Epoch=57 Step=0 Loss=0.40981 Rate=10.22 GlobalRate=10.22 Time=22:45:56\n",
            "| Training Device=xla:0/1 Epoch=57 Step=0 Loss=0.34313 Rate=10.22 GlobalRate=10.22 Time=22:45:56\n",
            "| Training Device=xla:0/3 Epoch=57 Step=0 Loss=0.48865 Rate=10.22 GlobalRate=10.22 Time=22:45:56\n",
            "Epoch 57 train end 22:45:57\n",
            "Epoch 58 train begin 22:45:57\n",
            "| Training Device=xla:0/4 Epoch=58 Step=0 Loss=0.31973 Rate=10.17 GlobalRate=10.17 Time=22:46:03\n",
            "| Training Device=xla:0/3 Epoch=58 Step=0 Loss=0.45296 Rate=10.16 GlobalRate=10.16 Time=22:46:03\n",
            "| Training Device=xla:0/1 Epoch=58 Step=0 Loss=0.33568 Rate=10.16 GlobalRate=10.16 Time=22:46:03\n",
            "| Training Device=xla:0/2 Epoch=58 Step=0 Loss=0.30337 Rate=10.16 GlobalRate=10.16 Time=22:46:03\n",
            "| Training Device=xla:0/7 Epoch=58 Step=0 Loss=0.29529 Rate=10.16 GlobalRate=10.16 Time=22:46:03\n",
            "| Training Device=xla:0/6 Epoch=58 Step=0 Loss=0.43525 Rate=10.16 GlobalRate=10.16 Time=22:46:03\n",
            "| Training Device=xla:1/0 Epoch=58 Step=0 Loss=0.36565 Rate=10.17 GlobalRate=10.17 Time=22:46:03\n",
            "| Training Device=xla:0/5 Epoch=58 Step=0 Loss=0.27145 Rate=10.16 GlobalRate=10.16 Time=22:46:03\n",
            "Epoch 58 train end 22:46:03\n",
            "Epoch 59 train begin 22:46:03\n",
            "| Training Device=xla:0/1 Epoch=59 Step=0 Loss=0.30979 Rate=10.22 GlobalRate=10.22 Time=22:46:09\n",
            "| Training Device=xla:1/0 Epoch=59 Step=0 Loss=0.34000 Rate=10.23 GlobalRate=10.23 Time=22:46:09\n",
            "| Training Device=xla:0/2 Epoch=59 Step=0 Loss=0.29058 Rate=10.22 GlobalRate=10.22 Time=22:46:09\n",
            "| Training Device=xla:0/3 Epoch=59 Step=0 Loss=0.42020 Rate=10.22 GlobalRate=10.22 Time=22:46:09\n",
            "| Training Device=xla:0/7 Epoch=59 Step=0 Loss=0.29120 Rate=10.22 GlobalRate=10.22 Time=22:46:09\n",
            "| Training Device=xla:0/5 Epoch=59 Step=0 Loss=0.24549 Rate=10.22 GlobalRate=10.22 Time=22:46:09\n",
            "| Training Device=xla:0/6 Epoch=59 Step=0 Loss=0.36662 Rate=10.22 GlobalRate=10.22 Time=22:46:09\n",
            "| Training Device=xla:0/4 Epoch=59 Step=0 Loss=0.26704 Rate=10.22 GlobalRate=10.22 Time=22:46:09\n",
            "Epoch 59 train end 22:46:10\n",
            "Epoch 60 train begin 22:46:10\n",
            "| Training Device=xla:0/4 Epoch=60 Step=0 Loss=0.32921 Rate=10.12 GlobalRate=10.12 Time=22:46:16\n",
            "| Training Device=xla:0/7 Epoch=60 Step=0 Loss=0.29436 Rate=10.12 GlobalRate=10.12 Time=22:46:16\n",
            "| Training Device=xla:0/2 Epoch=60 Step=0 Loss=0.29578 Rate=10.12 GlobalRate=10.12 Time=22:46:16\n",
            "| Training Device=xla:1/0 Epoch=60 Step=0 Loss=0.39166 Rate=10.12 GlobalRate=10.12 Time=22:46:16\n",
            "| Training Device=xla:0/5 Epoch=60 Step=0 Loss=0.31003 Rate=10.12 GlobalRate=10.12 Time=22:46:16\n",
            "| Training Device=xla:0/3 Epoch=60 Step=0 Loss=0.43279 Rate=10.12 GlobalRate=10.12 Time=22:46:16\n",
            "| Training Device=xla:0/1 Epoch=60 Step=0 Loss=0.29570 Rate=10.12 GlobalRate=10.12 Time=22:46:16\n",
            "| Training Device=xla:0/6 Epoch=60 Step=0 Loss=0.36183 Rate=10.12 GlobalRate=10.12 Time=22:46:16\n",
            "Epoch 60 train end 22:46:16\n",
            "Epoch 61 train begin 22:46:16\n",
            "| Training Device=xla:1/0 Epoch=61 Step=0 Loss=0.33358 Rate=10.24 GlobalRate=10.24 Time=22:46:22\n",
            "| Training Device=xla:0/7 Epoch=61 Step=0 Loss=0.29234 Rate=10.23 GlobalRate=10.23 Time=22:46:22\n",
            "| Training Device=xla:0/4 Epoch=61 Step=0 Loss=0.37347 Rate=10.24 GlobalRate=10.24 Time=22:46:22\n",
            "| Training Device=xla:0/2 Epoch=61 Step=0 Loss=0.31313 Rate=10.23 GlobalRate=10.23 Time=22:46:22\n",
            "| Training Device=xla:0/5 Epoch=61 Step=0 Loss=0.28842 Rate=10.23 GlobalRate=10.23 Time=22:46:22\n",
            "| Training Device=xla:0/1 Epoch=61 Step=0 Loss=0.38990 Rate=10.23 GlobalRate=10.23 Time=22:46:22\n",
            "| Training Device=xla:0/3 Epoch=61 Step=0 Loss=0.44939 Rate=10.24 GlobalRate=10.24 Time=22:46:22\n",
            "| Training Device=xla:0/6 Epoch=61 Step=0 Loss=0.41321 Rate=10.23 GlobalRate=10.23 Time=22:46:22\n",
            "Epoch 61 train end 22:46:23\n",
            "Epoch 62 train begin 22:46:23\n",
            "| Training Device=xla:0/7 Epoch=62 Step=0 Loss=0.27150 Rate=10.19 GlobalRate=10.19 Time=22:46:29\n",
            "| Training Device=xla:0/6 Epoch=62 Step=0 Loss=0.43950 Rate=10.20 GlobalRate=10.20 Time=22:46:29\n",
            "| Training Device=xla:0/1 Epoch=62 Step=0 Loss=0.35297 Rate=10.20 GlobalRate=10.20 Time=22:46:29\n",
            "| Training Device=xla:0/3 Epoch=62 Step=0 Loss=0.40547 Rate=10.20 GlobalRate=10.20 Time=22:46:29\n",
            "| Training Device=xla:0/5 Epoch=62 Step=0 Loss=0.27528 Rate=10.20 GlobalRate=10.20 Time=22:46:29\n",
            "| Training Device=xla:0/4 Epoch=62 Step=0 Loss=0.29336 Rate=10.20 GlobalRate=10.20 Time=22:46:29\n",
            "| Training Device=xla:1/0 Epoch=62 Step=0 Loss=0.38698 Rate=10.20 GlobalRate=10.20 Time=22:46:29\n",
            "| Training Device=xla:0/2 Epoch=62 Step=0 Loss=0.35287 Rate=10.20 GlobalRate=10.20 Time=22:46:29\n",
            "Epoch 62 train end 22:46:29\n",
            "Epoch 63 train begin 22:46:29\n",
            "| Training Device=xla:0/7 Epoch=63 Step=0 Loss=0.30353 Rate=10.15 GlobalRate=10.15 Time=22:46:36\n",
            "| Training Device=xla:0/4 Epoch=63 Step=0 Loss=0.28971 Rate=10.15 GlobalRate=10.15 Time=22:46:36\n",
            "| Training Device=xla:1/0 Epoch=63 Step=0 Loss=0.36065 Rate=10.16 GlobalRate=10.16 Time=22:46:36\n",
            "| Training Device=xla:0/6 Epoch=63 Step=0 Loss=0.45192 Rate=10.15 GlobalRate=10.15 Time=22:46:36\n",
            "| Training Device=xla:0/2 Epoch=63 Step=0 Loss=0.29288 Rate=10.15 GlobalRate=10.15 Time=22:46:36\n",
            "| Training Device=xla:0/3 Epoch=63 Step=0 Loss=0.42975 Rate=10.15 GlobalRate=10.15 Time=22:46:36\n",
            "| Training Device=xla:0/5 Epoch=63 Step=0 Loss=0.28400 Rate=10.15 GlobalRate=10.15 Time=22:46:36\n",
            "| Training Device=xla:0/1 Epoch=63 Step=0 Loss=0.31154 Rate=10.15 GlobalRate=10.15 Time=22:46:36\n",
            "Epoch 63 train end 22:46:36\n",
            "Epoch 64 train begin 22:46:36\n",
            "| Training Device=xla:0/3 Epoch=64 Step=0 Loss=0.42253 Rate=10.18 GlobalRate=10.18 Time=22:46:42\n",
            "| Training Device=xla:0/6 Epoch=64 Step=0 Loss=0.42957 Rate=10.18 GlobalRate=10.18 Time=22:46:42\n",
            "| Training Device=xla:0/7 Epoch=64 Step=0 Loss=0.34099 Rate=10.18 GlobalRate=10.18 Time=22:46:42\n",
            "| Training Device=xla:0/4 Epoch=64 Step=0 Loss=0.29980 Rate=10.18 GlobalRate=10.18 Time=22:46:42\n",
            "| Training Device=xla:0/1 Epoch=64 Step=0 Loss=0.34948 Rate=10.18 GlobalRate=10.18 Time=22:46:42\n",
            "| Training Device=xla:0/2 Epoch=64 Step=0 Loss=0.28502 Rate=10.18 GlobalRate=10.18 Time=22:46:42\n",
            "| Training Device=xla:1/0 Epoch=64 Step=0 Loss=0.35363 Rate=10.18 GlobalRate=10.18 Time=22:46:42\n",
            "| Training Device=xla:0/5 Epoch=64 Step=0 Loss=0.33911 Rate=10.18 GlobalRate=10.18 Time=22:46:42\n",
            "Epoch 64 train end 22:46:42\n",
            "Epoch 65 train begin 22:46:42\n",
            "| Training Device=xla:0/2 Epoch=65 Step=0 Loss=0.29873 Rate=10.21 GlobalRate=10.21 Time=22:46:49\n",
            "| Training Device=xla:0/5 Epoch=65 Step=0 Loss=0.30542 Rate=10.22 GlobalRate=10.22 Time=22:46:49\n",
            "| Training Device=xla:0/4 Epoch=65 Step=0 Loss=0.25636 Rate=10.21 GlobalRate=10.21 Time=22:46:49\n",
            "| Training Device=xla:0/1 Epoch=65 Step=0 Loss=0.30678 Rate=10.21 GlobalRate=10.21 Time=22:46:49\n",
            "| Training Device=xla:0/7 Epoch=65 Step=0 Loss=0.30201 Rate=10.21 GlobalRate=10.21 Time=22:46:49\n",
            "| Training Device=xla:0/6 Epoch=65 Step=0 Loss=0.47000 Rate=10.21 GlobalRate=10.21 Time=22:46:49\n",
            "| Training Device=xla:0/3 Epoch=65 Step=0 Loss=0.46619 Rate=10.21 GlobalRate=10.21 Time=22:46:49\n",
            "| Training Device=xla:1/0 Epoch=65 Step=0 Loss=0.35518 Rate=10.22 GlobalRate=10.22 Time=22:46:49\n",
            "Epoch 65 train end 22:46:49\n",
            "Epoch 66 train begin 22:46:49\n",
            "| Training Device=xla:0/4 Epoch=66 Step=0 Loss=0.33287 Rate=10.21 GlobalRate=10.21 Time=22:46:55\n",
            "| Training Device=xla:0/3 Epoch=66 Step=0 Loss=0.46126 Rate=10.21 GlobalRate=10.21 Time=22:46:55\n",
            "| Training Device=xla:0/7 Epoch=66 Step=0 Loss=0.26806 Rate=10.20 GlobalRate=10.20 Time=22:46:55\n",
            "| Training Device=xla:1/0 Epoch=66 Step=0 Loss=0.38556 Rate=10.21 GlobalRate=10.21 Time=22:46:55\n",
            "| Training Device=xla:0/1 Epoch=66 Step=0 Loss=0.33060 Rate=10.21 GlobalRate=10.21 Time=22:46:55\n",
            "| Training Device=xla:0/6 Epoch=66 Step=0 Loss=0.36923 Rate=10.21 GlobalRate=10.21 Time=22:46:55\n",
            "| Training Device=xla:0/5 Epoch=66 Step=0 Loss=0.27574 Rate=10.20 GlobalRate=10.20 Time=22:46:55\n",
            "| Training Device=xla:0/2 Epoch=66 Step=0 Loss=0.28745 Rate=10.21 GlobalRate=10.21 Time=22:46:55\n",
            "Epoch 66 train end 22:46:55\n",
            "Epoch 67 train begin 22:46:55\n",
            "| Training Device=xla:0/7 Epoch=67 Step=0 Loss=0.31053 Rate=10.16 GlobalRate=10.16 Time=22:47:02\n",
            "| Training Device=xla:1/0 Epoch=67 Step=0 Loss=0.35844 Rate=10.17 GlobalRate=10.17 Time=22:47:02\n",
            "| Training Device=xla:0/5 Epoch=67 Step=0 Loss=0.31571 Rate=10.16 GlobalRate=10.16 Time=22:47:02\n",
            "| Training Device=xla:0/4 Epoch=67 Step=0 Loss=0.32188 Rate=10.16 GlobalRate=10.16 Time=22:47:02\n",
            "| Training Device=xla:0/6 Epoch=67 Step=0 Loss=0.43455 Rate=10.16 GlobalRate=10.16 Time=22:47:02\n",
            "| Training Device=xla:0/2 Epoch=67 Step=0 Loss=0.29086 Rate=10.16 GlobalRate=10.16 Time=22:47:02\n",
            "| Training Device=xla:0/1 Epoch=67 Step=0 Loss=0.29655 Rate=10.16 GlobalRate=10.16 Time=22:47:02\n",
            "| Training Device=xla:0/3 Epoch=67 Step=0 Loss=0.43338 Rate=10.16 GlobalRate=10.16 Time=22:47:02\n",
            "Epoch 67 train end 22:47:02\n",
            "Epoch 68 train begin 22:47:02\n",
            "| Training Device=xla:0/5 Epoch=68 Step=0 Loss=0.29089 Rate=10.10 GlobalRate=10.10 Time=22:47:08\n",
            "| Training Device=xla:0/4 Epoch=68 Step=0 Loss=0.29161 Rate=10.09 GlobalRate=10.09 Time=22:47:08\n",
            "| Training Device=xla:0/7 Epoch=68 Step=0 Loss=0.34635 Rate=10.10 GlobalRate=10.10 Time=22:47:08\n",
            "| Training Device=xla:0/6 Epoch=68 Step=0 Loss=0.38892 Rate=10.09 GlobalRate=10.09 Time=22:47:08\n",
            "| Training Device=xla:0/2 Epoch=68 Step=0 Loss=0.37638 Rate=10.09 GlobalRate=10.09 Time=22:47:08\n",
            "| Training Device=xla:0/3 Epoch=68 Step=0 Loss=0.42332 Rate=10.09 GlobalRate=10.09 Time=22:47:08\n",
            "| Training Device=xla:0/1 Epoch=68 Step=0 Loss=0.29166 Rate=10.09 GlobalRate=10.09 Time=22:47:08\n",
            "| Training Device=xla:1/0 Epoch=68 Step=0 Loss=0.40248 Rate=10.10 GlobalRate=10.10 Time=22:47:08\n",
            "Epoch 68 train end 22:47:08\n",
            "Epoch 69 train begin 22:47:08\n",
            "| Training Device=xla:0/6 Epoch=69 Step=0 Loss=0.37700 Rate=10.18 GlobalRate=10.18 Time=22:47:15\n",
            "| Training Device=xla:0/4 Epoch=69 Step=0 Loss=0.30000 Rate=10.18 GlobalRate=10.18 Time=22:47:15\n",
            "| Training Device=xla:0/2 Epoch=69 Step=0 Loss=0.35688 Rate=10.18 GlobalRate=10.18 Time=22:47:15\n",
            "| Training Device=xla:0/7 Epoch=69 Step=0 Loss=0.30582 Rate=10.18 GlobalRate=10.18 Time=22:47:15\n",
            "| Training Device=xla:0/5 Epoch=69 Step=0 Loss=0.36083 Rate=10.18 GlobalRate=10.18 Time=22:47:15\n",
            "| Training Device=xla:0/1 Epoch=69 Step=0 Loss=0.33640 Rate=10.18 GlobalRate=10.18 Time=22:47:15\n",
            "| Training Device=xla:1/0 Epoch=69 Step=0 Loss=0.36560 Rate=10.19 GlobalRate=10.19 Time=22:47:15\n",
            "| Training Device=xla:0/3 Epoch=69 Step=0 Loss=0.39903 Rate=10.18 GlobalRate=10.18 Time=22:47:15\n",
            "Epoch 69 train end 22:47:15\n",
            "Epoch 70 train begin 22:47:15\n",
            "| Training Device=xla:0/3 Epoch=70 Step=0 Loss=0.45049 Rate=10.18 GlobalRate=10.18 Time=22:47:21\n",
            "| Training Device=xla:0/2 Epoch=70 Step=0 Loss=0.27655 Rate=10.18 GlobalRate=10.18 Time=22:47:21\n",
            "| Training Device=xla:1/0 Epoch=70 Step=0 Loss=0.37055 Rate=10.18 GlobalRate=10.18 Time=22:47:21\n",
            "| Training Device=xla:0/7 Epoch=70 Step=0 Loss=0.28494 Rate=10.17 GlobalRate=10.17 Time=22:47:21\n",
            "| Training Device=xla:0/4 Epoch=70 Step=0 Loss=0.30409 Rate=10.17 GlobalRate=10.17 Time=22:47:21\n",
            "| Training Device=xla:0/6 Epoch=70 Step=0 Loss=0.44551 Rate=10.17 GlobalRate=10.17 Time=22:47:21\n",
            "| Training Device=xla:0/1 Epoch=70 Step=0 Loss=0.36251 Rate=10.17 GlobalRate=10.17 Time=22:47:21\n",
            "| Training Device=xla:0/5 Epoch=70 Step=0 Loss=0.33682 Rate=10.17 GlobalRate=10.17 Time=22:47:21\n",
            "Epoch 70 train end 22:47:21\n",
            "Epoch 71 train begin 22:47:21\n",
            "| Training Device=xla:0/1 Epoch=71 Step=0 Loss=0.34859 Rate=10.22 GlobalRate=10.22 Time=22:47:28\n",
            "| Training Device=xla:0/7 Epoch=71 Step=0 Loss=0.26454 Rate=10.22 GlobalRate=10.22 Time=22:47:28\n",
            "| Training Device=xla:0/5 Epoch=71 Step=0 Loss=0.28793 Rate=10.22 GlobalRate=10.22 Time=22:47:28\n",
            "| Training Device=xla:0/4 Epoch=71 Step=0 Loss=0.31574 Rate=10.22 GlobalRate=10.22 Time=22:47:28\n",
            "| Training Device=xla:1/0 Epoch=71 Step=0 Loss=0.38503 Rate=10.23 GlobalRate=10.23 Time=22:47:28\n",
            "| Training Device=xla:0/3 Epoch=71 Step=0 Loss=0.47827 Rate=10.22 GlobalRate=10.22 Time=22:47:28\n",
            "| Training Device=xla:0/6 Epoch=71 Step=0 Loss=0.38472 Rate=10.22 GlobalRate=10.22 Time=22:47:28\n",
            "| Training Device=xla:0/2 Epoch=71 Step=0 Loss=0.32735 Rate=10.22 GlobalRate=10.22 Time=22:47:28\n",
            "Epoch 71 train end 22:47:28\n",
            "Epoch 72 train begin 22:47:28\n",
            "| Training Device=xla:0/5 Epoch=72 Step=0 Loss=0.29797 Rate=10.16 GlobalRate=10.16 Time=22:47:34\n",
            "| Training Device=xla:0/1 Epoch=72 Step=0 Loss=0.38145 Rate=10.16 GlobalRate=10.16 Time=22:47:34\n",
            "| Training Device=xla:0/4 Epoch=72 Step=0 Loss=0.28675 Rate=10.16 GlobalRate=10.16 Time=22:47:34\n",
            "| Training Device=xla:0/7 Epoch=72 Step=0 Loss=0.34678 Rate=10.16 GlobalRate=10.16 Time=22:47:34\n",
            "| Training Device=xla:0/3 Epoch=72 Step=0 Loss=0.41175 Rate=10.16 GlobalRate=10.16 Time=22:47:34\n",
            "| Training Device=xla:0/6 Epoch=72 Step=0 Loss=0.38429 Rate=10.16 GlobalRate=10.16 Time=22:47:34\n",
            "| Training Device=xla:0/2 Epoch=72 Step=0 Loss=0.33761 Rate=10.16 GlobalRate=10.16 Time=22:47:34\n",
            "| Training Device=xla:1/0 Epoch=72 Step=0 Loss=0.36269 Rate=10.16 GlobalRate=10.16 Time=22:47:34\n",
            "Epoch 72 train end 22:47:35\n",
            "Epoch 73 train begin 22:47:35\n",
            "| Training Device=xla:0/2 Epoch=73 Step=0 Loss=0.32975 Rate=10.26 GlobalRate=10.26 Time=22:47:41\n",
            "| Training Device=xla:0/4 Epoch=73 Step=0 Loss=0.33708 Rate=10.26 GlobalRate=10.26 Time=22:47:41\n",
            "| Training Device=xla:0/7 Epoch=73 Step=0 Loss=0.34434 Rate=10.26 GlobalRate=10.26 Time=22:47:41\n",
            "| Training Device=xla:0/1 Epoch=73 Step=0 Loss=0.38720 Rate=10.26 GlobalRate=10.26 Time=22:47:41\n",
            "| Training Device=xla:0/5 Epoch=73 Step=0 Loss=0.27487 Rate=10.26 GlobalRate=10.26 Time=22:47:41\n",
            "| Training Device=xla:0/6 Epoch=73 Step=0 Loss=0.40949 Rate=10.26 GlobalRate=10.26 Time=22:47:41\n",
            "| Training Device=xla:0/3 Epoch=73 Step=0 Loss=0.49508 Rate=10.26 GlobalRate=10.26 Time=22:47:41\n",
            "| Training Device=xla:1/0 Epoch=73 Step=0 Loss=0.38043 Rate=10.26 GlobalRate=10.26 Time=22:47:41\n",
            "Epoch 73 train end 22:47:41\n",
            "Epoch 74 train begin 22:47:41\n",
            "| Training Device=xla:0/2 Epoch=74 Step=0 Loss=0.33713 Rate=10.17 GlobalRate=10.17 Time=22:47:47\n",
            "| Training Device=xla:0/4 Epoch=74 Step=0 Loss=0.34462 Rate=10.17 GlobalRate=10.17 Time=22:47:47\n",
            "| Training Device=xla:0/5 Epoch=74 Step=0 Loss=0.29106 Rate=10.17 GlobalRate=10.17 Time=22:47:47\n",
            "| Training Device=xla:1/0 Epoch=74 Step=0 Loss=0.30623 Rate=10.18 GlobalRate=10.18 Time=22:47:47\n",
            "| Training Device=xla:0/6 Epoch=74 Step=0 Loss=0.45373 Rate=10.17 GlobalRate=10.17 Time=22:47:47\n",
            "| Training Device=xla:0/7 Epoch=74 Step=0 Loss=0.32408 Rate=10.17 GlobalRate=10.17 Time=22:47:47\n",
            "| Training Device=xla:0/1 Epoch=74 Step=0 Loss=0.36443 Rate=10.17 GlobalRate=10.17 Time=22:47:47\n",
            "| Training Device=xla:0/3 Epoch=74 Step=0 Loss=0.39793 Rate=10.17 GlobalRate=10.17 Time=22:47:47\n",
            "Epoch 74 train end 22:47:48\n",
            "Epoch 75 train begin 22:47:48\n",
            "| Training Device=xla:0/1 Epoch=75 Step=0 Loss=0.33764 Rate=10.22 GlobalRate=10.22 Time=22:47:54\n",
            "| Training Device=xla:0/7 Epoch=75 Step=0 Loss=0.33601 Rate=10.21 GlobalRate=10.21 Time=22:47:54\n",
            "| Training Device=xla:0/5 Epoch=75 Step=0 Loss=0.27872 Rate=10.21 GlobalRate=10.21 Time=22:47:54\n",
            "| Training Device=xla:0/6 Epoch=75 Step=0 Loss=0.40889 Rate=10.22 GlobalRate=10.22 Time=22:47:54\n",
            "| Training Device=xla:0/2 Epoch=75 Step=0 Loss=0.31288 Rate=10.22 GlobalRate=10.22 Time=22:47:54\n",
            "| Training Device=xla:0/3 Epoch=75 Step=0 Loss=0.37464 Rate=10.22 GlobalRate=10.22 Time=22:47:54\n",
            "| Training Device=xla:0/4 Epoch=75 Step=0 Loss=0.25383 Rate=10.21 GlobalRate=10.21 Time=22:47:54\n",
            "| Training Device=xla:1/0 Epoch=75 Step=0 Loss=0.37283 Rate=10.22 GlobalRate=10.22 Time=22:47:54\n",
            "Epoch 75 train end 22:47:54\n",
            "Epoch 76 train begin 22:47:54\n",
            "| Training Device=xla:0/6 Epoch=76 Step=0 Loss=0.42821 Rate=10.22 GlobalRate=10.22 Time=22:48:00\n",
            "| Training Device=xla:0/7 Epoch=76 Step=0 Loss=0.31321 Rate=10.22 GlobalRate=10.22 Time=22:48:00\n",
            "| Training Device=xla:0/5 Epoch=76 Step=0 Loss=0.26366 Rate=10.22 GlobalRate=10.22 Time=22:48:00\n",
            "| Training Device=xla:0/4 Epoch=76 Step=0 Loss=0.25380 Rate=10.22 GlobalRate=10.22 Time=22:48:00\n",
            "| Training Device=xla:0/3 Epoch=76 Step=0 Loss=0.43502 Rate=10.22 GlobalRate=10.22 Time=22:48:00\n",
            "| Training Device=xla:0/2 Epoch=76 Step=0 Loss=0.31969 Rate=10.22 GlobalRate=10.22 Time=22:48:00\n",
            "| Training Device=xla:0/1 Epoch=76 Step=0 Loss=0.32483 Rate=10.22 GlobalRate=10.22 Time=22:48:00\n",
            "| Training Device=xla:1/0 Epoch=76 Step=0 Loss=0.36998 Rate=10.22 GlobalRate=10.22 Time=22:48:00\n",
            "Epoch 76 train end 22:48:01\n",
            "Epoch 77 train begin 22:48:01\n",
            "| Training Device=xla:0/2 Epoch=77 Step=0 Loss=0.33343 Rate=10.17 GlobalRate=10.17 Time=22:48:07\n",
            "| Training Device=xla:0/6 Epoch=77 Step=0 Loss=0.44250 Rate=10.17 GlobalRate=10.17 Time=22:48:07\n",
            "| Training Device=xla:0/7 Epoch=77 Step=0 Loss=0.32761 Rate=10.17 GlobalRate=10.17 Time=22:48:07\n",
            "| Training Device=xla:0/4 Epoch=77 Step=0 Loss=0.32003 Rate=10.17 GlobalRate=10.17 Time=22:48:07\n",
            "| Training Device=xla:1/0 Epoch=77 Step=0 Loss=0.26466 Rate=10.17 GlobalRate=10.17 Time=22:48:07\n",
            "| Training Device=xla:0/1 Epoch=77 Step=0 Loss=0.27822 Rate=10.17 GlobalRate=10.17 Time=22:48:07\n",
            "| Training Device=xla:0/5 Epoch=77 Step=0 Loss=0.25932 Rate=10.17 GlobalRate=10.17 Time=22:48:07\n",
            "| Training Device=xla:0/3 Epoch=77 Step=0 Loss=0.42319 Rate=10.17 GlobalRate=10.17 Time=22:48:07\n",
            "Epoch 77 train end 22:48:07\n",
            "Epoch 78 train begin 22:48:07\n",
            "| Training Device=xla:0/7 Epoch=78 Step=0 Loss=0.30152 Rate=10.10 GlobalRate=10.10 Time=22:48:13\n",
            "| Training Device=xla:0/6 Epoch=78 Step=0 Loss=0.44255 Rate=10.10 GlobalRate=10.10 Time=22:48:13\n",
            "| Training Device=xla:0/3 Epoch=78 Step=0 Loss=0.46653 Rate=10.10 GlobalRate=10.10 Time=22:48:13\n",
            "| Training Device=xla:0/1 Epoch=78 Step=0 Loss=0.35277 Rate=10.10 GlobalRate=10.10 Time=22:48:13\n",
            "| Training Device=xla:1/0 Epoch=78 Step=0 Loss=0.36835 Rate=10.10 GlobalRate=10.10 Time=22:48:13\n",
            "| Training Device=xla:0/5 Epoch=78 Step=0 Loss=0.30613 Rate=10.10 GlobalRate=10.10 Time=22:48:13\n",
            "| Training Device=xla:0/4 Epoch=78 Step=0 Loss=0.33132 Rate=10.10 GlobalRate=10.10 Time=22:48:13\n",
            "| Training Device=xla:0/2 Epoch=78 Step=0 Loss=0.30959 Rate=10.10 GlobalRate=10.10 Time=22:48:13\n",
            "Epoch 78 train end 22:48:14\n",
            "Epoch 79 train begin 22:48:14\n",
            "| Training Device=xla:0/6 Epoch=79 Step=0 Loss=0.44308 Rate=10.22 GlobalRate=10.22 Time=22:48:20\n",
            "| Training Device=xla:0/1 Epoch=79 Step=0 Loss=0.30327 Rate=10.21 GlobalRate=10.21 Time=22:48:20\n",
            "| Training Device=xla:0/4 Epoch=79 Step=0 Loss=0.32726 Rate=10.21 GlobalRate=10.21 Time=22:48:20\n",
            "| Training Device=xla:0/7 Epoch=79 Step=0 Loss=0.28658 Rate=10.21 GlobalRate=10.21 Time=22:48:20\n",
            "| Training Device=xla:0/2 Epoch=79 Step=0 Loss=0.32072 Rate=10.21 GlobalRate=10.21 Time=22:48:20\n",
            "| Training Device=xla:0/3 Epoch=79 Step=0 Loss=0.46670 Rate=10.21 GlobalRate=10.21 Time=22:48:20\n",
            "| Training Device=xla:0/5 Epoch=79 Step=0 Loss=0.34705 Rate=10.21 GlobalRate=10.21 Time=22:48:20\n",
            "| Training Device=xla:1/0 Epoch=79 Step=0 Loss=0.37482 Rate=10.22 GlobalRate=10.22 Time=22:48:20\n",
            "Epoch 79 train end 22:48:20\n",
            "Epoch 80 train begin 22:48:20\n",
            "| Training Device=xla:0/6 Epoch=80 Step=0 Loss=0.42405 Rate=10.14 GlobalRate=10.14 Time=22:48:26\n",
            "| Training Device=xla:0/3 Epoch=80 Step=0 Loss=0.44833 Rate=10.14 GlobalRate=10.14 Time=22:48:26\n",
            "| Training Device=xla:0/4 Epoch=80 Step=0 Loss=0.29936 Rate=10.14 GlobalRate=10.14 Time=22:48:26\n",
            "| Training Device=xla:0/7 Epoch=80 Step=0 Loss=0.25606 Rate=10.14 GlobalRate=10.14 Time=22:48:26\n",
            "| Training Device=xla:0/1 Epoch=80 Step=0 Loss=0.32773 Rate=10.14 GlobalRate=10.14 Time=22:48:26\n",
            "| Training Device=xla:0/5 Epoch=80 Step=0 Loss=0.30089 Rate=10.14 GlobalRate=10.14 Time=22:48:26\n",
            "| Training Device=xla:1/0 Epoch=80 Step=0 Loss=0.44351 Rate=10.15 GlobalRate=10.15 Time=22:48:26\n",
            "| Training Device=xla:0/2 Epoch=80 Step=0 Loss=0.28134 Rate=10.14 GlobalRate=10.14 Time=22:48:26\n",
            "Epoch 80 train end 22:48:27\n",
            "Epoch 81 train begin 22:48:27\n",
            "| Training Device=xla:0/5 Epoch=81 Step=0 Loss=0.27774 Rate=10.10 GlobalRate=10.10 Time=22:48:33\n",
            "| Training Device=xla:0/2 Epoch=81 Step=0 Loss=0.40686 Rate=10.10 GlobalRate=10.10 Time=22:48:33\n",
            "| Training Device=xla:0/3 Epoch=81 Step=0 Loss=0.46311 Rate=10.10 GlobalRate=10.10 Time=22:48:33\n",
            "| Training Device=xla:0/6 Epoch=81 Step=0 Loss=0.41677 Rate=10.10 GlobalRate=10.10 Time=22:48:33\n",
            "| Training Device=xla:0/4 Epoch=81 Step=0 Loss=0.30718 Rate=10.10 GlobalRate=10.10 Time=22:48:33\n",
            "| Training Device=xla:0/7 Epoch=81 Step=0 Loss=0.28914 Rate=10.10 GlobalRate=10.10 Time=22:48:33\n",
            "| Training Device=xla:0/1 Epoch=81 Step=0 Loss=0.27915 Rate=10.10 GlobalRate=10.10 Time=22:48:33\n",
            "| Training Device=xla:1/0 Epoch=81 Step=0 Loss=0.37558 Rate=10.10 GlobalRate=10.10 Time=22:48:33\n",
            "Epoch 81 train end 22:48:33\n",
            "Epoch 82 train begin 22:48:33\n",
            "| Training Device=xla:0/4 Epoch=82 Step=0 Loss=0.31374 Rate=10.15 GlobalRate=10.15 Time=22:48:40\n",
            "| Training Device=xla:0/5 Epoch=82 Step=0 Loss=0.28442 Rate=10.15 GlobalRate=10.15 Time=22:48:40\n",
            "| Training Device=xla:0/2 Epoch=82 Step=0 Loss=0.35097 Rate=10.15 GlobalRate=10.15 Time=22:48:40\n",
            "| Training Device=xla:0/1 Epoch=82 Step=0 Loss=0.36715 Rate=10.15 GlobalRate=10.15 Time=22:48:40\n",
            "| Training Device=xla:0/6 Epoch=82 Step=0 Loss=0.38526 Rate=10.15 GlobalRate=10.15 Time=22:48:40\n",
            "| Training Device=xla:0/3 Epoch=82 Step=0 Loss=0.45922 Rate=10.15 GlobalRate=10.15 Time=22:48:40\n",
            "| Training Device=xla:0/7 Epoch=82 Step=0 Loss=0.34997 Rate=10.15 GlobalRate=10.15 Time=22:48:40\n",
            "| Training Device=xla:1/0 Epoch=82 Step=0 Loss=0.31580 Rate=10.15 GlobalRate=10.15 Time=22:48:40\n",
            "Epoch 82 train end 22:48:40\n",
            "Epoch 83 train begin 22:48:40\n",
            "| Training Device=xla:0/5 Epoch=83 Step=0 Loss=0.28152 Rate=10.19 GlobalRate=10.19 Time=22:48:46\n",
            "| Training Device=xla:0/7 Epoch=83 Step=0 Loss=0.31767 Rate=10.18 GlobalRate=10.18 Time=22:48:46\n",
            "| Training Device=xla:0/1 Epoch=83 Step=0 Loss=0.33856 Rate=10.18 GlobalRate=10.18 Time=22:48:46\n",
            "| Training Device=xla:0/6 Epoch=83 Step=0 Loss=0.42386 Rate=10.18 GlobalRate=10.18 Time=22:48:46\n",
            "| Training Device=xla:0/3 Epoch=83 Step=0 Loss=0.45604 Rate=10.18 GlobalRate=10.18 Time=22:48:46\n",
            "| Training Device=xla:0/4 Epoch=83 Step=0 Loss=0.35025 Rate=10.18 GlobalRate=10.18 Time=22:48:46\n",
            "| Training Device=xla:0/2 Epoch=83 Step=0 Loss=0.27734 Rate=10.18 GlobalRate=10.18 Time=22:48:46\n",
            "| Training Device=xla:1/0 Epoch=83 Step=0 Loss=0.33743 Rate=10.18 GlobalRate=10.18 Time=22:48:46\n",
            "Epoch 83 train end 22:48:46\n",
            "Epoch 84 train begin 22:48:46\n",
            "| Training Device=xla:0/6 Epoch=84 Step=0 Loss=0.38764 Rate=10.20 GlobalRate=10.20 Time=22:48:53\n",
            "| Training Device=xla:0/3 Epoch=84 Step=0 Loss=0.44014 Rate=10.20 GlobalRate=10.20 Time=22:48:53\n",
            "| Training Device=xla:0/4 Epoch=84 Step=0 Loss=0.27834 Rate=10.19 GlobalRate=10.19 Time=22:48:53\n",
            "| Training Device=xla:1/0 Epoch=84 Step=0 Loss=0.36820 Rate=10.20 GlobalRate=10.20 Time=22:48:53\n",
            "| Training Device=xla:0/5 Epoch=84 Step=0 Loss=0.29624 Rate=10.19 GlobalRate=10.19 Time=22:48:53\n",
            "| Training Device=xla:0/2 Epoch=84 Step=0 Loss=0.33799 Rate=10.19 GlobalRate=10.19 Time=22:48:53\n",
            "| Training Device=xla:0/7 Epoch=84 Step=0 Loss=0.29006 Rate=10.19 GlobalRate=10.19 Time=22:48:53\n",
            "| Training Device=xla:0/1 Epoch=84 Step=0 Loss=0.32623 Rate=10.19 GlobalRate=10.19 Time=22:48:53\n",
            "Epoch 84 train end 22:48:53\n",
            "Epoch 85 train begin 22:48:53\n",
            "| Training Device=xla:0/5 Epoch=85 Step=0 Loss=0.28569 Rate=10.23 GlobalRate=10.23 Time=22:48:59\n",
            "| Training Device=xla:0/4 Epoch=85 Step=0 Loss=0.25459 Rate=10.23 GlobalRate=10.23 Time=22:48:59\n",
            "| Training Device=xla:0/7 Epoch=85 Step=0 Loss=0.26517 Rate=10.23 GlobalRate=10.23 Time=22:48:59\n",
            "| Training Device=xla:0/3 Epoch=85 Step=0 Loss=0.48000 Rate=10.23 GlobalRate=10.23 Time=22:48:59\n",
            "| Training Device=xla:1/0 Epoch=85 Step=0 Loss=0.34848 Rate=10.24 GlobalRate=10.24 Time=22:48:59\n",
            "| Training Device=xla:0/6 Epoch=85 Step=0 Loss=0.41374 Rate=10.23 GlobalRate=10.23 Time=22:48:59\n",
            "| Training Device=xla:0/1 Epoch=85 Step=0 Loss=0.32548 Rate=10.23 GlobalRate=10.23 Time=22:48:59\n",
            "| Training Device=xla:0/2 Epoch=85 Step=0 Loss=0.30619 Rate=10.23 GlobalRate=10.23 Time=22:48:59\n",
            "Epoch 85 train end 22:48:59\n",
            "Epoch 86 train begin 22:48:59\n",
            "| Training Device=xla:0/2 Epoch=86 Step=0 Loss=0.31861 Rate=10.24 GlobalRate=10.24 Time=22:49:06\n",
            "| Training Device=xla:0/1 Epoch=86 Step=0 Loss=0.32173 Rate=10.24 GlobalRate=10.24 Time=22:49:06\n",
            "| Training Device=xla:1/0 Epoch=86 Step=0 Loss=0.33851 Rate=10.24 GlobalRate=10.24 Time=22:49:06\n",
            "| Training Device=xla:0/7 Epoch=86 Step=0 Loss=0.29539 Rate=10.24 GlobalRate=10.24 Time=22:49:06\n",
            "| Training Device=xla:0/5 Epoch=86 Step=0 Loss=0.29513 Rate=10.24 GlobalRate=10.24 Time=22:49:06\n",
            "| Training Device=xla:0/3 Epoch=86 Step=0 Loss=0.42054 Rate=10.24 GlobalRate=10.24 Time=22:49:06\n",
            "| Training Device=xla:0/6 Epoch=86 Step=0 Loss=0.37304 Rate=10.24 GlobalRate=10.24 Time=22:49:06\n",
            "| Training Device=xla:0/4 Epoch=86 Step=0 Loss=0.30590 Rate=10.24 GlobalRate=10.24 Time=22:49:06\n",
            "Epoch 86 train end 22:49:06\n",
            "Epoch 87 train begin 22:49:06\n",
            "| Training Device=xla:0/2 Epoch=87 Step=0 Loss=0.28937 Rate=10.18 GlobalRate=10.18 Time=22:49:12\n",
            "| Training Device=xla:0/3 Epoch=87 Step=0 Loss=0.41747 Rate=10.18 GlobalRate=10.18 Time=22:49:12\n",
            "| Training Device=xla:0/7 Epoch=87 Step=0 Loss=0.29173 Rate=10.18 GlobalRate=10.18 Time=22:49:12\n",
            "| Training Device=xla:0/4 Epoch=87 Step=0 Loss=0.28142 Rate=10.18 GlobalRate=10.18 Time=22:49:12\n",
            "| Training Device=xla:0/6 Epoch=87 Step=0 Loss=0.38547 Rate=10.18 GlobalRate=10.18 Time=22:49:12\n",
            "| Training Device=xla:0/5 Epoch=87 Step=0 Loss=0.25553 Rate=10.17 GlobalRate=10.17 Time=22:49:12\n",
            "| Training Device=xla:0/1 Epoch=87 Step=0 Loss=0.26851 Rate=10.18 GlobalRate=10.18 Time=22:49:12\n",
            "| Training Device=xla:1/0 Epoch=87 Step=0 Loss=0.29506 Rate=10.18 GlobalRate=10.18 Time=22:49:12\n",
            "Epoch 87 train end 22:49:12\n",
            "Epoch 88 train begin 22:49:12\n",
            "| Training Device=xla:0/3 Epoch=88 Step=0 Loss=0.45988 Rate=10.22 GlobalRate=10.22 Time=22:49:19\n",
            "| Training Device=xla:0/1 Epoch=88 Step=0 Loss=0.32733 Rate=10.22 GlobalRate=10.22 Time=22:49:19\n",
            "| Training Device=xla:0/6 Epoch=88 Step=0 Loss=0.40313 Rate=10.22 GlobalRate=10.22 Time=22:49:19\n",
            "| Training Device=xla:0/5 Epoch=88 Step=0 Loss=0.29983 Rate=10.22 GlobalRate=10.22 Time=22:49:19\n",
            "| Training Device=xla:0/4 Epoch=88 Step=0 Loss=0.28411 Rate=10.21 GlobalRate=10.21 Time=22:49:19\n",
            "| Training Device=xla:0/2 Epoch=88 Step=0 Loss=0.33094 Rate=10.21 GlobalRate=10.21 Time=22:49:19\n",
            "| Training Device=xla:0/7 Epoch=88 Step=0 Loss=0.30613 Rate=10.21 GlobalRate=10.21 Time=22:49:19\n",
            "| Training Device=xla:1/0 Epoch=88 Step=0 Loss=0.35274 Rate=10.22 GlobalRate=10.22 Time=22:49:19\n",
            "Epoch 88 train end 22:49:19\n",
            "Epoch 89 train begin 22:49:19\n",
            "| Training Device=xla:0/4 Epoch=89 Step=0 Loss=0.31349 Rate=10.19 GlobalRate=10.19 Time=22:49:25\n",
            "| Training Device=xla:0/3 Epoch=89 Step=0 Loss=0.41281 Rate=10.19 GlobalRate=10.19 Time=22:49:25\n",
            "| Training Device=xla:0/2 Epoch=89 Step=0 Loss=0.39848 Rate=10.19 GlobalRate=10.19 Time=22:49:25\n",
            "| Training Device=xla:0/1 Epoch=89 Step=0 Loss=0.36074 Rate=10.19 GlobalRate=10.19 Time=22:49:25\n",
            "| Training Device=xla:1/0 Epoch=89 Step=0 Loss=0.35952 Rate=10.19 GlobalRate=10.19 Time=22:49:25\n",
            "| Training Device=xla:0/6 Epoch=89 Step=0 Loss=0.40768 Rate=10.19 GlobalRate=10.19 Time=22:49:25\n",
            "| Training Device=xla:0/7 Epoch=89 Step=0 Loss=0.31193 Rate=10.19 GlobalRate=10.19 Time=22:49:25\n",
            "| Training Device=xla:0/5 Epoch=89 Step=0 Loss=0.30245 Rate=10.19 GlobalRate=10.19 Time=22:49:25\n",
            "Epoch 89 train end 22:49:25\n",
            "Epoch 90 train begin 22:49:25\n",
            "| Training Device=xla:0/1 Epoch=90 Step=0 Loss=0.29685 Rate=10.17 GlobalRate=10.17 Time=22:49:32\n",
            "| Training Device=xla:0/5 Epoch=90 Step=0 Loss=0.28093 Rate=10.17 GlobalRate=10.17 Time=22:49:32\n",
            "| Training Device=xla:1/0 Epoch=90 Step=0 Loss=0.36929 Rate=10.17 GlobalRate=10.17 Time=22:49:32\n",
            "| Training Device=xla:0/4 Epoch=90 Step=0 Loss=0.26912 Rate=10.17 GlobalRate=10.17 Time=22:49:32\n",
            "| Training Device=xla:0/6 Epoch=90 Step=0 Loss=0.41721 Rate=10.17 GlobalRate=10.17 Time=22:49:32\n",
            "| Training Device=xla:0/7 Epoch=90 Step=0 Loss=0.27685 Rate=10.17 GlobalRate=10.17 Time=22:49:32\n",
            "| Training Device=xla:0/3 Epoch=90 Step=0 Loss=0.46471 Rate=10.17 GlobalRate=10.17 Time=22:49:32\n",
            "| Training Device=xla:0/2 Epoch=90 Step=0 Loss=0.31921 Rate=10.16 GlobalRate=10.16 Time=22:49:32\n",
            "Epoch 90 train end 22:49:32\n",
            "Epoch 91 train begin 22:49:32\n",
            "| Training Device=xla:0/1 Epoch=91 Step=0 Loss=0.33902 Rate=10.23 GlobalRate=10.23 Time=22:49:38\n",
            "| Training Device=xla:0/7 Epoch=91 Step=0 Loss=0.30036 Rate=10.23 GlobalRate=10.23 Time=22:49:38\n",
            "| Training Device=xla:0/2 Epoch=91 Step=0 Loss=0.30005 Rate=10.23 GlobalRate=10.23 Time=22:49:38\n",
            "| Training Device=xla:0/4 Epoch=91 Step=0 Loss=0.30483 Rate=10.22 GlobalRate=10.22 Time=22:49:38\n",
            "| Training Device=xla:0/6 Epoch=91 Step=0 Loss=0.35643 Rate=10.22 GlobalRate=10.22 Time=22:49:38\n",
            "| Training Device=xla:0/5 Epoch=91 Step=0 Loss=0.30063 Rate=10.22 GlobalRate=10.22 Time=22:49:38\n",
            "| Training Device=xla:0/3 Epoch=91 Step=0 Loss=0.44523 Rate=10.22 GlobalRate=10.22 Time=22:49:38\n",
            "| Training Device=xla:1/0 Epoch=91 Step=0 Loss=0.50112 Rate=10.22 GlobalRate=10.22 Time=22:49:38\n",
            "Epoch 91 train end 22:49:38\n",
            "Epoch 92 train begin 22:49:38\n",
            "| Training Device=xla:0/4 Epoch=92 Step=0 Loss=0.33749 Rate=10.12 GlobalRate=10.12 Time=22:49:45\n",
            "| Training Device=xla:0/7 Epoch=92 Step=0 Loss=0.31842 Rate=10.12 GlobalRate=10.12 Time=22:49:45\n",
            "| Training Device=xla:0/3 Epoch=92 Step=0 Loss=0.41323 Rate=10.12 GlobalRate=10.12 Time=22:49:45\n",
            "| Training Device=xla:0/5 Epoch=92 Step=0 Loss=0.29389 Rate=10.12 GlobalRate=10.12 Time=22:49:45\n",
            "| Training Device=xla:0/1 Epoch=92 Step=0 Loss=0.31482 Rate=10.12 GlobalRate=10.12 Time=22:49:45\n",
            "| Training Device=xla:0/6 Epoch=92 Step=0 Loss=0.36495 Rate=10.12 GlobalRate=10.12 Time=22:49:45\n",
            "| Training Device=xla:0/2 Epoch=92 Step=0 Loss=0.31584 Rate=10.12 GlobalRate=10.12 Time=22:49:45\n",
            "| Training Device=xla:1/0 Epoch=92 Step=0 Loss=0.39641 Rate=10.12 GlobalRate=10.12 Time=22:49:45\n",
            "Epoch 92 train end 22:49:45\n",
            "Epoch 93 train begin 22:49:45\n",
            "| Training Device=xla:0/1 Epoch=93 Step=0 Loss=0.35185 Rate=10.14 GlobalRate=10.14 Time=22:49:51\n",
            "| Training Device=xla:0/4 Epoch=93 Step=0 Loss=0.31061 Rate=10.14 GlobalRate=10.14 Time=22:49:51\n",
            "| Training Device=xla:0/3 Epoch=93 Step=0 Loss=0.42803 Rate=10.14 GlobalRate=10.14 Time=22:49:51\n",
            "| Training Device=xla:1/0 Epoch=93 Step=0 Loss=0.38684 Rate=10.14 GlobalRate=10.14 Time=22:49:51\n",
            "| Training Device=xla:0/7 Epoch=93 Step=0 Loss=0.31008 Rate=10.14 GlobalRate=10.14 Time=22:49:51\n",
            "| Training Device=xla:0/2 Epoch=93 Step=0 Loss=0.27652 Rate=10.14 GlobalRate=10.14 Time=22:49:51\n",
            "| Training Device=xla:0/5 Epoch=93 Step=0 Loss=0.24280 Rate=10.14 GlobalRate=10.14 Time=22:49:51\n",
            "| Training Device=xla:0/6 Epoch=93 Step=0 Loss=0.39141 Rate=10.14 GlobalRate=10.14 Time=22:49:51\n",
            "Epoch 93 train end 22:49:51\n",
            "Epoch 94 train begin 22:49:51\n",
            "| Training Device=xla:0/4 Epoch=94 Step=0 Loss=0.33720 Rate=10.21 GlobalRate=10.21 Time=22:49:58\n",
            "| Training Device=xla:0/3 Epoch=94 Step=0 Loss=0.42123 Rate=10.21 GlobalRate=10.21 Time=22:49:58\n",
            "| Training Device=xla:1/0 Epoch=94 Step=0 Loss=0.36688 Rate=10.22 GlobalRate=10.22 Time=22:49:58\n",
            "| Training Device=xla:0/6 Epoch=94 Step=0 Loss=0.37311 Rate=10.21 GlobalRate=10.21 Time=22:49:58\n",
            "| Training Device=xla:0/7 Epoch=94 Step=0 Loss=0.32953 Rate=10.21 GlobalRate=10.21 Time=22:49:58\n",
            "| Training Device=xla:0/1 Epoch=94 Step=0 Loss=0.32944 Rate=10.21 GlobalRate=10.21 Time=22:49:58\n",
            "| Training Device=xla:0/5 Epoch=94 Step=0 Loss=0.28103 Rate=10.21 GlobalRate=10.21 Time=22:49:58\n",
            "| Training Device=xla:0/2 Epoch=94 Step=0 Loss=0.36165 Rate=10.21 GlobalRate=10.21 Time=22:49:58\n",
            "Epoch 94 train end 22:49:58\n",
            "Epoch 95 train begin 22:49:58\n",
            "| Training Device=xla:0/5 Epoch=95 Step=0 Loss=0.24932 Rate=10.23 GlobalRate=10.23 Time=22:50:04\n",
            "| Training Device=xla:0/3 Epoch=95 Step=0 Loss=0.37776 Rate=10.23 GlobalRate=10.23 Time=22:50:04\n",
            "| Training Device=xla:0/1 Epoch=95 Step=0 Loss=0.32557 Rate=10.23 GlobalRate=10.23 Time=22:50:04\n",
            "| Training Device=xla:0/7 Epoch=95 Step=0 Loss=0.29514 Rate=10.23 GlobalRate=10.23 Time=22:50:04\n",
            "| Training Device=xla:0/6 Epoch=95 Step=0 Loss=0.37302 Rate=10.23 GlobalRate=10.23 Time=22:50:04\n",
            "| Training Device=xla:0/4 Epoch=95 Step=0 Loss=0.27418 Rate=10.23 GlobalRate=10.23 Time=22:50:04\n",
            "| Training Device=xla:1/0 Epoch=95 Step=0 Loss=0.30907 Rate=10.23 GlobalRate=10.23 Time=22:50:04\n",
            "| Training Device=xla:0/2 Epoch=95 Step=0 Loss=0.30441 Rate=10.23 GlobalRate=10.23 Time=22:50:04\n",
            "Epoch 95 train end 22:50:04\n",
            "Epoch 96 train begin 22:50:04\n",
            "| Training Device=xla:0/1 Epoch=96 Step=0 Loss=0.37846 Rate=10.23 GlobalRate=10.23 Time=22:50:11\n",
            "| Training Device=xla:0/2 Epoch=96 Step=0 Loss=0.33798 Rate=10.23 GlobalRate=10.23 Time=22:50:11\n",
            "| Training Device=xla:0/7 Epoch=96 Step=0 Loss=0.29777 Rate=10.23 GlobalRate=10.23 Time=22:50:11\n",
            "| Training Device=xla:0/3 Epoch=96 Step=0 Loss=0.44478 Rate=10.23 GlobalRate=10.23 Time=22:50:11\n",
            "| Training Device=xla:0/5 Epoch=96 Step=0 Loss=0.26596 Rate=10.23 GlobalRate=10.23 Time=22:50:11\n",
            "| Training Device=xla:0/6 Epoch=96 Step=0 Loss=0.38499 Rate=10.23 GlobalRate=10.23 Time=22:50:11\n",
            "| Training Device=xla:0/4 Epoch=96 Step=0 Loss=0.28895 Rate=10.23 GlobalRate=10.23 Time=22:50:11\n",
            "| Training Device=xla:1/0 Epoch=96 Step=0 Loss=0.32103 Rate=10.24 GlobalRate=10.24 Time=22:50:11\n",
            "Epoch 96 train end 22:50:11\n",
            "Epoch 97 train begin 22:50:11\n",
            "| Training Device=xla:1/0 Epoch=97 Step=0 Loss=0.40731 Rate=10.22 GlobalRate=10.22 Time=22:50:17\n",
            "| Training Device=xla:0/4 Epoch=97 Step=0 Loss=0.34282 Rate=10.21 GlobalRate=10.21 Time=22:50:17\n",
            "| Training Device=xla:0/5 Epoch=97 Step=0 Loss=0.29536 Rate=10.21 GlobalRate=10.21 Time=22:50:17\n",
            "| Training Device=xla:0/2 Epoch=97 Step=0 Loss=0.36116 Rate=10.21 GlobalRate=10.21 Time=22:50:17\n",
            "| Training Device=xla:0/1 Epoch=97 Step=0 Loss=0.33832 Rate=10.21 GlobalRate=10.21 Time=22:50:17\n",
            "| Training Device=xla:0/7 Epoch=97 Step=0 Loss=0.26902 Rate=10.21 GlobalRate=10.21 Time=22:50:17\n",
            "| Training Device=xla:0/3 Epoch=97 Step=0 Loss=0.47497 Rate=10.21 GlobalRate=10.21 Time=22:50:17\n",
            "| Training Device=xla:0/6 Epoch=97 Step=0 Loss=0.42134 Rate=10.21 GlobalRate=10.21 Time=22:50:17\n",
            "Epoch 97 train end 22:50:17\n",
            "Epoch 98 train begin 22:50:17\n",
            "| Training Device=xla:0/6 Epoch=98 Step=0 Loss=0.39835 Rate=10.12 GlobalRate=10.12 Time=22:50:24\n",
            "| Training Device=xla:0/7 Epoch=98 Step=0 Loss=0.27570 Rate=10.11 GlobalRate=10.11 Time=22:50:24\n",
            "| Training Device=xla:0/5 Epoch=98 Step=0 Loss=0.28518 Rate=10.12 GlobalRate=10.12 Time=22:50:24\n",
            "| Training Device=xla:0/1 Epoch=98 Step=0 Loss=0.28943 Rate=10.12 GlobalRate=10.12 Time=22:50:24\n",
            "| Training Device=xla:0/2 Epoch=98 Step=0 Loss=0.27217 Rate=10.11 GlobalRate=10.11 Time=22:50:24\n",
            "| Training Device=xla:0/4 Epoch=98 Step=0 Loss=0.27876 Rate=10.12 GlobalRate=10.12 Time=22:50:24\n",
            "| Training Device=xla:1/0 Epoch=98 Step=0 Loss=0.38008 Rate=10.12 GlobalRate=10.12 Time=22:50:24\n",
            "| Training Device=xla:0/3 Epoch=98 Step=0 Loss=0.41653 Rate=10.11 GlobalRate=10.11 Time=22:50:24\n",
            "Epoch 98 train end 22:50:24\n",
            "Epoch 99 train begin 22:50:24\n",
            "| Training Device=xla:0/2 Epoch=99 Step=0 Loss=0.32972 Rate=10.13 GlobalRate=10.13 Time=22:50:30\n",
            "| Training Device=xla:0/6 Epoch=99 Step=0 Loss=0.38469 Rate=10.12 GlobalRate=10.12 Time=22:50:30\n",
            "| Training Device=xla:0/1 Epoch=99 Step=0 Loss=0.31989 Rate=10.12 GlobalRate=10.12 Time=22:50:30\n",
            "| Training Device=xla:0/3 Epoch=99 Step=0 Loss=0.42425 Rate=10.12 GlobalRate=10.12 Time=22:50:30\n",
            "| Training Device=xla:0/7 Epoch=99 Step=0 Loss=0.30169 Rate=10.12 GlobalRate=10.12 Time=22:50:30\n",
            "| Training Device=xla:0/5 Epoch=99 Step=0 Loss=0.32877 Rate=10.12 GlobalRate=10.12 Time=22:50:30\n",
            "| Training Device=xla:0/4 Epoch=99 Step=0 Loss=0.30304 Rate=10.12 GlobalRate=10.12 Time=22:50:30\n",
            "| Training Device=xla:1/0 Epoch=99 Step=0 Loss=0.35624 Rate=10.12 GlobalRate=10.12 Time=22:50:30\n",
            "Epoch 99 train end 22:50:31\n",
            "Epoch 100 train begin 22:50:31\n",
            "| Training Device=xla:0/7 Epoch=100 Step=0 Loss=0.33845 Rate=10.15 GlobalRate=10.15 Time=22:50:37\n",
            "| Training Device=xla:0/1 Epoch=100 Step=0 Loss=0.33254 Rate=10.15 GlobalRate=10.15 Time=22:50:37\n",
            "| Training Device=xla:0/5 Epoch=100 Step=0 Loss=0.30816 Rate=10.15 GlobalRate=10.15 Time=22:50:37\n",
            "| Training Device=xla:0/4 Epoch=100 Step=0 Loss=0.28158 Rate=10.15 GlobalRate=10.15 Time=22:50:37\n",
            "| Training Device=xla:0/6 Epoch=100 Step=0 Loss=0.44413 Rate=10.15 GlobalRate=10.15 Time=22:50:37\n",
            "| Training Device=xla:0/3 Epoch=100 Step=0 Loss=0.44861 Rate=10.15 GlobalRate=10.15 Time=22:50:37\n",
            "| Training Device=xla:0/2 Epoch=100 Step=0 Loss=0.31637 Rate=10.15 GlobalRate=10.15 Time=22:50:37\n",
            "| Training Device=xla:1/0 Epoch=100 Step=0 Loss=0.37459 Rate=10.16 GlobalRate=10.16 Time=22:50:37\n",
            "Epoch 100 train end 22:50:37\n",
            "Epoch 101 train begin 22:50:37\n",
            "| Training Device=xla:0/3 Epoch=101 Step=0 Loss=0.44270 Rate=10.06 GlobalRate=10.06 Time=22:50:44\n",
            "| Training Device=xla:0/2 Epoch=101 Step=0 Loss=0.30171 Rate=10.06 GlobalRate=10.06 Time=22:50:44\n",
            "| Training Device=xla:0/6 Epoch=101 Step=0 Loss=0.38948 Rate=10.06 GlobalRate=10.06 Time=22:50:44\n",
            "| Training Device=xla:1/0 Epoch=101 Step=0 Loss=0.37248 Rate=10.06 GlobalRate=10.06 Time=22:50:44\n",
            "| Training Device=xla:0/5 Epoch=101 Step=0 Loss=0.26660 Rate=10.06 GlobalRate=10.06 Time=22:50:44\n",
            "| Training Device=xla:0/4 Epoch=101 Step=0 Loss=0.31745 Rate=10.06 GlobalRate=10.06 Time=22:50:44\n",
            "| Training Device=xla:0/7 Epoch=101 Step=0 Loss=0.27891 Rate=10.05 GlobalRate=10.05 Time=22:50:44\n",
            "| Training Device=xla:0/1 Epoch=101 Step=0 Loss=0.29303 Rate=10.05 GlobalRate=10.05 Time=22:50:44\n",
            "Epoch 101 train end 22:50:44\n",
            "Epoch 102 train begin 22:50:44\n",
            "| Training Device=xla:0/5 Epoch=102 Step=0 Loss=0.28125 Rate=10.04 GlobalRate=10.04 Time=22:50:50\n",
            "| Training Device=xla:0/2 Epoch=102 Step=0 Loss=0.29771 Rate=10.04 GlobalRate=10.04 Time=22:50:50\n",
            "| Training Device=xla:0/3 Epoch=102 Step=0 Loss=0.39301 Rate=10.04 GlobalRate=10.04 Time=22:50:50\n",
            "| Training Device=xla:0/7 Epoch=102 Step=0 Loss=0.29687 Rate=10.04 GlobalRate=10.04 Time=22:50:50\n",
            "| Training Device=xla:0/1 Epoch=102 Step=0 Loss=0.36669 Rate=10.04 GlobalRate=10.04 Time=22:50:50\n",
            "| Training Device=xla:0/6 Epoch=102 Step=0 Loss=0.39316 Rate=10.03 GlobalRate=10.03 Time=22:50:50\n",
            "| Training Device=xla:1/0 Epoch=102 Step=0 Loss=0.32422 Rate=10.04 GlobalRate=10.04 Time=22:50:50\n",
            "| Training Device=xla:0/4 Epoch=102 Step=0 Loss=0.33559 Rate=10.03 GlobalRate=10.03 Time=22:50:50\n",
            "Epoch 102 train end 22:50:50\n",
            "Epoch 103 train begin 22:50:50\n",
            "| Training Device=xla:0/5 Epoch=103 Step=0 Loss=0.27323 Rate=10.07 GlobalRate=10.07 Time=22:50:57\n",
            "| Training Device=xla:0/7 Epoch=103 Step=0 Loss=0.30623 Rate=10.07 GlobalRate=10.07 Time=22:50:57\n",
            "| Training Device=xla:0/2 Epoch=103 Step=0 Loss=0.32785 Rate=10.07 GlobalRate=10.07 Time=22:50:57\n",
            "| Training Device=xla:0/1 Epoch=103 Step=0 Loss=0.30335 Rate=10.07 GlobalRate=10.07 Time=22:50:57\n",
            "| Training Device=xla:1/0 Epoch=103 Step=0 Loss=0.36078 Rate=10.07 GlobalRate=10.07 Time=22:50:57\n",
            "| Training Device=xla:0/3 Epoch=103 Step=0 Loss=0.42006 Rate=10.07 GlobalRate=10.07 Time=22:50:57\n",
            "| Training Device=xla:0/4 Epoch=103 Step=0 Loss=0.26342 Rate=10.07 GlobalRate=10.07 Time=22:50:57\n",
            "| Training Device=xla:0/6 Epoch=103 Step=0 Loss=0.37258 Rate=10.07 GlobalRate=10.07 Time=22:50:57\n",
            "Epoch 103 train end 22:50:57\n",
            "Epoch 104 train begin 22:50:57\n",
            "| Training Device=xla:0/6 Epoch=104 Step=0 Loss=0.40624 Rate=10.21 GlobalRate=10.21 Time=22:51:03\n",
            "| Training Device=xla:0/7 Epoch=104 Step=0 Loss=0.33550 Rate=10.21 GlobalRate=10.21 Time=22:51:03\n",
            "| Training Device=xla:0/4 Epoch=104 Step=0 Loss=0.34441 Rate=10.21 GlobalRate=10.21 Time=22:51:03\n",
            "| Training Device=xla:0/1 Epoch=104 Step=0 Loss=0.32198 Rate=10.21 GlobalRate=10.21 Time=22:51:03\n",
            "| Training Device=xla:0/5 Epoch=104 Step=0 Loss=0.28119 Rate=10.21 GlobalRate=10.21 Time=22:51:03\n",
            "| Training Device=xla:0/2 Epoch=104 Step=0 Loss=0.29093 Rate=10.21 GlobalRate=10.21 Time=22:51:03\n",
            "| Training Device=xla:0/3 Epoch=104 Step=0 Loss=0.47884 Rate=10.21 GlobalRate=10.21 Time=22:51:03\n",
            "| Training Device=xla:1/0 Epoch=104 Step=0 Loss=0.31541 Rate=10.21 GlobalRate=10.21 Time=22:51:03\n",
            "Epoch 104 train end 22:51:03\n",
            "Epoch 105 train begin 22:51:03\n",
            "| Training Device=xla:1/0 Epoch=105 Step=0 Loss=0.35741 Rate=10.13 GlobalRate=10.13 Time=22:51:10\n",
            "| Training Device=xla:0/3 Epoch=105 Step=0 Loss=0.42311 Rate=10.13 GlobalRate=10.13 Time=22:51:10\n",
            "| Training Device=xla:0/5 Epoch=105 Step=0 Loss=0.27763 Rate=10.13 GlobalRate=10.13 Time=22:51:10\n",
            "| Training Device=xla:0/4 Epoch=105 Step=0 Loss=0.28183 Rate=10.13 GlobalRate=10.13 Time=22:51:10\n",
            "| Training Device=xla:0/1 Epoch=105 Step=0 Loss=0.32834 Rate=10.13 GlobalRate=10.13 Time=22:51:10\n",
            "| Training Device=xla:0/6 Epoch=105 Step=0 Loss=0.40565 Rate=10.13 GlobalRate=10.13 Time=22:51:10\n",
            "| Training Device=xla:0/2 Epoch=105 Step=0 Loss=0.30518 Rate=10.12 GlobalRate=10.12 Time=22:51:10\n",
            "| Training Device=xla:0/7 Epoch=105 Step=0 Loss=0.27457 Rate=10.12 GlobalRate=10.12 Time=22:51:10\n",
            "Epoch 105 train end 22:51:10\n",
            "Epoch 106 train begin 22:51:10\n",
            "| Training Device=xla:0/7 Epoch=106 Step=0 Loss=0.28396 Rate=10.14 GlobalRate=10.14 Time=22:51:16\n",
            "| Training Device=xla:0/2 Epoch=106 Step=0 Loss=0.33129 Rate=10.14 GlobalRate=10.14 Time=22:51:16\n",
            "| Training Device=xla:1/0 Epoch=106 Step=0 Loss=0.39222 Rate=10.15 GlobalRate=10.15 Time=22:51:16\n",
            "| Training Device=xla:0/1 Epoch=106 Step=0 Loss=0.27760 Rate=10.14 GlobalRate=10.14 Time=22:51:16\n",
            "| Training Device=xla:0/5 Epoch=106 Step=0 Loss=0.29617 Rate=10.14 GlobalRate=10.14 Time=22:51:16\n",
            "| Training Device=xla:0/3 Epoch=106 Step=0 Loss=0.41702 Rate=10.14 GlobalRate=10.14 Time=22:51:16\n",
            "| Training Device=xla:0/4 Epoch=106 Step=0 Loss=0.29856 Rate=10.14 GlobalRate=10.14 Time=22:51:16\n",
            "| Training Device=xla:0/6 Epoch=106 Step=0 Loss=0.38062 Rate=10.14 GlobalRate=10.14 Time=22:51:16\n",
            "Epoch 106 train end 22:51:17\n",
            "Epoch 107 train begin 22:51:17\n",
            "| Training Device=xla:0/3 Epoch=107 Step=0 Loss=0.44074 Rate=10.18 GlobalRate=10.18 Time=22:51:23\n",
            "| Training Device=xla:0/1 Epoch=107 Step=0 Loss=0.32187 Rate=10.18 GlobalRate=10.18 Time=22:51:23\n",
            "| Training Device=xla:0/6 Epoch=107 Step=0 Loss=0.40258 Rate=10.18 GlobalRate=10.18 Time=22:51:23\n",
            "| Training Device=xla:0/2 Epoch=107 Step=0 Loss=0.31180 Rate=10.18 GlobalRate=10.18 Time=22:51:23\n",
            "| Training Device=xla:0/7 Epoch=107 Step=0 Loss=0.30838 Rate=10.18 GlobalRate=10.18 Time=22:51:23\n",
            "| Training Device=xla:0/5 Epoch=107 Step=0 Loss=0.26748 Rate=10.18 GlobalRate=10.18 Time=22:51:23\n",
            "| Training Device=xla:0/4 Epoch=107 Step=0 Loss=0.32484 Rate=10.18 GlobalRate=10.18 Time=22:51:23\n",
            "| Training Device=xla:1/0 Epoch=107 Step=0 Loss=0.34031 Rate=10.18 GlobalRate=10.18 Time=22:51:23\n",
            "Epoch 107 train end 22:51:23\n",
            "Epoch 108 train begin 22:51:23\n",
            "| Training Device=xla:0/3 Epoch=108 Step=0 Loss=0.46499 Rate=10.20 GlobalRate=10.20 Time=22:51:29\n",
            "| Training Device=xla:0/1 Epoch=108 Step=0 Loss=0.33568 Rate=10.20 GlobalRate=10.20 Time=22:51:29\n",
            "| Training Device=xla:0/7 Epoch=108 Step=0 Loss=0.30186 Rate=10.20 GlobalRate=10.20 Time=22:51:29\n",
            "| Training Device=xla:0/4 Epoch=108 Step=0 Loss=0.28365 Rate=10.20 GlobalRate=10.20 Time=22:51:29\n",
            "| Training Device=xla:0/2 Epoch=108 Step=0 Loss=0.34732 Rate=10.20 GlobalRate=10.20 Time=22:51:29\n",
            "| Training Device=xla:1/0 Epoch=108 Step=0 Loss=0.40261 Rate=10.20 GlobalRate=10.20 Time=22:51:29\n",
            "| Training Device=xla:0/5 Epoch=108 Step=0 Loss=0.29597 Rate=10.20 GlobalRate=10.20 Time=22:51:29\n",
            "| Training Device=xla:0/6 Epoch=108 Step=0 Loss=0.37652 Rate=10.20 GlobalRate=10.20 Time=22:51:29\n",
            "Epoch 108 train end 22:51:30\n",
            "Epoch 109 train begin 22:51:30\n",
            "| Training Device=xla:1/0 Epoch=109 Step=0 Loss=0.36695 Rate=10.16 GlobalRate=10.16 Time=22:51:36\n",
            "| Training Device=xla:0/4 Epoch=109 Step=0 Loss=0.28222 Rate=10.16 GlobalRate=10.16 Time=22:51:36\n",
            "| Training Device=xla:0/1 Epoch=109 Step=0 Loss=0.32701 Rate=10.16 GlobalRate=10.16 Time=22:51:36\n",
            "| Training Device=xla:0/5 Epoch=109 Step=0 Loss=0.31902 Rate=10.16 GlobalRate=10.16 Time=22:51:36\n",
            "| Training Device=xla:0/7 Epoch=109 Step=0 Loss=0.30992 Rate=10.15 GlobalRate=10.15 Time=22:51:36\n",
            "| Training Device=xla:0/2 Epoch=109 Step=0 Loss=0.35996 Rate=10.16 GlobalRate=10.16 Time=22:51:36\n",
            "| Training Device=xla:0/6 Epoch=109 Step=0 Loss=0.42182 Rate=10.15 GlobalRate=10.15 Time=22:51:36\n",
            "| Training Device=xla:0/3 Epoch=109 Step=0 Loss=0.50523 Rate=10.16 GlobalRate=10.16 Time=22:51:36\n",
            "Epoch 109 train end 22:51:36\n",
            "Epoch 110 train begin 22:51:36\n",
            "| Training Device=xla:0/1 Epoch=110 Step=0 Loss=0.32582 Rate=10.21 GlobalRate=10.21 Time=22:51:42\n",
            "| Training Device=xla:0/5 Epoch=110 Step=0 Loss=0.30604 Rate=10.21 GlobalRate=10.21 Time=22:51:42\n",
            "| Training Device=xla:1/0 Epoch=110 Step=0 Loss=0.42258 Rate=10.22 GlobalRate=10.22 Time=22:51:42\n",
            "| Training Device=xla:0/2 Epoch=110 Step=0 Loss=0.32310 Rate=10.21 GlobalRate=10.21 Time=22:51:42\n",
            "| Training Device=xla:0/4 Epoch=110 Step=0 Loss=0.32275 Rate=10.21 GlobalRate=10.21 Time=22:51:42\n",
            "| Training Device=xla:0/7 Epoch=110 Step=0 Loss=0.31247 Rate=10.21 GlobalRate=10.21 Time=22:51:42\n",
            "| Training Device=xla:0/3 Epoch=110 Step=0 Loss=0.41660 Rate=10.21 GlobalRate=10.21 Time=22:51:42\n",
            "| Training Device=xla:0/6 Epoch=110 Step=0 Loss=0.39062 Rate=10.21 GlobalRate=10.21 Time=22:51:42\n",
            "Epoch 110 train end 22:51:43\n",
            "Epoch 111 train begin 22:51:43\n",
            "| Training Device=xla:0/2 Epoch=111 Step=0 Loss=0.34302 Rate=10.24 GlobalRate=10.24 Time=22:51:49\n",
            "| Training Device=xla:0/5 Epoch=111 Step=0 Loss=0.29638 Rate=10.24 GlobalRate=10.24 Time=22:51:49\n",
            "| Training Device=xla:1/0 Epoch=111 Step=0 Loss=0.33606 Rate=10.24 GlobalRate=10.24 Time=22:51:49\n",
            "| Training Device=xla:0/6 Epoch=111 Step=0 Loss=0.39533 Rate=10.24 GlobalRate=10.24 Time=22:51:49\n",
            "| Training Device=xla:0/4 Epoch=111 Step=0 Loss=0.29868 Rate=10.24 GlobalRate=10.24 Time=22:51:49\n",
            "| Training Device=xla:0/7 Epoch=111 Step=0 Loss=0.31431 Rate=10.23 GlobalRate=10.23 Time=22:51:49\n",
            "| Training Device=xla:0/1 Epoch=111 Step=0 Loss=0.35244 Rate=10.24 GlobalRate=10.24 Time=22:51:49\n",
            "| Training Device=xla:0/3 Epoch=111 Step=0 Loss=0.47288 Rate=10.24 GlobalRate=10.24 Time=22:51:49\n",
            "Epoch 111 train end 22:51:49\n",
            "Epoch 112 train begin 22:51:49\n",
            "| Training Device=xla:0/3 Epoch=112 Step=0 Loss=0.46884 Rate=10.14 GlobalRate=10.14 Time=22:51:55\n",
            "| Training Device=xla:0/2 Epoch=112 Step=0 Loss=0.33733 Rate=10.14 GlobalRate=10.14 Time=22:51:55\n",
            "| Training Device=xla:0/1 Epoch=112 Step=0 Loss=0.30025 Rate=10.14 GlobalRate=10.14 Time=22:51:55\n",
            "| Training Device=xla:0/6 Epoch=112 Step=0 Loss=0.38604 Rate=10.13 GlobalRate=10.13 Time=22:51:55\n",
            "| Training Device=xla:0/5 Epoch=112 Step=0 Loss=0.35177 Rate=10.14 GlobalRate=10.14 Time=22:51:55\n",
            "| Training Device=xla:0/4 Epoch=112 Step=0 Loss=0.33040 Rate=10.14 GlobalRate=10.14 Time=22:51:55\n",
            "| Training Device=xla:1/0 Epoch=112 Step=0 Loss=0.38084 Rate=10.14 GlobalRate=10.14 Time=22:51:55\n",
            "| Training Device=xla:0/7 Epoch=112 Step=0 Loss=0.30573 Rate=10.13 GlobalRate=10.13 Time=22:51:55\n",
            "Epoch 112 train end 22:51:56\n",
            "Epoch 113 train begin 22:51:56\n",
            "| Training Device=xla:0/3 Epoch=113 Step=0 Loss=0.43683 Rate=10.17 GlobalRate=10.17 Time=22:52:02\n",
            "| Training Device=xla:0/5 Epoch=113 Step=0 Loss=0.33291 Rate=10.17 GlobalRate=10.17 Time=22:52:02\n",
            "| Training Device=xla:1/0 Epoch=113 Step=0 Loss=0.38513 Rate=10.17 GlobalRate=10.17 Time=22:52:02\n",
            "| Training Device=xla:0/7 Epoch=113 Step=0 Loss=0.32185 Rate=10.16 GlobalRate=10.16 Time=22:52:02\n",
            "| Training Device=xla:0/1 Epoch=113 Step=0 Loss=0.34233 Rate=10.17 GlobalRate=10.17 Time=22:52:02\n",
            "| Training Device=xla:0/2 Epoch=113 Step=0 Loss=0.29103 Rate=10.17 GlobalRate=10.17 Time=22:52:02\n",
            "| Training Device=xla:0/6 Epoch=113 Step=0 Loss=0.37895 Rate=10.17 GlobalRate=10.17 Time=22:52:02\n",
            "| Training Device=xla:0/4 Epoch=113 Step=0 Loss=0.32265 Rate=10.16 GlobalRate=10.16 Time=22:52:02\n",
            "Epoch 113 train end 22:52:02\n",
            "Epoch 114 train begin 22:52:02\n",
            "| Training Device=xla:0/3 Epoch=114 Step=0 Loss=0.45191 Rate=10.22 GlobalRate=10.22 Time=22:52:09\n",
            "| Training Device=xla:0/5 Epoch=114 Step=0 Loss=0.30105 Rate=10.22 GlobalRate=10.22 Time=22:52:09\n",
            "| Training Device=xla:0/6 Epoch=114 Step=0 Loss=0.38789 Rate=10.21 GlobalRate=10.21 Time=22:52:09\n",
            "| Training Device=xla:0/1 Epoch=114 Step=0 Loss=0.29891 Rate=10.21 GlobalRate=10.21 Time=22:52:09\n",
            "| Training Device=xla:0/2 Epoch=114 Step=0 Loss=0.29640 Rate=10.21 GlobalRate=10.21 Time=22:52:09\n",
            "| Training Device=xla:0/4 Epoch=114 Step=0 Loss=0.25883 Rate=10.22 GlobalRate=10.22 Time=22:52:09\n",
            "| Training Device=xla:0/7 Epoch=114 Step=0 Loss=0.29360 Rate=10.22 GlobalRate=10.22 Time=22:52:09\n",
            "| Training Device=xla:1/0 Epoch=114 Step=0 Loss=0.36477 Rate=10.22 GlobalRate=10.22 Time=22:52:09\n",
            "Epoch 114 train end 22:52:09\n",
            "Epoch 115 train begin 22:52:09\n",
            "| Training Device=xla:0/1 Epoch=115 Step=0 Loss=0.32294 Rate=10.14 GlobalRate=10.14 Time=22:52:15\n",
            "| Training Device=xla:0/6 Epoch=115 Step=0 Loss=0.35996 Rate=10.14 GlobalRate=10.14 Time=22:52:15\n",
            "| Training Device=xla:0/4 Epoch=115 Step=0 Loss=0.26188 Rate=10.14 GlobalRate=10.14 Time=22:52:15\n",
            "| Training Device=xla:0/3 Epoch=115 Step=0 Loss=0.37454 Rate=10.14 GlobalRate=10.14 Time=22:52:15\n",
            "| Training Device=xla:0/7 Epoch=115 Step=0 Loss=0.28396 Rate=10.14 GlobalRate=10.14 Time=22:52:15\n",
            "| Training Device=xla:0/5 Epoch=115 Step=0 Loss=0.33333 Rate=10.14 GlobalRate=10.14 Time=22:52:15\n",
            "| Training Device=xla:0/2 Epoch=115 Step=0 Loss=0.30919 Rate=10.14 GlobalRate=10.14 Time=22:52:15\n",
            "| Training Device=xla:1/0 Epoch=115 Step=0 Loss=0.36807 Rate=10.14 GlobalRate=10.14 Time=22:52:15\n",
            "Epoch 115 train end 22:52:15\n",
            "Epoch 116 train begin 22:52:15\n",
            "| Training Device=xla:0/7 Epoch=116 Step=0 Loss=0.32123 Rate=10.15 GlobalRate=10.15 Time=22:52:22\n",
            "| Training Device=xla:1/0 Epoch=116 Step=0 Loss=0.38529 Rate=10.15 GlobalRate=10.15 Time=22:52:22\n",
            "| Training Device=xla:0/5 Epoch=116 Step=0 Loss=0.30300 Rate=10.15 GlobalRate=10.15 Time=22:52:22\n",
            "| Training Device=xla:0/2 Epoch=116 Step=0 Loss=0.35318 Rate=10.15 GlobalRate=10.15 Time=22:52:22\n",
            "| Training Device=xla:0/3 Epoch=116 Step=0 Loss=0.41887 Rate=10.15 GlobalRate=10.15 Time=22:52:22\n",
            "| Training Device=xla:0/6 Epoch=116 Step=0 Loss=0.39193 Rate=10.15 GlobalRate=10.15 Time=22:52:22\n",
            "| Training Device=xla:0/1 Epoch=116 Step=0 Loss=0.33968 Rate=10.15 GlobalRate=10.15 Time=22:52:22\n",
            "| Training Device=xla:0/4 Epoch=116 Step=0 Loss=0.29715 Rate=10.14 GlobalRate=10.14 Time=22:52:22\n",
            "Epoch 116 train end 22:52:22\n",
            "Epoch 117 train begin 22:52:22\n",
            "| Training Device=xla:0/3 Epoch=117 Step=0 Loss=0.42941 Rate=10.01 GlobalRate=10.01 Time=22:52:28\n",
            "| Training Device=xla:0/2 Epoch=117 Step=0 Loss=0.38568 Rate=10.01 GlobalRate=10.01 Time=22:52:28\n",
            "| Training Device=xla:0/7 Epoch=117 Step=0 Loss=0.29971 Rate=10.01 GlobalRate=10.01 Time=22:52:28\n",
            "| Training Device=xla:0/1 Epoch=117 Step=0 Loss=0.28134 Rate=10.01 GlobalRate=10.01 Time=22:52:28\n",
            "| Training Device=xla:0/5 Epoch=117 Step=0 Loss=0.30268 Rate=10.01 GlobalRate=10.01 Time=22:52:28\n",
            "| Training Device=xla:0/6 Epoch=117 Step=0 Loss=0.37249 Rate=10.01 GlobalRate=10.01 Time=22:52:28\n",
            "| Training Device=xla:0/4 Epoch=117 Step=0 Loss=0.26689 Rate=10.01 GlobalRate=10.01 Time=22:52:28\n",
            "| Training Device=xla:1/0 Epoch=117 Step=0 Loss=0.36448 Rate=10.01 GlobalRate=10.01 Time=22:52:28\n",
            "Epoch 117 train end 22:52:28\n",
            "Epoch 118 train begin 22:52:28\n",
            "| Training Device=xla:0/6 Epoch=118 Step=0 Loss=0.41457 Rate=10.18 GlobalRate=10.18 Time=22:52:35\n",
            "| Training Device=xla:1/0 Epoch=118 Step=0 Loss=0.35578 Rate=10.18 GlobalRate=10.18 Time=22:52:35\n",
            "| Training Device=xla:0/7 Epoch=118 Step=0 Loss=0.30342 Rate=10.18 GlobalRate=10.18 Time=22:52:35\n",
            "| Training Device=xla:0/3 Epoch=118 Step=0 Loss=0.41123 Rate=10.17 GlobalRate=10.17 Time=22:52:35\n",
            "| Training Device=xla:0/2 Epoch=118 Step=0 Loss=0.35602 Rate=10.18 GlobalRate=10.18 Time=22:52:35\n",
            "| Training Device=xla:0/1 Epoch=118 Step=0 Loss=0.33392 Rate=10.17 GlobalRate=10.17 Time=22:52:35\n",
            "| Training Device=xla:0/5 Epoch=118 Step=0 Loss=0.29119 Rate=10.18 GlobalRate=10.18 Time=22:52:35\n",
            "| Training Device=xla:0/4 Epoch=118 Step=0 Loss=0.26585 Rate=10.18 GlobalRate=10.18 Time=22:52:35\n",
            "Epoch 118 train end 22:52:35\n",
            "Epoch 119 train begin 22:52:35\n",
            "| Training Device=xla:0/1 Epoch=119 Step=0 Loss=0.30513 Rate=10.16 GlobalRate=10.16 Time=22:52:41\n",
            "| Training Device=xla:0/7 Epoch=119 Step=0 Loss=0.31392 Rate=10.16 GlobalRate=10.16 Time=22:52:41\n",
            "| Training Device=xla:0/3 Epoch=119 Step=0 Loss=0.40545 Rate=10.16 GlobalRate=10.16 Time=22:52:41\n",
            "| Training Device=xla:0/4 Epoch=119 Step=0 Loss=0.27381 Rate=10.16 GlobalRate=10.16 Time=22:52:41\n",
            "| Training Device=xla:0/5 Epoch=119 Step=0 Loss=0.28376 Rate=10.16 GlobalRate=10.16 Time=22:52:41\n",
            "| Training Device=xla:0/2 Epoch=119 Step=0 Loss=0.28278 Rate=10.15 GlobalRate=10.15 Time=22:52:41\n",
            "| Training Device=xla:0/6 Epoch=119 Step=0 Loss=0.37571 Rate=10.16 GlobalRate=10.16 Time=22:52:41\n",
            "| Training Device=xla:1/0 Epoch=119 Step=0 Loss=0.35943 Rate=10.16 GlobalRate=10.16 Time=22:52:41\n",
            "Epoch 119 train end 22:52:42\n",
            "Epoch 120 train begin 22:52:42\n",
            "| Training Device=xla:0/7 Epoch=120 Step=0 Loss=0.32517 Rate=10.15 GlobalRate=10.15 Time=22:52:48\n",
            "| Training Device=xla:0/3 Epoch=120 Step=0 Loss=0.44467 Rate=10.16 GlobalRate=10.16 Time=22:52:48\n",
            "| Training Device=xla:0/6 Epoch=120 Step=0 Loss=0.36358 Rate=10.15 GlobalRate=10.15 Time=22:52:48\n",
            "| Training Device=xla:0/1 Epoch=120 Step=0 Loss=0.34523 Rate=10.15 GlobalRate=10.15 Time=22:52:48\n",
            "| Training Device=xla:0/2 Epoch=120 Step=0 Loss=0.33129 Rate=10.15 GlobalRate=10.15 Time=22:52:48\n",
            "| Training Device=xla:0/5 Epoch=120 Step=0 Loss=0.32630 Rate=10.15 GlobalRate=10.15 Time=22:52:48\n",
            "| Training Device=xla:0/4 Epoch=120 Step=0 Loss=0.31653 Rate=10.15 GlobalRate=10.15 Time=22:52:48\n",
            "| Training Device=xla:1/0 Epoch=120 Step=0 Loss=0.40295 Rate=10.15 GlobalRate=10.15 Time=22:52:48\n",
            "Epoch 120 train end 22:52:48\n",
            "Epoch 121 train begin 22:52:48\n",
            "| Training Device=xla:0/1 Epoch=121 Step=0 Loss=0.34695 Rate=10.15 GlobalRate=10.15 Time=22:52:54\n",
            "| Training Device=xla:1/0 Epoch=121 Step=0 Loss=0.35379 Rate=10.15 GlobalRate=10.15 Time=22:52:54\n",
            "| Training Device=xla:0/6 Epoch=121 Step=0 Loss=0.38936 Rate=10.14 GlobalRate=10.14 Time=22:52:54\n",
            "| Training Device=xla:0/5 Epoch=121 Step=0 Loss=0.32216 Rate=10.14 GlobalRate=10.14 Time=22:52:54\n",
            "| Training Device=xla:0/7 Epoch=121 Step=0 Loss=0.33254 Rate=10.14 GlobalRate=10.14 Time=22:52:54\n",
            "| Training Device=xla:0/2 Epoch=121 Step=0 Loss=0.36416 Rate=10.14 GlobalRate=10.14 Time=22:52:54\n",
            "| Training Device=xla:0/4 Epoch=121 Step=0 Loss=0.33207 Rate=10.14 GlobalRate=10.14 Time=22:52:54\n",
            "| Training Device=xla:0/3 Epoch=121 Step=0 Loss=0.45755 Rate=10.14 GlobalRate=10.14 Time=22:52:54\n",
            "Epoch 121 train end 22:52:55\n",
            "Epoch 122 train begin 22:52:55\n",
            "| Training Device=xla:0/7 Epoch=122 Step=0 Loss=0.28782 Rate=10.23 GlobalRate=10.23 Time=22:53:01\n",
            "| Training Device=xla:0/4 Epoch=122 Step=0 Loss=0.28082 Rate=10.24 GlobalRate=10.24 Time=22:53:01\n",
            "| Training Device=xla:0/1 Epoch=122 Step=0 Loss=0.34101 Rate=10.24 GlobalRate=10.24 Time=22:53:01\n",
            "| Training Device=xla:0/6 Epoch=122 Step=0 Loss=0.41064 Rate=10.23 GlobalRate=10.23 Time=22:53:01\n",
            "| Training Device=xla:0/2 Epoch=122 Step=0 Loss=0.31946 Rate=10.23 GlobalRate=10.23 Time=22:53:01\n",
            "| Training Device=xla:0/5 Epoch=122 Step=0 Loss=0.29952 Rate=10.23 GlobalRate=10.23 Time=22:53:01\n",
            "| Training Device=xla:0/3 Epoch=122 Step=0 Loss=0.46911 Rate=10.23 GlobalRate=10.23 Time=22:53:01\n",
            "| Training Device=xla:1/0 Epoch=122 Step=0 Loss=0.34356 Rate=10.24 GlobalRate=10.24 Time=22:53:01\n",
            "Epoch 122 train end 22:53:01\n",
            "Epoch 123 train begin 22:53:01\n",
            "| Training Device=xla:0/7 Epoch=123 Step=0 Loss=0.29074 Rate=10.25 GlobalRate=10.25 Time=22:53:07\n",
            "| Training Device=xla:0/5 Epoch=123 Step=0 Loss=0.31105 Rate=10.25 GlobalRate=10.25 Time=22:53:07\n",
            "| Training Device=xla:1/0 Epoch=123 Step=0 Loss=0.34029 Rate=10.25 GlobalRate=10.25 Time=22:53:07\n",
            "| Training Device=xla:0/1 Epoch=123 Step=0 Loss=0.28254 Rate=10.25 GlobalRate=10.25 Time=22:53:07\n",
            "| Training Device=xla:0/3 Epoch=123 Step=0 Loss=0.45151 Rate=10.25 GlobalRate=10.25 Time=22:53:07\n",
            "| Training Device=xla:0/4 Epoch=123 Step=0 Loss=0.31362 Rate=10.25 GlobalRate=10.25 Time=22:53:07\n",
            "| Training Device=xla:0/2 Epoch=123 Step=0 Loss=0.32065 Rate=10.25 GlobalRate=10.25 Time=22:53:07\n",
            "| Training Device=xla:0/6 Epoch=123 Step=0 Loss=0.34880 Rate=10.25 GlobalRate=10.25 Time=22:53:07\n",
            "Epoch 123 train end 22:53:08\n",
            "Epoch 124 train begin 22:53:08\n",
            "| Training Device=xla:0/2 Epoch=124 Step=0 Loss=0.34618 Rate=10.19 GlobalRate=10.19 Time=22:53:14\n",
            "| Training Device=xla:0/5 Epoch=124 Step=0 Loss=0.31425 Rate=10.19 GlobalRate=10.19 Time=22:53:14\n",
            "| Training Device=xla:0/1 Epoch=124 Step=0 Loss=0.32914 Rate=10.19 GlobalRate=10.19 Time=22:53:14\n",
            "| Training Device=xla:0/4 Epoch=124 Step=0 Loss=0.30471 Rate=10.19 GlobalRate=10.19 Time=22:53:14\n",
            "| Training Device=xla:0/7 Epoch=124 Step=0 Loss=0.28571 Rate=10.19 GlobalRate=10.19 Time=22:53:14\n",
            "| Training Device=xla:0/3 Epoch=124 Step=0 Loss=0.42068 Rate=10.19 GlobalRate=10.19 Time=22:53:14\n",
            "| Training Device=xla:0/6 Epoch=124 Step=0 Loss=0.37574 Rate=10.19 GlobalRate=10.19 Time=22:53:14\n",
            "| Training Device=xla:1/0 Epoch=124 Step=0 Loss=0.37468 Rate=10.19 GlobalRate=10.19 Time=22:53:14\n",
            "Epoch 124 train end 22:53:14\n",
            "Epoch 125 train begin 22:53:14\n",
            "| Training Device=xla:0/5 Epoch=125 Step=0 Loss=0.34945 Rate=10.15 GlobalRate=10.15 Time=22:53:20\n",
            "| Training Device=xla:0/3 Epoch=125 Step=0 Loss=0.48935 Rate=10.15 GlobalRate=10.15 Time=22:53:20\n",
            "| Training Device=xla:0/7 Epoch=125 Step=0 Loss=0.34396 Rate=10.15 GlobalRate=10.15 Time=22:53:20\n",
            "| Training Device=xla:0/2 Epoch=125 Step=0 Loss=0.35770 Rate=10.15 GlobalRate=10.15 Time=22:53:20\n",
            "| Training Device=xla:0/1 Epoch=125 Step=0 Loss=0.31139 Rate=10.15 GlobalRate=10.15 Time=22:53:20\n",
            "| Training Device=xla:0/6 Epoch=125 Step=0 Loss=0.37493 Rate=10.15 GlobalRate=10.15 Time=22:53:20\n",
            "| Training Device=xla:1/0 Epoch=125 Step=0 Loss=0.36124 Rate=10.15 GlobalRate=10.15 Time=22:53:20\n",
            "| Training Device=xla:0/4 Epoch=125 Step=0 Loss=0.27481 Rate=10.15 GlobalRate=10.15 Time=22:53:20\n",
            "Epoch 125 train end 22:53:21\n",
            "Epoch 126 train begin 22:53:21\n",
            "| Training Device=xla:1/0 Epoch=126 Step=0 Loss=0.43135 Rate=10.24 GlobalRate=10.24 Time=22:53:27\n",
            "| Training Device=xla:0/7 Epoch=126 Step=0 Loss=0.28734 Rate=10.23 GlobalRate=10.23 Time=22:53:27\n",
            "| Training Device=xla:0/1 Epoch=126 Step=0 Loss=0.33343 Rate=10.23 GlobalRate=10.23 Time=22:53:27\n",
            "| Training Device=xla:0/3 Epoch=126 Step=0 Loss=0.43164 Rate=10.23 GlobalRate=10.23 Time=22:53:27\n",
            "| Training Device=xla:0/4 Epoch=126 Step=0 Loss=0.29913 Rate=10.23 GlobalRate=10.23 Time=22:53:27\n",
            "| Training Device=xla:0/6 Epoch=126 Step=0 Loss=0.39842 Rate=10.23 GlobalRate=10.23 Time=22:53:27\n",
            "| Training Device=xla:0/2 Epoch=126 Step=0 Loss=0.33445 Rate=10.23 GlobalRate=10.23 Time=22:53:27\n",
            "| Training Device=xla:0/5 Epoch=126 Step=0 Loss=0.29264 Rate=10.23 GlobalRate=10.23 Time=22:53:27\n",
            "Epoch 126 train end 22:53:27\n",
            "Epoch 127 train begin 22:53:27\n",
            "| Training Device=xla:0/1 Epoch=127 Step=0 Loss=0.31869 Rate=10.10 GlobalRate=10.10 Time=22:53:33\n",
            "| Training Device=xla:1/0 Epoch=127 Step=0 Loss=0.37115 Rate=10.11 GlobalRate=10.11 Time=22:53:33\n",
            "| Training Device=xla:0/7 Epoch=127 Step=0 Loss=0.32899 Rate=10.10 GlobalRate=10.10 Time=22:53:33\n",
            "| Training Device=xla:0/3 Epoch=127 Step=0 Loss=0.42163 Rate=10.10 GlobalRate=10.10 Time=22:53:33\n",
            "| Training Device=xla:0/5 Epoch=127 Step=0 Loss=0.34771 Rate=10.10 GlobalRate=10.10 Time=22:53:33\n",
            "| Training Device=xla:0/6 Epoch=127 Step=0 Loss=0.42355 Rate=10.10 GlobalRate=10.10 Time=22:53:33\n",
            "| Training Device=xla:0/2 Epoch=127 Step=0 Loss=0.32754 Rate=10.10 GlobalRate=10.10 Time=22:53:33\n",
            "| Training Device=xla:0/4 Epoch=127 Step=0 Loss=0.33762 Rate=10.10 GlobalRate=10.10 Time=22:53:33\n",
            "Epoch 127 train end 22:53:34\n",
            "Epoch 128 train begin 22:53:34\n",
            "| Training Device=xla:0/6 Epoch=128 Step=0 Loss=0.34228 Rate=10.16 GlobalRate=10.16 Time=22:53:40\n",
            "| Training Device=xla:0/5 Epoch=128 Step=0 Loss=0.30607 Rate=10.15 GlobalRate=10.15 Time=22:53:40\n",
            "| Training Device=xla:1/0 Epoch=128 Step=0 Loss=0.37816 Rate=10.16 GlobalRate=10.16 Time=22:53:40\n",
            "| Training Device=xla:0/3 Epoch=128 Step=0 Loss=0.41699 Rate=10.15 GlobalRate=10.15 Time=22:53:40\n",
            "| Training Device=xla:0/4 Epoch=128 Step=0 Loss=0.32055 Rate=10.15 GlobalRate=10.15 Time=22:53:40\n",
            "| Training Device=xla:0/7 Epoch=128 Step=0 Loss=0.26037 Rate=10.15 GlobalRate=10.15 Time=22:53:40\n",
            "| Training Device=xla:0/1 Epoch=128 Step=0 Loss=0.33548 Rate=10.15 GlobalRate=10.15 Time=22:53:40\n",
            "| Training Device=xla:0/2 Epoch=128 Step=0 Loss=0.33749 Rate=10.15 GlobalRate=10.15 Time=22:53:40\n",
            "Epoch 128 train end 22:53:40\n",
            "Epoch 129 train begin 22:53:40\n",
            "| Training Device=xla:0/7 Epoch=129 Step=0 Loss=0.29365 Rate=10.10 GlobalRate=10.10 Time=22:53:47\n",
            "| Training Device=xla:0/6 Epoch=129 Step=0 Loss=0.39444 Rate=10.10 GlobalRate=10.10 Time=22:53:47\n",
            "| Training Device=xla:0/1 Epoch=129 Step=0 Loss=0.30082 Rate=10.10 GlobalRate=10.10 Time=22:53:47\n",
            "| Training Device=xla:0/2 Epoch=129 Step=0 Loss=0.32451 Rate=10.10 GlobalRate=10.10 Time=22:53:47\n",
            "| Training Device=xla:0/4 Epoch=129 Step=0 Loss=0.34387 Rate=10.10 GlobalRate=10.10 Time=22:53:47\n",
            "| Training Device=xla:0/3 Epoch=129 Step=0 Loss=0.42777 Rate=10.10 GlobalRate=10.10 Time=22:53:47\n",
            "| Training Device=xla:0/5 Epoch=129 Step=0 Loss=0.27739 Rate=10.10 GlobalRate=10.10 Time=22:53:47\n",
            "| Training Device=xla:1/0 Epoch=129 Step=0 Loss=0.38919 Rate=10.10 GlobalRate=10.10 Time=22:53:47\n",
            "Epoch 129 train end 22:53:47\n",
            "Epoch 130 train begin 22:53:47\n",
            "| Training Device=xla:0/1 Epoch=130 Step=0 Loss=0.31658 Rate=10.14 GlobalRate=10.14 Time=22:53:53\n",
            "| Training Device=xla:0/4 Epoch=130 Step=0 Loss=0.30493 Rate=10.14 GlobalRate=10.14 Time=22:53:53\n",
            "| Training Device=xla:0/6 Epoch=130 Step=0 Loss=0.38991 Rate=10.14 GlobalRate=10.14 Time=22:53:53\n",
            "| Training Device=xla:0/3 Epoch=130 Step=0 Loss=0.46169 Rate=10.14 GlobalRate=10.14 Time=22:53:53\n",
            "| Training Device=xla:0/2 Epoch=130 Step=0 Loss=0.27731 Rate=10.14 GlobalRate=10.14 Time=22:53:53\n",
            "| Training Device=xla:1/0 Epoch=130 Step=0 Loss=0.37619 Rate=10.15 GlobalRate=10.15 Time=22:53:53\n",
            "| Training Device=xla:0/5 Epoch=130 Step=0 Loss=0.27828 Rate=10.14 GlobalRate=10.14 Time=22:53:53\n",
            "| Training Device=xla:0/7 Epoch=130 Step=0 Loss=0.27385 Rate=10.14 GlobalRate=10.14 Time=22:53:53\n",
            "Epoch 130 train end 22:53:53\n",
            "Epoch 131 train begin 22:53:53\n",
            "| Training Device=xla:0/4 Epoch=131 Step=0 Loss=0.31377 Rate=10.21 GlobalRate=10.21 Time=22:54:00\n",
            "| Training Device=xla:0/2 Epoch=131 Step=0 Loss=0.33125 Rate=10.21 GlobalRate=10.21 Time=22:54:00\n",
            "| Training Device=xla:0/6 Epoch=131 Step=0 Loss=0.41997 Rate=10.21 GlobalRate=10.21 Time=22:54:00\n",
            "| Training Device=xla:1/0 Epoch=131 Step=0 Loss=0.37263 Rate=10.21 GlobalRate=10.21 Time=22:54:00\n",
            "| Training Device=xla:0/1 Epoch=131 Step=0 Loss=0.33571 Rate=10.21 GlobalRate=10.21 Time=22:54:00\n",
            "| Training Device=xla:0/7 Epoch=131 Step=0 Loss=0.27737 Rate=10.20 GlobalRate=10.20 Time=22:54:00\n",
            "| Training Device=xla:0/5 Epoch=131 Step=0 Loss=0.31032 Rate=10.21 GlobalRate=10.21 Time=22:54:00\n",
            "| Training Device=xla:0/3 Epoch=131 Step=0 Loss=0.41991 Rate=10.20 GlobalRate=10.20 Time=22:54:00\n",
            "Epoch 131 train end 22:54:00\n",
            "Epoch 132 train begin 22:54:00\n",
            "| Training Device=xla:0/6 Epoch=132 Step=0 Loss=0.38354 Rate=10.25 GlobalRate=10.25 Time=22:54:06\n",
            "| Training Device=xla:0/7 Epoch=132 Step=0 Loss=0.31124 Rate=10.25 GlobalRate=10.25 Time=22:54:06\n",
            "| Training Device=xla:0/3 Epoch=132 Step=0 Loss=0.39820 Rate=10.25 GlobalRate=10.25 Time=22:54:06\n",
            "| Training Device=xla:0/2 Epoch=132 Step=0 Loss=0.30912 Rate=10.25 GlobalRate=10.25 Time=22:54:06\n",
            "| Training Device=xla:0/5 Epoch=132 Step=0 Loss=0.24879 Rate=10.25 GlobalRate=10.25 Time=22:54:06\n",
            "| Training Device=xla:0/4 Epoch=132 Step=0 Loss=0.30304 Rate=10.25 GlobalRate=10.25 Time=22:54:06\n",
            "| Training Device=xla:0/1 Epoch=132 Step=0 Loss=0.32312 Rate=10.25 GlobalRate=10.25 Time=22:54:06\n",
            "| Training Device=xla:1/0 Epoch=132 Step=0 Loss=0.40344 Rate=10.26 GlobalRate=10.26 Time=22:54:06\n",
            "Epoch 132 train end 22:54:06\n",
            "Epoch 133 train begin 22:54:06\n",
            "| Training Device=xla:1/0 Epoch=133 Step=0 Loss=0.38121 Rate=10.26 GlobalRate=10.26 Time=22:54:13\n",
            "| Training Device=xla:0/1 Epoch=133 Step=0 Loss=0.34222 Rate=10.26 GlobalRate=10.26 Time=22:54:13\n",
            "| Training Device=xla:0/6 Epoch=133 Step=0 Loss=0.51988 Rate=10.26 GlobalRate=10.26 Time=22:54:13\n",
            "| Training Device=xla:0/2 Epoch=133 Step=0 Loss=0.35389 Rate=10.26 GlobalRate=10.26 Time=22:54:13\n",
            "| Training Device=xla:0/7 Epoch=133 Step=0 Loss=0.31333 Rate=10.26 GlobalRate=10.26 Time=22:54:13\n",
            "| Training Device=xla:0/4 Epoch=133 Step=0 Loss=0.32235 Rate=10.26 GlobalRate=10.26 Time=22:54:13\n",
            "| Training Device=xla:0/5 Epoch=133 Step=0 Loss=0.31965 Rate=10.26 GlobalRate=10.26 Time=22:54:13\n",
            "| Training Device=xla:0/3 Epoch=133 Step=0 Loss=0.44784 Rate=10.26 GlobalRate=10.26 Time=22:54:13\n",
            "Epoch 133 train end 22:54:13\n",
            "Epoch 134 train begin 22:54:13\n",
            "| Training Device=xla:0/3 Epoch=134 Step=0 Loss=0.52201 Rate=10.16 GlobalRate=10.16 Time=22:54:19\n",
            "| Training Device=xla:0/2 Epoch=134 Step=0 Loss=0.31407 Rate=10.16 GlobalRate=10.16 Time=22:54:19\n",
            "| Training Device=xla:0/6 Epoch=134 Step=0 Loss=0.38421 Rate=10.16 GlobalRate=10.16 Time=22:54:19\n",
            "| Training Device=xla:1/0 Epoch=134 Step=0 Loss=0.37957 Rate=10.16 GlobalRate=10.16 Time=22:54:19\n",
            "| Training Device=xla:0/5 Epoch=134 Step=0 Loss=0.28207 Rate=10.16 GlobalRate=10.16 Time=22:54:19\n",
            "| Training Device=xla:0/4 Epoch=134 Step=0 Loss=0.35448 Rate=10.15 GlobalRate=10.15 Time=22:54:19\n",
            "| Training Device=xla:0/1 Epoch=134 Step=0 Loss=0.31440 Rate=10.16 GlobalRate=10.16 Time=22:54:19\n",
            "| Training Device=xla:0/7 Epoch=134 Step=0 Loss=0.30256 Rate=10.16 GlobalRate=10.15 Time=22:54:19\n",
            "Epoch 134 train end 22:54:19\n",
            "Epoch 135 train begin 22:54:19\n",
            "| Training Device=xla:0/2 Epoch=135 Step=0 Loss=0.33169 Rate=10.20 GlobalRate=10.20 Time=22:54:26\n",
            "| Training Device=xla:0/7 Epoch=135 Step=0 Loss=0.26112 Rate=10.20 GlobalRate=10.20 Time=22:54:26\n",
            "| Training Device=xla:0/3 Epoch=135 Step=0 Loss=0.47560 Rate=10.21 GlobalRate=10.21 Time=22:54:26\n",
            "| Training Device=xla:0/6 Epoch=135 Step=0 Loss=0.38138 Rate=10.21 GlobalRate=10.21 Time=22:54:26\n",
            "| Training Device=xla:1/0 Epoch=135 Step=0 Loss=0.36207 Rate=10.21 GlobalRate=10.21 Time=22:54:26\n",
            "| Training Device=xla:0/5 Epoch=135 Step=0 Loss=0.28420 Rate=10.21 GlobalRate=10.21 Time=22:54:26\n",
            "| Training Device=xla:0/4 Epoch=135 Step=0 Loss=0.28439 Rate=10.21 GlobalRate=10.21 Time=22:54:26\n",
            "| Training Device=xla:0/1 Epoch=135 Step=0 Loss=0.34852 Rate=10.20 GlobalRate=10.20 Time=22:54:26\n",
            "Epoch 135 train end 22:54:26\n",
            "Epoch 136 train begin 22:54:26\n",
            "| Training Device=xla:0/7 Epoch=136 Step=0 Loss=0.31537 Rate=10.14 GlobalRate=10.14 Time=22:54:32\n",
            "| Training Device=xla:0/4 Epoch=136 Step=0 Loss=0.30783 Rate=10.15 GlobalRate=10.15 Time=22:54:32\n",
            "| Training Device=xla:1/0 Epoch=136 Step=0 Loss=0.43090 Rate=10.15 GlobalRate=10.15 Time=22:54:32\n",
            "| Training Device=xla:0/1 Epoch=136 Step=0 Loss=0.33432 Rate=10.14 GlobalRate=10.14 Time=22:54:32\n",
            "| Training Device=xla:0/6 Epoch=136 Step=0 Loss=0.41972 Rate=10.14 GlobalRate=10.14 Time=22:54:32\n",
            "| Training Device=xla:0/5 Epoch=136 Step=0 Loss=0.34733 Rate=10.14 GlobalRate=10.14 Time=22:54:32\n",
            "| Training Device=xla:0/2 Epoch=136 Step=0 Loss=0.32161 Rate=10.14 GlobalRate=10.14 Time=22:54:32\n",
            "| Training Device=xla:0/3 Epoch=136 Step=0 Loss=0.40023 Rate=10.14 GlobalRate=10.14 Time=22:54:32\n",
            "Epoch 136 train end 22:54:32\n",
            "Epoch 137 train begin 22:54:32\n",
            "| Training Device=xla:0/1 Epoch=137 Step=0 Loss=0.28353 Rate=10.12 GlobalRate=10.12 Time=22:54:39\n",
            "| Training Device=xla:1/0 Epoch=137 Step=0 Loss=0.40345 Rate=10.13 GlobalRate=10.13 Time=22:54:39\n",
            "| Training Device=xla:0/7 Epoch=137 Step=0 Loss=0.28010 Rate=10.12 GlobalRate=10.12 Time=22:54:39\n",
            "| Training Device=xla:0/5 Epoch=137 Step=0 Loss=0.30151 Rate=10.12 GlobalRate=10.12 Time=22:54:39\n",
            "| Training Device=xla:0/3 Epoch=137 Step=0 Loss=0.45547 Rate=10.12 GlobalRate=10.12 Time=22:54:39\n",
            "| Training Device=xla:0/4 Epoch=137 Step=0 Loss=0.27452 Rate=10.12 GlobalRate=10.12 Time=22:54:39\n",
            "| Training Device=xla:0/2 Epoch=137 Step=0 Loss=0.29304 Rate=10.12 GlobalRate=10.12 Time=22:54:39\n",
            "| Training Device=xla:0/6 Epoch=137 Step=0 Loss=0.38638 Rate=10.12 GlobalRate=10.12 Time=22:54:39\n",
            "Epoch 137 train end 22:54:39\n",
            "Epoch 138 train begin 22:54:39\n",
            "| Training Device=xla:0/1 Epoch=138 Step=0 Loss=0.31839 Rate=10.10 GlobalRate=10.10 Time=22:54:45\n",
            "| Training Device=xla:0/5 Epoch=138 Step=0 Loss=0.27343 Rate=10.10 GlobalRate=10.10 Time=22:54:45\n",
            "| Training Device=xla:0/4 Epoch=138 Step=0 Loss=0.30436 Rate=10.10 GlobalRate=10.10 Time=22:54:45\n",
            "| Training Device=xla:0/3 Epoch=138 Step=0 Loss=0.44133 Rate=10.10 GlobalRate=10.10 Time=22:54:45\n",
            "| Training Device=xla:1/0 Epoch=138 Step=0 Loss=0.38458 Rate=10.11 GlobalRate=10.11 Time=22:54:45\n",
            "| Training Device=xla:0/6 Epoch=138 Step=0 Loss=0.44221 Rate=10.10 GlobalRate=10.10 Time=22:54:45\n",
            "| Training Device=xla:0/7 Epoch=138 Step=0 Loss=0.24057 Rate=10.10 GlobalRate=10.10 Time=22:54:45\n",
            "| Training Device=xla:0/2 Epoch=138 Step=0 Loss=0.28575 Rate=10.10 GlobalRate=10.10 Time=22:54:45\n",
            "Epoch 138 train end 22:54:46\n",
            "Epoch 139 train begin 22:54:46\n",
            "| Training Device=xla:0/3 Epoch=139 Step=0 Loss=0.42106 Rate=10.11 GlobalRate=10.11 Time=22:54:52\n",
            "| Training Device=xla:0/2 Epoch=139 Step=0 Loss=0.31821 Rate=10.11 GlobalRate=10.11 Time=22:54:52\n",
            "| Training Device=xla:0/1 Epoch=139 Step=0 Loss=0.32093 Rate=10.11 GlobalRate=10.11 Time=22:54:52\n",
            "| Training Device=xla:0/6 Epoch=139 Step=0 Loss=0.37355 Rate=10.11 GlobalRate=10.11 Time=22:54:52\n",
            "| Training Device=xla:0/4 Epoch=139 Step=0 Loss=0.29574 Rate=10.11 GlobalRate=10.11 Time=22:54:52\n",
            "| Training Device=xla:0/5 Epoch=139 Step=0 Loss=0.25545 Rate=10.11 GlobalRate=10.11 Time=22:54:52\n",
            "| Training Device=xla:0/7 Epoch=139 Step=0 Loss=0.27264 Rate=10.11 GlobalRate=10.11 Time=22:54:52\n",
            "| Training Device=xla:1/0 Epoch=139 Step=0 Loss=0.38385 Rate=10.11 GlobalRate=10.11 Time=22:54:52\n",
            "Epoch 139 train end 22:54:52\n",
            "Epoch 140 train begin 22:54:52\n",
            "| Training Device=xla:0/1 Epoch=140 Step=0 Loss=0.34331 Rate=10.15 GlobalRate=10.15 Time=22:54:58\n",
            "| Training Device=xla:0/7 Epoch=140 Step=0 Loss=0.35040 Rate=10.15 GlobalRate=10.15 Time=22:54:58\n",
            "| Training Device=xla:1/0 Epoch=140 Step=0 Loss=0.34924 Rate=10.15 GlobalRate=10.15 Time=22:54:58\n",
            "| Training Device=xla:0/4 Epoch=140 Step=0 Loss=0.32356 Rate=10.15 GlobalRate=10.15 Time=22:54:58\n",
            "| Training Device=xla:0/2 Epoch=140 Step=0 Loss=0.33329 Rate=10.14 GlobalRate=10.14 Time=22:54:59\n",
            "| Training Device=xla:0/3 Epoch=140 Step=0 Loss=0.44317 Rate=10.14 GlobalRate=10.14 Time=22:54:59\n",
            "| Training Device=xla:0/6 Epoch=140 Step=0 Loss=0.39813 Rate=10.15 GlobalRate=10.15 Time=22:54:59\n",
            "| Training Device=xla:0/5 Epoch=140 Step=0 Loss=0.29114 Rate=10.14 GlobalRate=10.14 Time=22:54:59\n",
            "Epoch 140 train end 22:54:59\n",
            "Epoch 141 train begin 22:54:59\n",
            "| Training Device=xla:0/1 Epoch=141 Step=0 Loss=0.35541 Rate=10.11 GlobalRate=10.11 Time=22:55:05\n",
            "| Training Device=xla:0/4 Epoch=141 Step=0 Loss=0.28139 Rate=10.11 GlobalRate=10.11 Time=22:55:05\n",
            "| Training Device=xla:0/5 Epoch=141 Step=0 Loss=0.31753 Rate=10.11 GlobalRate=10.11 Time=22:55:05\n",
            "| Training Device=xla:0/6 Epoch=141 Step=0 Loss=0.39946 Rate=10.11 GlobalRate=10.11 Time=22:55:05\n",
            "| Training Device=xla:1/0 Epoch=141 Step=0 Loss=0.37589 Rate=10.11 GlobalRate=10.11 Time=22:55:05\n",
            "| Training Device=xla:0/2 Epoch=141 Step=0 Loss=0.29898 Rate=10.11 GlobalRate=10.11 Time=22:55:05\n",
            "| Training Device=xla:0/3 Epoch=141 Step=0 Loss=0.46823 Rate=10.11 GlobalRate=10.11 Time=22:55:05\n",
            "| Training Device=xla:0/7 Epoch=141 Step=0 Loss=0.27504 Rate=10.11 GlobalRate=10.11 Time=22:55:05\n",
            "Epoch 141 train end 22:55:05\n",
            "Epoch 142 train begin 22:55:05\n",
            "| Training Device=xla:1/0 Epoch=142 Step=0 Loss=0.33642 Rate=10.09 GlobalRate=10.09 Time=22:55:12\n",
            "| Training Device=xla:0/6 Epoch=142 Step=0 Loss=0.43428 Rate=10.08 GlobalRate=10.08 Time=22:55:12\n",
            "| Training Device=xla:0/5 Epoch=142 Step=0 Loss=0.34741 Rate=10.08 GlobalRate=10.08 Time=22:55:12\n",
            "| Training Device=xla:0/1 Epoch=142 Step=0 Loss=0.35549 Rate=10.08 GlobalRate=10.08 Time=22:55:12\n",
            "| Training Device=xla:0/4 Epoch=142 Step=0 Loss=0.33164 Rate=10.08 GlobalRate=10.08 Time=22:55:12\n",
            "| Training Device=xla:0/7 Epoch=142 Step=0 Loss=0.32625 Rate=10.08 GlobalRate=10.08 Time=22:55:12\n",
            "| Training Device=xla:0/3 Epoch=142 Step=0 Loss=0.44821 Rate=10.08 GlobalRate=10.08 Time=22:55:12\n",
            "| Training Device=xla:0/2 Epoch=142 Step=0 Loss=0.29874 Rate=10.08 GlobalRate=10.08 Time=22:55:12\n",
            "Epoch 142 train end 22:55:12\n",
            "Epoch 143 train begin 22:55:12\n",
            "| Training Device=xla:0/1 Epoch=143 Step=0 Loss=0.31479 Rate=10.11 GlobalRate=10.11 Time=22:55:18\n",
            "| Training Device=xla:0/2 Epoch=143 Step=0 Loss=0.32233 Rate=10.11 GlobalRate=10.11 Time=22:55:18\n",
            "| Training Device=xla:1/0 Epoch=143 Step=0 Loss=0.37100 Rate=10.11 GlobalRate=10.11 Time=22:55:18\n",
            "| Training Device=xla:0/4 Epoch=143 Step=0 Loss=0.26532 Rate=10.11 GlobalRate=10.11 Time=22:55:18\n",
            "| Training Device=xla:0/5 Epoch=143 Step=0 Loss=0.29089 Rate=10.11 GlobalRate=10.11 Time=22:55:18\n",
            "| Training Device=xla:0/7 Epoch=143 Step=0 Loss=0.30398 Rate=10.11 GlobalRate=10.11 Time=22:55:18\n",
            "| Training Device=xla:0/6 Epoch=143 Step=0 Loss=0.45130 Rate=10.11 GlobalRate=10.11 Time=22:55:18\n",
            "| Training Device=xla:0/3 Epoch=143 Step=0 Loss=0.40608 Rate=10.10 GlobalRate=10.10 Time=22:55:18\n",
            "Epoch 143 train end 22:55:18\n",
            "Epoch 144 train begin 22:55:18\n",
            "| Training Device=xla:0/5 Epoch=144 Step=0 Loss=0.24693 Rate=10.09 GlobalRate=10.09 Time=22:55:25\n",
            "| Training Device=xla:0/6 Epoch=144 Step=0 Loss=0.39778 Rate=10.09 GlobalRate=10.09 Time=22:55:25\n",
            "| Training Device=xla:0/3 Epoch=144 Step=0 Loss=0.44406 Rate=10.09 GlobalRate=10.09 Time=22:55:25\n",
            "| Training Device=xla:0/1 Epoch=144 Step=0 Loss=0.30795 Rate=10.09 GlobalRate=10.09 Time=22:55:25\n",
            "| Training Device=xla:0/7 Epoch=144 Step=0 Loss=0.28241 Rate=10.09 GlobalRate=10.09 Time=22:55:25\n",
            "| Training Device=xla:0/4 Epoch=144 Step=0 Loss=0.30520 Rate=10.09 GlobalRate=10.09 Time=22:55:25\n",
            "| Training Device=xla:0/2 Epoch=144 Step=0 Loss=0.33003 Rate=10.09 GlobalRate=10.09 Time=22:55:25\n",
            "| Training Device=xla:1/0 Epoch=144 Step=0 Loss=0.39115 Rate=10.09 GlobalRate=10.09 Time=22:55:25\n",
            "Epoch 144 train end 22:55:25\n",
            "Epoch 145 train begin 22:55:25\n",
            "| Training Device=xla:0/3 Epoch=145 Step=0 Loss=0.43619 Rate=10.11 GlobalRate=10.11 Time=22:55:31\n",
            "| Training Device=xla:0/2 Epoch=145 Step=0 Loss=0.25977 Rate=10.10 GlobalRate=10.10 Time=22:55:31\n",
            "| Training Device=xla:0/6 Epoch=145 Step=0 Loss=0.38249 Rate=10.11 GlobalRate=10.11 Time=22:55:31\n",
            "| Training Device=xla:0/4 Epoch=145 Step=0 Loss=0.29171 Rate=10.11 GlobalRate=10.11 Time=22:55:31\n",
            "| Training Device=xla:0/7 Epoch=145 Step=0 Loss=0.29949 Rate=10.11 GlobalRate=10.11 Time=22:55:31\n",
            "| Training Device=xla:0/5 Epoch=145 Step=0 Loss=0.24770 Rate=10.11 GlobalRate=10.11 Time=22:55:31\n",
            "| Training Device=xla:0/1 Epoch=145 Step=0 Loss=0.35582 Rate=10.10 GlobalRate=10.10 Time=22:55:31\n",
            "| Training Device=xla:1/0 Epoch=145 Step=0 Loss=0.40030 Rate=10.11 GlobalRate=10.11 Time=22:55:31\n",
            "Epoch 145 train end 22:55:32\n",
            "Epoch 146 train begin 22:55:32\n",
            "| Training Device=xla:0/6 Epoch=146 Step=0 Loss=0.40113 Rate=10.11 GlobalRate=10.11 Time=22:55:38\n",
            "| Training Device=xla:0/7 Epoch=146 Step=0 Loss=0.31310 Rate=10.12 GlobalRate=10.12 Time=22:55:38\n",
            "| Training Device=xla:0/1 Epoch=146 Step=0 Loss=0.35185 Rate=10.12 GlobalRate=10.12 Time=22:55:38\n",
            "| Training Device=xla:0/4 Epoch=146 Step=0 Loss=0.31388 Rate=10.11 GlobalRate=10.11 Time=22:55:38\n",
            "| Training Device=xla:0/2 Epoch=146 Step=0 Loss=0.32169 Rate=10.12 GlobalRate=10.12 Time=22:55:38\n",
            "| Training Device=xla:0/3 Epoch=146 Step=0 Loss=0.48756 Rate=10.11 GlobalRate=10.11 Time=22:55:38\n",
            "| Training Device=xla:0/5 Epoch=146 Step=0 Loss=0.28033 Rate=10.11 GlobalRate=10.11 Time=22:55:38\n",
            "| Training Device=xla:1/0 Epoch=146 Step=0 Loss=0.42896 Rate=10.12 GlobalRate=10.12 Time=22:55:38\n",
            "Epoch 146 train end 22:55:38\n",
            "Epoch 147 train begin 22:55:38\n",
            "| Training Device=xla:0/7 Epoch=147 Step=0 Loss=0.29133 Rate=10.11 GlobalRate=10.11 Time=22:55:45\n",
            "| Training Device=xla:0/2 Epoch=147 Step=0 Loss=0.33828 Rate=10.11 GlobalRate=10.11 Time=22:55:45\n",
            "| Training Device=xla:0/4 Epoch=147 Step=0 Loss=0.32254 Rate=10.11 GlobalRate=10.11 Time=22:55:45\n",
            "| Training Device=xla:0/5 Epoch=147 Step=0 Loss=0.26388 Rate=10.11 GlobalRate=10.11 Time=22:55:45\n",
            "| Training Device=xla:0/6 Epoch=147 Step=0 Loss=0.36923 Rate=10.11 GlobalRate=10.11 Time=22:55:45\n",
            "| Training Device=xla:1/0 Epoch=147 Step=0 Loss=0.36038 Rate=10.12 GlobalRate=10.12 Time=22:55:45\n",
            "| Training Device=xla:0/1 Epoch=147 Step=0 Loss=0.34253 Rate=10.11 GlobalRate=10.11 Time=22:55:45\n",
            "| Training Device=xla:0/3 Epoch=147 Step=0 Loss=0.44690 Rate=10.11 GlobalRate=10.11 Time=22:55:45\n",
            "Epoch 147 train end 22:55:45\n",
            "Epoch 148 train begin 22:55:45\n",
            "| Training Device=xla:0/7 Epoch=148 Step=0 Loss=0.27139 Rate=10.11 GlobalRate=10.11 Time=22:55:51\n",
            "| Training Device=xla:0/4 Epoch=148 Step=0 Loss=0.28093 Rate=10.10 GlobalRate=10.10 Time=22:55:51\n",
            "| Training Device=xla:0/1 Epoch=148 Step=0 Loss=0.37033 Rate=10.10 GlobalRate=10.10 Time=22:55:51\n",
            "| Training Device=xla:0/3 Epoch=148 Step=0 Loss=0.43329 Rate=10.10 GlobalRate=10.10 Time=22:55:51\n",
            "| Training Device=xla:0/6 Epoch=148 Step=0 Loss=0.38048 Rate=10.10 GlobalRate=10.10 Time=22:55:51\n",
            "| Training Device=xla:0/5 Epoch=148 Step=0 Loss=0.38147 Rate=10.10 GlobalRate=10.10 Time=22:55:51\n",
            "| Training Device=xla:0/2 Epoch=148 Step=0 Loss=0.33961 Rate=10.10 GlobalRate=10.10 Time=22:55:51\n",
            "| Training Device=xla:1/0 Epoch=148 Step=0 Loss=0.41642 Rate=10.11 GlobalRate=10.11 Time=22:55:51\n",
            "Epoch 148 train end 22:55:51\n",
            "Epoch 149 train begin 22:55:51\n",
            "| Training Device=xla:0/2 Epoch=149 Step=0 Loss=0.31075 Rate=10.11 GlobalRate=10.11 Time=22:55:58\n",
            "| Training Device=xla:0/4 Epoch=149 Step=0 Loss=0.30731 Rate=10.11 GlobalRate=10.11 Time=22:55:58\n",
            "| Training Device=xla:0/6 Epoch=149 Step=0 Loss=0.37126 Rate=10.11 GlobalRate=10.11 Time=22:55:58\n",
            "| Training Device=xla:0/5 Epoch=149 Step=0 Loss=0.30364 Rate=10.11 GlobalRate=10.11 Time=22:55:58\n",
            "| Training Device=xla:0/1 Epoch=149 Step=0 Loss=0.31058 Rate=10.11 GlobalRate=10.11 Time=22:55:58\n",
            "| Training Device=xla:0/7 Epoch=149 Step=0 Loss=0.33079 Rate=10.11 GlobalRate=10.11 Time=22:55:58\n",
            "| Training Device=xla:0/3 Epoch=149 Step=0 Loss=0.46774 Rate=10.11 GlobalRate=10.11 Time=22:55:58\n",
            "| Training Device=xla:1/0 Epoch=149 Step=0 Loss=0.38826 Rate=10.11 GlobalRate=10.11 Time=22:55:58\n",
            "Epoch 149 train end 22:55:58\n",
            "Epoch 150 train begin 22:55:58\n",
            "| Training Device=xla:0/7 Epoch=150 Step=0 Loss=0.28239 Rate=10.11 GlobalRate=10.11 Time=22:56:04\n",
            "| Training Device=xla:0/3 Epoch=150 Step=0 Loss=0.42906 Rate=10.10 GlobalRate=10.10 Time=22:56:04\n",
            "| Training Device=xla:0/2 Epoch=150 Step=0 Loss=0.32240 Rate=10.11 GlobalRate=10.11 Time=22:56:04\n",
            "| Training Device=xla:0/6 Epoch=150 Step=0 Loss=0.34943 Rate=10.11 GlobalRate=10.11 Time=22:56:04\n",
            "| Training Device=xla:1/0 Epoch=150 Step=0 Loss=0.38313 Rate=10.11 GlobalRate=10.11 Time=22:56:04\n",
            "| Training Device=xla:0/1 Epoch=150 Step=0 Loss=0.30156 Rate=10.11 GlobalRate=10.11 Time=22:56:04\n",
            "| Training Device=xla:0/4 Epoch=150 Step=0 Loss=0.25555 Rate=10.10 GlobalRate=10.10 Time=22:56:04\n",
            "| Training Device=xla:0/5 Epoch=150 Step=0 Loss=0.29849 Rate=10.11 GlobalRate=10.11 Time=22:56:04\n",
            "Epoch 150 train end 22:56:05\n",
            "Epoch 151 train begin 22:56:05\n",
            "| Training Device=xla:0/1 Epoch=151 Step=0 Loss=0.29735 Rate=10.17 GlobalRate=10.17 Time=22:56:11\n",
            "| Training Device=xla:0/6 Epoch=151 Step=0 Loss=0.38214 Rate=10.17 GlobalRate=10.17 Time=22:56:11\n",
            "| Training Device=xla:0/2 Epoch=151 Step=0 Loss=0.28829 Rate=10.17 GlobalRate=10.17 Time=22:56:11\n",
            "| Training Device=xla:0/7 Epoch=151 Step=0 Loss=0.32454 Rate=10.17 GlobalRate=10.17 Time=22:56:11\n",
            "| Training Device=xla:1/0 Epoch=151 Step=0 Loss=0.35955 Rate=10.17 GlobalRate=10.17 Time=22:56:11\n",
            "| Training Device=xla:0/5 Epoch=151 Step=0 Loss=0.25405 Rate=10.17 GlobalRate=10.17 Time=22:56:11\n",
            "| Training Device=xla:0/3 Epoch=151 Step=0 Loss=0.44085 Rate=10.17 GlobalRate=10.17 Time=22:56:11\n",
            "| Training Device=xla:0/4 Epoch=151 Step=0 Loss=0.32909 Rate=10.17 GlobalRate=10.17 Time=22:56:11\n",
            "Epoch 151 train end 22:56:11\n",
            "Epoch 152 train begin 22:56:11\n",
            "| Training Device=xla:0/1 Epoch=152 Step=0 Loss=0.29538 Rate=10.14 GlobalRate=10.14 Time=22:56:17\n",
            "| Training Device=xla:0/7 Epoch=152 Step=0 Loss=0.32307 Rate=10.14 GlobalRate=10.14 Time=22:56:17\n",
            "| Training Device=xla:0/5 Epoch=152 Step=0 Loss=0.33160 Rate=10.14 GlobalRate=10.14 Time=22:56:17\n",
            "| Training Device=xla:0/6 Epoch=152 Step=0 Loss=0.38920 Rate=10.14 GlobalRate=10.14 Time=22:56:17\n",
            "| Training Device=xla:1/0 Epoch=152 Step=0 Loss=0.40170 Rate=10.14 GlobalRate=10.14 Time=22:56:17\n",
            "| Training Device=xla:0/4 Epoch=152 Step=0 Loss=0.32332 Rate=10.14 GlobalRate=10.14 Time=22:56:17\n",
            "| Training Device=xla:0/2 Epoch=152 Step=0 Loss=0.33399 Rate=10.14 GlobalRate=10.14 Time=22:56:17\n",
            "| Training Device=xla:0/3 Epoch=152 Step=0 Loss=0.50404 Rate=10.14 GlobalRate=10.14 Time=22:56:17\n",
            "Epoch 152 train end 22:56:18\n",
            "Epoch 153 train begin 22:56:18\n",
            "| Training Device=xla:0/5 Epoch=153 Step=0 Loss=0.34969 Rate=10.13 GlobalRate=10.13 Time=22:56:24\n",
            "| Training Device=xla:0/3 Epoch=153 Step=0 Loss=0.47486 Rate=10.13 GlobalRate=10.13 Time=22:56:24\n",
            "| Training Device=xla:0/7 Epoch=153 Step=0 Loss=0.33105 Rate=10.13 GlobalRate=10.13 Time=22:56:24\n",
            "| Training Device=xla:0/6 Epoch=153 Step=0 Loss=0.43678 Rate=10.13 GlobalRate=10.13 Time=22:56:24\n",
            "| Training Device=xla:0/2 Epoch=153 Step=0 Loss=0.28630 Rate=10.13 GlobalRate=10.13 Time=22:56:24\n",
            "| Training Device=xla:0/1 Epoch=153 Step=0 Loss=0.32923 Rate=10.13 GlobalRate=10.13 Time=22:56:24\n",
            "| Training Device=xla:0/4 Epoch=153 Step=0 Loss=0.30692 Rate=10.13 GlobalRate=10.13 Time=22:56:24\n",
            "| Training Device=xla:1/0 Epoch=153 Step=0 Loss=0.34117 Rate=10.13 GlobalRate=10.13 Time=22:56:24\n",
            "Epoch 153 train end 22:56:24\n",
            "Epoch 154 train begin 22:56:24\n",
            "| Training Device=xla:0/6 Epoch=154 Step=0 Loss=0.39552 Rate=10.20 GlobalRate=10.20 Time=22:56:30\n",
            "| Training Device=xla:1/0 Epoch=154 Step=0 Loss=0.33990 Rate=10.20 GlobalRate=10.20 Time=22:56:30\n",
            "| Training Device=xla:0/7 Epoch=154 Step=0 Loss=0.31248 Rate=10.19 GlobalRate=10.19 Time=22:56:30\n",
            "| Training Device=xla:0/2 Epoch=154 Step=0 Loss=0.35860 Rate=10.19 GlobalRate=10.19 Time=22:56:30\n",
            "| Training Device=xla:0/3 Epoch=154 Step=0 Loss=0.40380 Rate=10.19 GlobalRate=10.19 Time=22:56:30\n",
            "| Training Device=xla:0/5 Epoch=154 Step=0 Loss=0.29394 Rate=10.20 GlobalRate=10.20 Time=22:56:30\n",
            "| Training Device=xla:0/1 Epoch=154 Step=0 Loss=0.35315 Rate=10.19 GlobalRate=10.19 Time=22:56:30\n",
            "| Training Device=xla:0/4 Epoch=154 Step=0 Loss=0.26697 Rate=10.19 GlobalRate=10.19 Time=22:56:30\n",
            "Epoch 154 train end 22:56:31\n",
            "Epoch 155 train begin 22:56:31\n",
            "| Training Device=xla:0/2 Epoch=155 Step=0 Loss=0.33300 Rate=10.20 GlobalRate=10.20 Time=22:56:37\n",
            "| Training Device=xla:0/7 Epoch=155 Step=0 Loss=0.28849 Rate=10.20 GlobalRate=10.20 Time=22:56:37\n",
            "| Training Device=xla:0/3 Epoch=155 Step=0 Loss=0.46919 Rate=10.20 GlobalRate=10.20 Time=22:56:37\n",
            "| Training Device=xla:0/1 Epoch=155 Step=0 Loss=0.34930 Rate=10.20 GlobalRate=10.20 Time=22:56:37\n",
            "| Training Device=xla:0/5 Epoch=155 Step=0 Loss=0.32148 Rate=10.20 GlobalRate=10.20 Time=22:56:37\n",
            "| Training Device=xla:0/6 Epoch=155 Step=0 Loss=0.44856 Rate=10.20 GlobalRate=10.20 Time=22:56:37\n",
            "| Training Device=xla:1/0 Epoch=155 Step=0 Loss=0.37480 Rate=10.20 GlobalRate=10.20 Time=22:56:37\n",
            "| Training Device=xla:0/4 Epoch=155 Step=0 Loss=0.27169 Rate=10.20 GlobalRate=10.20 Time=22:56:37\n",
            "Epoch 155 train end 22:56:37\n",
            "Epoch 156 train begin 22:56:37\n",
            "| Training Device=xla:0/3 Epoch=156 Step=0 Loss=0.39065 Rate=10.13 GlobalRate=10.13 Time=22:56:44\n",
            "| Training Device=xla:0/4 Epoch=156 Step=0 Loss=0.31749 Rate=10.13 GlobalRate=10.13 Time=22:56:44\n",
            "| Training Device=xla:1/0 Epoch=156 Step=0 Loss=0.36518 Rate=10.13 GlobalRate=10.13 Time=22:56:44\n",
            "| Training Device=xla:0/2 Epoch=156 Step=0 Loss=0.30777 Rate=10.13 GlobalRate=10.13 Time=22:56:44\n",
            "| Training Device=xla:0/6 Epoch=156 Step=0 Loss=0.38312 Rate=10.13 GlobalRate=10.13 Time=22:56:44\n",
            "| Training Device=xla:0/7 Epoch=156 Step=0 Loss=0.28143 Rate=10.13 GlobalRate=10.13 Time=22:56:44\n",
            "| Training Device=xla:0/1 Epoch=156 Step=0 Loss=0.33820 Rate=10.12 GlobalRate=10.12 Time=22:56:44\n",
            "| Training Device=xla:0/5 Epoch=156 Step=0 Loss=0.29643 Rate=10.13 GlobalRate=10.13 Time=22:56:44\n",
            "Epoch 156 train end 22:56:44\n",
            "Epoch 157 train begin 22:56:44\n",
            "| Training Device=xla:0/7 Epoch=157 Step=0 Loss=0.27777 Rate=10.13 GlobalRate=10.13 Time=22:56:50\n",
            "| Training Device=xla:0/4 Epoch=157 Step=0 Loss=0.29555 Rate=10.12 GlobalRate=10.12 Time=22:56:50\n",
            "| Training Device=xla:0/1 Epoch=157 Step=0 Loss=0.33271 Rate=10.13 GlobalRate=10.13 Time=22:56:50\n",
            "| Training Device=xla:0/3 Epoch=157 Step=0 Loss=0.43018 Rate=10.13 GlobalRate=10.13 Time=22:56:50\n",
            "| Training Device=xla:0/6 Epoch=157 Step=0 Loss=0.33052 Rate=10.13 GlobalRate=10.13 Time=22:56:50\n",
            "| Training Device=xla:0/2 Epoch=157 Step=0 Loss=0.26032 Rate=10.13 GlobalRate=10.13 Time=22:56:50\n",
            "| Training Device=xla:0/5 Epoch=157 Step=0 Loss=0.27316 Rate=10.13 GlobalRate=10.13 Time=22:56:50\n",
            "| Training Device=xla:1/0 Epoch=157 Step=0 Loss=0.37924 Rate=10.13 GlobalRate=10.13 Time=22:56:50\n",
            "Epoch 157 train end 22:56:50\n",
            "Epoch 158 train begin 22:56:50\n",
            "| Training Device=xla:0/4 Epoch=158 Step=0 Loss=0.25283 Rate=10.18 GlobalRate=10.18 Time=22:56:57\n",
            "| Training Device=xla:0/7 Epoch=158 Step=0 Loss=0.27363 Rate=10.18 GlobalRate=10.18 Time=22:56:57\n",
            "| Training Device=xla:0/2 Epoch=158 Step=0 Loss=0.36085 Rate=10.18 GlobalRate=10.18 Time=22:56:57\n",
            "| Training Device=xla:0/1 Epoch=158 Step=0 Loss=0.35318 Rate=10.18 GlobalRate=10.18 Time=22:56:57\n",
            "| Training Device=xla:0/6 Epoch=158 Step=0 Loss=0.36768 Rate=10.18 GlobalRate=10.18 Time=22:56:57\n",
            "| Training Device=xla:0/3 Epoch=158 Step=0 Loss=0.44453 Rate=10.18 GlobalRate=10.18 Time=22:56:57\n",
            "| Training Device=xla:1/0 Epoch=158 Step=0 Loss=0.40806 Rate=10.18 GlobalRate=10.18 Time=22:56:57\n",
            "| Training Device=xla:0/5 Epoch=158 Step=0 Loss=0.25564 Rate=10.18 GlobalRate=10.18 Time=22:56:57\n",
            "Epoch 158 train end 22:56:57\n",
            "Epoch 159 train begin 22:56:57\n",
            "| Training Device=xla:0/5 Epoch=159 Step=0 Loss=0.30725 Rate=10.21 GlobalRate=10.21 Time=22:57:03\n",
            "| Training Device=xla:0/6 Epoch=159 Step=0 Loss=0.45117 Rate=10.21 GlobalRate=10.21 Time=22:57:03\n",
            "| Training Device=xla:0/7 Epoch=159 Step=0 Loss=0.27231 Rate=10.21 GlobalRate=10.21 Time=22:57:03\n",
            "| Training Device=xla:0/4 Epoch=159 Step=0 Loss=0.30970 Rate=10.21 GlobalRate=10.21 Time=22:57:03\n",
            "| Training Device=xla:0/1 Epoch=159 Step=0 Loss=0.31964 Rate=10.21 GlobalRate=10.21 Time=22:57:03\n",
            "| Training Device=xla:0/2 Epoch=159 Step=0 Loss=0.31018 Rate=10.21 GlobalRate=10.21 Time=22:57:03\n",
            "| Training Device=xla:0/3 Epoch=159 Step=0 Loss=0.40043 Rate=10.21 GlobalRate=10.21 Time=22:57:03\n",
            "| Training Device=xla:1/0 Epoch=159 Step=0 Loss=0.34639 Rate=10.21 GlobalRate=10.21 Time=22:57:03\n",
            "Epoch 159 train end 22:57:03\n",
            "Epoch 160 train begin 22:57:03\n",
            "| Training Device=xla:1/0 Epoch=160 Step=0 Loss=0.36955 Rate=10.21 GlobalRate=10.21 Time=22:57:10\n",
            "| Training Device=xla:0/3 Epoch=160 Step=0 Loss=0.41613 Rate=10.20 GlobalRate=10.20 Time=22:57:10\n",
            "| Training Device=xla:0/2 Epoch=160 Step=0 Loss=0.30400 Rate=10.21 GlobalRate=10.21 Time=22:57:10\n",
            "| Training Device=xla:0/5 Epoch=160 Step=0 Loss=0.33249 Rate=10.20 GlobalRate=10.20 Time=22:57:10\n",
            "| Training Device=xla:0/1 Epoch=160 Step=0 Loss=0.32252 Rate=10.20 GlobalRate=10.20 Time=22:57:10\n",
            "| Training Device=xla:0/6 Epoch=160 Step=0 Loss=0.39854 Rate=10.20 GlobalRate=10.20 Time=22:57:10\n",
            "| Training Device=xla:0/4 Epoch=160 Step=0 Loss=0.31378 Rate=10.20 GlobalRate=10.20 Time=22:57:10\n",
            "| Training Device=xla:0/7 Epoch=160 Step=0 Loss=0.29954 Rate=10.20 GlobalRate=10.20 Time=22:57:10\n",
            "Epoch 160 train end 22:57:10\n",
            "Epoch 161 train begin 22:57:10\n",
            "| Training Device=xla:0/3 Epoch=161 Step=0 Loss=0.45880 Rate=10.14 GlobalRate=10.14 Time=22:57:16\n",
            "| Training Device=xla:0/2 Epoch=161 Step=0 Loss=0.32732 Rate=10.14 GlobalRate=10.14 Time=22:57:16\n",
            "| Training Device=xla:0/6 Epoch=161 Step=0 Loss=0.41390 Rate=10.14 GlobalRate=10.14 Time=22:57:16\n",
            "| Training Device=xla:0/5 Epoch=161 Step=0 Loss=0.29647 Rate=10.13 GlobalRate=10.13 Time=22:57:16\n",
            "| Training Device=xla:0/4 Epoch=161 Step=0 Loss=0.27310 Rate=10.14 GlobalRate=10.14 Time=22:57:16\n",
            "| Training Device=xla:1/0 Epoch=161 Step=0 Loss=0.31488 Rate=10.14 GlobalRate=10.14 Time=22:57:16\n",
            "| Training Device=xla:0/1 Epoch=161 Step=0 Loss=0.27907 Rate=10.14 GlobalRate=10.14 Time=22:57:16\n",
            "| Training Device=xla:0/7 Epoch=161 Step=0 Loss=0.29094 Rate=10.14 GlobalRate=10.14 Time=22:57:16\n",
            "Epoch 161 train end 22:57:16\n",
            "Epoch 162 train begin 22:57:16\n",
            "| Training Device=xla:0/2 Epoch=162 Step=0 Loss=0.34315 Rate=10.24 GlobalRate=10.24 Time=22:57:23\n",
            "| Training Device=xla:0/1 Epoch=162 Step=0 Loss=0.31831 Rate=10.24 GlobalRate=10.24 Time=22:57:23\n",
            "| Training Device=xla:1/0 Epoch=162 Step=0 Loss=0.34772 Rate=10.24 GlobalRate=10.24 Time=22:57:23\n",
            "| Training Device=xla:0/6 Epoch=162 Step=0 Loss=0.45781 Rate=10.24 GlobalRate=10.24 Time=22:57:23\n",
            "| Training Device=xla:0/5 Epoch=162 Step=0 Loss=0.28707 Rate=10.24 GlobalRate=10.24 Time=22:57:23\n",
            "| Training Device=xla:0/3 Epoch=162 Step=0 Loss=0.46984 Rate=10.24 GlobalRate=10.24 Time=22:57:23\n",
            "| Training Device=xla:0/7 Epoch=162 Step=0 Loss=0.30829 Rate=10.23 GlobalRate=10.23 Time=22:57:23\n",
            "| Training Device=xla:0/4 Epoch=162 Step=0 Loss=0.29194 Rate=10.23 GlobalRate=10.23 Time=22:57:23\n",
            "Epoch 162 train end 22:57:23\n",
            "Epoch 163 train begin 22:57:23\n",
            "| Training Device=xla:0/3 Epoch=163 Step=0 Loss=0.42034 Rate=10.16 GlobalRate=10.16 Time=22:57:29\n",
            "| Training Device=xla:0/2 Epoch=163 Step=0 Loss=0.37892 Rate=10.15 GlobalRate=10.15 Time=22:57:29\n",
            "| Training Device=xla:0/4 Epoch=163 Step=0 Loss=0.28867 Rate=10.16 GlobalRate=10.16 Time=22:57:29\n",
            "| Training Device=xla:0/1 Epoch=163 Step=0 Loss=0.36737 Rate=10.16 GlobalRate=10.16 Time=22:57:29\n",
            "| Training Device=xla:0/7 Epoch=163 Step=0 Loss=0.30863 Rate=10.16 GlobalRate=10.16 Time=22:57:29\n",
            "| Training Device=xla:0/6 Epoch=163 Step=0 Loss=0.40896 Rate=10.16 GlobalRate=10.16 Time=22:57:29\n",
            "| Training Device=xla:0/5 Epoch=163 Step=0 Loss=0.28683 Rate=10.16 GlobalRate=10.16 Time=22:57:29\n",
            "| Training Device=xla:1/0 Epoch=163 Step=0 Loss=0.39321 Rate=10.16 GlobalRate=10.16 Time=22:57:29\n",
            "Epoch 163 train end 22:57:29\n",
            "Epoch 164 train begin 22:57:29\n",
            "| Training Device=xla:0/1 Epoch=164 Step=0 Loss=0.34757 Rate=10.13 GlobalRate=10.13 Time=22:57:36\n",
            "| Training Device=xla:0/5 Epoch=164 Step=0 Loss=0.30702 Rate=10.13 GlobalRate=10.13 Time=22:57:36\n",
            "| Training Device=xla:0/6 Epoch=164 Step=0 Loss=0.45717 Rate=10.13 GlobalRate=10.13 Time=22:57:36\n",
            "| Training Device=xla:0/4 Epoch=164 Step=0 Loss=0.31234 Rate=10.13 GlobalRate=10.13 Time=22:57:36\n",
            "| Training Device=xla:1/0 Epoch=164 Step=0 Loss=0.30549 Rate=10.13 GlobalRate=10.13 Time=22:57:36\n",
            "| Training Device=xla:0/3 Epoch=164 Step=0 Loss=0.45097 Rate=10.13 GlobalRate=10.13 Time=22:57:36\n",
            "| Training Device=xla:0/7 Epoch=164 Step=0 Loss=0.29275 Rate=10.13 GlobalRate=10.13 Time=22:57:36\n",
            "| Training Device=xla:0/2 Epoch=164 Step=0 Loss=0.36577 Rate=10.13 GlobalRate=10.13 Time=22:57:36\n",
            "Epoch 164 train end 22:57:36\n",
            "Epoch 165 train begin 22:57:36\n",
            "| Training Device=xla:0/2 Epoch=165 Step=0 Loss=0.32977 Rate=10.16 GlobalRate=10.16 Time=22:57:42\n",
            "| Training Device=xla:0/3 Epoch=165 Step=0 Loss=0.46147 Rate=10.16 GlobalRate=10.16 Time=22:57:42\n",
            "| Training Device=xla:0/5 Epoch=165 Step=0 Loss=0.37951 Rate=10.16 GlobalRate=10.16 Time=22:57:42\n",
            "| Training Device=xla:0/7 Epoch=165 Step=0 Loss=0.29535 Rate=10.16 GlobalRate=10.16 Time=22:57:42\n",
            "| Training Device=xla:0/4 Epoch=165 Step=0 Loss=0.35876 Rate=10.16 GlobalRate=10.16 Time=22:57:42\n",
            "| Training Device=xla:0/6 Epoch=165 Step=0 Loss=0.44667 Rate=10.16 GlobalRate=10.16 Time=22:57:42\n",
            "| Training Device=xla:1/0 Epoch=165 Step=0 Loss=0.36527 Rate=10.16 GlobalRate=10.16 Time=22:57:42\n",
            "| Training Device=xla:0/1 Epoch=165 Step=0 Loss=0.35422 Rate=10.16 GlobalRate=10.16 Time=22:57:42\n",
            "Epoch 165 train end 22:57:43\n",
            "Epoch 166 train begin 22:57:43\n",
            "| Training Device=xla:0/1 Epoch=166 Step=0 Loss=0.33422 Rate=10.20 GlobalRate=10.20 Time=22:57:49\n",
            "| Training Device=xla:0/7 Epoch=166 Step=0 Loss=0.29885 Rate=10.20 GlobalRate=10.20 Time=22:57:49\n",
            "| Training Device=xla:0/2 Epoch=166 Step=0 Loss=0.32106 Rate=10.20 GlobalRate=10.20 Time=22:57:49\n",
            "| Training Device=xla:0/4 Epoch=166 Step=0 Loss=0.27621 Rate=10.20 GlobalRate=10.20 Time=22:57:49\n",
            "| Training Device=xla:0/3 Epoch=166 Step=0 Loss=0.46996 Rate=10.20 GlobalRate=10.20 Time=22:57:49\n",
            "| Training Device=xla:0/6 Epoch=166 Step=0 Loss=0.35353 Rate=10.20 GlobalRate=10.20 Time=22:57:49\n",
            "| Training Device=xla:1/0 Epoch=166 Step=0 Loss=0.34601 Rate=10.20 GlobalRate=10.20 Time=22:57:49\n",
            "| Training Device=xla:0/5 Epoch=166 Step=0 Loss=0.25512 Rate=10.20 GlobalRate=10.20 Time=22:57:49\n",
            "Epoch 166 train end 22:57:49\n",
            "Epoch 167 train begin 22:57:49\n",
            "| Training Device=xla:0/1 Epoch=167 Step=0 Loss=0.34136 Rate=10.17 GlobalRate=10.17 Time=22:57:55\n",
            "| Training Device=xla:0/7 Epoch=167 Step=0 Loss=0.29499 Rate=10.17 GlobalRate=10.17 Time=22:57:55\n",
            "| Training Device=xla:0/5 Epoch=167 Step=0 Loss=0.23923 Rate=10.17 GlobalRate=10.17 Time=22:57:55\n",
            "| Training Device=xla:0/6 Epoch=167 Step=0 Loss=0.40332 Rate=10.17 GlobalRate=10.17 Time=22:57:55\n",
            "| Training Device=xla:0/4 Epoch=167 Step=0 Loss=0.29750 Rate=10.17 GlobalRate=10.17 Time=22:57:55\n",
            "| Training Device=xla:0/2 Epoch=167 Step=0 Loss=0.29822 Rate=10.17 GlobalRate=10.17 Time=22:57:55\n",
            "| Training Device=xla:0/3 Epoch=167 Step=0 Loss=0.46120 Rate=10.17 GlobalRate=10.17 Time=22:57:55\n",
            "| Training Device=xla:1/0 Epoch=167 Step=0 Loss=0.35253 Rate=10.17 GlobalRate=10.17 Time=22:57:55\n",
            "Epoch 167 train end 22:57:56\n",
            "Epoch 168 train begin 22:57:56\n",
            "| Training Device=xla:0/3 Epoch=168 Step=0 Loss=0.40821 Rate=10.10 GlobalRate=10.10 Time=22:58:02\n",
            "| Training Device=xla:0/2 Epoch=168 Step=0 Loss=0.34478 Rate=10.10 GlobalRate=10.10 Time=22:58:02\n",
            "| Training Device=xla:0/4 Epoch=168 Step=0 Loss=0.30508 Rate=10.10 GlobalRate=10.10 Time=22:58:02\n",
            "| Training Device=xla:0/1 Epoch=168 Step=0 Loss=0.32814 Rate=10.10 GlobalRate=10.10 Time=22:58:02\n",
            "| Training Device=xla:0/5 Epoch=168 Step=0 Loss=0.28218 Rate=10.10 GlobalRate=10.10 Time=22:58:02\n",
            "| Training Device=xla:1/0 Epoch=168 Step=0 Loss=0.33744 Rate=10.11 GlobalRate=10.11 Time=22:58:02\n",
            "| Training Device=xla:0/7 Epoch=168 Step=0 Loss=0.27878 Rate=10.10 GlobalRate=10.10 Time=22:58:02\n",
            "| Training Device=xla:0/6 Epoch=168 Step=0 Loss=0.39675 Rate=10.10 GlobalRate=10.10 Time=22:58:02\n",
            "Epoch 168 train end 22:58:02\n",
            "Epoch 169 train begin 22:58:02\n",
            "| Training Device=xla:0/5 Epoch=169 Step=0 Loss=0.29891 Rate=10.18 GlobalRate=10.18 Time=22:58:08\n",
            "| Training Device=xla:0/2 Epoch=169 Step=0 Loss=0.25819 Rate=10.18 GlobalRate=10.18 Time=22:58:08\n",
            "| Training Device=xla:0/4 Epoch=169 Step=0 Loss=0.27201 Rate=10.18 GlobalRate=10.18 Time=22:58:08\n",
            "| Training Device=xla:0/6 Epoch=169 Step=0 Loss=0.35963 Rate=10.18 GlobalRate=10.18 Time=22:58:08\n",
            "| Training Device=xla:1/0 Epoch=169 Step=0 Loss=0.36552 Rate=10.18 GlobalRate=10.18 Time=22:58:08\n",
            "| Training Device=xla:0/3 Epoch=169 Step=0 Loss=0.42198 Rate=10.18 GlobalRate=10.18 Time=22:58:08\n",
            "| Training Device=xla:0/7 Epoch=169 Step=0 Loss=0.30700 Rate=10.18 GlobalRate=10.18 Time=22:58:08\n",
            "| Training Device=xla:0/1 Epoch=169 Step=0 Loss=0.31206 Rate=10.18 GlobalRate=10.18 Time=22:58:08\n",
            "Epoch 169 train end 22:58:09\n",
            "Epoch 170 train begin 22:58:09\n",
            "| Training Device=xla:0/1 Epoch=170 Step=0 Loss=0.30114 Rate=10.16 GlobalRate=10.16 Time=22:58:15\n",
            "| Training Device=xla:0/4 Epoch=170 Step=0 Loss=0.31666 Rate=10.16 GlobalRate=10.16 Time=22:58:15\n",
            "| Training Device=xla:0/5 Epoch=170 Step=0 Loss=0.24624 Rate=10.15 GlobalRate=10.15 Time=22:58:15\n",
            "| Training Device=xla:0/2 Epoch=170 Step=0 Loss=0.32360 Rate=10.15 GlobalRate=10.15 Time=22:58:15\n",
            "| Training Device=xla:0/6 Epoch=170 Step=0 Loss=0.34206 Rate=10.16 GlobalRate=10.16 Time=22:58:15\n",
            "| Training Device=xla:0/7 Epoch=170 Step=0 Loss=0.27026 Rate=10.15 GlobalRate=10.15 Time=22:58:15\n",
            "| Training Device=xla:1/0 Epoch=170 Step=0 Loss=0.40863 Rate=10.16 GlobalRate=10.16 Time=22:58:15\n",
            "| Training Device=xla:0/3 Epoch=170 Step=0 Loss=0.39106 Rate=10.15 GlobalRate=10.15 Time=22:58:15\n",
            "Epoch 170 train end 22:58:15\n",
            "Epoch 171 train begin 22:58:15\n",
            "| Training Device=xla:0/3 Epoch=171 Step=0 Loss=0.41449 Rate=10.18 GlobalRate=10.18 Time=22:58:21\n",
            "| Training Device=xla:0/5 Epoch=171 Step=0 Loss=0.25426 Rate=10.18 GlobalRate=10.18 Time=22:58:21\n",
            "| Training Device=xla:0/1 Epoch=171 Step=0 Loss=0.32672 Rate=10.18 GlobalRate=10.18 Time=22:58:21\n",
            "| Training Device=xla:0/7 Epoch=171 Step=0 Loss=0.25851 Rate=10.18 GlobalRate=10.18 Time=22:58:21\n",
            "| Training Device=xla:0/2 Epoch=171 Step=0 Loss=0.30445 Rate=10.18 GlobalRate=10.18 Time=22:58:21\n",
            "| Training Device=xla:0/6 Epoch=171 Step=0 Loss=0.38893 Rate=10.18 GlobalRate=10.18 Time=22:58:21\n",
            "| Training Device=xla:0/4 Epoch=171 Step=0 Loss=0.32423 Rate=10.18 GlobalRate=10.18 Time=22:58:21\n",
            "| Training Device=xla:1/0 Epoch=171 Step=0 Loss=0.35357 Rate=10.19 GlobalRate=10.19 Time=22:58:21\n",
            "Epoch 171 train end 22:58:22\n",
            "Epoch 172 train begin 22:58:22\n",
            "| Training Device=xla:0/3 Epoch=172 Step=0 Loss=0.46030 Rate=10.20 GlobalRate=10.20 Time=22:58:28\n",
            "| Training Device=xla:0/5 Epoch=172 Step=0 Loss=0.33857 Rate=10.20 GlobalRate=10.20 Time=22:58:28\n",
            "| Training Device=xla:0/4 Epoch=172 Step=0 Loss=0.30301 Rate=10.20 GlobalRate=10.20 Time=22:58:28\n",
            "| Training Device=xla:0/1 Epoch=172 Step=0 Loss=0.29337 Rate=10.20 GlobalRate=10.20 Time=22:58:28\n",
            "| Training Device=xla:1/0 Epoch=172 Step=0 Loss=0.35857 Rate=10.20 GlobalRate=10.20 Time=22:58:28\n",
            "| Training Device=xla:0/7 Epoch=172 Step=0 Loss=0.33177 Rate=10.20 GlobalRate=10.20 Time=22:58:28\n",
            "| Training Device=xla:0/6 Epoch=172 Step=0 Loss=0.34215 Rate=10.19 GlobalRate=10.19 Time=22:58:28\n",
            "| Training Device=xla:0/2 Epoch=172 Step=0 Loss=0.28746 Rate=10.19 GlobalRate=10.19 Time=22:58:28\n",
            "Epoch 172 train end 22:58:28\n",
            "Epoch 173 train begin 22:58:28\n",
            "| Training Device=xla:0/3 Epoch=173 Step=0 Loss=0.43916 Rate=10.19 GlobalRate=10.19 Time=22:58:35\n",
            "| Training Device=xla:1/0 Epoch=173 Step=0 Loss=0.34401 Rate=10.19 GlobalRate=10.19 Time=22:58:35\n",
            "| Training Device=xla:0/2 Epoch=173 Step=0 Loss=0.39295 Rate=10.18 GlobalRate=10.18 Time=22:58:35\n",
            "| Training Device=xla:0/5 Epoch=173 Step=0 Loss=0.27158 Rate=10.18 GlobalRate=10.18 Time=22:58:35\n",
            "| Training Device=xla:0/4 Epoch=173 Step=0 Loss=0.27462 Rate=10.18 GlobalRate=10.18 Time=22:58:35\n",
            "| Training Device=xla:0/6 Epoch=173 Step=0 Loss=0.36944 Rate=10.18 GlobalRate=10.18 Time=22:58:35\n",
            "| Training Device=xla:0/1 Epoch=173 Step=0 Loss=0.34800 Rate=10.18 GlobalRate=10.18 Time=22:58:35\n",
            "| Training Device=xla:0/7 Epoch=173 Step=0 Loss=0.31102 Rate=10.18 GlobalRate=10.18 Time=22:58:35\n",
            "Epoch 173 train end 22:58:35\n",
            "Epoch 174 train begin 22:58:35\n",
            "| Training Device=xla:1/0 Epoch=174 Step=0 Loss=0.36051 Rate=10.11 GlobalRate=10.11 Time=22:58:41\n",
            "| Training Device=xla:0/4 Epoch=174 Step=0 Loss=0.37948 Rate=10.11 GlobalRate=10.11 Time=22:58:41\n",
            "| Training Device=xla:0/5 Epoch=174 Step=0 Loss=0.26457 Rate=10.11 GlobalRate=10.11 Time=22:58:41\n",
            "| Training Device=xla:0/3 Epoch=174 Step=0 Loss=0.44687 Rate=10.11 GlobalRate=10.11 Time=22:58:41\n",
            "| Training Device=xla:0/2 Epoch=174 Step=0 Loss=0.31761 Rate=10.10 GlobalRate=10.10 Time=22:58:41\n",
            "| Training Device=xla:0/7 Epoch=174 Step=0 Loss=0.27746 Rate=10.10 GlobalRate=10.10 Time=22:58:41\n",
            "| Training Device=xla:0/6 Epoch=174 Step=0 Loss=0.41678 Rate=10.10 GlobalRate=10.10 Time=22:58:41\n",
            "| Training Device=xla:0/1 Epoch=174 Step=0 Loss=0.32079 Rate=10.10 GlobalRate=10.10 Time=22:58:41\n",
            "Epoch 174 train end 22:58:41\n",
            "Epoch 175 train begin 22:58:41\n",
            "| Training Device=xla:0/5 Epoch=175 Step=0 Loss=0.32215 Rate=10.14 GlobalRate=10.14 Time=22:58:48\n",
            "| Training Device=xla:0/3 Epoch=175 Step=0 Loss=0.42562 Rate=10.14 GlobalRate=10.14 Time=22:58:48\n",
            "| Training Device=xla:0/2 Epoch=175 Step=0 Loss=0.32002 Rate=10.14 GlobalRate=10.14 Time=22:58:48\n",
            "| Training Device=xla:0/7 Epoch=175 Step=0 Loss=0.31281 Rate=10.14 GlobalRate=10.14 Time=22:58:48\n",
            "| Training Device=xla:0/6 Epoch=175 Step=0 Loss=0.39727 Rate=10.14 GlobalRate=10.14 Time=22:58:48\n",
            "| Training Device=xla:1/0 Epoch=175 Step=0 Loss=0.36113 Rate=10.14 GlobalRate=10.14 Time=22:58:48\n",
            "| Training Device=xla:0/4 Epoch=175 Step=0 Loss=0.30262 Rate=10.14 GlobalRate=10.14 Time=22:58:48\n",
            "| Training Device=xla:0/1 Epoch=175 Step=0 Loss=0.30872 Rate=10.14 GlobalRate=10.14 Time=22:58:48\n",
            "Epoch 175 train end 22:58:48\n",
            "Epoch 176 train begin 22:58:48\n",
            "| Training Device=xla:0/5 Epoch=176 Step=0 Loss=0.25943 Rate=10.11 GlobalRate=10.11 Time=22:58:54\n",
            "| Training Device=xla:0/7 Epoch=176 Step=0 Loss=0.28865 Rate=10.11 GlobalRate=10.11 Time=22:58:54\n",
            "| Training Device=xla:0/2 Epoch=176 Step=0 Loss=0.38019 Rate=10.11 GlobalRate=10.11 Time=22:58:54\n",
            "| Training Device=xla:0/1 Epoch=176 Step=0 Loss=0.30381 Rate=10.11 GlobalRate=10.11 Time=22:58:54\n",
            "| Training Device=xla:0/4 Epoch=176 Step=0 Loss=0.31407 Rate=10.11 GlobalRate=10.11 Time=22:58:54\n",
            "| Training Device=xla:0/3 Epoch=176 Step=0 Loss=0.42113 Rate=10.11 GlobalRate=10.11 Time=22:58:54\n",
            "| Training Device=xla:0/6 Epoch=176 Step=0 Loss=0.39749 Rate=10.11 GlobalRate=10.11 Time=22:58:54\n",
            "| Training Device=xla:1/0 Epoch=176 Step=0 Loss=0.35259 Rate=10.12 GlobalRate=10.12 Time=22:58:54\n",
            "Epoch 176 train end 22:58:54\n",
            "Epoch 177 train begin 22:58:54\n",
            "| Training Device=xla:0/3 Epoch=177 Step=0 Loss=0.46714 Rate=10.13 GlobalRate=10.13 Time=22:59:01\n",
            "| Training Device=xla:0/7 Epoch=177 Step=0 Loss=0.28650 Rate=10.13 GlobalRate=10.13 Time=22:59:01\n",
            "| Training Device=xla:0/5 Epoch=177 Step=0 Loss=0.29686 Rate=10.13 GlobalRate=10.13 Time=22:59:01\n",
            "| Training Device=xla:1/0 Epoch=177 Step=0 Loss=0.34911 Rate=10.14 GlobalRate=10.14 Time=22:59:01\n",
            "| Training Device=xla:0/1 Epoch=177 Step=0 Loss=0.29515 Rate=10.13 GlobalRate=10.13 Time=22:59:01\n",
            "| Training Device=xla:0/4 Epoch=177 Step=0 Loss=0.29683 Rate=10.13 GlobalRate=10.13 Time=22:59:01\n",
            "| Training Device=xla:0/2 Epoch=177 Step=0 Loss=0.35317 Rate=10.13 GlobalRate=10.13 Time=22:59:01\n",
            "| Training Device=xla:0/6 Epoch=177 Step=0 Loss=0.41241 Rate=10.13 GlobalRate=10.13 Time=22:59:01\n",
            "Epoch 177 train end 22:59:01\n",
            "Epoch 178 train begin 22:59:01\n",
            "| Training Device=xla:1/0 Epoch=178 Step=0 Loss=0.33240 Rate=10.09 GlobalRate=10.09 Time=22:59:07\n",
            "| Training Device=xla:0/7 Epoch=178 Step=0 Loss=0.31090 Rate=10.09 GlobalRate=10.09 Time=22:59:07\n",
            "| Training Device=xla:0/6 Epoch=178 Step=0 Loss=0.37640 Rate=10.09 GlobalRate=10.09 Time=22:59:07\n",
            "| Training Device=xla:0/2 Epoch=178 Step=0 Loss=0.30857 Rate=10.09 GlobalRate=10.09 Time=22:59:07\n",
            "| Training Device=xla:0/5 Epoch=178 Step=0 Loss=0.29847 Rate=10.09 GlobalRate=10.09 Time=22:59:07\n",
            "| Training Device=xla:0/1 Epoch=178 Step=0 Loss=0.29618 Rate=10.09 GlobalRate=10.09 Time=22:59:07\n",
            "| Training Device=xla:0/4 Epoch=178 Step=0 Loss=0.33234 Rate=10.09 GlobalRate=10.09 Time=22:59:07\n",
            "| Training Device=xla:0/3 Epoch=178 Step=0 Loss=0.40368 Rate=10.09 GlobalRate=10.09 Time=22:59:07\n",
            "Epoch 178 train end 22:59:08\n",
            "Epoch 179 train begin 22:59:08\n",
            "| Training Device=xla:0/5 Epoch=179 Step=0 Loss=0.33407 Rate=10.12 GlobalRate=10.12 Time=22:59:14\n",
            "| Training Device=xla:0/6 Epoch=179 Step=0 Loss=0.43726 Rate=10.12 GlobalRate=10.12 Time=22:59:14\n",
            "| Training Device=xla:0/7 Epoch=179 Step=0 Loss=0.33135 Rate=10.12 GlobalRate=10.12 Time=22:59:14\n",
            "| Training Device=xla:0/3 Epoch=179 Step=0 Loss=0.46760 Rate=10.11 GlobalRate=10.11 Time=22:59:14\n",
            "| Training Device=xla:0/1 Epoch=179 Step=0 Loss=0.30880 Rate=10.11 GlobalRate=10.11 Time=22:59:14\n",
            "| Training Device=xla:0/4 Epoch=179 Step=0 Loss=0.27874 Rate=10.11 GlobalRate=10.11 Time=22:59:14\n",
            "| Training Device=xla:0/2 Epoch=179 Step=0 Loss=0.32073 Rate=10.11 GlobalRate=10.11 Time=22:59:14\n",
            "| Training Device=xla:1/0 Epoch=179 Step=0 Loss=0.31861 Rate=10.12 GlobalRate=10.12 Time=22:59:14\n",
            "Epoch 179 train end 22:59:14\n",
            "Epoch 180 train begin 22:59:14\n",
            "| Training Device=xla:0/1 Epoch=180 Step=0 Loss=0.29938 Rate=10.20 GlobalRate=10.20 Time=22:59:20\n",
            "| Training Device=xla:0/2 Epoch=180 Step=0 Loss=0.31472 Rate=10.20 GlobalRate=10.20 Time=22:59:20\n",
            "| Training Device=xla:0/6 Epoch=180 Step=0 Loss=0.38536 Rate=10.19 GlobalRate=10.19 Time=22:59:20\n",
            "| Training Device=xla:0/7 Epoch=180 Step=0 Loss=0.28278 Rate=10.20 GlobalRate=10.20 Time=22:59:20\n",
            "| Training Device=xla:0/4 Epoch=180 Step=0 Loss=0.31694 Rate=10.19 GlobalRate=10.19 Time=22:59:20\n",
            "| Training Device=xla:0/5 Epoch=180 Step=0 Loss=0.29046 Rate=10.19 GlobalRate=10.19 Time=22:59:20\n",
            "| Training Device=xla:1/0 Epoch=180 Step=0 Loss=0.39510 Rate=10.20 GlobalRate=10.20 Time=22:59:20\n",
            "| Training Device=xla:0/3 Epoch=180 Step=0 Loss=0.43694 Rate=10.19 GlobalRate=10.19 Time=22:59:20\n",
            "Epoch 180 train end 22:59:21\n",
            "Epoch 181 train begin 22:59:21\n",
            "| Training Device=xla:0/3 Epoch=181 Step=0 Loss=0.42876 Rate=10.15 GlobalRate=10.15 Time=22:59:27\n",
            "| Training Device=xla:0/6 Epoch=181 Step=0 Loss=0.38846 Rate=10.15 GlobalRate=10.15 Time=22:59:27\n",
            "| Training Device=xla:0/5 Epoch=181 Step=0 Loss=0.29260 Rate=10.15 GlobalRate=10.15 Time=22:59:27\n",
            "| Training Device=xla:0/1 Epoch=181 Step=0 Loss=0.30775 Rate=10.15 GlobalRate=10.15 Time=22:59:27\n",
            "| Training Device=xla:0/2 Epoch=181 Step=0 Loss=0.33015 Rate=10.15 GlobalRate=10.15 Time=22:59:27\n",
            "| Training Device=xla:0/7 Epoch=181 Step=0 Loss=0.27342 Rate=10.15 GlobalRate=10.15 Time=22:59:27\n",
            "| Training Device=xla:0/4 Epoch=181 Step=0 Loss=0.28882 Rate=10.15 GlobalRate=10.15 Time=22:59:27\n",
            "| Training Device=xla:1/0 Epoch=181 Step=0 Loss=0.38095 Rate=10.16 GlobalRate=10.16 Time=22:59:27\n",
            "Epoch 181 train end 22:59:27\n",
            "Epoch 182 train begin 22:59:27\n",
            "| Training Device=xla:0/5 Epoch=182 Step=0 Loss=0.24849 Rate=10.13 GlobalRate=10.13 Time=22:59:34\n",
            "| Training Device=xla:0/6 Epoch=182 Step=0 Loss=0.41878 Rate=10.12 GlobalRate=10.12 Time=22:59:34\n",
            "| Training Device=xla:0/4 Epoch=182 Step=0 Loss=0.29092 Rate=10.13 GlobalRate=10.13 Time=22:59:34\n",
            "| Training Device=xla:1/0 Epoch=182 Step=0 Loss=0.36997 Rate=10.13 GlobalRate=10.13 Time=22:59:34\n",
            "| Training Device=xla:0/7 Epoch=182 Step=0 Loss=0.27207 Rate=10.13 GlobalRate=10.13 Time=22:59:34\n",
            "| Training Device=xla:0/1 Epoch=182 Step=0 Loss=0.28270 Rate=10.13 GlobalRate=10.13 Time=22:59:34\n",
            "| Training Device=xla:0/3 Epoch=182 Step=0 Loss=0.45178 Rate=10.13 GlobalRate=10.13 Time=22:59:34\n",
            "| Training Device=xla:0/2 Epoch=182 Step=0 Loss=0.31271 Rate=10.12 GlobalRate=10.12 Time=22:59:34\n",
            "Epoch 182 train end 22:59:34\n",
            "Epoch 183 train begin 22:59:34\n",
            "| Training Device=xla:0/5 Epoch=183 Step=0 Loss=0.24256 Rate=10.14 GlobalRate=10.14 Time=22:59:40\n",
            "| Training Device=xla:0/1 Epoch=183 Step=0 Loss=0.33748 Rate=10.14 GlobalRate=10.14 Time=22:59:40\n",
            "| Training Device=xla:0/2 Epoch=183 Step=0 Loss=0.28942 Rate=10.14 GlobalRate=10.14 Time=22:59:40\n",
            "| Training Device=xla:0/6 Epoch=183 Step=0 Loss=0.42780 Rate=10.14 GlobalRate=10.14 Time=22:59:40\n",
            "| Training Device=xla:0/4 Epoch=183 Step=0 Loss=0.34451 Rate=10.14 GlobalRate=10.14 Time=22:59:40\n",
            "| Training Device=xla:1/0 Epoch=183 Step=0 Loss=0.32559 Rate=10.14 GlobalRate=10.14 Time=22:59:40\n",
            "| Training Device=xla:0/3 Epoch=183 Step=0 Loss=0.43687 Rate=10.14 GlobalRate=10.14 Time=22:59:40\n",
            "| Training Device=xla:0/7 Epoch=183 Step=0 Loss=0.29148 Rate=10.14 GlobalRate=10.14 Time=22:59:40\n",
            "Epoch 183 train end 22:59:40\n",
            "Epoch 184 train begin 22:59:40\n",
            "| Training Device=xla:1/0 Epoch=184 Step=0 Loss=0.32396 Rate=10.14 GlobalRate=10.14 Time=22:59:47\n",
            "| Training Device=xla:0/1 Epoch=184 Step=0 Loss=0.33786 Rate=10.13 GlobalRate=10.13 Time=22:59:47\n",
            "| Training Device=xla:0/5 Epoch=184 Step=0 Loss=0.28954 Rate=10.13 GlobalRate=10.13 Time=22:59:47\n",
            "| Training Device=xla:0/6 Epoch=184 Step=0 Loss=0.36558 Rate=10.13 GlobalRate=10.13 Time=22:59:47\n",
            "| Training Device=xla:0/3 Epoch=184 Step=0 Loss=0.42165 Rate=10.13 GlobalRate=10.13 Time=22:59:47\n",
            "| Training Device=xla:0/7 Epoch=184 Step=0 Loss=0.28406 Rate=10.13 GlobalRate=10.13 Time=22:59:47\n",
            "| Training Device=xla:0/4 Epoch=184 Step=0 Loss=0.27541 Rate=10.13 GlobalRate=10.13 Time=22:59:47\n",
            "| Training Device=xla:0/2 Epoch=184 Step=0 Loss=0.29902 Rate=10.13 GlobalRate=10.13 Time=22:59:47\n",
            "Epoch 184 train end 22:59:47\n",
            "Epoch 185 train begin 22:59:47\n",
            "| Training Device=xla:0/2 Epoch=185 Step=0 Loss=0.31810 Rate=10.20 GlobalRate=10.20 Time=22:59:53\n",
            "| Training Device=xla:0/7 Epoch=185 Step=0 Loss=0.30302 Rate=10.20 GlobalRate=10.20 Time=22:59:53\n",
            "| Training Device=xla:0/3 Epoch=185 Step=0 Loss=0.44523 Rate=10.20 GlobalRate=10.20 Time=22:59:53\n",
            "| Training Device=xla:0/1 Epoch=185 Step=0 Loss=0.29700 Rate=10.20 GlobalRate=10.20 Time=22:59:53\n",
            "| Training Device=xla:0/6 Epoch=185 Step=0 Loss=0.40341 Rate=10.20 GlobalRate=10.20 Time=22:59:53\n",
            "| Training Device=xla:0/4 Epoch=185 Step=0 Loss=0.32477 Rate=10.20 GlobalRate=10.20 Time=22:59:53\n",
            "| Training Device=xla:1/0 Epoch=185 Step=0 Loss=0.30432 Rate=10.20 GlobalRate=10.20 Time=22:59:53\n",
            "| Training Device=xla:0/5 Epoch=185 Step=0 Loss=0.30428 Rate=10.20 GlobalRate=10.20 Time=22:59:53\n",
            "Epoch 185 train end 22:59:53\n",
            "Epoch 186 train begin 22:59:53\n",
            "| Training Device=xla:0/6 Epoch=186 Step=0 Loss=0.37217 Rate=10.21 GlobalRate=10.21 Time=23:00:00\n",
            "| Training Device=xla:0/5 Epoch=186 Step=0 Loss=0.28377 Rate=10.21 GlobalRate=10.21 Time=23:00:00\n",
            "| Training Device=xla:1/0 Epoch=186 Step=0 Loss=0.36233 Rate=10.22 GlobalRate=10.22 Time=23:00:00\n",
            "| Training Device=xla:0/3 Epoch=186 Step=0 Loss=0.42828 Rate=10.21 GlobalRate=10.21 Time=23:00:00\n",
            "| Training Device=xla:0/2 Epoch=186 Step=0 Loss=0.29683 Rate=10.21 GlobalRate=10.21 Time=23:00:00\n",
            "| Training Device=xla:0/7 Epoch=186 Step=0 Loss=0.26179 Rate=10.21 GlobalRate=10.21 Time=23:00:00\n",
            "| Training Device=xla:0/4 Epoch=186 Step=0 Loss=0.26458 Rate=10.21 GlobalRate=10.21 Time=23:00:00\n",
            "| Training Device=xla:0/1 Epoch=186 Step=0 Loss=0.34696 Rate=10.21 GlobalRate=10.21 Time=23:00:00\n",
            "Epoch 186 train end 23:00:00\n",
            "Epoch 187 train begin 23:00:00\n",
            "| Training Device=xla:0/6 Epoch=187 Step=0 Loss=0.43118 Rate=10.18 GlobalRate=10.18 Time=23:00:06\n",
            "| Training Device=xla:0/4 Epoch=187 Step=0 Loss=0.33825 Rate=10.18 GlobalRate=10.18 Time=23:00:06\n",
            "| Training Device=xla:0/5 Epoch=187 Step=0 Loss=0.31449 Rate=10.18 GlobalRate=10.18 Time=23:00:06\n",
            "| Training Device=xla:1/0 Epoch=187 Step=0 Loss=0.37167 Rate=10.19 GlobalRate=10.19 Time=23:00:06\n",
            "| Training Device=xla:0/7 Epoch=187 Step=0 Loss=0.28778 Rate=10.18 GlobalRate=10.18 Time=23:00:06\n",
            "| Training Device=xla:0/3 Epoch=187 Step=0 Loss=0.46667 Rate=10.18 GlobalRate=10.18 Time=23:00:06\n",
            "| Training Device=xla:0/2 Epoch=187 Step=0 Loss=0.31420 Rate=10.18 GlobalRate=10.18 Time=23:00:06\n",
            "| Training Device=xla:0/1 Epoch=187 Step=0 Loss=0.31526 Rate=10.18 GlobalRate=10.18 Time=23:00:06\n",
            "Epoch 187 train end 23:00:06\n",
            "Epoch 188 train begin 23:00:06\n",
            "| Training Device=xla:0/3 Epoch=188 Step=0 Loss=0.45686 Rate=9.98 GlobalRate=9.98 Time=23:00:13\n",
            "| Training Device=xla:0/7 Epoch=188 Step=0 Loss=0.26031 Rate=9.98 GlobalRate=9.98 Time=23:00:13\n",
            "| Training Device=xla:0/1 Epoch=188 Step=0 Loss=0.35943 Rate=9.98 GlobalRate=9.98 Time=23:00:13\n",
            "| Training Device=xla:0/5 Epoch=188 Step=0 Loss=0.30287 Rate=9.98 GlobalRate=9.98 Time=23:00:13\n",
            "| Training Device=xla:0/6 Epoch=188 Step=0 Loss=0.40177 Rate=9.98 GlobalRate=9.98 Time=23:00:13\n",
            "| Training Device=xla:0/2 Epoch=188 Step=0 Loss=0.29911 Rate=9.98 GlobalRate=9.98 Time=23:00:13\n",
            "| Training Device=xla:0/4 Epoch=188 Step=0 Loss=0.30820 Rate=9.98 GlobalRate=9.98 Time=23:00:13\n",
            "| Training Device=xla:1/0 Epoch=188 Step=0 Loss=0.35231 Rate=9.98 GlobalRate=9.98 Time=23:00:13\n",
            "Epoch 188 train end 23:00:13\n",
            "Epoch 189 train begin 23:00:13\n",
            "| Training Device=xla:0/4 Epoch=189 Step=0 Loss=0.32077 Rate=10.12 GlobalRate=10.12 Time=23:00:19\n",
            "| Training Device=xla:0/7 Epoch=189 Step=0 Loss=0.31354 Rate=10.12 GlobalRate=10.12 Time=23:00:19\n",
            "| Training Device=xla:0/2 Epoch=189 Step=0 Loss=0.25979 Rate=10.12 GlobalRate=10.12 Time=23:00:19\n",
            "| Training Device=xla:0/6 Epoch=189 Step=0 Loss=0.39956 Rate=10.12 GlobalRate=10.12 Time=23:00:19\n",
            "| Training Device=xla:0/5 Epoch=189 Step=0 Loss=0.30342 Rate=10.12 GlobalRate=10.12 Time=23:00:19\n",
            "| Training Device=xla:1/0 Epoch=189 Step=0 Loss=0.33009 Rate=10.12 GlobalRate=10.12 Time=23:00:19\n",
            "| Training Device=xla:0/3 Epoch=189 Step=0 Loss=0.42126 Rate=10.12 GlobalRate=10.12 Time=23:00:19\n",
            "| Training Device=xla:0/1 Epoch=189 Step=0 Loss=0.35363 Rate=10.12 GlobalRate=10.12 Time=23:00:19\n",
            "Epoch 189 train end 23:00:20\n",
            "Epoch 190 train begin 23:00:20\n",
            "| Training Device=xla:0/1 Epoch=190 Step=0 Loss=0.31953 Rate=10.13 GlobalRate=10.13 Time=23:00:26\n",
            "| Training Device=xla:0/7 Epoch=190 Step=0 Loss=0.30011 Rate=10.13 GlobalRate=10.13 Time=23:00:26\n",
            "| Training Device=xla:0/5 Epoch=190 Step=0 Loss=0.28545 Rate=10.13 GlobalRate=10.13 Time=23:00:26\n",
            "| Training Device=xla:0/4 Epoch=190 Step=0 Loss=0.28708 Rate=10.13 GlobalRate=10.13 Time=23:00:26\n",
            "| Training Device=xla:0/6 Epoch=190 Step=0 Loss=0.36128 Rate=10.13 GlobalRate=10.13 Time=23:00:26\n",
            "| Training Device=xla:0/3 Epoch=190 Step=0 Loss=0.47831 Rate=10.13 GlobalRate=10.13 Time=23:00:26\n",
            "| Training Device=xla:0/2 Epoch=190 Step=0 Loss=0.30864 Rate=10.13 GlobalRate=10.13 Time=23:00:26\n",
            "| Training Device=xla:1/0 Epoch=190 Step=0 Loss=0.41838 Rate=10.14 GlobalRate=10.14 Time=23:00:26\n",
            "Epoch 190 train end 23:00:26\n",
            "Epoch 191 train begin 23:00:26\n",
            "| Training Device=xla:0/1 Epoch=191 Step=0 Loss=0.34090 Rate=10.10 GlobalRate=10.10 Time=23:00:32\n",
            "| Training Device=xla:0/4 Epoch=191 Step=0 Loss=0.29917 Rate=10.10 GlobalRate=10.10 Time=23:00:32\n",
            "| Training Device=xla:0/6 Epoch=191 Step=0 Loss=0.39699 Rate=10.10 GlobalRate=10.10 Time=23:00:32\n",
            "| Training Device=xla:0/2 Epoch=191 Step=0 Loss=0.30960 Rate=10.10 GlobalRate=10.10 Time=23:00:32\n",
            "| Training Device=xla:0/3 Epoch=191 Step=0 Loss=0.42385 Rate=10.10 GlobalRate=10.10 Time=23:00:32\n",
            "| Training Device=xla:0/7 Epoch=191 Step=0 Loss=0.28840 Rate=10.10 GlobalRate=10.10 Time=23:00:32\n",
            "| Training Device=xla:0/5 Epoch=191 Step=0 Loss=0.24633 Rate=10.10 GlobalRate=10.10 Time=23:00:32\n",
            "| Training Device=xla:1/0 Epoch=191 Step=0 Loss=0.37862 Rate=10.10 GlobalRate=10.10 Time=23:00:32\n",
            "Epoch 191 train end 23:00:33\n",
            "Epoch 192 train begin 23:00:33\n",
            "| Training Device=xla:0/7 Epoch=192 Step=0 Loss=0.34273 Rate=10.10 GlobalRate=10.10 Time=23:00:39\n",
            "| Training Device=xla:0/5 Epoch=192 Step=0 Loss=0.30059 Rate=10.10 GlobalRate=10.10 Time=23:00:39\n",
            "| Training Device=xla:0/6 Epoch=192 Step=0 Loss=0.37451 Rate=10.10 GlobalRate=10.10 Time=23:00:39\n",
            "| Training Device=xla:0/1 Epoch=192 Step=0 Loss=0.33213 Rate=10.10 GlobalRate=10.10 Time=23:00:39\n",
            "| Training Device=xla:0/4 Epoch=192 Step=0 Loss=0.28194 Rate=10.10 GlobalRate=10.10 Time=23:00:39\n",
            "| Training Device=xla:0/3 Epoch=192 Step=0 Loss=0.47325 Rate=10.09 GlobalRate=10.09 Time=23:00:39\n",
            "| Training Device=xla:1/0 Epoch=192 Step=0 Loss=0.34756 Rate=10.10 GlobalRate=10.10 Time=23:00:39\n",
            "| Training Device=xla:0/2 Epoch=192 Step=0 Loss=0.29511 Rate=10.10 GlobalRate=10.10 Time=23:00:39\n",
            "Epoch 192 train end 23:00:39\n",
            "Epoch 193 train begin 23:00:39\n",
            "| Training Device=xla:0/7 Epoch=193 Step=0 Loss=0.30873 Rate=10.09 GlobalRate=10.09 Time=23:00:46\n",
            "| Training Device=xla:0/5 Epoch=193 Step=0 Loss=0.32316 Rate=10.09 GlobalRate=10.09 Time=23:00:46\n",
            "| Training Device=xla:1/0 Epoch=193 Step=0 Loss=0.37758 Rate=10.10 GlobalRate=10.10 Time=23:00:46\n",
            "| Training Device=xla:0/4 Epoch=193 Step=0 Loss=0.33224 Rate=10.09 GlobalRate=10.09 Time=23:00:46\n",
            "| Training Device=xla:0/6 Epoch=193 Step=0 Loss=0.39018 Rate=10.09 GlobalRate=10.09 Time=23:00:46\n",
            "| Training Device=xla:0/3 Epoch=193 Step=0 Loss=0.40628 Rate=10.09 GlobalRate=10.09 Time=23:00:46\n",
            "| Training Device=xla:0/1 Epoch=193 Step=0 Loss=0.28317 Rate=10.09 GlobalRate=10.09 Time=23:00:46\n",
            "| Training Device=xla:0/2 Epoch=193 Step=0 Loss=0.32223 Rate=10.09 GlobalRate=10.09 Time=23:00:46\n",
            "Epoch 193 train end 23:00:46\n",
            "Epoch 194 train begin 23:00:46\n",
            "| Training Device=xla:0/3 Epoch=194 Step=0 Loss=0.45770 Rate=10.15 GlobalRate=10.15 Time=23:00:52\n",
            "| Training Device=xla:0/2 Epoch=194 Step=0 Loss=0.34151 Rate=10.15 GlobalRate=10.15 Time=23:00:52\n",
            "| Training Device=xla:0/7 Epoch=194 Step=0 Loss=0.29561 Rate=10.15 GlobalRate=10.15 Time=23:00:52\n",
            "| Training Device=xla:0/6 Epoch=194 Step=0 Loss=0.40622 Rate=10.15 GlobalRate=10.15 Time=23:00:52\n",
            "| Training Device=xla:0/5 Epoch=194 Step=0 Loss=0.24947 Rate=10.15 GlobalRate=10.15 Time=23:00:52\n",
            "| Training Device=xla:1/0 Epoch=194 Step=0 Loss=0.34701 Rate=10.15 GlobalRate=10.15 Time=23:00:52\n",
            "| Training Device=xla:0/4 Epoch=194 Step=0 Loss=0.30766 Rate=10.14 GlobalRate=10.14 Time=23:00:52\n",
            "| Training Device=xla:0/1 Epoch=194 Step=0 Loss=0.35529 Rate=10.14 GlobalRate=10.14 Time=23:00:52\n",
            "Epoch 194 train end 23:00:52\n",
            "Epoch 195 train begin 23:00:52\n",
            "| Training Device=xla:1/0 Epoch=195 Step=0 Loss=0.33148 Rate=10.18 GlobalRate=10.18 Time=23:00:59\n",
            "| Training Device=xla:0/2 Epoch=195 Step=0 Loss=0.32822 Rate=10.17 GlobalRate=10.17 Time=23:00:59\n",
            "| Training Device=xla:0/6 Epoch=195 Step=0 Loss=0.44715 Rate=10.17 GlobalRate=10.17 Time=23:00:59\n",
            "| Training Device=xla:0/1 Epoch=195 Step=0 Loss=0.34210 Rate=10.17 GlobalRate=10.17 Time=23:00:59\n",
            "| Training Device=xla:0/7 Epoch=195 Step=0 Loss=0.25470 Rate=10.17 GlobalRate=10.17 Time=23:00:59\n",
            "| Training Device=xla:0/4 Epoch=195 Step=0 Loss=0.26871 Rate=10.17 GlobalRate=10.17 Time=23:00:59\n",
            "| Training Device=xla:0/3 Epoch=195 Step=0 Loss=0.39266 Rate=10.17 GlobalRate=10.17 Time=23:00:59\n",
            "| Training Device=xla:0/5 Epoch=195 Step=0 Loss=0.26704 Rate=10.17 GlobalRate=10.17 Time=23:00:59\n",
            "Epoch 195 train end 23:00:59\n",
            "Epoch 196 train begin 23:00:59\n",
            "| Training Device=xla:0/6 Epoch=196 Step=0 Loss=0.36966 Rate=10.05 GlobalRate=10.05 Time=23:01:05\n",
            "| Training Device=xla:0/3 Epoch=196 Step=0 Loss=0.45307 Rate=10.06 GlobalRate=10.06 Time=23:01:05\n",
            "| Training Device=xla:0/5 Epoch=196 Step=0 Loss=0.27046 Rate=10.06 GlobalRate=10.06 Time=23:01:05\n",
            "| Training Device=xla:0/7 Epoch=196 Step=0 Loss=0.30982 Rate=10.06 GlobalRate=10.06 Time=23:01:05\n",
            "| Training Device=xla:0/1 Epoch=196 Step=0 Loss=0.32394 Rate=10.05 GlobalRate=10.05 Time=23:01:05\n",
            "| Training Device=xla:0/4 Epoch=196 Step=0 Loss=0.29952 Rate=10.05 GlobalRate=10.05 Time=23:01:05\n",
            "| Training Device=xla:0/2 Epoch=196 Step=0 Loss=0.29481 Rate=10.05 GlobalRate=10.05 Time=23:01:05\n",
            "| Training Device=xla:1/0 Epoch=196 Step=0 Loss=0.34864 Rate=10.06 GlobalRate=10.06 Time=23:01:05\n",
            "Epoch 196 train end 23:01:06\n",
            "Epoch 197 train begin 23:01:06\n",
            "| Training Device=xla:0/5 Epoch=197 Step=0 Loss=0.29010 Rate=10.19 GlobalRate=10.19 Time=23:01:12\n",
            "| Training Device=xla:0/2 Epoch=197 Step=0 Loss=0.30292 Rate=10.19 GlobalRate=10.19 Time=23:01:12\n",
            "| Training Device=xla:1/0 Epoch=197 Step=0 Loss=0.33383 Rate=10.19 GlobalRate=10.19 Time=23:01:12\n",
            "| Training Device=xla:0/1 Epoch=197 Step=0 Loss=0.28762 Rate=10.19 GlobalRate=10.19 Time=23:01:12\n",
            "| Training Device=xla:0/7 Epoch=197 Step=0 Loss=0.30727 Rate=10.19 GlobalRate=10.19 Time=23:01:12\n",
            "| Training Device=xla:0/4 Epoch=197 Step=0 Loss=0.30701 Rate=10.19 GlobalRate=10.19 Time=23:01:12\n",
            "| Training Device=xla:0/6 Epoch=197 Step=0 Loss=0.36149 Rate=10.19 GlobalRate=10.19 Time=23:01:12\n",
            "| Training Device=xla:0/3 Epoch=197 Step=0 Loss=0.40647 Rate=10.19 GlobalRate=10.19 Time=23:01:12\n",
            "Epoch 197 train end 23:01:12\n",
            "Epoch 198 train begin 23:01:12\n",
            "| Training Device=xla:0/7 Epoch=198 Step=0 Loss=0.27441 Rate=10.10 GlobalRate=10.10 Time=23:01:18\n",
            "| Training Device=xla:0/3 Epoch=198 Step=0 Loss=0.36726 Rate=10.10 GlobalRate=10.10 Time=23:01:18\n",
            "| Training Device=xla:0/4 Epoch=198 Step=0 Loss=0.29326 Rate=10.11 GlobalRate=10.11 Time=23:01:18\n",
            "| Training Device=xla:0/2 Epoch=198 Step=0 Loss=0.30820 Rate=10.10 GlobalRate=10.10 Time=23:01:18\n",
            "| Training Device=xla:1/0 Epoch=198 Step=0 Loss=0.37809 Rate=10.11 GlobalRate=10.11 Time=23:01:18\n",
            "| Training Device=xla:0/5 Epoch=198 Step=0 Loss=0.28904 Rate=10.10 GlobalRate=10.10 Time=23:01:18\n",
            "| Training Device=xla:0/1 Epoch=198 Step=0 Loss=0.34453 Rate=10.10 GlobalRate=10.10 Time=23:01:18\n",
            "| Training Device=xla:0/6 Epoch=198 Step=0 Loss=0.43831 Rate=10.10 GlobalRate=10.10 Time=23:01:18\n",
            "Epoch 198 train end 23:01:19\n",
            "Epoch 199 train begin 23:01:19\n",
            "| Training Device=xla:0/4 Epoch=199 Step=0 Loss=0.34121 Rate=10.05 GlobalRate=10.05 Time=23:01:25\n",
            "| Training Device=xla:0/1 Epoch=199 Step=0 Loss=0.34226 Rate=10.05 GlobalRate=10.05 Time=23:01:25\n",
            "| Training Device=xla:0/3 Epoch=199 Step=0 Loss=0.47711 Rate=10.05 GlobalRate=10.05 Time=23:01:25\n",
            "| Training Device=xla:0/2 Epoch=199 Step=0 Loss=0.38304 Rate=10.05 GlobalRate=10.05 Time=23:01:25\n",
            "| Training Device=xla:0/5 Epoch=199 Step=0 Loss=0.35616 Rate=10.05 GlobalRate=10.05 Time=23:01:25\n",
            "| Training Device=xla:0/6 Epoch=199 Step=0 Loss=0.40336 Rate=10.05 GlobalRate=10.05 Time=23:01:25\n",
            "| Training Device=xla:0/7 Epoch=199 Step=0 Loss=0.32254 Rate=10.05 GlobalRate=10.05 Time=23:01:25\n",
            "| Training Device=xla:1/0 Epoch=199 Step=0 Loss=0.35605 Rate=10.06 GlobalRate=10.06 Time=23:01:25\n",
            "Epoch 199 train end 23:01:25\n",
            "Epoch 200 train begin 23:01:25\n",
            "| Training Device=xla:0/3 Epoch=200 Step=0 Loss=0.43378 Rate=10.08 GlobalRate=10.08 Time=23:01:32\n",
            "| Training Device=xla:0/4 Epoch=200 Step=0 Loss=0.29298 Rate=10.08 GlobalRate=10.08 Time=23:01:32\n",
            "| Training Device=xla:0/5 Epoch=200 Step=0 Loss=0.32368 Rate=10.08 GlobalRate=10.08 Time=23:01:32\n",
            "| Training Device=xla:0/7 Epoch=200 Step=0 Loss=0.29176 Rate=10.08 GlobalRate=10.08 Time=23:01:32\n",
            "| Training Device=xla:0/6 Epoch=200 Step=0 Loss=0.36441 Rate=10.08 GlobalRate=10.08 Time=23:01:32\n",
            "| Training Device=xla:0/1 Epoch=200 Step=0 Loss=0.31378 Rate=10.08 GlobalRate=10.08 Time=23:01:32\n",
            "| Training Device=xla:0/2 Epoch=200 Step=0 Loss=0.31432 Rate=10.08 GlobalRate=10.08 Time=23:01:32\n",
            "| Training Device=xla:1/0 Epoch=200 Step=0 Loss=0.38923 Rate=10.09 GlobalRate=10.09 Time=23:01:32\n",
            "Epoch 200 train end 23:01:32\n",
            "Finished training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJB7S4MlSCHr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJm4ZDyVSD7z"
      },
      "source": [
        "## Test SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BeMrdacT6c9"
      },
      "source": [
        "device = xm.xla_device()\n",
        "model = get_model_property('model_fn')().to(device)\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 512),\n",
        "    nn.Linear(512, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b7voDQHT_dO"
      },
      "source": [
        "state_dict = xser.load('/content/drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR-Finetuned-Test-{}.pt'.format(LABELED))\n",
        "#state_dict = xser.load('/content/drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR-Finetuned-Test.pt')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ0t8T0EUAQR",
        "outputId": "81fa14db-2035-4279-f088-c0d67965cb52"
      },
      "source": [
        "state_dict.keys()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.0.weight', 'fc.0.bias', 'fc.1.weight', 'fc.1.bias'])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7mSzyjETOtu"
      },
      "source": [
        "for k in list(state_dict.keys()):\n",
        "    if k.startswith('backbone.'):\n",
        "        if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "            # remove prefix\n",
        "            state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "del state_dict[k]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC-x2AVGTl0r"
      },
      "source": [
        "log = model.load_state_dict(state_dict, strict=False)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFaRBi4xTre5",
        "outputId": "44139709-8d1b-463f-b880-d855e6a59255"
      },
      "source": [
        "log"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['fc.1.bias'], unexpected_keys=[])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GHP7D0VSCom"
      },
      "source": [
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftq2MFAHSFjS"
      },
      "source": [
        "test_data = {\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\",\n",
        "    \"messidor2\": \"https://drive.google.com/uc?id=1HaUAxDtN4BNj0hpH8QYGmiX39Va-Ke8p\",\n",
        "}\n",
        "\n",
        "TEST_DATASET = 'messidor2'\n",
        "URL_TEST_DATASET = test_data[TEST_DATASET]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m1XHql2SKTw",
        "outputId": "d573dd4c-c7f2-4870-fb51-ec5f78db78bb"
      },
      "source": [
        "!gdown $URL_TEST_DATASET"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HaUAxDtN4BNj0hpH8QYGmiX39Va-Ke8p\n",
            "To: /content/messidor2.zip\n",
            "106MB [00:00, 229MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5ZUz1-WSMWB"
      },
      "source": [
        "local_zip = '{}.zip'.format(TEST_DATASET)\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWAX0N6hSOx9"
      },
      "source": [
        "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
        "cifar10_std = (0.2471, 0.2435, 0.2616)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZfoKcb-SQsO"
      },
      "source": [
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=cifar10_mean, std=cifar10_std)  # What happens if I change This \n",
        "])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A7qhuYFSRsE"
      },
      "source": [
        "test_dataset = datasets.ImageFolder(root=\"messidor2\", transform=transform_val) # root: test/messidor2"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsuwZuBpSTC1"
      },
      "source": [
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    num_workers=1,\n",
        "    shuffle=False)\n",
        "\n",
        "loader = test_loader"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGMMogMMSaL_",
        "outputId": "9d6cb870-bc16-482f-cf45-a6e35e8f383a"
      },
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    with tqdm(total=len(loader)) as pbar:\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "\n",
        "            output = output.to(device)\n",
        "\n",
        "            # Yo le agrege esto\n",
        "            y_true.append(targets.cpu().detach().numpy()[0])\n",
        "            y_pred.append(output.cpu().detach().numpy()[0][0])\n",
        "\n",
        "            pbar.update(1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1748/1748 [01:06<00:00, 26.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBmiwR_MVmnw",
        "outputId": "691699a2-9437-4ad6-c6d0-70730a2055a4"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
        "metrics.auc(fpr, tpr)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8473607263773467"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "90LPlaoWVo9K",
        "outputId": "66897c1f-0315-451e-ddd1-30a65fb42e67"
      },
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from mlxtend.plotting import plot_confusion_matrix \n",
        "# %matplotlib inline\n",
        "\n",
        "#cm=metrics.confusion_matrix(y_true, y_pred)\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "#print('AUC: %.3f' % auc)\n",
        "#print('Accuracy: {}'.format(accuracy_score(y_true, y_pred)))\n",
        "\n",
        "# Plot ROC curve\n",
        "lw = 2\n",
        "sns.set_style({'axes.grid' : False})\n",
        "sns.set_style(\"darkgrid\")\n",
        "ax1 = sns.lineplot(fpr, tpr, color='darkorange',\n",
        "        lw=lw, label='AUC = %0.2f' % auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "ax1.set_title('Receiver operating characteristic')\n",
        "ax1.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbIQBHZuhg4s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}