{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PAWS_DR_V3.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsj3PQnWbL6G",
        "outputId": "7ca9d21e-dd34-4175-9932-32155d8758b8"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install --quiet -v --no-cache-dir ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8054, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 8054 (delta 68), reused 97 (delta 44), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8054/8054), 14.11 MiB | 26.96 MiB/s, done.\n",
            "Resolving deltas: 100% (5467/5467), done.\n",
            "/content/apex\n",
            "Processing /content/apex\n",
            "Building wheels for collected packages: apex\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp37-none-any.whl size=204709 sha256=a532fb26c1bcef2c3e2b7d49101e9cf04c4ea76d175870c556a2e8550f22e4b7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8om69unv/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "Successfully installed apex-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRMdV8mzcyku",
        "outputId": "fdd1547d-c74d-48e6-90d4-3c4fcc16361b"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3c8kaoBc2AO",
        "outputId": "92f4a46b-ccae-4c9f-ba93-c82995d369b0"
      },
      "source": [
        "!pip install -U PyYAML"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyYAML\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\r\u001b[K     |▌                               | 10kB 22.5MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 15.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 12.8MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 12.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 7.3MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 9.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 593kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 7.1MB/s \n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKgD9nsOc2HR",
        "outputId": "5d226cf9-3f9d-4462-9601-1db6e589ac46"
      },
      "source": [
        "!git clone -b feature/DR-images https://github.com/jmarrietar/suncet.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'suncet'...\n",
            "remote: Enumerating objects: 231, done.\u001b[K\n",
            "remote: Counting objects: 100% (231/231), done.\u001b[K\n",
            "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
            "remote: Total 231 (delta 127), reused 179 (delta 82), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (231/231), 1.09 MiB | 18.61 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPKZy3pFc2Jt",
        "outputId": "3e6732dd-e442-4ea5-9d07-b17c9da9e795"
      },
      "source": [
        "cd suncet"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VJRZRwCc2ME"
      },
      "source": [
        "!mkdir datasets"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qo6F2Y8c2Om"
      },
      "source": [
        "!mkdir datasets/dr"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqve6pwuc2RO"
      },
      "source": [
        "!mkdir logs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teZBPPTJc_od",
        "outputId": "2ff2211d-520c-467f-dbfd-8e7d91f3ce63"
      },
      "source": [
        "!python download.py -d sample@1000"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\n",
            "To: /content/suncet/datasets/dr/sample@1000.zip\n",
            "108MB [00:00, 125MB/s]  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNiNlWH1dDgN"
      },
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import os\n",
        "\n",
        "# -- FOR DISTRIBUTED TRAINING ENSURE ONLY 1 DEVICE VISIBLE PER PROCESS\n",
        "try:\n",
        "    # -- WARNING: IF DOING DISTRIBUTED TRAINING ON A NON-SLURM CLUSTER, MAKE\n",
        "    # --          SURE TO UPDATE THIS TO GET LOCAL-RANK ON NODE, OR ENSURE\n",
        "    # --          THAT YOUR JOBS ARE LAUNCHED WITH ONLY 1 DEVICE VISIBLE\n",
        "    # --          TO EACH PROCESS\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['SLURM_LOCALID']\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    gpu_timer,\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule,\n",
        "    CSVLogger,\n",
        "    AverageMeter\n",
        ")\n",
        "from src.losses import (\n",
        "    init_simclr_loss,\n",
        "    init_suncet_loss,\n",
        "    make_labels_matrix\n",
        ")\n",
        "from src.data_manager import (\n",
        "    init_data,\n",
        "    make_transforms\n",
        ")\n",
        "from src.sgd import SGD\n",
        "from src.lars import LARS\n",
        "\n",
        "import apex\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "import argparse\n",
        "\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "import pprint\n",
        "import yaml\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOui0vSWdIe_",
        "outputId": "22595ef4-0a06-4b50-81de-7ee98a97f912"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    '--fname', type=str,\n",
        "    help='name of config file to load',\n",
        "    default='configs.yaml')\n",
        "parser.add_argument(\n",
        "    '--devices', type=str, nargs='+', default=['cuda:0'],\n",
        "    help='which devices to use on local machine')\n",
        "parser.add_argument(\n",
        "    '--sel', type=str,\n",
        "    help='which script to run',\n",
        "    choices=[\n",
        "        'paws_train',\n",
        "        'suncet_train',\n",
        "        'fine_tune',\n",
        "        'snn_fine_tune'\n",
        "    ])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--sel'], dest='sel', nargs=None, const=None, default=None, type=<class 'str'>, choices=['paws_train', 'suncet_train', 'fine_tune', 'snn_fine_tune'], help='which script to run', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpAUW9rudKAP"
      },
      "source": [
        "args = parser.parse_args(['--sel', 'paws_train',\n",
        "                          '--fname', 'configs/paws/dr_train.yaml'\n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLS5r_YwdKDp"
      },
      "source": [
        "fname = args.fname\n",
        "sel = args.sel"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErBZ_ppldKGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499e9a28-c72f-468b-dfbe-9c638f1897b0"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "\n",
        "logger.info(f'called-params {sel} {fname}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:called-params paws_train configs/paws/dr_train.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shYBn8CxdnDp"
      },
      "source": [
        "rank = 0"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90hq9Y4Fdnwm",
        "outputId": "190a9df4-5367-4b3e-d2f0-9aa4eada5967"
      },
      "source": [
        "# -- load script params\n",
        "params = None\n",
        "with open(fname, 'r') as y_file:\n",
        "    params = yaml.load(y_file, Loader=yaml.FullLoader)\n",
        "    logger.info('loaded params...')\n",
        "    if rank == 0:\n",
        "        pp = pprint.PrettyPrinter(indent=4)\n",
        "        pp.pprint(params)\n",
        "\n",
        "if rank == 0:\n",
        "    dump = os.path.join(params['logging']['folder'], f'params-{sel}.yaml')\n",
        "    with open(dump, 'w') as f:\n",
        "        yaml.dump(params, f)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:loaded params...\n",
            "{   'criterion': {   'classes_per_batch': 2,\n",
            "                     'me_max': True,\n",
            "                     'sharpen': 0.25,\n",
            "                     'supervised_imgs_per_class': 32,\n",
            "                     'supervised_views': 1,\n",
            "                     'temperature': 0.1,\n",
            "                     'unsupervised_batch_size': 32},\n",
            "    'data': {   'color_jitter_strength': 1.0,\n",
            "                'data_seed': None,\n",
            "                'dataset': 'dr',\n",
            "                'image_folder': 'dr/sample@1000/',\n",
            "                'label_smoothing': 0.1,\n",
            "                'multicrop': 6,\n",
            "                'normalize': True,\n",
            "                'root_path': 'datasets/',\n",
            "                'subset_path': 'dr_subsets',\n",
            "                'unique_classes_per_rank': False,\n",
            "                'unlabeled_frac': 0.9},\n",
            "    'logging': {'folder': 'logs/', 'write_tag': 'paws'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'model_name': 'resnet50',\n",
            "                'output_dim': 2048,\n",
            "                'read_checkpoint': None,\n",
            "                'use_fp16': True,\n",
            "                'use_pred_head': True},\n",
            "    'optimization': {   'epochs': 10,\n",
            "                        'final_lr': 0.064,\n",
            "                        'lr': 6.4,\n",
            "                        'momentum': 0.9,\n",
            "                        'nesterov': False,\n",
            "                        'start_lr': 0.3,\n",
            "                        'warmup': 10,\n",
            "                        'weight_decay': 1e-06}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGeeFcYcdrN-"
      },
      "source": [
        "args = params"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wxbn1W_drTl"
      },
      "source": [
        "def init_model(\n",
        "    device,\n",
        "    model_name='resnet50',\n",
        "    use_pred=False,\n",
        "    output_dim=128\n",
        "):\n",
        "    if 'wide_resnet' in model_name:\n",
        "        encoder = wide_resnet.__dict__[model_name](dropout_rate=0.0)\n",
        "        hidden_dim = 128\n",
        "    else:\n",
        "        encoder = resnet.__dict__[model_name]()\n",
        "        hidden_dim = 2048\n",
        "        if 'w2' in model_name:\n",
        "            hidden_dim *= 2\n",
        "        elif 'w4' in model_name:\n",
        "            hidden_dim *= 4\n",
        "\n",
        "    # -- projection head\n",
        "    encoder.fc = torch.nn.Sequential(OrderedDict([\n",
        "        ('fc1', torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "        ('bn1', torch.nn.BatchNorm1d(hidden_dim)),\n",
        "        ('relu1', torch.nn.ReLU(inplace=True)),\n",
        "        ('fc2', torch.nn.Linear(hidden_dim, hidden_dim)),\n",
        "        ('bn2', torch.nn.BatchNorm1d(hidden_dim)),\n",
        "        ('relu2', torch.nn.ReLU(inplace=True)),\n",
        "        ('fc3', torch.nn.Linear(hidden_dim, output_dim))\n",
        "    ]))\n",
        "\n",
        "    # -- prediction head\n",
        "    encoder.pred = None\n",
        "    if use_pred:\n",
        "        mx = 4  # 4x bottleneck prediction head\n",
        "        pred_head = OrderedDict([])\n",
        "        pred_head['bn1'] = torch.nn.BatchNorm1d(output_dim)\n",
        "        pred_head['fc1'] = torch.nn.Linear(output_dim, output_dim//mx)\n",
        "        pred_head['bn2'] = torch.nn.BatchNorm1d(output_dim//mx)\n",
        "        pred_head['relu'] = torch.nn.ReLU(inplace=True)\n",
        "        pred_head['fc2'] = torch.nn.Linear(output_dim//mx, output_dim)\n",
        "        encoder.pred = torch.nn.Sequential(pred_head)\n",
        "\n",
        "    encoder.to(device)\n",
        "    logger.info(encoder)\n",
        "    return encoder"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OHC8OIOdrXm"
      },
      "source": [
        "def init_opt(\n",
        "    encoder,\n",
        "    iterations_per_epoch,\n",
        "    start_lr,\n",
        "    ref_lr,\n",
        "    ref_mom,\n",
        "    nesterov,\n",
        "    warmup,\n",
        "    num_epochs,\n",
        "    weight_decay=1e-6,\n",
        "    final_lr=0.0\n",
        "):\n",
        "    param_groups = [\n",
        "        {'params': (p for n, p in encoder.named_parameters()\n",
        "                    if ('bias' not in n) and ('bn' not in n))},\n",
        "        {'params': (p for n, p in encoder.named_parameters()\n",
        "                    if ('bias' in n) or ('bn' in n)),\n",
        "         'LARS_exclude': True,\n",
        "         'weight_decay': 0}\n",
        "    ]\n",
        "    optimizer = SGD(\n",
        "        param_groups,\n",
        "        weight_decay=weight_decay,\n",
        "        momentum=0.9,\n",
        "        nesterov=nesterov,\n",
        "        lr=ref_lr)\n",
        "    scheduler = WarmupCosineSchedule(\n",
        "        optimizer,\n",
        "        warmup_steps=warmup*iterations_per_epoch,\n",
        "        start_lr=start_lr,\n",
        "        ref_lr=ref_lr,\n",
        "        final_lr=final_lr,\n",
        "        T_max=num_epochs*iterations_per_epoch)\n",
        "    optimizer = LARS(optimizer, trust_coefficient=0.001)\n",
        "    return encoder, optimizer, scheduler"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s68hN9YdxF4"
      },
      "source": [
        "import os\n",
        "\n",
        "# -- FOR DISTRIBUTED TRAINING ENSURE ONLY 1 DEVICE VISIBLE PER PROCESS\n",
        "try:\n",
        "    # -- WARNING: IF DOING DISTRIBUTED TRAINING ON A NON-SLURM CLUSTER, MAKE\n",
        "    # --          SURE TO UPDATE THIS TO GET LOCAL-RANK ON NODE, OR ENSURE\n",
        "    # --          THAT YOUR JOBS ARE LAUNCHED WITH ONLY 1 DEVICE VISIBLE\n",
        "    # --          TO EACH PROCESS\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['SLURM_LOCALID']\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "import src.resnet as resnet\n",
        "import src.wide_resnet as wide_resnet\n",
        "from src.utils import (\n",
        "    gpu_timer,\n",
        "    init_distributed,\n",
        "    WarmupCosineSchedule,\n",
        "    CSVLogger,\n",
        "    AverageMeter\n",
        ")\n",
        "from src.losses import (\n",
        "    init_paws_loss,\n",
        "    make_labels_matrix\n",
        ")\n",
        "from src.data_manager import (\n",
        "    init_data,\n",
        "    make_transforms,\n",
        "    make_multicrop_transform\n",
        ")\n",
        "from src.sgd import SGD\n",
        "from src.lars import LARS\n",
        "\n",
        "import apex\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "\n",
        "# --\n",
        "log_timings = True\n",
        "log_freq = 10\n",
        "checkpoint_freq = 50\n",
        "# --\n",
        "\n",
        "_GLOBAL_SEED = 0\n",
        "np.random.seed(_GLOBAL_SEED)\n",
        "torch.manual_seed(_GLOBAL_SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logger = logging.getLogger()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RRx0qzXdzxv"
      },
      "source": [
        "# ----------------------------------------------------------------------- #\n",
        "#  PASSED IN PARAMS FROM CONFIG FILE\n",
        "# ----------------------------------------------------------------------- #\n",
        "# -- META\n",
        "model_name = args['meta']['model_name']\n",
        "output_dim = args['meta']['output_dim']\n",
        "load_model = args['meta']['load_checkpoint']\n",
        "r_file = args['meta']['read_checkpoint']\n",
        "copy_data = args['meta']['copy_data']\n",
        "use_fp16 = args['meta']['use_fp16']\n",
        "use_pred_head = args['meta']['use_pred_head']\n",
        "device = torch.device(args['meta']['device'])\n",
        "torch.cuda.set_device(device)\n",
        "\n",
        "# -- CRITERTION\n",
        "reg = args['criterion']['me_max']\n",
        "supervised_views = args['criterion']['supervised_views']\n",
        "classes_per_batch = args['criterion']['classes_per_batch']\n",
        "s_batch_size = args['criterion']['supervised_imgs_per_class']\n",
        "u_batch_size = args['criterion']['unsupervised_batch_size']\n",
        "temperature = args['criterion']['temperature']\n",
        "sharpen = args['criterion']['sharpen']\n",
        "\n",
        "# -- DATA\n",
        "unlabeled_frac = args['data']['unlabeled_frac']\n",
        "color_jitter = args['data']['color_jitter_strength']\n",
        "normalize = args['data']['normalize']\n",
        "root_path = args['data']['root_path']\n",
        "image_folder = args['data']['image_folder']\n",
        "dataset_name = args['data']['dataset']\n",
        "subset_path = args['data']['subset_path']\n",
        "unique_classes = args['data']['unique_classes_per_rank']\n",
        "multicrop = args['data']['multicrop']\n",
        "label_smoothing = args['data']['label_smoothing']\n",
        "data_seed = None\n",
        "if 'cifar10' in dataset_name:\n",
        "    data_seed = args['data']['data_seed']\n",
        "    crop_scale = (0.75, 1.0) if multicrop > 0 else (0.5, 1.0)\n",
        "    mc_scale = (0.3, 0.75)\n",
        "    mc_size = 18\n",
        "else:\n",
        "    crop_scale = (0.14, 1.0) if multicrop > 0 else (0.08, 1.0)\n",
        "    mc_scale = (0.05, 0.14)\n",
        "    mc_size = 96"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI1GmgZjdz8h"
      },
      "source": [
        "world_size = 1\n",
        "rank = 0 "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOYd12kIefxF"
      },
      "source": [
        "# -- OPTIMIZATION\n",
        "wd = float(args['optimization']['weight_decay'])\n",
        "num_epochs = args['optimization']['epochs']\n",
        "warmup = args['optimization']['warmup']\n",
        "start_lr = args['optimization']['start_lr']\n",
        "lr = args['optimization']['lr']\n",
        "final_lr = args['optimization']['final_lr']\n",
        "mom = args['optimization']['momentum']\n",
        "nesterov = args['optimization']['nesterov']\n",
        "\n",
        "# -- LOGGING\n",
        "folder = args['logging']['folder']\n",
        "tag = args['logging']['write_tag']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MdFJ7wbem4L"
      },
      "source": [
        "# -- log/checkpointing paths\n",
        "log_file = os.path.join(folder, f'{tag}_r{rank}.csv')\n",
        "save_path = os.path.join(folder, f'{tag}' + '-ep{epoch}.pth.tar')\n",
        "latest_path = os.path.join(folder, f'{tag}-latest.pth.tar')\n",
        "best_path = os.path.join(folder, f'{tag}' + '-best.pth.tar')\n",
        "load_path = None\n",
        "if load_model:\n",
        "    load_path = os.path.join(folder, r_file) if r_file is not None else latest_path"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or6hmGnqem6Z"
      },
      "source": [
        "# -- make csv_logger\n",
        "csv_logger = CSVLogger(log_file,\n",
        "                        ('%d', 'epoch'),\n",
        "                        ('%d', 'itr'),\n",
        "                        ('%.5f', 'paws-xent-loss'),\n",
        "                        ('%.5f', 'paws-me_max-reg'),\n",
        "                        ('%d', 'time (ms)'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeVfgaW-em9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731ed00e-91af-422a-da95-036035f86ef4"
      },
      "source": [
        "# -- init model\n",
        "encoder = init_model(\n",
        "    device=device,\n",
        "    model_name=model_name,\n",
        "    use_pred=use_pred_head,\n",
        "    output_dim=output_dim)\n",
        "if world_size > 1:\n",
        "    process_group = apex.parallel.create_syncbn_process_group(0)\n",
        "    encoder = apex.parallel.convert_syncbn_model(encoder, process_group=process_group)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "    (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu1): ReLU(inplace=True)\n",
            "    (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "    (bn2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu2): ReLU(inplace=True)\n",
            "    (fc3): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "  )\n",
            "  (pred): Sequential(\n",
            "    (bn1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
            "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (fc2): Linear(in_features=512, out_features=2048, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJrCIwfAdz_A"
      },
      "source": [
        "# -- init losses\n",
        "paws = init_paws_loss(\n",
        "    multicrop=multicrop,\n",
        "    tau=temperature,\n",
        "    T=sharpen,\n",
        "    me_max=reg)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XFQuyTker2M"
      },
      "source": [
        "# -- assume support images are sampled with ClassStratifiedSampler\n",
        "labels_matrix = make_labels_matrix(\n",
        "    num_classes=classes_per_batch,\n",
        "    s_batch_size=s_batch_size,\n",
        "    world_size=world_size,\n",
        "    device=device,\n",
        "    unique_classes=unique_classes,\n",
        "    smoothing=label_smoothing)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuBoPOfaer5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b7b1f4-5b35-4edb-d376-97a9d09f12e6"
      },
      "source": [
        "# -- make data transforms\n",
        "transform, init_transform = make_transforms(\n",
        "    dataset_name=dataset_name,\n",
        "    subset_path=subset_path,\n",
        "    unlabeled_frac=unlabeled_frac,\n",
        "    training=True,\n",
        "    split_seed=data_seed,\n",
        "    crop_scale=crop_scale,\n",
        "    basic_augmentations=False,\n",
        "    color_jitter=color_jitter,\n",
        "    normalize=normalize)\n",
        "multicrop_transform = (multicrop, None)\n",
        "if multicrop > 0:\n",
        "    multicrop_transform = make_multicrop_transform(\n",
        "            dataset_name=dataset_name,\n",
        "            num_crops=multicrop,\n",
        "            size=mc_size,\n",
        "            crop_scale=mc_scale,\n",
        "            normalize=normalize,\n",
        "            color_distortion=color_jitter)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:making imagenet data transforms\n",
            "INFO:root:keep file: dr_subsets/90percent.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvJW6B4_er-N",
        "outputId": "27b8b917-0ddc-4c29-c8f1-9c94e6008a1a"
      },
      "source": [
        "# -- init data-loaders/samplers\n",
        "(unsupervised_loader,\n",
        "    unsupervised_sampler,\n",
        "    supervised_loader,\n",
        "    supervised_sampler) = init_data(\n",
        "        dataset_name=dataset_name,\n",
        "        transform=transform,\n",
        "        init_transform=init_transform,\n",
        "        supervised_views=supervised_views,\n",
        "        u_batch_size=u_batch_size,\n",
        "        s_batch_size=s_batch_size,\n",
        "        unique_classes=unique_classes,\n",
        "        classes_per_batch=classes_per_batch,\n",
        "        multicrop_transform=multicrop_transform,\n",
        "        world_size=world_size,\n",
        "        rank=rank,\n",
        "        root_path=root_path,\n",
        "        image_folder=image_folder,\n",
        "        training=True,\n",
        "        copy_data=copy_data)\n",
        "iter_supervised = None\n",
        "ipe = len(unsupervised_loader)\n",
        "logger.info(f'iterations per epoch: {ipe}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:copying data locally\n",
            "INFO:root:No job-id, will load directly from network file\n",
            "INFO:root:data-path datasets/dr/sample@1000/train/\n",
            "INFO:root:Initialized ImageDR\n",
            "INFO:root:ImageDR dataset created\n",
            "self.multicrop_transform (6, Compose(\n",
            "    Compose(\n",
            "    RandomResizedCrop(size=(96, 96), scale=(0.05, 0.14), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    Compose(\n",
            "    RandomApply(\n",
            "    p=0.8\n",
            "    ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
            ")\n",
            "    RandomGrayscale(p=0.2)\n",
            ")\n",
            "    <src.data_manager.GaussianBlur object at 0x7f7b41e7d590>\n",
            "    ToTensor()\n",
            ")\n",
            "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "))\n",
            "INFO:root:ImageDR unsupervised data loader created\n",
            "INFO:root:Making supervised ImageDR data loader...\n",
            "self.multicrop_transform (0, None)\n",
            "INFO:root:flipping coin to keep labels\n",
            "INFO:root:supervised-reset-period 31\n",
            "INFO:root:ImageDR supervised data loader created\n",
            "INFO:root:iterations per epoch: 31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqprZHJNesAf"
      },
      "source": [
        "# -- init optimizer and scheduler\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_fp16)\n",
        "encoder, optimizer, scheduler = init_opt(\n",
        "    encoder=encoder,\n",
        "    weight_decay=wd,\n",
        "    start_lr=start_lr,\n",
        "    ref_lr=lr,\n",
        "    final_lr=final_lr,\n",
        "    ref_mom=mom,\n",
        "    nesterov=nesterov,\n",
        "    iterations_per_epoch=ipe,\n",
        "    warmup=warmup,\n",
        "    num_epochs=num_epochs)\n",
        "if world_size > 1:\n",
        "    encoder = DistributedDataParallel(encoder, broadcast_buffers=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNn5_mbkd0Bu"
      },
      "source": [
        "start_epoch = 0\n",
        "# -- load training checkpoint\n",
        "if load_model:\n",
        "    encoder, optimizer, start_epoch = load_checkpoint(\n",
        "        r_path=load_path,\n",
        "        encoder=encoder,\n",
        "        opt=optimizer,\n",
        "        scaler=scaler,\n",
        "        use_fp16=use_fp16)\n",
        "    for _ in range(start_epoch):\n",
        "        for _ in range(ipe):\n",
        "            scheduler.step()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54hArUPee283"
      },
      "source": [
        "##########################################\n",
        "################## DEBUG #################\n",
        "##########################################"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssiQp6qigdL5"
      },
      "source": [
        "epoch = 0 "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE4WsivBe2_j"
      },
      "source": [
        "# -- update distributed-data-loader epoch\n",
        "unsupervised_sampler.set_epoch(epoch)\n",
        "if supervised_sampler is not None:\n",
        "    supervised_sampler.set_epoch(epoch)\n",
        "\n",
        "loss_meter = AverageMeter()\n",
        "ploss_meter = AverageMeter()\n",
        "rloss_meter = AverageMeter()\n",
        "time_meter = AverageMeter()\n",
        "data_meter = AverageMeter()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADTReW30e604"
      },
      "source": [
        "best_loss = None"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwew1fgUe3B_",
        "outputId": "d6c54879-64c9-4037-8f57-5330e854cccc"
      },
      "source": [
        "for itr, udata in enumerate(unsupervised_loader):\n",
        "\n",
        "    def load_imgs():\n",
        "        # -- unsupervised imgs\n",
        "        uimgs = [u.to(device, non_blocking=True) for u in udata[:-1]]\n",
        "        # -- supervised imgs\n",
        "        global iter_supervised\n",
        "        try:\n",
        "            sdata = next(iter_supervised)\n",
        "        except Exception:\n",
        "            iter_supervised = iter(supervised_loader)\n",
        "            logger.info(f'len.supervised_loader: {len(iter_supervised)}')\n",
        "            sdata = next(iter_supervised)\n",
        "        finally:\n",
        "            labels = torch.cat([labels_matrix for _ in range(supervised_views)])\n",
        "            simgs = [s.to(device, non_blocking=True) for s in sdata[:-1]]\n",
        "        # -- concatenate supervised imgs and unsupervised imgs\n",
        "        imgs = simgs + uimgs\n",
        "        return imgs, labels\n",
        "    (imgs, labels), dtime = gpu_timer(load_imgs)\n",
        "    data_meter.update(dtime)\n",
        "    break"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:len.supervised_loader: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQhYXzvUsC0k",
        "outputId": "64ed6ee2-9a94-400f-ffe3-edc73f044ba0"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "732xCy2ttHIs",
        "outputId": "cd4c13e7-21a7-48ac-f678-45474c44cb22"
      },
      "source": [
        "imgs[1].shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 224, 224])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf17v1ZItJwy",
        "outputId": "17152bbf-4213-4e6e-cbe5-79dcb91a7f67"
      },
      "source": [
        "imgs[8].shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 96, 96])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1PG3WjBuZW3",
        "outputId": "0fecfe95-f7ef-4b2b-8607-d703f6a4063e"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a0_mdQ6Yals"
      },
      "source": [
        "Cuantas simgs? y cuantas uimgs?\n",
        "\n",
        "simages siempre van adelante tons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Tu2-gze93W"
      },
      "source": [
        "from logging import getLogger\n",
        "import torch\n",
        "from src.utils import (\n",
        "    AllGather,\n",
        "    AllReduce\n",
        ")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3jNVX_Ie95n"
      },
      "source": [
        "tau=0.1\n",
        "T=0.25\n",
        "me_max=True"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgIRot94e98K",
        "outputId": "c6ae3fd5-b2ab-42fe-b622-eace652200db"
      },
      "source": [
        "with torch.cuda.amp.autocast(enabled=use_fp16):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # --\n",
        "    # h: representations of 'imgs' before head\n",
        "    # z: representations of 'imgs' after head\n",
        "    # -- If use_pred_head=False, then encoder.pred (prediction\n",
        "    #    head) is None, and _forward_head just returns the\n",
        "    #    identity, z=h\n",
        "\n",
        "    \"\"\"\n",
        "    Nota: Creo que ya entiendo, las diferentes representaciones/vistas son realizadas es con esto \n",
        "          de antes de la cabeza y despues de la cabeza. \n",
        "    \"\"\"\n",
        "\n",
        "    h, z = encoder(imgs, return_before_head=True)\n",
        "\n",
        "    # Compute paws loss in full precision\n",
        "    with torch.cuda.amp.autocast(enabled=False):\n",
        "\n",
        "        # Step 1. convert representations to fp32\n",
        "        h, z = h.float(), z.float()\n",
        "\n",
        "        # Step 2. determine anchor views/supports and their\n",
        "        #         corresponding target views/supports\n",
        "        # --\n",
        "\n",
        "        \"\"\"\n",
        "        Nota: Este indice de `num_support` es muy importante ya que me dira hasta \n",
        "              donde seran las representaciones del anchor y desde donde \n",
        "              las etiquetadas (supports). \n",
        "        \"\"\"\n",
        "\n",
        "        num_support = supervised_views * s_batch_size * classes_per_batch\n",
        "        # --\n",
        "        anchor_supports = z[:num_support]\n",
        "        anchor_views = z[num_support:]\n",
        "        # --\n",
        "        \"\"\"\n",
        "        Nota: Este `target_supportst` me dice cuales son las representaciones de `support` (las etiquetadas)\n",
        "              que voy a utilizar con las vistas. \n",
        "        \"\"\"\n",
        "        target_supports = h[:num_support].detach() # Este Target es una REPRESENTACION\n",
        "        target_views = h[num_support:].detach()\n",
        "        target_views = torch.cat([\n",
        "            target_views[u_batch_size:2*u_batch_size],\n",
        "            target_views[:u_batch_size]], dim=0)\n",
        "\n",
        "        softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "        def sharpen(p):\n",
        "            sharp_p = p**(1./T)\n",
        "            sharp_p /= torch.sum(sharp_p, dim=1, keepdim=True)\n",
        "            return sharp_p\n",
        "\n",
        "        def snn(query, supports, labels):\n",
        "            \"\"\" Soft Nearest Neighbours similarity classifier \"\"\"\n",
        "            # Step 1: normalize embeddings\n",
        "            query = torch.nn.functional.normalize(query)\n",
        "            supports = torch.nn.functional.normalize(supports)\n",
        "\n",
        "            # Step 2: gather embeddings from all workers\n",
        "            supports = AllGather.apply(supports)\n",
        "\n",
        "            # Step 3: compute similarlity between local embeddings\n",
        "            return softmax(query @ supports.T / tau) @ labels\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        Nota: `anchor_support_labels` y `target_support_labels` son las mismas \n",
        "               las que vienen de `labels`. \n",
        "        \"\"\"\n",
        "        #anchor_views=anchor_views\n",
        "        #anchor_supports=anchor_supports\n",
        "        anchor_support_labels=labels\n",
        "        #target_views=target_views\n",
        "        #target_supports=target_supports\n",
        "        target_support_labels=labels\n",
        "        # -- NOTE: num views of each unlabeled instance = 2+multicrop\n",
        "        batch_size = len(anchor_views) // (2+multicrop)\n",
        "\n",
        "        # Step 1: compute anchor predictions\n",
        "        probs = snn(anchor_views, anchor_supports, anchor_support_labels)\n",
        "\n",
        "\n",
        "        # Step 2: compute targets for anchor predictions\n",
        "        with torch.no_grad():\n",
        "            targets = snn(target_views, target_supports, target_support_labels)\n",
        "            targets = sharpen(targets)\n",
        "            if multicrop > 0:\n",
        "                mc_target = 0.5*(targets[:batch_size]+targets[batch_size:])\n",
        "                targets = torch.cat([targets, *[mc_target for _ in range(multicrop)]], dim=0)\n",
        "            targets[targets < 1e-4] *= 0  # numerical stability\n",
        "\n",
        "        # Step 3: compute cross-entropy loss H(targets, queries)\n",
        "        loss = torch.mean(torch.sum(torch.log(probs**(-targets)), dim=1))\n",
        "\n",
        "        # Step 4: compute me-max regularizer\n",
        "        rloss = 0.\n",
        "        if me_max:\n",
        "            avg_probs = AllReduce.apply(torch.mean(sharpen(probs), dim=0))\n",
        "            rloss -= torch.sum(torch.log(avg_probs**(-avg_probs)))\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig7fGM2jySk3",
        "outputId": "abcab607-5612-4cb8-a676-ee00b10f43f0"
      },
      "source": [
        "rloss"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.6930, device='cuda:0', grad_fn=<RsubBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qcLUG7ot1WB"
      },
      "source": [
        "########### DEBUG   2 ################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-Uf2CgHt6Nw"
      },
      "source": [
        "optimizer.zero_grad()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_gwlAf6t6ua",
        "outputId": "978568f8-d610-4b9d-d948-4091554a4c99"
      },
      "source": [
        "h, z = encoder(imgs, return_before_head=True)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0Otiujgt6w9",
        "outputId": "2370394d-769a-4dd5-931b-01bc109042a0"
      },
      "source": [
        "z.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([320, 2048])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTWA3oAzt60B",
        "outputId": "856679e4-2eff-47ea-f070-e7de379f1230"
      },
      "source": [
        "h.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([320, 2048])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M8cUkbqt62e"
      },
      "source": [
        "h, z = h.float(), z.float()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uf-NBB3t65O"
      },
      "source": [
        "num_support = supervised_views * s_batch_size * classes_per_batch"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUHnFWwFuGUf"
      },
      "source": [
        "anchor_supports = z[:num_support]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jwjzxYVuGW-"
      },
      "source": [
        "anchor_views = z[num_support:]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBfqKS7Cu3Xk"
      },
      "source": [
        "target_supports = h[:num_support].detach() # Este Target es una REPRESENTACION"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwMEwZPFuGZy"
      },
      "source": [
        "target_views = h[num_support:].detach()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDJx4lFfuGb-"
      },
      "source": [
        "target_views = torch.cat([\n",
        "    target_views[u_batch_size:2*u_batch_size],\n",
        "    target_views[:u_batch_size]], dim=0)\n",
        "\n",
        "softmax = torch.nn.Softmax(dim=1)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmKWiTHOvASy"
      },
      "source": [
        "def sharpen(p):\n",
        "    sharp_p = p**(1./T)\n",
        "    sharp_p /= torch.sum(sharp_p, dim=1, keepdim=True)\n",
        "    return sharp_p\n",
        "\n",
        "def snn(query, supports, labels):\n",
        "    \"\"\" Soft Nearest Neighbours similarity classifier \"\"\"\n",
        "    # Step 1: normalize embeddings\n",
        "    query = torch.nn.functional.normalize(query)\n",
        "    supports = torch.nn.functional.normalize(supports)\n",
        "\n",
        "    # Step 2: gather embeddings from all workers\n",
        "    supports = AllGather.apply(supports)\n",
        "\n",
        "    # Step 3: compute similarlity between local embeddings\n",
        "    return softmax(query @ supports.T / tau) @ labels"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEo8lMDsvAVp"
      },
      "source": [
        "anchor_support_labels=labels\n",
        "\n",
        "target_support_labels=labels"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XDIU39DvAa1"
      },
      "source": [
        "# -- NOTE: num views of each unlabeled instance = 2+multicrop\n",
        "batch_size = len(anchor_views) // (2+multicrop)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_6mhIvZvaoM"
      },
      "source": [
        "# Step 1: compute anchor predictions\n",
        "probs = snn(anchor_views, anchor_supports, anchor_support_labels)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkaAg23Fvat7"
      },
      "source": [
        "# Step 2: compute targets for anchor predictions\n",
        "with torch.no_grad():\n",
        "    targets = snn(target_views, target_supports, target_support_labels)\n",
        "    targets = sharpen(targets)\n",
        "    if multicrop > 0:\n",
        "        mc_target = 0.5*(targets[:batch_size]+targets[batch_size:])\n",
        "        targets = torch.cat([targets, *[mc_target for _ in range(multicrop)]], dim=0)\n",
        "    targets[targets < 1e-4] *= 0  # numerical stability"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY7qLZK4vmK2"
      },
      "source": [
        "loss = torch.mean(torch.sum(torch.log(probs**(-targets)), dim=1))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voLEw8tavmOF"
      },
      "source": [
        "# Step 4: compute me-max regularizer\n",
        "rloss = 0.\n",
        "if me_max:\n",
        "    avg_probs = AllReduce.apply(torch.mean(sharpen(probs), dim=0))\n",
        "    rloss -= torch.sum(torch.log(avg_probs**(-avg_probs)))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZhSiv0Jt2E8"
      },
      "source": [
        "###############@###################"
      ],
      "execution_count": 62,
      "outputs": []
    }
  ]
}