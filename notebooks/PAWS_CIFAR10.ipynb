{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PAWS-CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPUBCrUVNpXRnIQeXo+CIMX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/PAWS_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtjbLBqDedOu",
        "outputId": "87ac059a-984d-459d-d087-9c6297a1a8cc"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --no-cache-dir ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8048, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 8048 (delta 65), reused 97 (delta 44), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8048/8048), 14.11 MiB | 14.35 MiB/s, done.\n",
            "Resolving deltas: 100% (5464/5464), done.\n",
            "/content/apex\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-k04k5rly\n",
            "Created temporary directory: /tmp/pip-req-tracker-s8e1_thr\n",
            "Created requirements tracker '/tmp/pip-req-tracker-s8e1_thr'\n",
            "Created temporary directory: /tmp/pip-install-t09h9_nk\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-lswf64cw\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-s8e1_thr'\n",
            "    Running setup.py (path:/tmp/pip-req-build-lswf64cw/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.8.1+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-lswf64cw/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-lswf64cw/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-lswf64cw/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-lswf64cw/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-lswf64cw/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
            "    writing manifest file '/tmp/pip-req-build-lswf64cw/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-lswf64cw/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-lswf64cw has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-s8e1_thr'\n",
            "Building wheels for collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-wheel-_8vlndbk\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-_8vlndbk\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-lswf64cw/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-lswf64cw/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-_8vlndbk --python-tag cp37\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.8.1+cu101\n",
            "\n",
            "\n",
            "  /tmp/pip-req-build-lswf64cw/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/apex\n",
            "  copying apex/__init__.py -> build/lib/apex\n",
            "  creating build/lib/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
            "  creating build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
            "  creating build/lib/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
            "  creating build/lib/apex/mlp\n",
            "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
            "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
            "  creating build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
            "  creating build/lib/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
            "  creating build/lib/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  creating build/lib/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
            "  creating build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
            "  creating build/lib/apex/pyprof\n",
            "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
            "  creating build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
            "  creating build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
            "  creating build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  creating build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
            "  creating build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
            "  creating build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/fmha.py -> build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/__init__.py -> build/lib/apex/contrib/fmha\n",
            "  creating build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/__init__.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/test.py -> build/lib/apex/contrib/bottleneck\n",
            "  creating build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/__init__.py -> build/lib/apex/contrib/layer_norm\n",
            "  creating build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  creating build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/__init__.py -> build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/transducer.py -> build/lib/apex/contrib/transducer\n",
            "  creating build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
            "  creating build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
            "  creating build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
            "  creating build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.7.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-_8vlndbk/apex-0.1-cp37-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'apex/__init__.py'\n",
            "  adding 'apex/RNN/RNNBackend.py'\n",
            "  adding 'apex/RNN/__init__.py'\n",
            "  adding 'apex/RNN/cells.py'\n",
            "  adding 'apex/RNN/models.py'\n",
            "  adding 'apex/amp/__init__.py'\n",
            "  adding 'apex/amp/__version__.py'\n",
            "  adding 'apex/amp/_amp_state.py'\n",
            "  adding 'apex/amp/_initialize.py'\n",
            "  adding 'apex/amp/_process_optimizer.py'\n",
            "  adding 'apex/amp/amp.py'\n",
            "  adding 'apex/amp/compat.py'\n",
            "  adding 'apex/amp/frontend.py'\n",
            "  adding 'apex/amp/handle.py'\n",
            "  adding 'apex/amp/opt.py'\n",
            "  adding 'apex/amp/rnn_compat.py'\n",
            "  adding 'apex/amp/scaler.py'\n",
            "  adding 'apex/amp/utils.py'\n",
            "  adding 'apex/amp/wrap.py'\n",
            "  adding 'apex/amp/lists/__init__.py'\n",
            "  adding 'apex/amp/lists/functional_overrides.py'\n",
            "  adding 'apex/amp/lists/tensor_overrides.py'\n",
            "  adding 'apex/amp/lists/torch_overrides.py'\n",
            "  adding 'apex/contrib/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/bottleneck.py'\n",
            "  adding 'apex/contrib/bottleneck/test.py'\n",
            "  adding 'apex/contrib/fmha/__init__.py'\n",
            "  adding 'apex/contrib/fmha/fmha.py'\n",
            "  adding 'apex/contrib/groupbn/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
            "  adding 'apex/contrib/layer_norm/__init__.py'\n",
            "  adding 'apex/contrib/layer_norm/layer_norm.py'\n",
            "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
            "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
            "  adding 'apex/contrib/sparsity/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/asp.py'\n",
            "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
            "  adding 'apex/contrib/transducer/__init__.py'\n",
            "  adding 'apex/contrib/transducer/transducer.py'\n",
            "  adding 'apex/contrib/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
            "  adding 'apex/fp16_utils/__init__.py'\n",
            "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
            "  adding 'apex/fp16_utils/fp16util.py'\n",
            "  adding 'apex/fp16_utils/loss_scaler.py'\n",
            "  adding 'apex/mlp/__init__.py'\n",
            "  adding 'apex/mlp/mlp.py'\n",
            "  adding 'apex/multi_tensor_apply/__init__.py'\n",
            "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
            "  adding 'apex/normalization/__init__.py'\n",
            "  adding 'apex/normalization/fused_layer_norm.py'\n",
            "  adding 'apex/optimizers/__init__.py'\n",
            "  adding 'apex/optimizers/fused_adagrad.py'\n",
            "  adding 'apex/optimizers/fused_adam.py'\n",
            "  adding 'apex/optimizers/fused_lamb.py'\n",
            "  adding 'apex/optimizers/fused_novograd.py'\n",
            "  adding 'apex/optimizers/fused_sgd.py'\n",
            "  adding 'apex/parallel/LARC.py'\n",
            "  adding 'apex/parallel/__init__.py'\n",
            "  adding 'apex/parallel/distributed.py'\n",
            "  adding 'apex/parallel/multiproc.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
            "  adding 'apex/parallel/sync_batchnorm.py'\n",
            "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
            "  adding 'apex/pyprof/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
            "  adding 'apex/pyprof/parse/__init__.py'\n",
            "  adding 'apex/pyprof/parse/__main__.py'\n",
            "  adding 'apex/pyprof/parse/db.py'\n",
            "  adding 'apex/pyprof/parse/kernel.py'\n",
            "  adding 'apex/pyprof/parse/nvvp.py'\n",
            "  adding 'apex/pyprof/parse/parse.py'\n",
            "  adding 'apex/pyprof/prof/__init__.py'\n",
            "  adding 'apex/pyprof/prof/__main__.py'\n",
            "  adding 'apex/pyprof/prof/activation.py'\n",
            "  adding 'apex/pyprof/prof/base.py'\n",
            "  adding 'apex/pyprof/prof/blas.py'\n",
            "  adding 'apex/pyprof/prof/conv.py'\n",
            "  adding 'apex/pyprof/prof/convert.py'\n",
            "  adding 'apex/pyprof/prof/data.py'\n",
            "  adding 'apex/pyprof/prof/dropout.py'\n",
            "  adding 'apex/pyprof/prof/embedding.py'\n",
            "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
            "  adding 'apex/pyprof/prof/linear.py'\n",
            "  adding 'apex/pyprof/prof/loss.py'\n",
            "  adding 'apex/pyprof/prof/misc.py'\n",
            "  adding 'apex/pyprof/prof/normalization.py'\n",
            "  adding 'apex/pyprof/prof/optim.py'\n",
            "  adding 'apex/pyprof/prof/output.py'\n",
            "  adding 'apex/pyprof/prof/pointwise.py'\n",
            "  adding 'apex/pyprof/prof/pooling.py'\n",
            "  adding 'apex/pyprof/prof/prof.py'\n",
            "  adding 'apex/pyprof/prof/randomSample.py'\n",
            "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
            "  adding 'apex/pyprof/prof/reduction.py'\n",
            "  adding 'apex/pyprof/prof/softmax.py'\n",
            "  adding 'apex/pyprof/prof/usage.py'\n",
            "  adding 'apex/pyprof/prof/utility.py'\n",
            "  adding 'apex/reparameterization/__init__.py'\n",
            "  adding 'apex/reparameterization/reparameterization.py'\n",
            "  adding 'apex/reparameterization/weight_norm.py'\n",
            "  adding 'apex-0.1.dist-info/LICENSE'\n",
            "  adding 'apex-0.1.dist-info/METADATA'\n",
            "  adding 'apex-0.1.dist-info/WHEEL'\n",
            "  adding 'apex-0.1.dist-info/top_level.txt'\n",
            "  adding 'apex-0.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp37-none-any.whl size=204691 sha256=3cdbdfc8535757ea4159e63f870677f69c57593203c36754c9d28bae977e42d4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k04k5rly/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n",
            "  Removing source in /tmp/pip-req-build-lswf64cw\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-s8e1_thr'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7nqHmPWe88z",
        "outputId": "bc132045-6c22-4155-bec2-cc2d7aa69f32"
      },
      "source": [
        "pip install PyYAML"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGHPN1P9gdEZ",
        "outputId": "702404b4-b939-4042-d329-7b37644d6d86"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/apex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyfOVpqKgezC",
        "outputId": "50c50500-2781-420e-85f1-afaef7ca21ea"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuMOOgUDKydX",
        "outputId": "3e05a76f-2232-42a2-a147-a248761945c9"
      },
      "source": [
        "!git clone -b develop https://github.com/jmarrietar/suncet.git"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'suncet'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 103 (delta 47), reused 81 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (103/103), 1.08 MiB | 953.00 KiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKBJOKiSQZlO",
        "outputId": "6645ff45-d7d5-4b7b-8926-722001426f48"
      },
      "source": [
        "cd suncet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qMmBF5jQwoa"
      },
      "source": [
        "!mkdir datasets\n",
        "!mkdir datasets/cifar10-data"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_loWdUq4LeOA",
        "outputId": "ca015cfd-8bef-4a23-ad88-d383e8bfdab1"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz \\\n",
        "    -O /content/suncet/datasets/cifar10-data/cifar-10-python.tar.gz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-30 18:21:09--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘/content/suncet/datasets/cifar10-data/cifar-10-python.tar.gz’\n",
            "\n",
            "/content/suncet/dat 100%[===================>] 162.60M  30.1MB/s    in 5.9s    \n",
            "\n",
            "2021-05-30 18:21:15 (27.6 MB/s) - ‘/content/suncet/datasets/cifar10-data/cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dnUzK6mRXbM",
        "outputId": "8f6bba02-f03c-4c8e-c599-d19783648075"
      },
      "source": [
        " cd /content/suncet/datasets/cifar10-data/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet/datasets/cifar10-data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jFs3-ZAO0KL",
        "outputId": "2c21f076-820e-4843-e3cf-9c23f0af108a"
      },
      "source": [
        "!tar xvf cifar-10-python.tar.gz"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNsbwz4pRoFQ",
        "outputId": "3e7d43b2-fb0e-4382-8537-b034085eaa6e"
      },
      "source": [
        "cd ../../"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zapo23YCRpV5",
        "outputId": "fb6b0c2d-d1e6-4663-89b8-10df25fd6440"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/suncet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-fH1YiCg187",
        "outputId": "3c66990e-498b-43db-9d7f-8b435590304b"
      },
      "source": [
        "pip install -U PyYAML"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyYAML\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\r\u001b[K     |▌                               | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 28.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 22.1MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 18.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 15.5MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 17.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 13.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 14.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 593kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 14.4MB/s \n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jypg8LwnRsPq",
        "outputId": "958ddc50-ddf4-421f-ecf8-32c0125310bf"
      },
      "source": [
        "!python main.py --sel paws_train --fname configs/paws/cifar10_train.yaml"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:called-params paws_train configs/paws/cifar10_train.yaml\n",
            "INFO:root:loaded params...\n",
            "{   'criterion': {   'classes_per_batch': 10,\n",
            "                     'me_max': True,\n",
            "                     'sharpen': 0.25,\n",
            "                     'supervised_imgs_per_class': 64,\n",
            "                     'supervised_views': 2,\n",
            "                     'temperature': 0.1,\n",
            "                     'unsupervised_batch_size': 256},\n",
            "    'data': {   'color_jitter_strength': 0.5,\n",
            "                'data_seed': 152,\n",
            "                'dataset': 'cifar10',\n",
            "                'image_folder': 'cifar10-data/',\n",
            "                'label_smoothing': 0.1,\n",
            "                'multicrop': 6,\n",
            "                'normalize': True,\n",
            "                'root_path': 'datasets/',\n",
            "                'subset_path': 'cifar10_subsets/',\n",
            "                'unique_classes_per_rank': False,\n",
            "                'unlabeled_frac': 0.92},\n",
            "    'logging': {'folder': '/content/suncet/logs/', 'write_tag': 'paws'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'model_name': 'wide_resnet28w2',\n",
            "                'output_dim': 128,\n",
            "                'read_checkpoint': None,\n",
            "                'use_fp16': True,\n",
            "                'use_pred_head': False},\n",
            "    'optimization': {   'epochs': 600,\n",
            "                        'final_lr': 0.032,\n",
            "                        'lr': 3.2,\n",
            "                        'momentum': 0.9,\n",
            "                        'nesterov': False,\n",
            "                        'start_lr': 0.8,\n",
            "                        'warmup': 10,\n",
            "                        'weight_decay': 1e-06}}\n",
            "INFO:root:Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO:root:Running paws_train (rank: 0/1)\n",
            "INFO:root:Initialized (rank/world-size) 0/1\n",
            "INFO:root:WideResNet(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (layer1): Sequential(\n",
            "    (0): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (1): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (3): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
            "      )\n",
            "    )\n",
            "    (1): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (3): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "      )\n",
            "    )\n",
            "    (1): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (3): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu1): ReLU(inplace=True)\n",
            "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu2): ReLU(inplace=True)\n",
            "    (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            ")\n",
            "INFO:root:making cifar10 data transforms\n",
            "INFO:root:keep file: cifar10_subsets/spc.4000_split.152.txt\n",
            "_make_multicrop_cifar10_transforms distortion strength 0.5\n",
            "INFO:root:copying data locally\n",
            "INFO:root:No job-id, will load directly from network file\n",
            "INFO:root:data-path datasets/cifar10-data/\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "INFO:root:copying data locally\n",
            "INFO:root:No job-id, will load directly from network file\n",
            "INFO:root:data-path datasets/cifar10-data/\n",
            "INFO:root:Using cifar10_subsets/spc.4000_split.152.txt\n",
            "INFO:root:num-labeled 4000\n",
            "INFO:root:num-labeled target 0 400\n",
            "INFO:root:num-labeled target 1 400\n",
            "INFO:root:num-labeled target 2 400\n",
            "INFO:root:num-labeled target 3 400\n",
            "INFO:root:num-labeled target 4 400\n",
            "INFO:root:num-labeled target 5 400\n",
            "INFO:root:num-labeled target 6 400\n",
            "INFO:root:num-labeled target 7 400\n",
            "INFO:root:num-labeled target 8 400\n",
            "INFO:root:num-labeled target 9 400\n",
            "INFO:root:min. labeled indices 400\n",
            "INFO:root:iterations per epoch: 195\n",
            "INFO:root:Epoch 1\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 93, in <module>\n",
            "    args=(args.sel, args.fname, num_gpus, args.devices))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 230, in spawn\n",
            "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 188, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 150, in join\n",
            "    raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
            "torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\n",
            "-- Process 0 terminated with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/spawn.py\", line 59, in _wrap\n",
            "    fn(i, *args)\n",
            "  File \"/content/suncet/main.py\", line 77, in process_main\n",
            "    return paws(params)\n",
            "  File \"/content/suncet/src/paws_train.py\", line 265, in main\n",
            "    for itr, udata in enumerate(unsupervised_loader):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 355, in __iter__\n",
            "    return self._get_iterator()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 301, in _get_iterator\n",
            "    return _MultiProcessingDataLoaderIter(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 914, in __init__\n",
            "    w.start()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 112, in start\n",
            "    self._popen = self._Popen(self)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/context.py\", line 223, in _Popen\n",
            "    return _default_context.get_context().Process._Popen(process_obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/context.py\", line 284, in _Popen\n",
            "    return Popen(process_obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/popen_spawn_posix.py\", line 32, in __init__\n",
            "    super().__init__(process_obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 20, in __init__\n",
            "    self._launch(process_obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/popen_spawn_posix.py\", line 47, in _launch\n",
            "    reduction.dump(process_obj, fp)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/reduction.py\", line 60, in dump\n",
            "    ForkingPickler(file, protocol).dump(obj)\n",
            "AttributeError: Can't pickle local object '_make_cifar10_transforms.<locals>.get_color_distortion.<locals>.Solarize'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfL5vAK8jwWc",
        "outputId": "67566c10-eadf-4c08-f073-d56e914220a0"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5oOdKyakUfh",
        "outputId": "3509178f-1382-430e-e77c-f4ac7518904a"
      },
      "source": [
        "cd logs"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/suncet/logs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcrFbCUGkWC9",
        "outputId": "461aa71d-1839-44c7-af87-4797f24df8bf"
      },
      "source": [
        "ls"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params-paws_train.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "evxK-9qlk-Lg",
        "outputId": "f13f2b86-7624-4e92-ee63-6e15fb8fb9e5"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/suncet/logs'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtnEaWV3kn_8"
      },
      "source": [
        "import yaml"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m_cEWcmkN1T"
      },
      "source": [
        "dump = '/content/suncet/logs/params-paws_train.yaml'\n",
        "with open(dump, 'w') as f:\n",
        "    yaml.dump(\"ss\", f)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "S8CKehQWiYjL",
        "outputId": "b9c269b2-70b2-4fe3-d6fc-2c4d8105d335"
      },
      "source": [
        "/content/suncet/logs/params-paws_train.yaml"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-7e032b648caa>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    content(/suncet/logs/params-paws_train.yaml)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkZZYdqKg-8l"
      },
      "source": [
        "!mkdir logs"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAX0GsL1SDvI"
      },
      "source": [
        "from src.paws_train import main as paws"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3CJWLezVjO-"
      },
      "source": [
        "def my_func():\n",
        "    numbers = [2, 1, 3, 4, 7]\n",
        "    more_numbers = [*numbers, 11, 18]\n",
        "    ans = *[2, 1, 3, 4, 7], 1\n",
        "    return ans"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7yWKucRVjqK"
      },
      "source": [
        "def f():\n",
        "    rest = [2, 3]\n",
        "    t = 1, *rest\n",
        "    return t"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CHWXaq5aZdr"
      },
      "source": [
        "######### DEBUG ##############"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPkMyz6kmfNY"
      },
      "source": [
        "import argparse\n",
        "\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "import pprint\n",
        "import yaml\n",
        "\n",
        "from src.paws_train import main as paws\n",
        "from src.suncet_train import main as suncet\n",
        "from src.fine_tune import main as fine_tune\n",
        "from src.snn_fine_tune import main as snn_fine_tune\n",
        "\n",
        "from src.utils import init_distributed"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07efEicxmg-G",
        "outputId": "1608a9c5-49ec-4375-fab1-1717a889f345"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    '--fname', type=str,\n",
        "    help='name of config file to load',\n",
        "    default='configs.yaml')\n",
        "parser.add_argument(\n",
        "    '--devices', type=str, nargs='+', default=['cuda:0'],\n",
        "    help='which devices to use on local machine')\n",
        "parser.add_argument(\n",
        "    '--sel', type=str,\n",
        "    help='which script to run',\n",
        "    choices=[\n",
        "        'paws_train',\n",
        "        'suncet_train',\n",
        "        'fine_tune',\n",
        "        'snn_fine_tune'\n",
        "    ])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--sel'], dest='sel', nargs=None, const=None, default=None, type=<class 'str'>, choices=['paws_train', 'suncet_train', 'fine_tune', 'snn_fine_tune'], help='which script to run', metavar=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhkmDZhOmhnX"
      },
      "source": [
        "args = parser.parse_args(['--sel', 'paws_train',\n",
        "                            '--fname', 'configs/paws/cifar10_train.yaml'\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kao-kgRCmb4k"
      },
      "source": [
        "def process_main(rank, sel, fname, world_size, devices):\n",
        "    import os\n",
        "    #os.environ['CUDA_VISIBLE_DEVICES'] = str(devices[rank].split(':')[-1])\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.devices[rank].split(':')[-1]) # YO\n",
        "\n",
        "    import logging\n",
        "    logging.basicConfig()\n",
        "    logger = logging.getLogger()\n",
        "\n",
        "    logger.info(f'called-params {sel} {fname}')\n",
        "\n",
        "    # -- load script params\n",
        "    params = None\n",
        "    with open(fname, 'r') as y_file:\n",
        "        params = yaml.load(y_file, Loader=yaml.FullLoader)\n",
        "        logger.info('loaded params...')\n",
        "        if rank == 0:\n",
        "            pp = pprint.PrettyPrinter(indent=4)\n",
        "            pp.pprint(params)\n",
        "\n",
        "    if rank == 0:\n",
        "        dump = os.path.join(params['logging']['folder'], f'params-{sel}.yaml')\n",
        "        with open(dump, 'w') as f:\n",
        "            yaml.dump(params, f)\n",
        "\n",
        "    world_size, rank = init_distributed(rank_and_world_size=(rank, world_size))\n",
        "\n",
        "    # -- make sure all processes correctly initialized torch-distributed\n",
        "    logger.info(f'Running {sel} (rank: {rank}/{world_size})')\n",
        "\n",
        "    # -- turn off info-logging for ranks > 0, otherwise too much std output\n",
        "    if rank == 0:\n",
        "        logger.setLevel(logging.INFO)\n",
        "    else:\n",
        "        logger.setLevel(logging.ERROR)\n",
        "\n",
        "    if sel == 'paws_train':\n",
        "        return paws(params)\n",
        "    elif sel == 'suncet_train':\n",
        "        return suncet(params)\n",
        "    elif sel == 'fine_tune':\n",
        "        return fine_tune(params)\n",
        "    elif sel == 'snn_fine_tune':\n",
        "        return snn_fine_tune(params)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C35eyI_PpUlw"
      },
      "source": [
        "num_gpus = len(args.devices)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQRy3ahsnvph",
        "outputId": "c2764b37-6b66-4fa5-a4c1-ac33250f8d42"
      },
      "source": [
        "process_main(0, args.sel, args.fname, num_gpus, args.devices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:called-params paws_train configs/paws/cifar10_train.yaml\n",
            "INFO:root:loaded params...\n",
            "{   'criterion': {   'classes_per_batch': 10,\n",
            "                     'me_max': True,\n",
            "                     'sharpen': 0.25,\n",
            "                     'supervised_imgs_per_class': 64,\n",
            "                     'supervised_views': 2,\n",
            "                     'temperature': 0.1,\n",
            "                     'unsupervised_batch_size': 256},\n",
            "    'data': {   'color_jitter_strength': 0.5,\n",
            "                'data_seed': 152,\n",
            "                'dataset': 'cifar10',\n",
            "                'image_folder': 'cifar10-data/',\n",
            "                'label_smoothing': 0.1,\n",
            "                'multicrop': 6,\n",
            "                'normalize': True,\n",
            "                'root_path': 'datasets/',\n",
            "                'subset_path': 'cifar10_subsets/',\n",
            "                'unique_classes_per_rank': False,\n",
            "                'unlabeled_frac': 0.92},\n",
            "    'logging': {'folder': '/content/suncet/logs/', 'write_tag': 'paws'},\n",
            "    'meta': {   'copy_data': True,\n",
            "                'device': 'cuda:0',\n",
            "                'load_checkpoint': False,\n",
            "                'model_name': 'wide_resnet28w2',\n",
            "                'output_dim': 128,\n",
            "                'read_checkpoint': None,\n",
            "                'use_fp16': True,\n",
            "                'use_pred_head': False},\n",
            "    'optimization': {   'epochs': 600,\n",
            "                        'final_lr': 0.032,\n",
            "                        'lr': 3.2,\n",
            "                        'momentum': 0.9,\n",
            "                        'nesterov': False,\n",
            "                        'start_lr': 0.8,\n",
            "                        'warmup': 10,\n",
            "                        'weight_decay': 1e-06}}\n",
            "INFO:root:Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO:root:Running paws_train (rank: 0/1)\n",
            "INFO:root:Initialized (rank/world-size) 0/1\n",
            "INFO:root:WideResNet(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (layer1): Sequential(\n",
            "    (0): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (1): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (3): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
            "      )\n",
            "    )\n",
            "    (1): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (3): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
            "      )\n",
            "    )\n",
            "    (1): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (3): WideBasicBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential(\n",
            "    (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu1): ReLU(inplace=True)\n",
            "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu2): ReLU(inplace=True)\n",
            "    (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            ")\n",
            "INFO:root:making cifar10 data transforms\n",
            "INFO:root:keep file: cifar10_subsets/spc.4000_split.152.txt\n",
            "_make_multicrop_cifar10_transforms distortion strength 0.5\n",
            "INFO:root:copying data locally\n",
            "INFO:root:No job-id, will load directly from network file\n",
            "INFO:root:data-path datasets/cifar10-data/\n",
            "INFO:root:copying data locally\n",
            "INFO:root:No job-id, will load directly from network file\n",
            "INFO:root:data-path datasets/cifar10-data/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Using cifar10_subsets/spc.4000_split.152.txt\n",
            "INFO:root:num-labeled 4000\n",
            "INFO:root:num-labeled target 0 400\n",
            "INFO:root:num-labeled target 1 400\n",
            "INFO:root:num-labeled target 2 400\n",
            "INFO:root:num-labeled target 3 400\n",
            "INFO:root:num-labeled target 4 400\n",
            "INFO:root:num-labeled target 5 400\n",
            "INFO:root:num-labeled target 6 400\n",
            "INFO:root:num-labeled target 7 400\n",
            "INFO:root:num-labeled target 8 400\n",
            "INFO:root:num-labeled target 9 400\n",
            "INFO:root:min. labeled indices 400\n",
            "INFO:root:iterations per epoch: 195\n",
            "INFO:root:Epoch 1\n",
            "INFO:root:len.supervised_loader: 195\n",
            "INFO:root:[1,     0] loss: -0.020 (2.260 -2.279) (4712 ms; 14446 ms)\n",
            "INFO:root:[1,     0] lr_stats: 0.017 (6.03e-03, 4.39e-02)\n",
            "INFO:root:[1,    10] loss: -0.069 (2.222 -2.291) (956 ms; 1598 ms)\n",
            "INFO:root:[1,    10] lr_stats: 0.040 (1.18e-02, 1.30e-01)\n",
            "INFO:root:[1,    20] loss: -0.099 (2.192 -2.292) (806 ms; 1100 ms)\n",
            "INFO:root:[1,    20] lr_stats: 0.042 (1.55e-02, 1.00e-01)\n",
            "INFO:root:[1,    30] loss: -0.127 (2.164 -2.291) (758 ms; 772 ms)\n",
            "INFO:root:[1,    30] lr_stats: 0.049 (7.83e-03, 1.20e-01)\n",
            "INFO:root:[1,    40] loss: -0.154 (2.136 -2.290) (733 ms; 605 ms)\n",
            "INFO:root:[1,    40] lr_stats: 0.033 (7.83e-03, 1.06e-01)\n",
            "INFO:root:[1,    50] loss: -0.173 (2.116 -2.290) (693 ms; 498 ms)\n",
            "INFO:root:[1,    50] lr_stats: 0.039 (8.21e-03, 8.95e-02)\n",
            "INFO:root:[1,    60] loss: -0.194 (2.096 -2.290) (667 ms; 428 ms)\n",
            "INFO:root:[1,    60] lr_stats: 0.041 (9.79e-03, 9.58e-02)\n",
            "INFO:root:[1,    70] loss: -0.218 (2.072 -2.290) (651 ms; 378 ms)\n",
            "INFO:root:[1,    70] lr_stats: 0.037 (8.60e-03, 9.51e-02)\n",
            "INFO:root:[1,    80] loss: -0.239 (2.051 -2.289) (636 ms; 339 ms)\n",
            "INFO:root:[1,    80] lr_stats: 0.035 (4.15e-03, 8.99e-02)\n",
            "INFO:root:[1,    90] loss: -0.257 (2.032 -2.289) (624 ms; 309 ms)\n",
            "INFO:root:[1,    90] lr_stats: 0.030 (4.74e-03, 7.79e-02)\n",
            "INFO:root:[1,   100] loss: -0.276 (2.013 -2.289) (616 ms; 286 ms)\n",
            "INFO:root:[1,   100] lr_stats: 0.036 (5.69e-03, 8.41e-02)\n",
            "INFO:root:[1,   110] loss: -0.291 (1.998 -2.289) (610 ms; 267 ms)\n",
            "INFO:root:[1,   110] lr_stats: 0.034 (3.23e-03, 8.30e-02)\n",
            "INFO:root:[1,   120] loss: -0.305 (1.984 -2.289) (605 ms; 251 ms)\n",
            "INFO:root:[1,   120] lr_stats: 0.035 (7.41e-03, 8.34e-02)\n",
            "INFO:root:[1,   130] loss: -0.320 (1.970 -2.290) (599 ms; 237 ms)\n",
            "INFO:root:[1,   130] lr_stats: 0.033 (4.25e-03, 7.66e-02)\n",
            "INFO:root:[1,   140] loss: -0.335 (1.955 -2.290) (595 ms; 225 ms)\n",
            "INFO:root:[1,   140] lr_stats: 0.032 (5.41e-03, 7.85e-02)\n",
            "INFO:root:[1,   150] loss: -0.348 (1.942 -2.290) (591 ms; 215 ms)\n",
            "INFO:root:[1,   150] lr_stats: 0.032 (5.50e-03, 6.96e-02)\n",
            "INFO:root:[1,   160] loss: -0.362 (1.928 -2.290) (588 ms; 206 ms)\n",
            "INFO:root:[1,   160] lr_stats: 0.034 (4.65e-03, 7.71e-02)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnnHl0PhoxTG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}