{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Refactor PyTorch/XLA ResNet18/DR Training",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4153554bdaf44b1e9ee7f3099f0776bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10a9e3e96b83467db539e365a98f1cdf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_309e730070034a2d99d97af4fc30bba2",
              "IPY_MODEL_724c7355e538474fb777ff01e3e3534e"
            ]
          }
        },
        "10a9e3e96b83467db539e365a98f1cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "309e730070034a2d99d97af4fc30bba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_74641cf9607a44038b65684c6b1dc025",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f80bec577ba44d639755877dc1e50870"
          }
        },
        "724c7355e538474fb777ff01e3e3534e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dfbf84ba276c4a7f9fde3e607ed86aae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 96.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_100da3aceb2d410487a64c75f011205c"
          }
        },
        "74641cf9607a44038b65684c6b1dc025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f80bec577ba44d639755877dc1e50870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfbf84ba276c4a7f9fde3e607ed86aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "100da3aceb2d410487a64c75f011205c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmarrietar/ocular/blob/master/notebooks/Refactor_PyTorch_XLA_ResNet18_DR_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX1hxqUQn47M"
      },
      "source": [
        "## PyTorch/XLA ResNet/DR (GPU or TPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr3oYPye53E2"
      },
      "source": [
        "import gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbnXNRlJrQXV"
      },
      "source": [
        "from google.colab import auth, drive\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjC_ZzWM55ga"
      },
      "source": [
        "def download(data, url):\n",
        "    # Download dataset\n",
        "    import zipfile\n",
        "    url = url\n",
        "    output = \"{}.zip\".format(data)\n",
        "    gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # Uncompress dataset\n",
        "    local_zip = '{}.zip'.format(data)\n",
        "    zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyd1aK557sH"
      },
      "source": [
        "data_samples = {\n",
        "    \"sample@200\": \"https://drive.google.com/uc?id=1FfV7YyDJvNUCDP5r3-8iQfZ2-xJp_pgb\",\n",
        "    \"sample@500\": \"https://drive.google.com/uc?id=1dHwUqpmSogEdjAB9rwDUL-OKFRUcVXte\",\n",
        "    \"sample@1000\": \"https://drive.google.com/uc?id=1DPZrHrj3Bdte5Dc6NCZ33CAqMG-Oipa2\",\n",
        "    \"sample@2000\": \"https://drive.google.com/uc?id=1PB7uGd-dUnZKnKZpZl-HvE1DVcWgX50F\",\n",
        "    \"sample@3000\": \"https://drive.google.com/uc?id=1_yre5K9YYvJgSrT4xvrI8eD_htucIywA\",\n",
        "    \"sample@4000_images\": \"https://drive.google.com/uc?id=1dqVB8EozEpwWzyuU80AauoQmsiw3Gtm2\",\n",
        "    \"sample@20000\": \"https://drive.google.com/uc?id=1MTDpLzpmhSiZq2jSdmHx2UDPn9FC8gzO\",\n",
        "    \"val-voets-tf\": \"https://drive.google.com/uc?id=1VzVgMGTkBBPG2qbzLunD9HvLzH6tcyrv\",\n",
        "    \"train_voets\": \"https://drive.google.com/uc?id=1AmcFh1MOOZ6aqKm2eO7XEdgmIEqHKTZ5\",\n",
        "    \"voets_test_images\": \"https://drive.google.com/uc?id=15S_V3B_Z3BOjCT3AbO2c887FyS5B0Lyd\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oroPxW1C5881"
      },
      "source": [
        "UNLABELED = 'train_voets'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJYWOqWZ5-x1",
        "outputId": "2306b712-bb40-4e4e-9ad6-a04f4dcb5911"
      },
      "source": [
        "URL_UNLABELED = data_samples[UNLABELED]\n",
        "download(UNLABELED, URL_UNLABELED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AmcFh1MOOZ6aqKm2eO7XEdgmIEqHKTZ5\n",
            "To: /content/train_voets.zip\n",
            "3.09GB [00:32, 94.1MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVIHHvvTrRET",
        "outputId": "62675c54-477b-4813-e475-a750f748cd33"
      },
      "source": [
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "O53lrJMDn9Rd",
        "outputId": "2396bf25-7cf3-4503-ca6d-cc1363ef0b67"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cloud-tpu-client==0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting torch-xla==1.8.1\n",
            "\u001b[?25l  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl (145.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 145.0MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.7.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.30.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (56.1.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.12.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (20.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\n",
            "\u001b[31mERROR: earthengine-api 0.1.264 has requirement google-api-python-client<2,>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client, torch-xla\n",
            "  Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0 torch-xla-1.8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "googleapiclient"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IednejwkIW-K"
      },
      "source": [
        "Only run the below commented cell if you would like a nightly release"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Micd3xZvoA-c"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.utils.utils as xu\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import logging\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-bBdzgeISaP"
      },
      "source": [
        "# VERSION = \"nightly\"  #@param [\"nightly\", \"20200516\"]  # or YYYYMMDD format\n",
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFzLg5gy7l6"
      },
      "source": [
        "# PyTorch/XLA GPU Setup (only if GPU runtime)\n",
        "import os\n",
        "if os.environ.get('COLAB_GPU', '0') == '1':\n",
        "  os.environ['GPU_NUM_DEVICES'] = '1'\n",
        "  os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rroH9yiAn-XE"
      },
      "source": [
        "### Define Parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy62hTvp9H9H"
      },
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHJ65sZygG2b"
      },
      "source": [
        "def accuracy_func(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMdPRFXIn_jH"
      },
      "source": [
        "# Define Parameters\n",
        "FLAGS = {}\n",
        "FLAGS['data_dir'] = \"/tmp/cifar\"\n",
        "FLAGS['batch_size'] = 64\n",
        "FLAGS['num_workers'] = 2\n",
        "FLAGS['learning_rate'] = 0.00001\n",
        "FLAGS['momentum'] = 0.9\n",
        "FLAGS['num_epochs'] = 100 \n",
        "FLAGS['num_cores'] = 8 if os.environ.get('TPU_NAME', None) else 1\n",
        "FLAGS['log_steps'] = 100\n",
        "FLAGS['metrics_debug'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF57q1swuvk5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "class GaussianBlur(object):\n",
        "    \"\"\"blur a single image on CPU\"\"\"\n",
        "    def __init__(self, kernel_size):\n",
        "        radias = kernel_size // 2\n",
        "        kernel_size = radias * 2 + 1\n",
        "        self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n",
        "                                stride=1, padding=0, bias=False, groups=3)\n",
        "        self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n",
        "                                stride=1, padding=0, bias=False, groups=3)\n",
        "        self.k = kernel_size\n",
        "        self.r = radias\n",
        "\n",
        "        self.blur = nn.Sequential(\n",
        "            nn.ReflectionPad2d(radias),\n",
        "            self.blur_h,\n",
        "            self.blur_v\n",
        "        )\n",
        "\n",
        "        self.pil_to_tensor = transforms.ToTensor()\n",
        "        self.tensor_to_pil = transforms.ToPILImage()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = self.pil_to_tensor(img).unsqueeze(0)\n",
        "\n",
        "        sigma = np.random.uniform(0.1, 2.0)\n",
        "        x = np.arange(-self.r, self.r + 1)\n",
        "        x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n",
        "        x = x / x.sum()\n",
        "        x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n",
        "\n",
        "        self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n",
        "        self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            img = self.blur(img)\n",
        "            img = img.squeeze()\n",
        "\n",
        "        img = self.tensor_to_pil(img)\n",
        "\n",
        "        return img\n",
        "\n",
        "class ContrastiveLearningViewGenerator(object):\n",
        "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
        "\n",
        "    def __init__(self, base_transform, n_views=2):\n",
        "        self.base_transform = base_transform\n",
        "        self.n_views = n_views\n",
        "\n",
        "    def __call__(self, x):\n",
        "        #return [self.base_transform(x) for i in range(self.n_views)][0]\n",
        "        return [self.base_transform(x) for i in range(self.n_views)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afsDoLfvuyBE"
      },
      "source": [
        "def get_simclr_pipeline_transform(size, s=1):\n",
        "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
        "    color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "    data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
        "                                            transforms.RandomHorizontalFlip(),\n",
        "                                            transforms.RandomApply([color_jitter], p=0.8),\n",
        "                                            transforms.RandomGrayscale(p=0.2),\n",
        "                                            GaussianBlur(kernel_size=int(0.1 * size)),\n",
        "                                            transforms.ToTensor()])\n",
        "    return data_transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMQOBeMTu0My"
      },
      "source": [
        "def info_nce_loss(features, device):\n",
        "\n",
        "    labels = torch.cat([torch.arange(FLAGS['batch_size']) for i in range(2)], dim=0) # modifique a 2\n",
        "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
        "\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    features = F.normalize(features, dim=1)\n",
        "\n",
        "    similarity_matrix = torch.matmul(features, features.T)\n",
        "    # assert similarity_matrix.shape == (\n",
        "    #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
        "    # assert similarity_matrix.shape == labels.shape\n",
        "\n",
        "    # discard the main diagonal from both: labels and similarities matrix\n",
        "    \n",
        "    mask = torch.eye(labels.shape[0], dtype=torch.bool).to(device)\n",
        "\n",
        "    labels = labels[~mask].view(labels.shape[0], -1)\n",
        "    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
        "    # assert similarity_matrix.shape == labels.shape\n",
        "\n",
        "    # select and combine multiple positives\n",
        "    positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
        "\n",
        "    # select only the negatives the negatives\n",
        "    negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
        "\n",
        "    logits = torch.cat([positives, negatives], dim=1)\n",
        "    labels = torch.zeros(logits.shape[0], dtype=torch.long).to(device)\n",
        "\n",
        "    TEMPERATURE = 0.07 # Yo lo Hardcodie\n",
        "\n",
        "    logits = logits / TEMPERATURE\n",
        "    return logits, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnjt7xOa2Qia"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class BaseSimCLRException(Exception):\n",
        "    \"\"\"Base exception\"\"\"\n",
        "\n",
        "\n",
        "class InvalidBackboneError(BaseSimCLRException):\n",
        "    \"\"\"Raised when the choice of backbone Convnet is invalid.\"\"\"\n",
        "\n",
        "\n",
        "class InvalidDatasetSelection(BaseSimCLRException):\n",
        "    \"\"\"Raised when the choice of dataset is invalid.\"\"\"\n",
        "\n",
        "\n",
        "class ResNetSimCLR(nn.Module):\n",
        "\n",
        "    def __init__(self, base_model, out_dim=128):\n",
        "        super(ResNetSimCLR, self).__init__()\n",
        "        self.resnet_dict = {\"resnet18\": models.resnet18(pretrained=False, num_classes=out_dim),\n",
        "                            \"resnet50\": models.resnet50(pretrained=True)}\n",
        "\n",
        "        self.backbone = self._get_basemodel(base_model)\n",
        "        dim_mlp = self.backbone.fc.in_features\n",
        "\n",
        "        # add mlp projection head\n",
        "        self.backbone.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.backbone.fc)\n",
        "\n",
        "    def _get_basemodel(self, model_name):\n",
        "        try:\n",
        "            model = self.resnet_dict[model_name]\n",
        "        except KeyError:\n",
        "            raise InvalidBackboneError(\n",
        "                \"Invalid backbone architecture. Check the config file and pass one of: resnet18 or resnet50\")\n",
        "        else:\n",
        "            return model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64OZ6LR5u3Xc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "4153554bdaf44b1e9ee7f3099f0776bd",
            "10a9e3e96b83467db539e365a98f1cdf",
            "309e730070034a2d99d97af4fc30bba2",
            "724c7355e538474fb777ff01e3e3534e",
            "74641cf9607a44038b65684c6b1dc025",
            "f80bec577ba44d639755877dc1e50870",
            "dfbf84ba276c4a7f9fde3e607ed86aae",
            "100da3aceb2d410487a64c75f011205c"
          ]
        },
        "outputId": "ff4051d1-f545-4899-d560-547f55001fb8"
      },
      "source": [
        "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
        "\n",
        "#WRAPPED_MODEL = xmp.MpModelWrapper(ResNetSimCLR(base_model='resnet50', out_dim=128))\n",
        "WRAPPED_MODEL = xmp.MpModelWrapper(ResNetSimCLR(base_model='resnet50'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4153554bdaf44b1e9ee7f3099f0776bd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vMl96KLoCq8"
      },
      "source": [
        "def train_resnet():\n",
        "  torch.manual_seed(1)\n",
        "\n",
        "  def get_dataset():\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(root=\"{}\".format(UNLABELED), \n",
        "                                         transform=ContrastiveLearningViewGenerator(\n",
        "                                        get_simclr_pipeline_transform(224),n_views=2))\n",
        "\n",
        "    return train_dataset\n",
        "  \n",
        "  # Using the serial executor avoids multiple processes\n",
        "  # to download the same data.\n",
        "  train_dataset = SERIAL_EXEC.run(get_dataset)\n",
        "  \n",
        "  train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "      train_dataset,\n",
        "      num_replicas=xm.xrt_world_size(),\n",
        "      rank=xm.get_ordinal(),\n",
        "      shuffle=True)\n",
        "  \n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=FLAGS['batch_size'],\n",
        "      sampler=train_sampler,\n",
        "      num_workers=FLAGS['num_workers'],\n",
        "      drop_last=True)\n",
        "  \n",
        "\n",
        "  # Scale learning rate to num cores\n",
        "  learning_rate = FLAGS['learning_rate'] * xm.xrt_world_size()\n",
        "\n",
        "  # Get loss function, optimizer, and model\n",
        "  device = xm.xla_device()\n",
        "  model = WRAPPED_MODEL.to(device)\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), \n",
        "                               learning_rate, \n",
        "                               weight_decay=5e-4)\n",
        "\n",
        "  criterion = torch.nn.CrossEntropyLoss().to(device)  # YO\n",
        "\n",
        "  def train_loop_fn(loader):\n",
        "    tracker = xm.RateTracker()\n",
        "    model.train()\n",
        "\n",
        "    for x, (data, _) in enumerate(loader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      data = torch.cat(data, dim=0)\n",
        "\n",
        "      output = model(data)\n",
        "      logits, labels = info_nce_loss(output, device) # YO\n",
        "\n",
        "      loss = criterion(logits, labels) # YO\n",
        "\n",
        "      loss.backward()\n",
        "      xm.optimizer_step(optimizer)\n",
        "      tracker.add(FLAGS['batch_size'])\n",
        "\n",
        "      top1, top5 = accuracy_func(logits, labels, topk=(1, 5))\n",
        "\n",
        "      if x % FLAGS['log_steps'] == 0:\n",
        "        print('[xla:{}]({}) Loss={:.5f} Rate={:.2f} GlobalRate={:.2f} Time={}'.format(\n",
        "            xm.get_ordinal(), x, loss.item(), tracker.rate(),\n",
        "            tracker.global_rate(), time.asctime()), flush=True)\n",
        "        print(f\"Top1 accuracy: {top1[0]}\")\n",
        "\n",
        "\n",
        "  # Train and eval loops\n",
        "  accuracy = 0.0\n",
        "  data, pred, target = None, None, None\n",
        "  for epoch in range(1, FLAGS['num_epochs'] + 1):\n",
        "    para_loader = pl.ParallelLoader(train_loader, [device])\n",
        "    train_loop_fn(para_loader.per_device_loader(device))\n",
        "    xm.master_print(\"Finished training epoch {}\".format(epoch))\n",
        "\n",
        "    xm.save(\n",
        "            model.state_dict(),\n",
        "            \"drive/MyDrive/Colab Notebooks/SimCLR/models/SimCLR-1-DR-pytorch/net-DR-SimCLR.pt\"\n",
        "        )\n",
        "\n",
        "    if FLAGS['metrics_debug']:\n",
        "      xm.master_print(met.metrics_report(), flush=True)\n",
        "\n",
        "\n",
        "  return accuracy, data, pred, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2nL4HmloEyl",
        "outputId": "f93d560c-ab9e-40e8-e4e6-4fd4534c7592"
      },
      "source": [
        "# Start training processes\n",
        "def _mp_fn(rank, flags):\n",
        "  global FLAGS\n",
        "  FLAGS = flags\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  accuracy, data, pred, target = train_resnet()\n",
        "\n",
        "\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'],\n",
        "          start_method='fork')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[xla:0](0) Loss=4.53163 Rate=2.80 GlobalRate=2.80 Time=Tue May 25 15:12:22 2021\n",
            "[xla:6](0) Loss=4.54450 Rate=2.66 GlobalRate=2.66 Time=Tue May 25 15:12:26 2021\n",
            "Top1 accuracy: 9.375\n",
            "Top1 accuracy: 9.375\n",
            "[xla:3](0) Loss=4.64167 Rate=2.49 GlobalRate=2.49 Time=Tue May 25 15:12:29 2021\n",
            "Top1 accuracy: 5.46875\n",
            "[xla:2](0) Loss=4.63687 Rate=2.45 GlobalRate=2.45 Time=Tue May 25 15:12:32 2021\n",
            "Top1 accuracy: 9.375\n",
            "[xla:7](0) Loss=4.65762 Rate=2.75 GlobalRate=2.75 Time=Tue May 25 15:12:34 2021\n",
            "Top1 accuracy: 4.6875\n",
            "[xla:4](0) Loss=4.65069 Rate=4.42 GlobalRate=4.42 Time=Tue May 25 15:12:50 2021\n",
            "Top1 accuracy: 7.03125\n",
            "[xla:5](0) Loss=4.61165 Rate=3.64 GlobalRate=3.64 Time=Tue May 25 15:12:55 2021\n",
            "Top1 accuracy: 1.5625\n",
            "[xla:1](0) Loss=4.64581 Rate=3.58 GlobalRate=3.58 Time=Tue May 25 15:12:57 2021\n",
            "Top1 accuracy: 7.03125\n",
            "[xla:6](100) Loss=1.32761 Rate=7.62 GlobalRate=10.60 Time=Tue May 25 15:22:12 2021\n",
            "[xla:3](100) Loss=1.42676 Rate=7.59 GlobalRate=10.63 Time=Tue May 25 15:22:12 2021\n",
            "[xla:5](100) Loss=1.35283 Rate=8.36 GlobalRate=11.26 Time=Tue May 25 15:22:12 2021\n",
            "[xla:0](100) Loss=1.33069 Rate=7.64 GlobalRate=10.56 Time=Tue May 25 15:22:12 2021\n",
            "[xla:1](100) Loss=1.30261 Rate=8.36 GlobalRate=11.30 Time=Tue May 25 15:22:12 2021\n",
            "[xla:4](100) Loss=1.52405 Rate=8.61 GlobalRate=11.22 Time=Tue May 25 15:22:12 2021\n",
            "[xla:2](100) Loss=1.39421 Rate=7.60 GlobalRate=10.67 Time=Tue May 25 15:22:12 2021\n",
            "Top1 accuracy: 68.75\n",
            "Top1 accuracy: 66.40625\n",
            "Top1 accuracy: 63.28125\n",
            "Top1 accuracy: 62.5\n",
            "Top1 accuracy: 64.84375\n",
            "Top1 accuracy: 64.84375\n",
            "Top1 accuracy: 64.84375\n",
            "[xla:7](100) Loss=1.55900 Rate=7.74 GlobalRate=10.75 Time=Tue May 25 15:22:12 2021\n",
            "Top1 accuracy: 60.9375\n",
            "Finished training epoch 1\n",
            "[xla:2](0) Loss=1.40604 Rate=3.23 GlobalRate=3.23 Time=Tue May 25 15:23:09 2021\n",
            "Top1 accuracy: 69.53125\n",
            "[xla:6](0) Loss=1.50324 Rate=2.57 GlobalRate=2.57 Time=Tue May 25 15:23:14 2021\n",
            "Top1 accuracy: 65.625\n",
            "[xla:1](0) Loss=1.34972 Rate=2.42 GlobalRate=2.42 Time=Tue May 25 15:23:15 2021\n",
            "Top1 accuracy: 67.96875\n",
            "[xla:7](0) Loss=1.35978 Rate=1.76 GlobalRate=1.76 Time=Tue May 25 15:23:25 2021\n",
            "Top1 accuracy: 65.625\n",
            "[xla:0](0) Loss=1.30776 Rate=1.68 GlobalRate=1.68 Time=Tue May 25 15:23:27 2021\n",
            "Top1 accuracy: 67.1875\n",
            "[xla:4](0) Loss=1.46012 Rate=1.64 GlobalRate=1.64 Time=Tue May 25 15:23:28 2021\n",
            "Top1 accuracy: 61.71875\n",
            "[xla:3](0) Loss=1.36065 Rate=1.46 GlobalRate=1.46 Time=Tue May 25 15:23:33 2021\n",
            "Top1 accuracy: 66.40625\n",
            "[xla:5](0) Loss=1.41971 Rate=1.41 GlobalRate=1.41 Time=Tue May 25 15:23:34 2021\n",
            "Top1 accuracy: 67.1875\n",
            "[xla:7](100) Loss=0.99178 Rate=7.87 GlobalRate=11.29 Time=Tue May 25 15:32:21 2021\n",
            "[xla:1](100) Loss=1.29054 Rate=8.00 GlobalRate=11.29 Time=Tue May 25 15:32:21 2021\n",
            "[xla:5](100) Loss=0.90768 Rate=7.85 GlobalRate=11.29 Time=Tue May 25 15:32:21 2021\n",
            "[xla:4](100) Loss=1.02335 Rate=7.85 GlobalRate=11.29 Time=Tue May 25 15:32:21 2021\n",
            "[xla:2](100) Loss=1.17065 Rate=8.24 GlobalRate=11.29 Time=Tue May 25 15:32:21 2021\n",
            "Top1 accuracy: 75.78125\n",
            "Top1 accuracy: 69.53125\n",
            "Top1 accuracy: 78.90625\n",
            "Top1 accuracy: 70.3125\n",
            "Top1 accuracy: 76.5625\n",
            "[xla:6](100) Loss=0.96438 Rate=8.03 GlobalRate=11.28 Time=Tue May 25 15:32:22 2021\n",
            "Top1 accuracy: 74.21875\n",
            "[xla:3](100) Loss=1.21218 Rate=7.84 GlobalRate=11.27 Time=Tue May 25 15:32:22 2021\n",
            "[xla:0](100) Loss=1.22777 Rate=7.85 GlobalRate=11.27 Time=Tue May 25 15:32:22 2021\n",
            "Top1 accuracy: 71.875\n",
            "Top1 accuracy: 72.65625\n",
            "Finished training epoch 2\n",
            "[xla:7](0) Loss=0.94826 Rate=2.75 GlobalRate=2.75 Time=Tue May 25 15:33:20 2021\n",
            "Top1 accuracy: 79.6875\n",
            "[xla:1](0) Loss=0.81091 Rate=2.37 GlobalRate=2.37 Time=Tue May 25 15:33:23 2021\n",
            "Top1 accuracy: 79.6875\n",
            "[xla:2](0) Loss=1.02491 Rate=2.06 GlobalRate=2.06 Time=Tue May 25 15:33:27 2021\n",
            "Top1 accuracy: 78.90625\n",
            "[xla:6](0) Loss=0.97159 Rate=1.70 GlobalRate=1.70 Time=Tue May 25 15:33:34 2021\n",
            "Top1 accuracy: 75.0\n",
            "[xla:3](0) Loss=0.96096 Rate=1.63 GlobalRate=1.63 Time=Tue May 25 15:33:36 2021\n",
            "Top1 accuracy: 78.125\n",
            "[xla:5](0) Loss=0.80701 Rate=1.54 GlobalRate=1.54 Time=Tue May 25 15:33:38 2021\n",
            "Top1 accuracy: 80.46875\n",
            "[xla:4](0) Loss=1.11397 Rate=1.52 GlobalRate=1.52 Time=Tue May 25 15:33:39 2021\n",
            "Top1 accuracy: 69.53125\n",
            "[xla:0](0) Loss=0.82248 Rate=1.36 GlobalRate=1.36 Time=Tue May 25 15:33:44 2021\n",
            "Top1 accuracy: 80.46875\n",
            "[xla:7](100) Loss=0.66533 Rate=8.10 GlobalRate=11.31 Time=Tue May 25 15:42:28 2021\n",
            "[xla:3](100) Loss=0.63583 Rate=7.87 GlobalRate=11.31 Time=Tue May 25 15:42:28 2021\n",
            "[xla:2](100) Loss=0.64256 Rate=7.93 GlobalRate=11.31 Time=Tue May 25 15:42:28 2021\n",
            "[xla:4](100) Loss=0.72409 Rate=7.86 GlobalRate=11.31 Time=Tue May 25 15:42:28 2021\n",
            "[xla:1](100) Loss=0.47044 Rate=8.00 GlobalRate=11.31 Time=Tue May 25 15:42:28 2021\n",
            "[xla:6](100) Loss=0.69824 Rate=7.87 GlobalRate=11.31 Time=Tue May 25 15:42:28 2021\n",
            "Top1 accuracy: 87.5\n",
            "Top1 accuracy: 85.15625\n",
            "Top1 accuracy: 87.5\n",
            "Top1 accuracy: 82.8125\n",
            "Top1 accuracy: 89.84375\n",
            "Top1 accuracy: 84.375\n",
            "[xla:0](100) Loss=0.66217 Rate=7.86 GlobalRate=11.30 Time=Tue May 25 15:42:28 2021\n",
            "Top1 accuracy: 79.6875\n",
            "[xla:5](100) Loss=0.59859 Rate=7.84 GlobalRate=11.29 Time=Tue May 25 15:42:29 2021\n",
            "Top1 accuracy: 86.71875\n",
            "Finished training epoch 3\n",
            "[xla:4](0) Loss=0.86619 Rate=2.66 GlobalRate=2.66 Time=Tue May 25 15:43:29 2021\n",
            "Top1 accuracy: 77.34375\n",
            "[xla:7](0) Loss=0.72823 Rate=2.35 GlobalRate=2.35 Time=Tue May 25 15:43:32 2021\n",
            "Top1 accuracy: 85.15625\n",
            "[xla:6](0) Loss=0.82385 Rate=2.27 GlobalRate=2.27 Time=Tue May 25 15:43:33 2021\n",
            "[xla:5](0) Loss=0.62187 Rate=2.27 GlobalRate=2.27 Time=Tue May 25 15:43:33 2021\n",
            "Top1 accuracy: 73.4375\n",
            "Top1 accuracy: 84.375\n",
            "[xla:2](0) Loss=0.80934 Rate=2.13 GlobalRate=2.13 Time=Tue May 25 15:43:35 2021\n",
            "Top1 accuracy: 82.03125\n",
            "[xla:0](0) Loss=0.72093 Rate=1.47 GlobalRate=1.47 Time=Tue May 25 15:43:49 2021\n",
            "Top1 accuracy: 82.03125\n",
            "[xla:3](0) Loss=0.97598 Rate=1.44 GlobalRate=1.44 Time=Tue May 25 15:43:50 2021\n",
            "Top1 accuracy: 79.6875\n",
            "[xla:1](0) Loss=0.71708 Rate=1.31 GlobalRate=1.31 Time=Tue May 25 15:43:54 2021\n",
            "Top1 accuracy: 82.03125\n",
            "[xla:6](100) Loss=1.16621 Rate=7.89 GlobalRate=11.18 Time=Tue May 25 15:52:43 2021\n",
            "[xla:4](100) Loss=0.71271 Rate=8.00 GlobalRate=11.18 Time=Tue May 25 15:52:43 2021\n",
            "[xla:3](100) Loss=0.73134 Rate=7.77 GlobalRate=11.18 Time=Tue May 25 15:52:43 2021\n",
            "[xla:0](100) Loss=0.62704 Rate=7.77 GlobalRate=11.18 Time=Tue May 25 15:52:43 2021\n",
            "Top1 accuracy: 75.78125\n",
            "Top1 accuracy: 82.8125\n",
            "[xla:5](100) Loss=0.76409 Rate=7.89 GlobalRate=11.18 Time=Tue May 25 15:52:43 2021\n",
            "Top1 accuracy: 83.59375\n",
            "Top1 accuracy: 83.59375\n",
            "Top1 accuracy: 82.03125\n",
            "[xla:7](100) Loss=0.91240 Rate=7.90 GlobalRate=11.17 Time=Tue May 25 15:52:44 2021\n",
            "Top1 accuracy: 81.25\n",
            "[xla:1](100) Loss=0.82083 Rate=7.75 GlobalRate=11.14 Time=Tue May 25 15:52:45 2021\n",
            "[xla:2](100) Loss=1.03627 Rate=7.83 GlobalRate=11.14 Time=Tue May 25 15:52:46 2021\n",
            "Top1 accuracy: 80.46875\n",
            "Top1 accuracy: 74.21875\n",
            "Finished training epoch 4\n",
            "[xla:0](0) Loss=0.63397 Rate=2.56 GlobalRate=2.56 Time=Tue May 25 15:53:40 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:6](0) Loss=0.65521 Rate=2.39 GlobalRate=2.39 Time=Tue May 25 15:53:41 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:4](0) Loss=0.56947 Rate=2.11 GlobalRate=2.11 Time=Tue May 25 15:53:45 2021\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:3](0) Loss=0.59599 Rate=1.92 GlobalRate=1.92 Time=Tue May 25 15:53:48 2021\n",
            "Top1 accuracy: 84.375\n",
            "[xla:2](0) Loss=0.69258 Rate=1.83 GlobalRate=1.83 Time=Tue May 25 15:53:49 2021\n",
            "Top1 accuracy: 83.59375\n",
            "[xla:5](0) Loss=0.53134 Rate=1.75 GlobalRate=1.75 Time=Tue May 25 15:53:51 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:1](0) Loss=0.62434 Rate=1.58 GlobalRate=1.58 Time=Tue May 25 15:53:55 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:7](0) Loss=0.60764 Rate=1.36 GlobalRate=1.36 Time=Tue May 25 15:54:02 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:2](100) Loss=0.38890 Rate=7.98 GlobalRate=11.44 Time=Tue May 25 16:02:40 2021\n",
            "[xla:3](100) Loss=0.77567 Rate=7.99 GlobalRate=11.44 Time=Tue May 25 16:02:40 2021\n",
            "[xla:5](100) Loss=0.47303 Rate=7.96 GlobalRate=11.44 Time=Tue May 25 16:02:40 2021\n",
            "[xla:4](100) Loss=0.50941 Rate=8.02 GlobalRate=11.44 Time=Tue May 25 16:02:40 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 78.90625\n",
            "Top1 accuracy: 89.84375\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:7](100) Loss=0.51185 Rate=7.95 GlobalRate=11.43 Time=Tue May 25 16:02:40 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:0](100) Loss=0.51569 Rate=8.04 GlobalRate=11.29 Time=Tue May 25 16:02:47 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:6](100) Loss=0.45821 Rate=7.83 GlobalRate=11.04 Time=Tue May 25 16:03:00 2021\n",
            "[xla:1](100) Loss=0.47195 Rate=7.68 GlobalRate=11.04 Time=Tue May 25 16:03:00 2021\n",
            "Top1 accuracy: 89.84375\n",
            "Top1 accuracy: 85.15625\n",
            "Finished training epoch 5\n",
            "[xla:6](0) Loss=0.79281 Rate=2.64 GlobalRate=2.64 Time=Tue May 25 16:03:47 2021\n",
            "Top1 accuracy: 78.125\n",
            "[xla:0](0) Loss=0.78578 Rate=2.54 GlobalRate=2.54 Time=Tue May 25 16:03:48 2021\n",
            "[xla:4](0) Loss=0.79243 Rate=2.53 GlobalRate=2.53 Time=Tue May 25 16:03:48 2021\n",
            "Top1 accuracy: 81.25\n",
            "Top1 accuracy: 82.03125\n",
            "[xla:2](0) Loss=0.74069 Rate=2.01 GlobalRate=2.01 Time=Tue May 25 16:03:54 2021\n",
            "Top1 accuracy: 82.8125\n",
            "[xla:7](0) Loss=0.62947 Rate=1.79 GlobalRate=1.79 Time=Tue May 25 16:03:58 2021\n",
            "Top1 accuracy: 81.25\n",
            "[xla:1](0) Loss=0.60954 Rate=1.40 GlobalRate=1.40 Time=Tue May 25 16:04:08 2021\n",
            "Top1 accuracy: 83.59375\n",
            "[xla:3](0) Loss=0.65279 Rate=1.38 GlobalRate=1.38 Time=Tue May 25 16:04:09 2021\n",
            "[xla:5](0) Loss=0.53310 Rate=1.37 GlobalRate=1.37 Time=Tue May 25 16:04:09 2021\n",
            "Top1 accuracy: 82.8125\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:2](100) Loss=0.69429 Rate=8.06 GlobalRate=11.52 Time=Tue May 25 16:12:44 2021\n",
            "Top1 accuracy: 83.59375\n",
            "[xla:6](100) Loss=0.61773 Rate=8.20 GlobalRate=11.51 Time=Tue May 25 16:12:44 2021\n",
            "Top1 accuracy: 85.15625\n",
            "[xla:4](100) Loss=0.78768 Rate=8.17 GlobalRate=11.50 Time=Tue May 25 16:12:44 2021\n",
            "Top1 accuracy: 82.8125\n",
            "[xla:5](100) Loss=0.67845 Rate=7.82 GlobalRate=11.25 Time=Tue May 25 16:12:57 2021\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:1](100) Loss=0.56682 Rate=7.78 GlobalRate=11.19 Time=Tue May 25 16:13:00 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:0](100) Loss=0.58333 Rate=7.95 GlobalRate=11.16 Time=Tue May 25 16:13:02 2021\n",
            "[xla:7](100) Loss=0.48979 Rate=7.78 GlobalRate=11.16 Time=Tue May 25 16:13:02 2021\n",
            "Top1 accuracy: 85.15625\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:3](100) Loss=0.49555 Rate=7.70 GlobalRate=11.07 Time=Tue May 25 16:13:07 2021\n",
            "Top1 accuracy: 85.9375\n",
            "Finished training epoch 6\n",
            "[xla:4](0) Loss=0.30438 Rate=2.30 GlobalRate=2.30 Time=Tue May 25 16:14:00 2021\n",
            "[xla:6](0) Loss=0.37998 Rate=2.29 GlobalRate=2.29 Time=Tue May 25 16:14:00 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:1](0) Loss=0.37826 Rate=2.01 GlobalRate=2.01 Time=Tue May 25 16:14:04 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:3](0) Loss=0.57306 Rate=1.90 GlobalRate=1.90 Time=Tue May 25 16:14:06 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:2](0) Loss=0.44454 Rate=1.85 GlobalRate=1.85 Time=Tue May 25 16:14:07 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:7](0) Loss=0.42161 Rate=1.80 GlobalRate=1.80 Time=Tue May 25 16:14:08 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:5](0) Loss=0.34842 Rate=1.62 GlobalRate=1.62 Time=Tue May 25 16:14:12 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:0](0) Loss=0.38349 Rate=1.29 GlobalRate=1.29 Time=Tue May 25 16:14:22 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:0](100) Loss=0.75115 Rate=7.85 GlobalRate=11.28 Time=Tue May 25 16:23:06 2021\n",
            "[xla:2](100) Loss=0.65515 Rate=7.87 GlobalRate=11.28 Time=Tue May 25 16:23:06 2021\n",
            "[xla:3](100) Loss=0.69032 Rate=7.88 GlobalRate=11.28 Time=Tue May 25 16:23:06 2021\n",
            "[xla:1](100) Loss=0.51494 Rate=7.90 GlobalRate=11.28 Time=Tue May 25 16:23:06 2021\n",
            "[xla:6](100) Loss=0.55196 Rate=7.96 GlobalRate=11.28 Time=Tue May 25 16:23:06 2021\n",
            "[xla:4](100) Loss=0.60391 Rate=7.96 GlobalRate=11.28 Time=Tue May 25 16:23:06 2021\n",
            "Top1 accuracy: 80.46875\n",
            "Top1 accuracy: 83.59375\n",
            "Top1 accuracy: 80.46875\n",
            "Top1 accuracy: 85.9375\n",
            "Top1 accuracy: 85.15625\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:5](100) Loss=0.69320 Rate=7.80 GlobalRate=11.22 Time=Tue May 25 16:23:09 2021\n",
            "Top1 accuracy: 84.375\n",
            "[xla:7](100) Loss=0.67673 Rate=7.80 GlobalRate=11.19 Time=Tue May 25 16:23:10 2021\n",
            "Top1 accuracy: 82.8125\n",
            "Finished training epoch 7\n",
            "[xla:4](0) Loss=0.40475 Rate=2.42 GlobalRate=2.42 Time=Tue May 25 16:24:09 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:6](0) Loss=0.37228 Rate=2.33 GlobalRate=2.33 Time=Tue May 25 16:24:09 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:3](0) Loss=0.38572 Rate=2.05 GlobalRate=2.05 Time=Tue May 25 16:24:13 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:2](0) Loss=0.36963 Rate=2.01 GlobalRate=2.01 Time=Tue May 25 16:24:14 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:1](0) Loss=0.50221 Rate=1.76 GlobalRate=1.76 Time=Tue May 25 16:24:18 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:0](0) Loss=0.41232 Rate=1.71 GlobalRate=1.71 Time=Tue May 25 16:24:19 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:7](0) Loss=0.36164 Rate=1.42 GlobalRate=1.42 Time=Tue May 25 16:24:27 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:5](0) Loss=0.47784 Rate=1.29 GlobalRate=1.29 Time=Tue May 25 16:24:32 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:2](100) Loss=0.46283 Rate=8.00 GlobalRate=11.43 Time=Tue May 25 16:33:08 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:7](100) Loss=0.33869 Rate=7.94 GlobalRate=11.43 Time=Tue May 25 16:33:08 2021\n",
            "[xla:3](100) Loss=0.48087 Rate=8.00 GlobalRate=11.42 Time=Tue May 25 16:33:08 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 90.625\n",
            "[xla:0](100) Loss=0.40214 Rate=7.94 GlobalRate=11.41 Time=Tue May 25 16:33:08 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:4](100) Loss=0.40584 Rate=8.07 GlobalRate=11.39 Time=Tue May 25 16:33:09 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:5](100) Loss=0.51143 Rate=7.81 GlobalRate=11.22 Time=Tue May 25 16:33:18 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:6](100) Loss=0.41465 Rate=7.83 GlobalRate=11.07 Time=Tue May 25 16:33:26 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:1](100) Loss=0.29303 Rate=7.71 GlobalRate=11.05 Time=Tue May 25 16:33:27 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Finished training epoch 8\n",
            "[xla:4](0) Loss=0.70540 Rate=2.87 GlobalRate=2.87 Time=Tue May 25 16:34:14 2021\n",
            "Top1 accuracy: 82.03125\n",
            "[xla:0](0) Loss=0.49312 Rate=2.72 GlobalRate=2.72 Time=Tue May 25 16:34:15 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:2](0) Loss=0.52435 Rate=1.98 GlobalRate=1.98 Time=Tue May 25 16:34:24 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:5](0) Loss=0.56604 Rate=1.75 GlobalRate=1.75 Time=Tue May 25 16:34:28 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:6](0) Loss=0.62110 Rate=1.58 GlobalRate=1.58 Time=Tue May 25 16:34:32 2021\n",
            "Top1 accuracy: 84.375\n",
            "[xla:7](0) Loss=0.39229 Rate=1.54 GlobalRate=1.54 Time=Tue May 25 16:34:33 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:3](0) Loss=0.78100 Rate=1.52 GlobalRate=1.52 Time=Tue May 25 16:34:34 2021\n",
            "Top1 accuracy: 82.03125\n",
            "[xla:1](0) Loss=0.59470 Rate=1.38 GlobalRate=1.38 Time=Tue May 25 16:34:38 2021\n",
            "Top1 accuracy: 83.59375\n",
            "[xla:2](100) Loss=0.48660 Rate=7.95 GlobalRate=11.36 Time=Tue May 25 16:43:20 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:7](100) Loss=0.35246 Rate=7.89 GlobalRate=11.35 Time=Tue May 25 16:43:21 2021\n",
            "[xla:3](100) Loss=0.50947 Rate=7.89 GlobalRate=11.35 Time=Tue May 25 16:43:21 2021\n",
            "[xla:1](100) Loss=0.45665 Rate=7.89 GlobalRate=11.35 Time=Tue May 25 16:43:21 2021\n",
            "[xla:6](100) Loss=0.37192 Rate=7.89 GlobalRate=11.35 Time=Tue May 25 16:43:21 2021\n",
            "Top1 accuracy: 86.71875\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:4](100) Loss=0.43240 Rate=8.16 GlobalRate=11.33 Time=Tue May 25 16:43:22 2021\n",
            "[xla:5](100) Loss=0.40555 Rate=7.89 GlobalRate=11.33 Time=Tue May 25 16:43:22 2021\n",
            "Top1 accuracy: 89.0625\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:0](100) Loss=0.24700 Rate=7.92 GlobalRate=11.04 Time=Tue May 25 16:43:37 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 9\n",
            "[xla:0](0) Loss=0.46573 Rate=2.45 GlobalRate=2.45 Time=Tue May 25 16:44:25 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:1](0) Loss=0.65749 Rate=2.30 GlobalRate=2.30 Time=Tue May 25 16:44:27 2021\n",
            "Top1 accuracy: 83.59375\n",
            "[xla:3](0) Loss=0.60220 Rate=1.96 GlobalRate=1.96 Time=Tue May 25 16:44:31 2021\n",
            "Top1 accuracy: 85.15625\n",
            "[xla:7](0) Loss=0.42718 Rate=1.91 GlobalRate=1.91 Time=Tue May 25 16:44:32 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:4](0) Loss=0.36752 Rate=1.86 GlobalRate=1.86 Time=Tue May 25 16:44:33 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:5](0) Loss=0.47256 Rate=1.76 GlobalRate=1.76 Time=Tue May 25 16:44:35 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:6](0) Loss=0.46578 Rate=1.40 GlobalRate=1.40 Time=Tue May 25 16:44:45 2021\n",
            "Top1 accuracy: 85.9375\n",
            "[xla:2](0) Loss=0.58295 Rate=1.37 GlobalRate=1.37 Time=Tue May 25 16:44:46 2021\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:7](100) Loss=0.39104 Rate=7.97 GlobalRate=11.41 Time=Tue May 25 16:53:25 2021\n",
            "[xla:2](100) Loss=0.69180 Rate=7.93 GlobalRate=11.40 Time=Tue May 25 16:53:26 2021\n",
            "[xla:5](100) Loss=0.43972 Rate=7.94 GlobalRate=11.40 Time=Tue May 25 16:53:26 2021\n",
            "Top1 accuracy: 90.625\n",
            "Top1 accuracy: 80.46875\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:1](100) Loss=0.61243 Rate=7.97 GlobalRate=11.28 Time=Tue May 25 16:53:32 2021\n",
            "Top1 accuracy: 83.59375\n",
            "[xla:3](100) Loss=0.32108 Rate=7.83 GlobalRate=11.19 Time=Tue May 25 16:53:37 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:4](100) Loss=0.40254 Rate=7.75 GlobalRate=11.10 Time=Tue May 25 16:53:41 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:6](100) Loss=0.44117 Rate=7.69 GlobalRate=11.07 Time=Tue May 25 16:53:43 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:0](100) Loss=0.48645 Rate=7.83 GlobalRate=11.01 Time=Tue May 25 16:53:46 2021\n",
            "Top1 accuracy: 90.625\n",
            "Finished training epoch 10\n",
            "[xla:3](0) Loss=0.45683 Rate=2.83 GlobalRate=2.83 Time=Tue May 25 16:54:31 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:1](0) Loss=0.54769 Rate=2.30 GlobalRate=2.30 Time=Tue May 25 16:54:37 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:2](0) Loss=0.50482 Rate=1.93 GlobalRate=1.93 Time=Tue May 25 16:54:42 2021\n",
            "Top1 accuracy: 85.15625\n",
            "[xla:7](0) Loss=0.44099 Rate=1.83 GlobalRate=1.83 Time=Tue May 25 16:54:44 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:0](0) Loss=0.43711 Rate=1.77 GlobalRate=1.77 Time=Tue May 25 16:54:45 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:6](0) Loss=0.61285 Rate=1.51 GlobalRate=1.51 Time=Tue May 25 16:54:51 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:5](0) Loss=0.54202 Rate=1.49 GlobalRate=1.49 Time=Tue May 25 16:54:52 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:4](0) Loss=0.39444 Rate=1.33 GlobalRate=1.33 Time=Tue May 25 16:54:57 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:4](100) Loss=0.38310 Rate=7.88 GlobalRate=11.33 Time=Tue May 25 17:03:40 2021\n",
            "[xla:1](100) Loss=0.27092 Rate=7.99 GlobalRate=11.32 Time=Tue May 25 17:03:40 2021\n",
            "[xla:2](100) Loss=0.38307 Rate=7.91 GlobalRate=11.32 Time=Tue May 25 17:03:40 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 90.625\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:3](100) Loss=0.27664 Rate=8.13 GlobalRate=11.31 Time=Tue May 25 17:03:40 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](100) Loss=0.29080 Rate=7.87 GlobalRate=11.30 Time=Tue May 25 17:03:41 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:5](100) Loss=0.38814 Rate=7.83 GlobalRate=11.27 Time=Tue May 25 17:03:42 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:7](100) Loss=0.36366 Rate=7.83 GlobalRate=11.23 Time=Tue May 25 17:03:45 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:6](100) Loss=0.28326 Rate=7.78 GlobalRate=11.19 Time=Tue May 25 17:03:47 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 11\n",
            "[xla:0](0) Loss=0.32638 Rate=3.43 GlobalRate=3.43 Time=Tue May 25 17:04:36 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](0) Loss=0.32010 Rate=3.23 GlobalRate=3.23 Time=Tue May 25 17:04:37 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](0) Loss=0.34971 Rate=1.85 GlobalRate=1.85 Time=Tue May 25 17:04:51 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:6](0) Loss=0.42053 Rate=1.78 GlobalRate=1.78 Time=Tue May 25 17:04:53 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:7](0) Loss=0.39217 Rate=1.70 GlobalRate=1.70 Time=Tue May 25 17:04:55 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:1](0) Loss=0.49014 Rate=1.61 GlobalRate=1.61 Time=Tue May 25 17:04:57 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:4](0) Loss=0.46851 Rate=1.54 GlobalRate=1.54 Time=Tue May 25 17:04:58 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:5](0) Loss=0.41178 Rate=1.32 GlobalRate=1.32 Time=Tue May 25 17:05:05 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:4](100) Loss=0.44661 Rate=8.08 GlobalRate=11.63 Time=Tue May 25 17:13:33 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:2](100) Loss=0.26342 Rate=8.27 GlobalRate=11.34 Time=Tue May 25 17:13:47 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](100) Loss=0.25747 Rate=7.90 GlobalRate=11.33 Time=Tue May 25 17:13:47 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](100) Loss=0.34153 Rate=8.29 GlobalRate=11.27 Time=Tue May 25 17:13:50 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:1](100) Loss=0.31546 Rate=7.83 GlobalRate=11.26 Time=Tue May 25 17:13:51 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:6](100) Loss=0.31026 Rate=7.81 GlobalRate=11.21 Time=Tue May 25 17:13:54 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:5](100) Loss=0.25544 Rate=7.78 GlobalRate=11.18 Time=Tue May 25 17:13:55 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:7](100) Loss=0.34319 Rate=7.76 GlobalRate=11.14 Time=Tue May 25 17:13:57 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Finished training epoch 12\n",
            "[xla:5](0) Loss=0.41678 Rate=2.38 GlobalRate=2.38 Time=Tue May 25 17:14:51 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:4](0) Loss=0.45960 Rate=2.33 GlobalRate=2.33 Time=Tue May 25 17:14:52 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:3](0) Loss=0.27976 Rate=2.21 GlobalRate=2.21 Time=Tue May 25 17:14:53 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:2](0) Loss=0.35304 Rate=1.96 GlobalRate=1.96 Time=Tue May 25 17:14:57 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:1](0) Loss=0.40059 Rate=1.89 GlobalRate=1.89 Time=Tue May 25 17:14:58 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:6](0) Loss=0.30222 Rate=1.63 GlobalRate=1.63 Time=Tue May 25 17:15:04 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:7](0) Loss=0.30293 Rate=1.58 GlobalRate=1.58 Time=Tue May 25 17:15:05 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](0) Loss=0.38398 Rate=1.54 GlobalRate=1.54 Time=Tue May 25 17:15:06 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:2](100) Loss=0.45107 Rate=7.95 GlobalRate=11.37 Time=Tue May 25 17:23:53 2021\n",
            "[xla:3](100) Loss=0.35232 Rate=8.00 GlobalRate=11.37 Time=Tue May 25 17:23:53 2021\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:6](100) Loss=0.43139 Rate=7.91 GlobalRate=11.37 Time=Tue May 25 17:23:53 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:4](100) Loss=0.45149 Rate=8.01 GlobalRate=11.34 Time=Tue May 25 17:23:54 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:7](100) Loss=0.33796 Rate=7.85 GlobalRate=11.30 Time=Tue May 25 17:23:57 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](100) Loss=0.36373 Rate=7.84 GlobalRate=11.23 Time=Tue May 25 17:24:00 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:0](100) Loss=0.50684 Rate=7.78 GlobalRate=11.18 Time=Tue May 25 17:24:02 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:5](100) Loss=0.32049 Rate=7.84 GlobalRate=11.06 Time=Tue May 25 17:24:09 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Finished training epoch 13\n",
            "[xla:3](0) Loss=0.34325 Rate=2.74 GlobalRate=2.74 Time=Tue May 25 17:24:56 2021\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:6](0) Loss=0.21822 Rate=2.60 GlobalRate=2.60 Time=Tue May 25 17:24:57 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:7](0) Loss=0.31206 Rate=2.55 GlobalRate=2.55 Time=Tue May 25 17:24:58 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](0) Loss=0.34915 Rate=1.76 GlobalRate=1.76 Time=Tue May 25 17:25:09 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](0) Loss=0.37149 Rate=1.56 GlobalRate=1.56 Time=Tue May 25 17:25:14 2021\n",
            "[xla:0](0) Loss=0.28970 Rate=1.56 GlobalRate=1.56 Time=Tue May 25 17:25:14 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](0) Loss=0.31272 Rate=1.37 GlobalRate=1.37 Time=Tue May 25 17:25:19 2021\n",
            "[xla:5](0) Loss=0.40003 Rate=1.37 GlobalRate=1.37 Time=Tue May 25 17:25:19 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:3](100) Loss=0.29367 Rate=8.28 GlobalRate=11.58 Time=Tue May 25 17:33:51 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:2](100) Loss=0.46663 Rate=7.87 GlobalRate=11.32 Time=Tue May 25 17:34:04 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:5](100) Loss=0.43850 Rate=7.83 GlobalRate=11.27 Time=Tue May 25 17:34:06 2021\n",
            "[xla:4](100) Loss=0.38789 Rate=7.85 GlobalRate=11.26 Time=Tue May 25 17:34:07 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 90.625\n",
            "[xla:1](100) Loss=0.34831 Rate=7.81 GlobalRate=11.23 Time=Tue May 25 17:34:08 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:0](100) Loss=0.31642 Rate=7.79 GlobalRate=11.20 Time=Tue May 25 17:34:10 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:7](100) Loss=0.35507 Rate=7.94 GlobalRate=11.14 Time=Tue May 25 17:34:13 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:6](100) Loss=0.38695 Rate=7.88 GlobalRate=11.04 Time=Tue May 25 17:34:18 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Finished training epoch 14\n",
            "[xla:7](0) Loss=0.28331 Rate=3.07 GlobalRate=3.07 Time=Tue May 25 17:35:04 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:0](0) Loss=0.32004 Rate=2.73 GlobalRate=2.73 Time=Tue May 25 17:35:07 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](0) Loss=0.49297 Rate=2.05 GlobalRate=2.05 Time=Tue May 25 17:35:15 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:3](0) Loss=0.54881 Rate=1.99 GlobalRate=1.99 Time=Tue May 25 17:35:15 2021\n",
            "Top1 accuracy: 85.15625\n",
            "[xla:4](0) Loss=0.24719 Rate=1.70 GlobalRate=1.70 Time=Tue May 25 17:35:21 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:5](0) Loss=0.36755 Rate=1.58 GlobalRate=1.58 Time=Tue May 25 17:35:24 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](0) Loss=0.40472 Rate=1.35 GlobalRate=1.35 Time=Tue May 25 17:35:31 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:6](0) Loss=0.35488 Rate=1.34 GlobalRate=1.34 Time=Tue May 25 17:35:31 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:7](100) Loss=0.24904 Rate=8.18 GlobalRate=11.28 Time=Tue May 25 17:44:16 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](100) Loss=0.41858 Rate=7.84 GlobalRate=11.27 Time=Tue May 25 17:44:17 2021\n",
            "[xla:4](100) Loss=0.47896 Rate=7.84 GlobalRate=11.27 Time=Tue May 25 17:44:17 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 85.9375\n",
            "[xla:5](100) Loss=0.34957 Rate=7.83 GlobalRate=11.26 Time=Tue May 25 17:44:17 2021\n",
            "[xla:6](100) Loss=0.30725 Rate=7.83 GlobalRate=11.26 Time=Tue May 25 17:44:17 2021\n",
            "[xla:0](100) Loss=0.46410 Rate=8.07 GlobalRate=11.26 Time=Tue May 25 17:44:17 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 90.625\n",
            "[xla:3](100) Loss=0.31634 Rate=7.79 GlobalRate=11.13 Time=Tue May 25 17:44:24 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:1](100) Loss=0.34691 Rate=7.73 GlobalRate=11.01 Time=Tue May 25 17:44:30 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Finished training epoch 15\n",
            "[xla:5](0) Loss=0.39166 Rate=2.59 GlobalRate=2.59 Time=Tue May 25 17:45:18 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:2](0) Loss=0.48275 Rate=2.38 GlobalRate=2.38 Time=Tue May 25 17:45:20 2021\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:6](0) Loss=0.48104 Rate=1.99 GlobalRate=1.99 Time=Tue May 25 17:45:25 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:7](0) Loss=0.25677 Rate=1.97 GlobalRate=1.97 Time=Tue May 25 17:45:26 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](0) Loss=0.38675 Rate=1.80 GlobalRate=1.80 Time=Tue May 25 17:45:29 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:0](0) Loss=0.33623 Rate=1.63 GlobalRate=1.63 Time=Tue May 25 17:45:32 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:3](0) Loss=0.51609 Rate=1.56 GlobalRate=1.56 Time=Tue May 25 17:45:34 2021\n",
            "Top1 accuracy: 87.5\n",
            "[xla:1](0) Loss=0.42086 Rate=1.39 GlobalRate=1.39 Time=Tue May 25 17:45:39 2021\n",
            "Top1 accuracy: 85.9375\n",
            "[xla:7](100) Loss=0.24975 Rate=8.01 GlobalRate=11.46 Time=Tue May 25 17:54:17 2021\n",
            "[xla:6](100) Loss=0.18757 Rate=8.02 GlobalRate=11.46 Time=Tue May 25 17:54:17 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 96.875\n",
            "[xla:4](100) Loss=0.22653 Rate=7.98 GlobalRate=11.45 Time=Tue May 25 17:54:18 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:2](100) Loss=0.17529 Rate=8.01 GlobalRate=11.32 Time=Tue May 25 17:54:24 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:5](100) Loss=0.34737 Rate=8.02 GlobalRate=11.25 Time=Tue May 25 17:54:28 2021\n",
            "[xla:1](100) Loss=0.16262 Rate=7.82 GlobalRate=11.25 Time=Tue May 25 17:54:28 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:3](100) Loss=0.23312 Rate=7.76 GlobalRate=11.16 Time=Tue May 25 17:54:33 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:0](100) Loss=0.26228 Rate=7.73 GlobalRate=11.11 Time=Tue May 25 17:54:35 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 16\n",
            "[xla:6](0) Loss=0.36751 Rate=2.76 GlobalRate=2.76 Time=Tue May 25 17:55:26 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:7](0) Loss=0.37662 Rate=2.28 GlobalRate=2.28 Time=Tue May 25 17:55:31 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:2](0) Loss=0.30584 Rate=2.15 GlobalRate=2.15 Time=Tue May 25 17:55:32 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:3](0) Loss=0.34552 Rate=2.05 GlobalRate=2.05 Time=Tue May 25 17:55:34 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:4](0) Loss=0.37005 Rate=1.80 GlobalRate=1.80 Time=Tue May 25 17:55:38 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:5](0) Loss=0.32546 Rate=1.63 GlobalRate=1.63 Time=Tue May 25 17:55:42 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:1](0) Loss=0.42568 Rate=1.51 GlobalRate=1.51 Time=Tue May 25 17:55:45 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:0](0) Loss=0.22737 Rate=1.40 GlobalRate=1.40 Time=Tue May 25 17:55:48 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:7](100) Loss=0.16422 Rate=8.05 GlobalRate=11.42 Time=Tue May 25 18:04:28 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:5](100) Loss=0.30060 Rate=7.94 GlobalRate=11.41 Time=Tue May 25 18:04:29 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:3](100) Loss=0.32347 Rate=7.99 GlobalRate=11.41 Time=Tue May 25 18:04:29 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:6](100) Loss=0.31820 Rate=8.15 GlobalRate=11.37 Time=Tue May 25 18:04:31 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:0](100) Loss=0.15829 Rate=7.86 GlobalRate=11.31 Time=Tue May 25 18:04:34 2021\n",
            "Top1 accuracy: 100.0\n",
            "[xla:4](100) Loss=0.21172 Rate=7.80 GlobalRate=11.19 Time=Tue May 25 18:04:40 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:2](100) Loss=0.35056 Rate=7.83 GlobalRate=11.14 Time=Tue May 25 18:04:43 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:1](100) Loss=0.30644 Rate=7.70 GlobalRate=11.07 Time=Tue May 25 18:04:46 2021\n",
            "Top1 accuracy: 93.75\n",
            "Finished training epoch 17\n",
            "[xla:0](0) Loss=0.39071 Rate=2.54 GlobalRate=2.54 Time=Tue May 25 18:05:36 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:6](0) Loss=0.27653 Rate=2.16 GlobalRate=2.16 Time=Tue May 25 18:05:40 2021\n",
            "[xla:3](0) Loss=0.27703 Rate=2.14 GlobalRate=2.14 Time=Tue May 25 18:05:40 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:5](0) Loss=0.35497 Rate=2.08 GlobalRate=2.08 Time=Tue May 25 18:05:41 2021\n",
            "[xla:4](0) Loss=0.37809 Rate=2.07 GlobalRate=2.07 Time=Tue May 25 18:05:41 2021\n",
            "Top1 accuracy: 89.0625\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](0) Loss=0.44536 Rate=1.82 GlobalRate=1.82 Time=Tue May 25 18:05:46 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:7](0) Loss=0.36713 Rate=1.58 GlobalRate=1.58 Time=Tue May 25 18:05:51 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:2](0) Loss=0.35007 Rate=1.35 GlobalRate=1.35 Time=Tue May 25 18:05:58 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](100) Loss=0.28757 Rate=8.00 GlobalRate=11.48 Time=Tue May 25 18:14:34 2021\n",
            "[xla:2](100) Loss=0.29553 Rate=7.98 GlobalRate=11.48 Time=Tue May 25 18:14:34 2021\n",
            "[xla:0](100) Loss=0.38386 Rate=8.15 GlobalRate=11.48 Time=Tue May 25 18:14:34 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:7](100) Loss=0.42505 Rate=7.97 GlobalRate=11.47 Time=Tue May 25 18:14:34 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 88.28125\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:3](100) Loss=0.39440 Rate=7.99 GlobalRate=11.37 Time=Tue May 25 18:14:39 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:6](100) Loss=0.29104 Rate=7.91 GlobalRate=11.25 Time=Tue May 25 18:14:45 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:5](100) Loss=0.47049 Rate=7.87 GlobalRate=11.21 Time=Tue May 25 18:14:47 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:4](100) Loss=0.30226 Rate=7.80 GlobalRate=11.11 Time=Tue May 25 18:14:52 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Finished training epoch 18\n",
            "[xla:0](0) Loss=0.39852 Rate=2.79 GlobalRate=2.79 Time=Tue May 25 18:15:41 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:7](0) Loss=0.28875 Rate=2.61 GlobalRate=2.61 Time=Tue May 25 18:15:43 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](0) Loss=0.43761 Rate=2.39 GlobalRate=2.39 Time=Tue May 25 18:15:45 2021\n",
            "Top1 accuracy: 85.9375\n",
            "[xla:3](0) Loss=0.33293 Rate=1.88 GlobalRate=1.88 Time=Tue May 25 18:15:52 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:5](0) Loss=0.27464 Rate=1.87 GlobalRate=1.87 Time=Tue May 25 18:15:52 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:6](0) Loss=0.29113 Rate=1.44 GlobalRate=1.44 Time=Tue May 25 18:16:03 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:4](0) Loss=0.27035 Rate=1.39 GlobalRate=1.39 Time=Tue May 25 18:16:04 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:2](0) Loss=0.41888 Rate=1.37 GlobalRate=1.37 Time=Tue May 25 18:16:05 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:4](100) Loss=0.26708 Rate=7.81 GlobalRate=11.23 Time=Tue May 25 18:24:54 2021\n",
            "[xla:6](100) Loss=0.31204 Rate=7.81 GlobalRate=11.23 Time=Tue May 25 18:24:54 2021\n",
            "[xla:2](100) Loss=0.35941 Rate=7.81 GlobalRate=11.23 Time=Tue May 25 18:24:54 2021\n",
            "[xla:1](100) Loss=0.29841 Rate=7.95 GlobalRate=11.23 Time=Tue May 25 18:24:54 2021\n",
            "[xla:0](100) Loss=0.28574 Rate=8.06 GlobalRate=11.23 Time=Tue May 25 18:24:54 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 90.625\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:7](100) Loss=0.41590 Rate=8.01 GlobalRate=11.22 Time=Tue May 25 18:24:54 2021\n",
            "[xla:5](100) Loss=0.25160 Rate=7.84 GlobalRate=11.22 Time=Tue May 25 18:24:54 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 89.84375\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:3](100) Loss=0.37761 Rate=7.83 GlobalRate=11.22 Time=Tue May 25 18:24:55 2021\n",
            "Top1 accuracy: 90.625\n",
            "Finished training epoch 19\n",
            "[xla:4](0) Loss=0.34540 Rate=2.45 GlobalRate=2.45 Time=Tue May 25 18:25:55 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:6](0) Loss=0.29240 Rate=2.08 GlobalRate=2.08 Time=Tue May 25 18:26:00 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:0](0) Loss=0.34877 Rate=2.01 GlobalRate=2.01 Time=Tue May 25 18:26:01 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:7](0) Loss=0.21622 Rate=1.95 GlobalRate=1.95 Time=Tue May 25 18:26:02 2021\n",
            "[xla:1](0) Loss=0.41536 Rate=1.94 GlobalRate=1.94 Time=Tue May 25 18:26:02 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:3](0) Loss=0.42114 Rate=1.87 GlobalRate=1.87 Time=Tue May 25 18:26:03 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:2](0) Loss=0.34104 Rate=1.48 GlobalRate=1.48 Time=Tue May 25 18:26:12 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:5](0) Loss=0.35597 Rate=1.35 GlobalRate=1.35 Time=Tue May 25 18:26:16 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:7](100) Loss=0.30742 Rate=7.90 GlobalRate=11.29 Time=Tue May 25 18:35:01 2021\n",
            "[xla:5](100) Loss=0.28572 Rate=7.85 GlobalRate=11.29 Time=Tue May 25 18:35:01 2021\n",
            "[xla:4](100) Loss=0.43626 Rate=8.01 GlobalRate=11.29 Time=Tue May 25 18:35:01 2021\n",
            "[xla:0](100) Loss=0.34048 Rate=7.91 GlobalRate=11.29 Time=Tue May 25 18:35:01 2021\n",
            "[xla:2](100) Loss=0.41602 Rate=7.85 GlobalRate=11.29 Time=Tue May 25 18:35:01 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 89.84375\n",
            "Top1 accuracy: 90.625\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:1](100) Loss=0.47902 Rate=7.89 GlobalRate=11.29 Time=Tue May 25 18:35:02 2021\n",
            "[xla:6](100) Loss=0.43895 Rate=7.92 GlobalRate=11.28 Time=Tue May 25 18:35:02 2021\n",
            "Top1 accuracy: 89.84375\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:3](100) Loss=0.43598 Rate=7.84 GlobalRate=11.23 Time=Tue May 25 18:35:04 2021\n",
            "Top1 accuracy: 90.625\n",
            "Finished training epoch 20\n",
            "[xla:3](0) Loss=0.44790 Rate=2.70 GlobalRate=2.70 Time=Tue May 25 18:36:03 2021\n",
            "[xla:5](0) Loss=0.30260 Rate=2.70 GlobalRate=2.70 Time=Tue May 25 18:36:03 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](0) Loss=0.29880 Rate=2.01 GlobalRate=2.01 Time=Tue May 25 18:36:11 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:7](0) Loss=0.54275 Rate=1.85 GlobalRate=1.85 Time=Tue May 25 18:36:14 2021\n",
            "Top1 accuracy: 85.9375\n",
            "[xla:2](0) Loss=0.27214 Rate=1.79 GlobalRate=1.79 Time=Tue May 25 18:36:15 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:6](0) Loss=0.40764 Rate=1.64 GlobalRate=1.64 Time=Tue May 25 18:36:18 2021\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:1](0) Loss=0.39836 Rate=1.52 GlobalRate=1.52 Time=Tue May 25 18:36:21 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:4](0) Loss=0.41108 Rate=1.31 GlobalRate=1.31 Time=Tue May 25 18:36:28 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:1](100) Loss=0.19763 Rate=7.81 GlobalRate=11.24 Time=Tue May 25 18:45:15 2021\n",
            "[xla:7](100) Loss=0.19666 Rate=7.84 GlobalRate=11.24 Time=Tue May 25 18:45:15 2021\n",
            "[xla:3](100) Loss=0.21345 Rate=8.04 GlobalRate=11.24 Time=Tue May 25 18:45:15 2021\n",
            "[xla:4](100) Loss=0.19454 Rate=7.82 GlobalRate=11.24 Time=Tue May 25 18:45:15 2021\n",
            "[xla:2](100) Loss=0.23212 Rate=7.83 GlobalRate=11.23 Time=Tue May 25 18:45:15 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:5](100) Loss=0.24681 Rate=8.04 GlobalRate=11.23 Time=Tue May 25 18:45:15 2021\n",
            "[xla:6](100) Loss=0.18609 Rate=7.81 GlobalRate=11.23 Time=Tue May 25 18:45:15 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:0](100) Loss=0.15166 Rate=7.85 GlobalRate=11.21 Time=Tue May 25 18:45:16 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Finished training epoch 21\n",
            "[xla:0](0) Loss=0.25520 Rate=2.72 GlobalRate=2.72 Time=Tue May 25 18:46:13 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:6](0) Loss=0.37777 Rate=2.62 GlobalRate=2.62 Time=Tue May 25 18:46:14 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:3](0) Loss=0.28518 Rate=2.54 GlobalRate=2.54 Time=Tue May 25 18:46:14 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:5](0) Loss=0.17799 Rate=2.43 GlobalRate=2.43 Time=Tue May 25 18:46:16 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:7](0) Loss=0.39368 Rate=1.64 GlobalRate=1.64 Time=Tue May 25 18:46:28 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:1](0) Loss=0.33480 Rate=1.49 GlobalRate=1.49 Time=Tue May 25 18:46:32 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:2](0) Loss=0.21267 Rate=1.41 GlobalRate=1.41 Time=Tue May 25 18:46:35 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:4](0) Loss=0.26075 Rate=1.39 GlobalRate=1.39 Time=Tue May 25 18:46:35 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:4](100) Loss=0.27509 Rate=8.07 GlobalRate=11.60 Time=Tue May 25 18:55:06 2021\n",
            "[xla:3](100) Loss=0.39377 Rate=8.24 GlobalRate=11.60 Time=Tue May 25 18:55:06 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:0](100) Loss=0.16307 Rate=8.24 GlobalRate=11.54 Time=Tue May 25 18:55:10 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:6](100) Loss=0.16180 Rate=8.08 GlobalRate=11.33 Time=Tue May 25 18:55:20 2021\n",
            "[xla:7](100) Loss=0.19137 Rate=7.88 GlobalRate=11.32 Time=Tue May 25 18:55:20 2021\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 96.875\n",
            "[xla:1](100) Loss=0.25383 Rate=7.86 GlobalRate=11.31 Time=Tue May 25 18:55:21 2021\n",
            "[xla:2](100) Loss=0.26636 Rate=7.86 GlobalRate=11.31 Time=Tue May 25 18:55:21 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](100) Loss=0.27374 Rate=7.88 GlobalRate=11.10 Time=Tue May 25 18:55:32 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Finished training epoch 22\n",
            "[xla:2](0) Loss=0.16981 Rate=3.20 GlobalRate=3.20 Time=Tue May 25 18:56:15 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:0](0) Loss=0.26903 Rate=2.54 GlobalRate=2.54 Time=Tue May 25 18:56:21 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](0) Loss=0.32013 Rate=2.34 GlobalRate=2.34 Time=Tue May 25 18:56:23 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:7](0) Loss=0.20855 Rate=2.12 GlobalRate=2.12 Time=Tue May 25 18:56:26 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:6](0) Loss=0.25514 Rate=1.77 GlobalRate=1.77 Time=Tue May 25 18:56:31 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:3](0) Loss=0.34085 Rate=1.43 GlobalRate=1.43 Time=Tue May 25 18:56:40 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:4](0) Loss=0.50568 Rate=1.38 GlobalRate=1.38 Time=Tue May 25 18:56:42 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:1](0) Loss=0.28025 Rate=1.37 GlobalRate=1.37 Time=Tue May 25 18:56:42 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](100) Loss=0.43128 Rate=7.79 GlobalRate=11.20 Time=Tue May 25 19:05:32 2021\n",
            "Top1 accuracy: 85.9375\n",
            "[xla:4](100) Loss=0.30670 Rate=7.78 GlobalRate=11.20 Time=Tue May 25 19:05:33 2021\n",
            "[xla:5](100) Loss=0.33276 Rate=7.92 GlobalRate=11.20 Time=Tue May 25 19:05:33 2021\n",
            "[xla:0](100) Loss=0.37174 Rate=7.97 GlobalRate=11.20 Time=Tue May 25 19:05:33 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 90.625\n",
            "[xla:2](100) Loss=0.35806 Rate=8.17 GlobalRate=11.19 Time=Tue May 25 19:05:33 2021\n",
            "[xla:6](100) Loss=0.51511 Rate=7.80 GlobalRate=11.19 Time=Tue May 25 19:05:33 2021\n",
            "Top1 accuracy: 90.625\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:1](100) Loss=0.24011 Rate=7.77 GlobalRate=11.17 Time=Tue May 25 19:05:34 2021\n",
            "[xla:7](100) Loss=0.32219 Rate=7.85 GlobalRate=11.17 Time=Tue May 25 19:05:34 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 91.40625\n",
            "Finished training epoch 23\n",
            "[xla:3](0) Loss=0.33451 Rate=2.59 GlobalRate=2.59 Time=Tue May 25 19:06:30 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:0](0) Loss=0.25285 Rate=2.55 GlobalRate=2.55 Time=Tue May 25 19:06:31 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:1](0) Loss=0.30678 Rate=2.00 GlobalRate=2.00 Time=Tue May 25 19:06:38 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:6](0) Loss=0.24469 Rate=1.95 GlobalRate=1.95 Time=Tue May 25 19:06:38 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:5](0) Loss=0.25473 Rate=1.86 GlobalRate=1.86 Time=Tue May 25 19:06:40 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](0) Loss=0.24820 Rate=1.41 GlobalRate=1.41 Time=Tue May 25 19:06:51 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:2](0) Loss=0.29182 Rate=1.40 GlobalRate=1.40 Time=Tue May 25 19:06:51 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:4](0) Loss=0.31955 Rate=1.31 GlobalRate=1.31 Time=Tue May 25 19:06:54 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:0](100) Loss=0.13049 Rate=8.07 GlobalRate=11.35 Time=Tue May 25 19:15:35 2021\n",
            "Top1 accuracy: 100.0\n",
            "[xla:7](100) Loss=0.23368 Rate=7.88 GlobalRate=11.34 Time=Tue May 25 19:15:36 2021\n",
            "[xla:4](100) Loss=0.22646 Rate=7.89 GlobalRate=11.34 Time=Tue May 25 19:15:36 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](100) Loss=0.21559 Rate=7.88 GlobalRate=11.33 Time=Tue May 25 19:15:36 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](100) Loss=0.15704 Rate=8.00 GlobalRate=11.22 Time=Tue May 25 19:15:42 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:1](100) Loss=0.16770 Rate=7.85 GlobalRate=11.21 Time=Tue May 25 19:15:42 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:6](100) Loss=0.19637 Rate=7.76 GlobalRate=11.09 Time=Tue May 25 19:15:48 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:5](100) Loss=0.26132 Rate=7.70 GlobalRate=11.03 Time=Tue May 25 19:15:52 2021\n",
            "Top1 accuracy: 90.625\n",
            "Finished training epoch 24\n",
            "[xla:2](0) Loss=0.35889 Rate=2.23 GlobalRate=2.23 Time=Tue May 25 19:16:44 2021\n",
            "[xla:6](0) Loss=0.38149 Rate=2.22 GlobalRate=2.22 Time=Tue May 25 19:16:44 2021\n",
            "Top1 accuracy: 90.625\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:4](0) Loss=0.17573 Rate=2.18 GlobalRate=2.18 Time=Tue May 25 19:16:45 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:0](0) Loss=0.21189 Rate=2.15 GlobalRate=2.15 Time=Tue May 25 19:16:45 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:1](0) Loss=0.25099 Rate=1.72 GlobalRate=1.72 Time=Tue May 25 19:16:53 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](0) Loss=0.29010 Rate=1.66 GlobalRate=1.66 Time=Tue May 25 19:16:54 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:5](0) Loss=0.16722 Rate=1.59 GlobalRate=1.59 Time=Tue May 25 19:16:56 2021\n",
            "[xla:7](0) Loss=0.24486 Rate=1.59 GlobalRate=1.59 Time=Tue May 25 19:16:56 2021\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:3](100) Loss=0.21770 Rate=7.87 GlobalRate=11.32 Time=Tue May 25 19:25:47 2021\n",
            "[xla:4](100) Loss=0.34876 Rate=7.96 GlobalRate=11.32 Time=Tue May 25 19:25:47 2021\n",
            "[xla:0](100) Loss=0.34507 Rate=7.95 GlobalRate=11.32 Time=Tue May 25 19:25:47 2021\n",
            "[xla:5](100) Loss=0.29766 Rate=7.87 GlobalRate=11.32 Time=Tue May 25 19:25:47 2021\n",
            "[xla:1](100) Loss=0.36991 Rate=7.88 GlobalRate=11.31 Time=Tue May 25 19:25:47 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 90.625\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:6](100) Loss=0.29345 Rate=7.93 GlobalRate=11.26 Time=Tue May 25 19:25:50 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:2](100) Loss=0.14587 Rate=7.92 GlobalRate=11.23 Time=Tue May 25 19:25:51 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:7](100) Loss=0.33841 Rate=7.73 GlobalRate=11.12 Time=Tue May 25 19:25:57 2021\n",
            "Top1 accuracy: 89.0625\n",
            "Finished training epoch 25\n",
            "[xla:5](0) Loss=0.23932 Rate=2.40 GlobalRate=2.40 Time=Tue May 25 19:26:51 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](0) Loss=0.14000 Rate=2.28 GlobalRate=2.28 Time=Tue May 25 19:26:53 2021\n",
            "[xla:4](0) Loss=0.10360 Rate=2.26 GlobalRate=2.26 Time=Tue May 25 19:26:53 2021\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:3](0) Loss=0.18772 Rate=1.84 GlobalRate=1.84 Time=Tue May 25 19:26:59 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](0) Loss=0.12960 Rate=1.63 GlobalRate=1.63 Time=Tue May 25 19:27:04 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:6](0) Loss=0.24352 Rate=1.51 GlobalRate=1.51 Time=Tue May 25 19:27:07 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](0) Loss=0.29037 Rate=1.42 GlobalRate=1.42 Time=Tue May 25 19:27:10 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:7](0) Loss=0.21846 Rate=1.33 GlobalRate=1.33 Time=Tue May 25 19:27:13 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](100) Loss=0.27744 Rate=7.94 GlobalRate=11.42 Time=Tue May 25 19:35:51 2021\n",
            "[xla:6](100) Loss=0.25181 Rate=7.93 GlobalRate=11.42 Time=Tue May 25 19:35:51 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:7](100) Loss=0.27279 Rate=7.94 GlobalRate=11.41 Time=Tue May 25 19:35:51 2021\n",
            "[xla:3](100) Loss=0.31308 Rate=7.96 GlobalRate=11.41 Time=Tue May 25 19:35:51 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](100) Loss=0.24289 Rate=8.04 GlobalRate=11.37 Time=Tue May 25 19:35:53 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:1](100) Loss=0.25254 Rate=7.86 GlobalRate=11.31 Time=Tue May 25 19:35:56 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:4](100) Loss=0.30434 Rate=7.88 GlobalRate=11.17 Time=Tue May 25 19:36:04 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:0](100) Loss=0.26407 Rate=7.83 GlobalRate=11.09 Time=Tue May 25 19:36:07 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Finished training epoch 26\n",
            "[xla:3](0) Loss=0.30481 Rate=2.59 GlobalRate=2.59 Time=Tue May 25 19:36:57 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:0](0) Loss=0.32659 Rate=2.27 GlobalRate=2.27 Time=Tue May 25 19:37:00 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:5](0) Loss=0.26727 Rate=1.97 GlobalRate=1.97 Time=Tue May 25 19:37:05 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:1](0) Loss=0.24726 Rate=1.88 GlobalRate=1.88 Time=Tue May 25 19:37:06 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](0) Loss=0.33958 Rate=1.83 GlobalRate=1.83 Time=Tue May 25 19:37:07 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:7](0) Loss=0.26850 Rate=1.77 GlobalRate=1.77 Time=Tue May 25 19:37:09 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:4](0) Loss=0.42793 Rate=1.50 GlobalRate=1.50 Time=Tue May 25 19:37:15 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:6](0) Loss=0.28201 Rate=1.32 GlobalRate=1.32 Time=Tue May 25 19:37:21 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](100) Loss=0.30786 Rate=8.12 GlobalRate=11.65 Time=Tue May 25 19:45:47 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:4](100) Loss=0.17780 Rate=7.93 GlobalRate=11.40 Time=Tue May 25 19:45:59 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:0](100) Loss=0.23860 Rate=7.96 GlobalRate=11.29 Time=Tue May 25 19:46:05 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](100) Loss=0.22787 Rate=8.01 GlobalRate=11.23 Time=Tue May 25 19:46:08 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:5](100) Loss=0.22486 Rate=7.84 GlobalRate=11.20 Time=Tue May 25 19:46:09 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:6](100) Loss=0.22701 Rate=7.78 GlobalRate=11.18 Time=Tue May 25 19:46:10 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](100) Loss=0.33555 Rate=7.79 GlobalRate=11.17 Time=Tue May 25 19:46:11 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:7](100) Loss=0.24632 Rate=7.78 GlobalRate=11.16 Time=Tue May 25 19:46:12 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 27\n",
            "[xla:1](0) Loss=0.23751 Rate=2.57 GlobalRate=2.57 Time=Tue May 25 19:47:05 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](0) Loss=0.14106 Rate=2.49 GlobalRate=2.49 Time=Tue May 25 19:47:06 2021\n",
            "[xla:5](0) Loss=0.11072 Rate=2.48 GlobalRate=2.48 Time=Tue May 25 19:47:06 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:2](0) Loss=0.19172 Rate=2.02 GlobalRate=2.02 Time=Tue May 25 19:47:12 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:4](0) Loss=0.18306 Rate=1.68 GlobalRate=1.68 Time=Tue May 25 19:47:19 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:0](0) Loss=0.14778 Rate=1.64 GlobalRate=1.64 Time=Tue May 25 19:47:19 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:7](0) Loss=0.17208 Rate=1.48 GlobalRate=1.48 Time=Tue May 25 19:47:24 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:6](0) Loss=0.17207 Rate=1.28 GlobalRate=1.28 Time=Tue May 25 19:47:30 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:7](100) Loss=0.23051 Rate=7.85 GlobalRate=11.30 Time=Tue May 25 19:56:13 2021\n",
            "[xla:1](100) Loss=0.22166 Rate=8.04 GlobalRate=11.30 Time=Tue May 25 19:56:13 2021\n",
            "[xla:0](100) Loss=0.35272 Rate=7.86 GlobalRate=11.30 Time=Tue May 25 19:56:13 2021\n",
            "[xla:2](100) Loss=0.20408 Rate=7.91 GlobalRate=11.30 Time=Tue May 25 19:56:13 2021\n",
            "[xla:3](100) Loss=0.25428 Rate=8.02 GlobalRate=11.30 Time=Tue May 25 19:56:13 2021\n",
            "[xla:5](100) Loss=0.32067 Rate=8.02 GlobalRate=11.30 Time=Tue May 25 19:56:13 2021\n",
            "[xla:4](100) Loss=0.21470 Rate=7.86 GlobalRate=11.30 Time=Tue May 25 19:56:13 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:6](100) Loss=0.23294 Rate=7.86 GlobalRate=11.29 Time=Tue May 25 19:56:13 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Finished training epoch 28\n",
            "[xla:7](0) Loss=0.27851 Rate=2.33 GlobalRate=2.33 Time=Tue May 25 19:57:18 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:4](0) Loss=0.13947 Rate=2.26 GlobalRate=2.26 Time=Tue May 25 19:57:18 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:5](0) Loss=0.26628 Rate=2.15 GlobalRate=2.15 Time=Tue May 25 19:57:20 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](0) Loss=0.20681 Rate=2.11 GlobalRate=2.11 Time=Tue May 25 19:57:20 2021\n",
            "[xla:6](0) Loss=0.33285 Rate=2.09 GlobalRate=2.09 Time=Tue May 25 19:57:21 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](0) Loss=0.15432 Rate=1.79 GlobalRate=1.79 Time=Tue May 25 19:57:26 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:3](0) Loss=0.27563 Rate=1.42 GlobalRate=1.42 Time=Tue May 25 19:57:35 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](0) Loss=0.22083 Rate=1.31 GlobalRate=1.31 Time=Tue May 25 19:57:39 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:2](100) Loss=0.30997 Rate=7.92 GlobalRate=11.38 Time=Tue May 25 20:06:18 2021\n",
            "[xla:4](100) Loss=0.17395 Rate=8.02 GlobalRate=11.38 Time=Tue May 25 20:06:18 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:3](100) Loss=0.26131 Rate=7.90 GlobalRate=11.37 Time=Tue May 25 20:06:19 2021\n",
            "[xla:0](100) Loss=0.28350 Rate=7.98 GlobalRate=11.37 Time=Tue May 25 20:06:19 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 93.75\n",
            "[xla:1](100) Loss=0.25530 Rate=7.85 GlobalRate=11.26 Time=Tue May 25 20:06:24 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:5](100) Loss=0.24199 Rate=7.77 GlobalRate=11.04 Time=Tue May 25 20:06:35 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](100) Loss=0.23371 Rate=7.78 GlobalRate=10.99 Time=Tue May 25 20:06:39 2021\n",
            "[xla:6](100) Loss=0.34407 Rate=7.72 GlobalRate=10.98 Time=Tue May 25 20:06:39 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 92.1875\n",
            "Finished training epoch 29\n",
            "[xla:4](0) Loss=0.19180 Rate=2.40 GlobalRate=2.40 Time=Tue May 25 20:07:29 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](0) Loss=0.16575 Rate=2.32 GlobalRate=2.32 Time=Tue May 25 20:07:30 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](0) Loss=0.27653 Rate=2.22 GlobalRate=2.22 Time=Tue May 25 20:07:32 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:5](0) Loss=0.15437 Rate=1.80 GlobalRate=1.80 Time=Tue May 25 20:07:38 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:2](0) Loss=0.13477 Rate=1.71 GlobalRate=1.71 Time=Tue May 25 20:07:40 2021\n",
            "[xla:6](0) Loss=0.13033 Rate=1.70 GlobalRate=1.70 Time=Tue May 25 20:07:40 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:7](0) Loss=0.16692 Rate=1.64 GlobalRate=1.64 Time=Tue May 25 20:07:42 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:3](0) Loss=0.31586 Rate=1.36 GlobalRate=1.36 Time=Tue May 25 20:07:50 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](100) Loss=0.21308 Rate=7.90 GlobalRate=11.21 Time=Tue May 25 20:16:39 2021\n",
            "[xla:0](100) Loss=0.22602 Rate=7.92 GlobalRate=11.21 Time=Tue May 25 20:16:39 2021\n",
            "[xla:7](100) Loss=0.19759 Rate=7.80 GlobalRate=11.21 Time=Tue May 25 20:16:39 2021\n",
            "[xla:2](100) Loss=0.19754 Rate=7.80 GlobalRate=11.21 Time=Tue May 25 20:16:39 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:6](100) Loss=0.14493 Rate=7.79 GlobalRate=11.19 Time=Tue May 25 20:16:40 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:3](100) Loss=0.19766 Rate=7.76 GlobalRate=11.16 Time=Tue May 25 20:16:42 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](100) Loss=0.25456 Rate=7.74 GlobalRate=11.09 Time=Tue May 25 20:16:46 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:4](100) Loss=0.20848 Rate=7.78 GlobalRate=10.96 Time=Tue May 25 20:16:52 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 30\n",
            "[xla:7](0) Loss=0.22738 Rate=2.95 GlobalRate=2.95 Time=Tue May 25 20:17:39 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:1](0) Loss=0.23459 Rate=2.41 GlobalRate=2.41 Time=Tue May 25 20:17:44 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:5](0) Loss=0.16565 Rate=1.98 GlobalRate=1.98 Time=Tue May 25 20:17:50 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:6](0) Loss=0.12984 Rate=1.86 GlobalRate=1.86 Time=Tue May 25 20:17:52 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](0) Loss=0.23641 Rate=1.72 GlobalRate=1.72 Time=Tue May 25 20:17:55 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:2](0) Loss=0.13796 Rate=1.59 GlobalRate=1.59 Time=Tue May 25 20:17:58 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:4](0) Loss=0.28687 Rate=1.40 GlobalRate=1.40 Time=Tue May 25 20:18:03 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](0) Loss=0.22674 Rate=1.32 GlobalRate=1.32 Time=Tue May 25 20:18:06 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:6](100) Loss=0.34339 Rate=7.84 GlobalRate=11.22 Time=Tue May 25 20:26:54 2021\n",
            "[xla:4](100) Loss=0.43916 Rate=7.80 GlobalRate=11.22 Time=Tue May 25 20:26:54 2021\n",
            "[xla:7](100) Loss=0.57583 Rate=8.10 GlobalRate=11.22 Time=Tue May 25 20:26:54 2021\n",
            "[xla:1](100) Loss=0.39562 Rate=7.95 GlobalRate=11.22 Time=Tue May 25 20:26:54 2021\n",
            "[xla:3](100) Loss=0.56517 Rate=7.81 GlobalRate=11.22 Time=Tue May 25 20:26:54 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:0](100) Loss=0.53177 Rate=7.81 GlobalRate=11.22 Time=Tue May 25 20:26:54 2021\n",
            "[xla:2](100) Loss=0.58075 Rate=7.80 GlobalRate=11.22 Time=Tue May 25 20:26:54 2021\n",
            "Top1 accuracy: 89.0625\n",
            "Top1 accuracy: 85.15625\n",
            "Top1 accuracy: 85.9375\n",
            "Top1 accuracy: 89.84375\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:5](100) Loss=0.47623 Rate=7.81 GlobalRate=11.15 Time=Tue May 25 20:26:57 2021\n",
            "Top1 accuracy: 86.71875\n",
            "Finished training epoch 31\n",
            "[xla:7](0) Loss=0.51725 Rate=2.57 GlobalRate=2.57 Time=Tue May 25 20:27:53 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:3](0) Loss=0.63322 Rate=2.48 GlobalRate=2.48 Time=Tue May 25 20:27:54 2021\n",
            "Top1 accuracy: 85.9375\n",
            "[xla:1](0) Loss=0.54298 Rate=2.43 GlobalRate=2.43 Time=Tue May 25 20:27:55 2021\n",
            "Top1 accuracy: 83.59375\n",
            "[xla:0](0) Loss=0.47397 Rate=1.94 GlobalRate=1.94 Time=Tue May 25 20:28:02 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:5](0) Loss=0.47982 Rate=1.88 GlobalRate=1.88 Time=Tue May 25 20:28:02 2021\n",
            "Top1 accuracy: 85.9375\n",
            "[xla:6](0) Loss=0.33217 Rate=1.62 GlobalRate=1.62 Time=Tue May 25 20:28:08 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:4](0) Loss=0.56154 Rate=1.41 GlobalRate=1.41 Time=Tue May 25 20:28:14 2021\n",
            "Top1 accuracy: 83.59375\n",
            "[xla:2](0) Loss=0.49046 Rate=1.27 GlobalRate=1.27 Time=Tue May 25 20:28:19 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:5](100) Loss=0.21126 Rate=7.88 GlobalRate=11.29 Time=Tue May 25 20:37:01 2021\n",
            "[xla:6](100) Loss=0.41835 Rate=7.85 GlobalRate=11.29 Time=Tue May 25 20:37:01 2021\n",
            "[xla:4](100) Loss=0.24936 Rate=7.85 GlobalRate=11.29 Time=Tue May 25 20:37:01 2021\n",
            "[xla:7](100) Loss=0.27817 Rate=8.04 GlobalRate=11.29 Time=Tue May 25 20:37:01 2021\n",
            "[xla:1](100) Loss=0.24820 Rate=8.00 GlobalRate=11.29 Time=Tue May 25 20:37:01 2021\n",
            "[xla:2](100) Loss=0.20252 Rate=7.86 GlobalRate=11.29 Time=Tue May 25 20:37:01 2021\n",
            "[xla:3](100) Loss=0.21424 Rate=8.01 GlobalRate=11.29 Time=Tue May 25 20:37:01 2021\n",
            "[xla:0](100) Loss=0.21482 Rate=7.89 GlobalRate=11.29 Time=Tue May 25 20:37:01 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 89.84375\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 96.09375\n",
            "Finished training epoch 32\n",
            "[xla:5](0) Loss=0.14620 Rate=2.73 GlobalRate=2.73 Time=Tue May 25 20:38:01 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:6](0) Loss=0.13772 Rate=2.36 GlobalRate=2.36 Time=Tue May 25 20:38:05 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:2](0) Loss=0.13569 Rate=2.15 GlobalRate=2.15 Time=Tue May 25 20:38:07 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:1](0) Loss=0.13861 Rate=2.04 GlobalRate=2.04 Time=Tue May 25 20:38:09 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:4](0) Loss=0.22966 Rate=2.02 GlobalRate=2.02 Time=Tue May 25 20:38:09 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](0) Loss=0.19855 Rate=1.59 GlobalRate=1.59 Time=Tue May 25 20:38:18 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](0) Loss=0.22388 Rate=1.35 GlobalRate=1.35 Time=Tue May 25 20:38:25 2021\n",
            "[xla:7](0) Loss=0.10328 Rate=1.34 GlobalRate=1.34 Time=Tue May 25 20:38:25 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:5](100) Loss=0.25950 Rate=8.10 GlobalRate=11.31 Time=Tue May 25 20:47:09 2021\n",
            "[xla:6](100) Loss=0.29367 Rate=8.00 GlobalRate=11.31 Time=Tue May 25 20:47:09 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:1](100) Loss=0.24698 Rate=7.92 GlobalRate=11.30 Time=Tue May 25 20:47:09 2021\n",
            "[xla:3](100) Loss=0.30340 Rate=7.86 GlobalRate=11.30 Time=Tue May 25 20:47:10 2021\n",
            "[xla:4](100) Loss=0.31167 Rate=7.91 GlobalRate=11.30 Time=Tue May 25 20:47:10 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](100) Loss=0.37336 Rate=7.94 GlobalRate=11.30 Time=Tue May 25 20:47:10 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:7](100) Loss=0.24935 Rate=7.82 GlobalRate=11.24 Time=Tue May 25 20:47:13 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](100) Loss=0.21986 Rate=7.65 GlobalRate=11.00 Time=Tue May 25 20:47:25 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 33\n",
            "[xla:4](0) Loss=0.33550 Rate=2.88 GlobalRate=2.88 Time=Tue May 25 20:48:09 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:5](0) Loss=0.33127 Rate=2.68 GlobalRate=2.68 Time=Tue May 25 20:48:11 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:6](0) Loss=0.27142 Rate=1.83 GlobalRate=1.83 Time=Tue May 25 20:48:22 2021\n",
            "[xla:2](0) Loss=0.29220 Rate=1.83 GlobalRate=1.83 Time=Tue May 25 20:48:22 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 93.75\n",
            "[xla:1](0) Loss=0.25705 Rate=1.63 GlobalRate=1.63 Time=Tue May 25 20:48:26 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:3](0) Loss=0.42727 Rate=1.50 GlobalRate=1.50 Time=Tue May 25 20:48:30 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:7](0) Loss=0.27024 Rate=1.39 GlobalRate=1.39 Time=Tue May 25 20:48:33 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:0](0) Loss=0.31959 Rate=1.38 GlobalRate=1.38 Time=Tue May 25 20:48:34 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:1](100) Loss=0.16571 Rate=7.85 GlobalRate=11.29 Time=Tue May 25 20:57:20 2021\n",
            "[xla:5](100) Loss=0.12569 Rate=8.07 GlobalRate=11.29 Time=Tue May 25 20:57:20 2021\n",
            "[xla:4](100) Loss=0.09837 Rate=8.13 GlobalRate=11.29 Time=Tue May 25 20:57:20 2021\n",
            "[xla:3](100) Loss=0.19170 Rate=7.85 GlobalRate=11.29 Time=Tue May 25 20:57:20 2021\n",
            "[xla:7](100) Loss=0.10429 Rate=7.85 GlobalRate=11.29 Time=Tue May 25 20:57:20 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 99.21875\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:0](100) Loss=0.25733 Rate=7.85 GlobalRate=11.29 Time=Tue May 25 20:57:20 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:6](100) Loss=0.11551 Rate=7.87 GlobalRate=11.28 Time=Tue May 25 20:57:20 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:2](100) Loss=0.17845 Rate=7.81 GlobalRate=11.19 Time=Tue May 25 20:57:25 2021\n",
            "Top1 accuracy: 96.875\n",
            "Finished training epoch 34\n",
            "[xla:1](0) Loss=0.19439 Rate=2.47 GlobalRate=2.47 Time=Tue May 25 20:58:23 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:7](0) Loss=0.25960 Rate=2.39 GlobalRate=2.39 Time=Tue May 25 20:58:23 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:0](0) Loss=0.27432 Rate=2.11 GlobalRate=2.11 Time=Tue May 25 20:58:27 2021\n",
            "[xla:2](0) Loss=0.16110 Rate=2.10 GlobalRate=2.10 Time=Tue May 25 20:58:27 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:5](0) Loss=0.23978 Rate=1.72 GlobalRate=1.72 Time=Tue May 25 20:58:34 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:4](0) Loss=0.23833 Rate=1.53 GlobalRate=1.53 Time=Tue May 25 20:58:39 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](0) Loss=0.19705 Rate=1.42 GlobalRate=1.42 Time=Tue May 25 20:58:42 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:6](0) Loss=0.25861 Rate=1.39 GlobalRate=1.39 Time=Tue May 25 20:58:43 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:2](100) Loss=0.34449 Rate=8.00 GlobalRate=11.41 Time=Tue May 25 21:07:23 2021\n",
            "[xla:0](100) Loss=0.32776 Rate=8.00 GlobalRate=11.41 Time=Tue May 25 21:07:23 2021\n",
            "[xla:4](100) Loss=0.28430 Rate=7.93 GlobalRate=11.41 Time=Tue May 25 21:07:23 2021\n",
            "[xla:5](100) Loss=0.26993 Rate=7.94 GlobalRate=11.41 Time=Tue May 25 21:07:23 2021\n",
            "[xla:7](100) Loss=0.32990 Rate=8.07 GlobalRate=11.41 Time=Tue May 25 21:07:23 2021\n",
            "Top1 accuracy: 90.625\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:3](100) Loss=0.37752 Rate=7.92 GlobalRate=11.40 Time=Tue May 25 21:07:24 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:6](100) Loss=0.24994 Rate=7.88 GlobalRate=11.34 Time=Tue May 25 21:07:27 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:1](100) Loss=0.31095 Rate=7.83 GlobalRate=11.01 Time=Tue May 25 21:07:44 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Finished training epoch 35\n",
            "[xla:4](0) Loss=0.25811 Rate=2.63 GlobalRate=2.63 Time=Tue May 25 21:08:31 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](0) Loss=0.47121 Rate=2.05 GlobalRate=2.05 Time=Tue May 25 21:08:37 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:3](0) Loss=0.36209 Rate=1.92 GlobalRate=1.92 Time=Tue May 25 21:08:39 2021\n",
            "[xla:5](0) Loss=0.22057 Rate=1.91 GlobalRate=1.91 Time=Tue May 25 21:08:40 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](0) Loss=0.36314 Rate=1.84 GlobalRate=1.84 Time=Tue May 25 21:08:41 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:6](0) Loss=0.26320 Rate=1.80 GlobalRate=1.80 Time=Tue May 25 21:08:42 2021\n",
            "[xla:0](0) Loss=0.33409 Rate=1.80 GlobalRate=1.80 Time=Tue May 25 21:08:42 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:7](0) Loss=0.15001 Rate=1.36 GlobalRate=1.36 Time=Tue May 25 21:08:53 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:7](100) Loss=0.22148 Rate=7.80 GlobalRate=11.22 Time=Tue May 25 21:17:43 2021\n",
            "[xla:1](100) Loss=0.15831 Rate=7.86 GlobalRate=11.21 Time=Tue May 25 21:17:43 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:6](100) Loss=0.20980 Rate=7.81 GlobalRate=11.20 Time=Tue May 25 21:17:43 2021\n",
            "[xla:5](100) Loss=0.16939 Rate=7.83 GlobalRate=11.20 Time=Tue May 25 21:17:43 2021\n",
            "[xla:4](100) Loss=0.36947 Rate=8.00 GlobalRate=11.20 Time=Tue May 25 21:17:43 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](100) Loss=0.13349 Rate=7.82 GlobalRate=11.19 Time=Tue May 25 21:17:44 2021\n",
            "[xla:0](100) Loss=0.19365 Rate=7.81 GlobalRate=11.19 Time=Tue May 25 21:17:44 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](100) Loss=0.18875 Rate=7.80 GlobalRate=11.18 Time=Tue May 25 21:17:44 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Finished training epoch 36\n",
            "[xla:1](0) Loss=0.20273 Rate=3.01 GlobalRate=3.01 Time=Tue May 25 21:18:38 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](0) Loss=0.19338 Rate=2.85 GlobalRate=2.85 Time=Tue May 25 21:18:39 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:7](0) Loss=0.22756 Rate=2.22 GlobalRate=2.22 Time=Tue May 25 21:18:46 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:4](0) Loss=0.21355 Rate=1.77 GlobalRate=1.77 Time=Tue May 25 21:18:53 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:5](0) Loss=0.28023 Rate=1.53 GlobalRate=1.53 Time=Tue May 25 21:18:58 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:6](0) Loss=0.13321 Rate=1.50 GlobalRate=1.50 Time=Tue May 25 21:18:59 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:0](0) Loss=0.21379 Rate=1.47 GlobalRate=1.47 Time=Tue May 25 21:19:00 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:3](0) Loss=0.20979 Rate=1.37 GlobalRate=1.37 Time=Tue May 25 21:19:03 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:3](100) Loss=0.20771 Rate=7.84 GlobalRate=11.28 Time=Tue May 25 21:27:50 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:6](100) Loss=0.12884 Rate=7.84 GlobalRate=11.28 Time=Tue May 25 21:27:50 2021\n",
            "[xla:2](100) Loss=0.17718 Rate=8.11 GlobalRate=11.28 Time=Tue May 25 21:27:50 2021\n",
            "[xla:5](100) Loss=0.11891 Rate=7.84 GlobalRate=11.28 Time=Tue May 25 21:27:50 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:1](100) Loss=0.19219 Rate=8.15 GlobalRate=11.27 Time=Tue May 25 21:27:50 2021\n",
            "[xla:7](100) Loss=0.24631 Rate=7.93 GlobalRate=11.26 Time=Tue May 25 21:27:51 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:4](100) Loss=0.22432 Rate=7.78 GlobalRate=11.16 Time=Tue May 25 21:27:56 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](100) Loss=0.08474 Rate=7.70 GlobalRate=11.07 Time=Tue May 25 21:28:00 2021\n",
            "Top1 accuracy: 100.0\n",
            "Finished training epoch 37\n",
            "[xla:1](0) Loss=0.33311 Rate=2.70 GlobalRate=2.70 Time=Tue May 25 21:28:50 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:0](0) Loss=0.27340 Rate=2.51 GlobalRate=2.51 Time=Tue May 25 21:28:51 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](0) Loss=0.27709 Rate=1.97 GlobalRate=1.97 Time=Tue May 25 21:28:59 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:7](0) Loss=0.50448 Rate=1.81 GlobalRate=1.81 Time=Tue May 25 21:29:01 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:3](0) Loss=0.20918 Rate=1.55 GlobalRate=1.55 Time=Tue May 25 21:29:07 2021\n",
            "[xla:6](0) Loss=0.33595 Rate=1.55 GlobalRate=1.55 Time=Tue May 25 21:29:07 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](0) Loss=0.27518 Rate=1.51 GlobalRate=1.51 Time=Tue May 25 21:29:08 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:2](0) Loss=0.42160 Rate=1.46 GlobalRate=1.46 Time=Tue May 25 21:29:10 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:4](100) Loss=0.40287 Rate=7.88 GlobalRate=11.27 Time=Tue May 25 21:38:00 2021\n",
            "[xla:0](100) Loss=0.30578 Rate=8.01 GlobalRate=11.27 Time=Tue May 25 21:38:00 2021\n",
            "[xla:3](100) Loss=0.25193 Rate=7.84 GlobalRate=11.27 Time=Tue May 25 21:38:00 2021\n",
            "[xla:2](100) Loss=0.19590 Rate=7.83 GlobalRate=11.27 Time=Tue May 25 21:38:00 2021\n",
            "[xla:7](100) Loss=0.29860 Rate=7.86 GlobalRate=11.27 Time=Tue May 25 21:38:00 2021\n",
            "[xla:1](100) Loss=0.28403 Rate=8.06 GlobalRate=11.27 Time=Tue May 25 21:38:00 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:5](100) Loss=0.37118 Rate=7.83 GlobalRate=11.26 Time=Tue May 25 21:38:00 2021\n",
            "[xla:6](100) Loss=0.23758 Rate=7.83 GlobalRate=11.26 Time=Tue May 25 21:38:00 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 38\n",
            "[xla:4](0) Loss=0.30069 Rate=3.41 GlobalRate=3.41 Time=Tue May 25 21:38:54 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:0](0) Loss=0.25655 Rate=3.19 GlobalRate=3.19 Time=Tue May 25 21:38:55 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](0) Loss=0.28489 Rate=1.92 GlobalRate=1.92 Time=Tue May 25 21:39:09 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:7](0) Loss=0.30559 Rate=1.66 GlobalRate=1.66 Time=Tue May 25 21:39:14 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:6](0) Loss=0.21240 Rate=1.62 GlobalRate=1.62 Time=Tue May 25 21:39:15 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:5](0) Loss=0.24256 Rate=1.56 GlobalRate=1.56 Time=Tue May 25 21:39:16 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:2](0) Loss=0.25534 Rate=1.46 GlobalRate=1.46 Time=Tue May 25 21:39:19 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](0) Loss=0.39782 Rate=1.42 GlobalRate=1.42 Time=Tue May 25 21:39:21 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:4](100) Loss=0.13006 Rate=8.34 GlobalRate=11.35 Time=Tue May 25 21:48:05 2021\n",
            "[xla:6](100) Loss=0.10270 Rate=7.90 GlobalRate=11.35 Time=Tue May 25 21:48:05 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:5](100) Loss=0.21026 Rate=7.89 GlobalRate=11.35 Time=Tue May 25 21:48:05 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](100) Loss=0.11137 Rate=7.88 GlobalRate=11.34 Time=Tue May 25 21:48:05 2021\n",
            "[xla:7](100) Loss=0.09803 Rate=7.89 GlobalRate=11.34 Time=Tue May 25 21:48:05 2021\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 100.0\n",
            "[xla:2](100) Loss=0.17322 Rate=7.86 GlobalRate=11.31 Time=Tue May 25 21:48:07 2021\n",
            "[xla:1](100) Loss=0.14843 Rate=7.90 GlobalRate=11.31 Time=Tue May 25 21:48:07 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](100) Loss=0.20607 Rate=8.23 GlobalRate=11.29 Time=Tue May 25 21:48:08 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Finished training epoch 39\n",
            "[xla:1](0) Loss=0.09928 Rate=2.55 GlobalRate=2.55 Time=Tue May 25 21:49:10 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:6](0) Loss=0.20658 Rate=2.44 GlobalRate=2.44 Time=Tue May 25 21:49:11 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:5](0) Loss=0.19130 Rate=2.03 GlobalRate=2.03 Time=Tue May 25 21:49:17 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:3](0) Loss=0.20955 Rate=1.87 GlobalRate=1.87 Time=Tue May 25 21:49:19 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](0) Loss=0.20551 Rate=1.59 GlobalRate=1.59 Time=Tue May 25 21:49:25 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](0) Loss=0.17380 Rate=1.52 GlobalRate=1.52 Time=Tue May 25 21:49:27 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:0](0) Loss=0.20983 Rate=1.51 GlobalRate=1.51 Time=Tue May 25 21:49:28 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](0) Loss=0.13364 Rate=1.40 GlobalRate=1.40 Time=Tue May 25 21:49:31 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:1](100) Loss=0.16090 Rate=8.11 GlobalRate=11.41 Time=Tue May 25 21:58:12 2021\n",
            "[xla:7](100) Loss=0.11921 Rate=7.93 GlobalRate=11.41 Time=Tue May 25 21:58:12 2021\n",
            "[xla:2](100) Loss=0.21634 Rate=7.93 GlobalRate=11.41 Time=Tue May 25 21:58:12 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](100) Loss=0.18516 Rate=7.95 GlobalRate=11.40 Time=Tue May 25 21:58:12 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](100) Loss=0.14474 Rate=7.90 GlobalRate=11.37 Time=Tue May 25 21:58:14 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:4](100) Loss=0.24898 Rate=7.90 GlobalRate=11.36 Time=Tue May 25 21:58:14 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:6](100) Loss=0.09483 Rate=7.90 GlobalRate=11.12 Time=Tue May 25 21:58:26 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:5](100) Loss=0.19458 Rate=7.71 GlobalRate=10.99 Time=Tue May 25 21:58:33 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 40\n",
            "[xla:0](0) Loss=0.22698 Rate=2.35 GlobalRate=2.35 Time=Tue May 25 21:59:23 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:5](0) Loss=0.21516 Rate=2.17 GlobalRate=2.17 Time=Tue May 25 21:59:25 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:2](0) Loss=0.21199 Rate=2.06 GlobalRate=2.06 Time=Tue May 25 21:59:26 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:1](0) Loss=0.38202 Rate=2.03 GlobalRate=2.03 Time=Tue May 25 21:59:27 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:7](0) Loss=0.23832 Rate=1.94 GlobalRate=1.94 Time=Tue May 25 21:59:28 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:3](0) Loss=0.23791 Rate=1.67 GlobalRate=1.67 Time=Tue May 25 21:59:33 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:4](0) Loss=0.19611 Rate=1.58 GlobalRate=1.58 Time=Tue May 25 21:59:36 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:6](0) Loss=0.30018 Rate=1.35 GlobalRate=1.35 Time=Tue May 25 21:59:42 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:5](100) Loss=0.33170 Rate=7.92 GlobalRate=11.26 Time=Tue May 25 22:08:30 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:4](100) Loss=0.37578 Rate=7.82 GlobalRate=11.25 Time=Tue May 25 22:08:30 2021\n",
            "[xla:2](100) Loss=0.24781 Rate=7.89 GlobalRate=11.25 Time=Tue May 25 22:08:30 2021\n",
            "[xla:7](100) Loss=0.24899 Rate=7.86 GlobalRate=11.25 Time=Tue May 25 22:08:30 2021\n",
            "[xla:0](100) Loss=0.20655 Rate=7.95 GlobalRate=11.25 Time=Tue May 25 22:08:30 2021\n",
            "Top1 accuracy: 89.0625\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:6](100) Loss=0.25930 Rate=7.82 GlobalRate=11.24 Time=Tue May 25 22:08:30 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](100) Loss=0.19795 Rate=7.82 GlobalRate=11.24 Time=Tue May 25 22:08:30 2021\n",
            "[xla:1](100) Loss=0.19804 Rate=7.88 GlobalRate=11.24 Time=Tue May 25 22:08:30 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 96.875\n",
            "Finished training epoch 41\n",
            "[xla:1](0) Loss=0.29023 Rate=2.86 GlobalRate=2.86 Time=Tue May 25 22:09:26 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:6](0) Loss=0.30777 Rate=2.73 GlobalRate=2.73 Time=Tue May 25 22:09:27 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:2](0) Loss=0.41272 Rate=2.48 GlobalRate=2.48 Time=Tue May 25 22:09:29 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:5](0) Loss=0.23963 Rate=2.16 GlobalRate=2.16 Time=Tue May 25 22:09:33 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:0](0) Loss=0.27018 Rate=1.50 GlobalRate=1.50 Time=Tue May 25 22:09:46 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:4](0) Loss=0.37021 Rate=1.41 GlobalRate=1.41 Time=Tue May 25 22:09:49 2021\n",
            "[xla:7](0) Loss=0.41732 Rate=1.41 GlobalRate=1.41 Time=Tue May 25 22:09:49 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:3](0) Loss=0.27178 Rate=1.39 GlobalRate=1.39 Time=Tue May 25 22:09:50 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](100) Loss=0.20071 Rate=7.84 GlobalRate=11.28 Time=Tue May 25 22:18:37 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:2](100) Loss=0.10940 Rate=8.00 GlobalRate=11.27 Time=Tue May 25 22:18:37 2021\n",
            "[xla:5](100) Loss=0.18894 Rate=7.92 GlobalRate=11.27 Time=Tue May 25 22:18:37 2021\n",
            "[xla:1](100) Loss=0.17395 Rate=8.11 GlobalRate=11.26 Time=Tue May 25 22:18:37 2021\n",
            "[xla:4](100) Loss=0.17153 Rate=7.83 GlobalRate=11.26 Time=Tue May 25 22:18:38 2021\n",
            "[xla:3](100) Loss=0.25792 Rate=7.83 GlobalRate=11.26 Time=Tue May 25 22:18:38 2021\n",
            "[xla:6](100) Loss=0.12694 Rate=8.07 GlobalRate=11.26 Time=Tue May 25 22:18:38 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:7](100) Loss=0.17713 Rate=7.75 GlobalRate=11.15 Time=Tue May 25 22:18:43 2021\n",
            "Top1 accuracy: 96.875\n",
            "Finished training epoch 42\n",
            "[xla:5](0) Loss=0.19850 Rate=2.90 GlobalRate=2.90 Time=Tue May 25 22:19:33 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](0) Loss=0.25379 Rate=2.48 GlobalRate=2.48 Time=Tue May 25 22:19:37 2021\n",
            "[xla:7](0) Loss=0.19013 Rate=2.45 GlobalRate=2.45 Time=Tue May 25 22:19:37 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](0) Loss=0.27684 Rate=2.10 GlobalRate=2.10 Time=Tue May 25 22:19:42 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](0) Loss=0.17426 Rate=1.95 GlobalRate=1.95 Time=Tue May 25 22:19:44 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:6](0) Loss=0.20134 Rate=1.49 GlobalRate=1.49 Time=Tue May 25 22:19:54 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](0) Loss=0.18517 Rate=1.43 GlobalRate=1.43 Time=Tue May 25 22:19:56 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:2](0) Loss=0.13253 Rate=1.38 GlobalRate=1.38 Time=Tue May 25 22:19:58 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:3](100) Loss=0.19079 Rate=7.99 GlobalRate=11.44 Time=Tue May 25 22:28:36 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](100) Loss=0.13529 Rate=8.09 GlobalRate=11.41 Time=Tue May 25 22:28:38 2021\n",
            "[xla:6](100) Loss=0.23516 Rate=7.93 GlobalRate=11.40 Time=Tue May 25 22:28:38 2021\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](100) Loss=0.22017 Rate=7.98 GlobalRate=11.25 Time=Tue May 25 22:28:46 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](100) Loss=0.23601 Rate=7.80 GlobalRate=11.22 Time=Tue May 25 22:28:47 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](100) Loss=0.20757 Rate=8.02 GlobalRate=11.11 Time=Tue May 25 22:28:53 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](100) Loss=0.26910 Rate=7.77 GlobalRate=11.06 Time=Tue May 25 22:28:56 2021\n",
            "[xla:4](100) Loss=0.18045 Rate=7.68 GlobalRate=11.05 Time=Tue May 25 22:28:56 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 98.4375\n",
            "Finished training epoch 43\n",
            "[xla:7](0) Loss=0.12007 Rate=2.23 GlobalRate=2.23 Time=Tue May 25 22:29:49 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:6](0) Loss=0.10360 Rate=2.11 GlobalRate=2.11 Time=Tue May 25 22:29:51 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:0](0) Loss=0.12011 Rate=2.04 GlobalRate=2.04 Time=Tue May 25 22:29:52 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:5](0) Loss=0.26100 Rate=1.97 GlobalRate=1.97 Time=Tue May 25 22:29:53 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:4](0) Loss=0.19342 Rate=1.91 GlobalRate=1.91 Time=Tue May 25 22:29:54 2021\n",
            "[xla:2](0) Loss=0.12170 Rate=1.91 GlobalRate=1.91 Time=Tue May 25 22:29:54 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:3](0) Loss=0.14600 Rate=1.78 GlobalRate=1.78 Time=Tue May 25 22:29:57 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](0) Loss=0.17571 Rate=1.39 GlobalRate=1.39 Time=Tue May 25 22:30:06 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:4](100) Loss=0.28939 Rate=8.09 GlobalRate=11.59 Time=Tue May 25 22:38:38 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](100) Loss=0.21919 Rate=8.07 GlobalRate=11.58 Time=Tue May 25 22:38:39 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](100) Loss=0.18771 Rate=7.91 GlobalRate=11.29 Time=Tue May 25 22:38:53 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:1](100) Loss=0.12211 Rate=7.83 GlobalRate=11.26 Time=Tue May 25 22:38:55 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:6](100) Loss=0.32738 Rate=7.89 GlobalRate=11.24 Time=Tue May 25 22:38:55 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:7](100) Loss=0.24178 Rate=7.91 GlobalRate=11.22 Time=Tue May 25 22:38:56 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:2](100) Loss=0.21312 Rate=7.82 GlobalRate=11.19 Time=Tue May 25 22:38:58 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:5](100) Loss=0.27239 Rate=7.77 GlobalRate=11.09 Time=Tue May 25 22:39:03 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Finished training epoch 44\n",
            "[xla:0](0) Loss=0.23855 Rate=2.79 GlobalRate=2.79 Time=Tue May 25 22:39:51 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:4](0) Loss=0.14449 Rate=2.69 GlobalRate=2.69 Time=Tue May 25 22:39:52 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:2](0) Loss=0.17077 Rate=2.21 GlobalRate=2.21 Time=Tue May 25 22:39:57 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:3](0) Loss=0.23696 Rate=1.90 GlobalRate=1.90 Time=Tue May 25 22:40:02 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:7](0) Loss=0.20475 Rate=1.76 GlobalRate=1.76 Time=Tue May 25 22:40:04 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:5](0) Loss=0.15295 Rate=1.73 GlobalRate=1.73 Time=Tue May 25 22:40:05 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:6](0) Loss=0.15012 Rate=1.42 GlobalRate=1.42 Time=Tue May 25 22:40:13 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:1](0) Loss=0.20929 Rate=1.27 GlobalRate=1.27 Time=Tue May 25 22:40:18 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:4](100) Loss=0.17242 Rate=8.00 GlobalRate=11.17 Time=Tue May 25 22:49:07 2021\n",
            "[xla:6](100) Loss=0.10352 Rate=7.76 GlobalRate=11.17 Time=Tue May 25 22:49:07 2021\n",
            "[xla:2](100) Loss=0.17933 Rate=7.87 GlobalRate=11.17 Time=Tue May 25 22:49:07 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](100) Loss=0.11422 Rate=8.02 GlobalRate=11.16 Time=Tue May 25 22:49:07 2021\n",
            "[xla:7](100) Loss=0.12203 Rate=7.78 GlobalRate=11.16 Time=Tue May 25 22:49:07 2021\n",
            "[xla:3](100) Loss=0.15441 Rate=7.80 GlobalRate=11.16 Time=Tue May 25 22:49:07 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:5](100) Loss=0.19381 Rate=7.76 GlobalRate=11.14 Time=Tue May 25 22:49:09 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](100) Loss=0.12159 Rate=7.73 GlobalRate=11.10 Time=Tue May 25 22:49:10 2021\n",
            "Top1 accuracy: 98.4375\n",
            "Finished training epoch 45\n",
            "[xla:5](0) Loss=0.22342 Rate=2.63 GlobalRate=2.63 Time=Tue May 25 22:50:03 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](0) Loss=0.34952 Rate=2.38 GlobalRate=2.38 Time=Tue May 25 22:50:06 2021\n",
            "[xla:7](0) Loss=0.18376 Rate=2.36 GlobalRate=2.36 Time=Tue May 25 22:50:06 2021\n",
            "Top1 accuracy: 89.0625\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:0](0) Loss=0.23423 Rate=2.32 GlobalRate=2.32 Time=Tue May 25 22:50:07 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:4](0) Loss=0.22600 Rate=1.61 GlobalRate=1.61 Time=Tue May 25 22:50:19 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](0) Loss=0.26676 Rate=1.55 GlobalRate=1.55 Time=Tue May 25 22:50:20 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:6](0) Loss=0.25939 Rate=1.46 GlobalRate=1.46 Time=Tue May 25 22:50:23 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](0) Loss=0.37395 Rate=1.28 GlobalRate=1.28 Time=Tue May 25 22:50:29 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:5](100) Loss=0.28069 Rate=8.08 GlobalRate=11.33 Time=Tue May 25 22:59:09 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](100) Loss=0.24850 Rate=7.88 GlobalRate=11.32 Time=Tue May 25 22:59:10 2021\n",
            "[xla:3](100) Loss=0.29069 Rate=7.87 GlobalRate=11.32 Time=Tue May 25 22:59:10 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:2](100) Loss=0.33438 Rate=7.95 GlobalRate=11.23 Time=Tue May 25 22:59:15 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:4](100) Loss=0.33271 Rate=7.73 GlobalRate=11.11 Time=Tue May 25 22:59:21 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:0](100) Loss=0.23718 Rate=7.84 GlobalRate=11.09 Time=Tue May 25 22:59:22 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:6](100) Loss=0.22355 Rate=7.70 GlobalRate=11.07 Time=Tue May 25 22:59:23 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](100) Loss=0.21057 Rate=7.83 GlobalRate=11.06 Time=Tue May 25 22:59:23 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Finished training epoch 46\n",
            "[xla:3](0) Loss=0.20483 Rate=2.67 GlobalRate=2.67 Time=Tue May 25 23:00:15 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:4](0) Loss=0.35810 Rate=2.35 GlobalRate=2.35 Time=Tue May 25 23:00:18 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:7](0) Loss=0.42261 Rate=2.26 GlobalRate=2.26 Time=Tue May 25 23:00:19 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:0](0) Loss=0.28120 Rate=2.00 GlobalRate=2.00 Time=Tue May 25 23:00:23 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](0) Loss=0.42015 Rate=1.92 GlobalRate=1.92 Time=Tue May 25 23:00:24 2021\n",
            "[xla:6](0) Loss=0.34757 Rate=1.91 GlobalRate=1.91 Time=Tue May 25 23:00:24 2021\n",
            "Top1 accuracy: 89.0625\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:1](0) Loss=0.23898 Rate=1.65 GlobalRate=1.65 Time=Tue May 25 23:00:30 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:5](0) Loss=0.32694 Rate=1.32 GlobalRate=1.32 Time=Tue May 25 23:00:39 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:1](100) Loss=0.31609 Rate=7.75 GlobalRate=11.14 Time=Tue May 25 23:09:31 2021\n",
            "[xla:0](100) Loss=0.31305 Rate=7.80 GlobalRate=11.14 Time=Tue May 25 23:09:31 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:4](100) Loss=0.34572 Rate=7.88 GlobalRate=11.14 Time=Tue May 25 23:09:31 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:2](100) Loss=0.37824 Rate=7.78 GlobalRate=11.13 Time=Tue May 25 23:09:31 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:5](100) Loss=0.30335 Rate=7.74 GlobalRate=11.13 Time=Tue May 25 23:09:31 2021\n",
            "[xla:7](100) Loss=0.41366 Rate=7.86 GlobalRate=11.13 Time=Tue May 25 23:09:32 2021\n",
            "[xla:6](100) Loss=0.31323 Rate=7.78 GlobalRate=11.13 Time=Tue May 25 23:09:32 2021\n",
            "Top1 accuracy: 89.84375\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:3](100) Loss=0.49754 Rate=7.96 GlobalRate=11.12 Time=Tue May 25 23:09:32 2021\n",
            "Top1 accuracy: 88.28125\n",
            "Finished training epoch 47\n",
            "[xla:2](0) Loss=0.23113 Rate=2.99 GlobalRate=2.99 Time=Tue May 25 23:10:20 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](0) Loss=0.36927 Rate=2.35 GlobalRate=2.35 Time=Tue May 25 23:10:26 2021\n",
            "Top1 accuracy: 88.28125\n",
            "[xla:3](0) Loss=0.36107 Rate=2.28 GlobalRate=2.28 Time=Tue May 25 23:10:27 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:5](0) Loss=0.30582 Rate=2.17 GlobalRate=2.17 Time=Tue May 25 23:10:28 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:6](0) Loss=0.29500 Rate=1.59 GlobalRate=1.59 Time=Tue May 25 23:10:39 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:4](0) Loss=0.30871 Rate=1.56 GlobalRate=1.56 Time=Tue May 25 23:10:40 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:1](0) Loss=0.27280 Rate=1.53 GlobalRate=1.53 Time=Tue May 25 23:10:41 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:0](0) Loss=0.18391 Rate=1.40 GlobalRate=1.40 Time=Tue May 25 23:10:45 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:1](100) Loss=0.22535 Rate=7.90 GlobalRate=11.37 Time=Tue May 25 23:19:28 2021\n",
            "[xla:0](100) Loss=0.22790 Rate=7.90 GlobalRate=11.36 Time=Tue May 25 23:19:28 2021\n",
            "[xla:5](100) Loss=0.25223 Rate=7.99 GlobalRate=11.36 Time=Tue May 25 23:19:28 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:4](100) Loss=0.16898 Rate=7.90 GlobalRate=11.36 Time=Tue May 25 23:19:28 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 96.875\n",
            "[xla:3](100) Loss=0.25348 Rate=8.00 GlobalRate=11.34 Time=Tue May 25 23:19:29 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](100) Loss=0.23383 Rate=8.15 GlobalRate=11.27 Time=Tue May 25 23:19:32 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:6](100) Loss=0.15901 Rate=7.81 GlobalRate=11.23 Time=Tue May 25 23:19:34 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:7](100) Loss=0.25994 Rate=7.86 GlobalRate=11.11 Time=Tue May 25 23:19:41 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Finished training epoch 48\n",
            "[xla:4](0) Loss=0.19834 Rate=2.96 GlobalRate=2.96 Time=Tue May 25 23:20:27 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](0) Loss=0.08211 Rate=2.83 GlobalRate=2.83 Time=Tue May 25 23:20:27 2021\n",
            "Top1 accuracy: 100.0\n",
            "[xla:6](0) Loss=0.16695 Rate=2.34 GlobalRate=2.34 Time=Tue May 25 23:20:32 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](0) Loss=0.27726 Rate=2.13 GlobalRate=2.13 Time=Tue May 25 23:20:35 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:2](0) Loss=0.22257 Rate=1.79 GlobalRate=1.79 Time=Tue May 25 23:20:41 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:5](0) Loss=0.20864 Rate=1.44 GlobalRate=1.44 Time=Tue May 25 23:20:49 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:1](0) Loss=0.19880 Rate=1.41 GlobalRate=1.41 Time=Tue May 25 23:20:50 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:7](0) Loss=0.16764 Rate=1.38 GlobalRate=1.38 Time=Tue May 25 23:20:51 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](100) Loss=0.19887 Rate=7.88 GlobalRate=11.33 Time=Tue May 25 23:29:35 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:7](100) Loss=0.28954 Rate=7.87 GlobalRate=11.32 Time=Tue May 25 23:29:36 2021\n",
            "[xla:6](100) Loss=0.21244 Rate=8.00 GlobalRate=11.32 Time=Tue May 25 23:29:36 2021\n",
            "[xla:5](100) Loss=0.19247 Rate=7.86 GlobalRate=11.31 Time=Tue May 25 23:29:36 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 96.875\n",
            "[xla:2](100) Loss=0.32697 Rate=7.88 GlobalRate=11.30 Time=Tue May 25 23:29:37 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:3](100) Loss=0.16829 Rate=8.12 GlobalRate=11.30 Time=Tue May 25 23:29:37 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](100) Loss=0.38826 Rate=8.15 GlobalRate=11.28 Time=Tue May 25 23:29:38 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:0](100) Loss=0.17005 Rate=7.91 GlobalRate=11.25 Time=Tue May 25 23:29:39 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Finished training epoch 49\n",
            "[xla:1](0) Loss=0.24341 Rate=2.75 GlobalRate=2.75 Time=Tue May 25 23:30:35 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:0](0) Loss=0.22559 Rate=2.50 GlobalRate=2.50 Time=Tue May 25 23:30:38 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:2](0) Loss=0.13432 Rate=2.17 GlobalRate=2.17 Time=Tue May 25 23:30:42 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:3](0) Loss=0.15924 Rate=2.10 GlobalRate=2.10 Time=Tue May 25 23:30:43 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:5](0) Loss=0.15732 Rate=2.09 GlobalRate=2.09 Time=Tue May 25 23:30:43 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:7](0) Loss=0.29056 Rate=1.96 GlobalRate=1.96 Time=Tue May 25 23:30:45 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:4](0) Loss=0.19770 Rate=1.56 GlobalRate=1.56 Time=Tue May 25 23:30:53 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:6](0) Loss=0.21170 Rate=1.39 GlobalRate=1.39 Time=Tue May 25 23:30:58 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](100) Loss=0.11936 Rate=7.96 GlobalRate=11.34 Time=Tue May 25 23:39:42 2021\n",
            "[xla:6](100) Loss=0.20597 Rate=7.88 GlobalRate=11.34 Time=Tue May 25 23:39:42 2021\n",
            "[xla:0](100) Loss=0.20445 Rate=8.05 GlobalRate=11.34 Time=Tue May 25 23:39:42 2021\n",
            "Top1 accuracy: 99.21875\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 93.75\n",
            "[xla:7](100) Loss=0.17339 Rate=7.90 GlobalRate=11.29 Time=Tue May 25 23:39:45 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:1](100) Loss=0.08969 Rate=8.07 GlobalRate=11.26 Time=Tue May 25 23:39:46 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:5](100) Loss=0.21528 Rate=7.87 GlobalRate=11.21 Time=Tue May 25 23:39:49 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:4](100) Loss=0.24498 Rate=7.75 GlobalRate=11.15 Time=Tue May 25 23:39:52 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](100) Loss=0.28706 Rate=7.81 GlobalRate=11.09 Time=Tue May 25 23:39:55 2021\n",
            "Top1 accuracy: 93.75\n",
            "Finished training epoch 50\n",
            "[xla:5](0) Loss=0.17413 Rate=2.88 GlobalRate=2.88 Time=Tue May 25 23:40:45 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:0](0) Loss=0.19618 Rate=2.73 GlobalRate=2.73 Time=Tue May 25 23:40:46 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:7](0) Loss=0.21452 Rate=2.31 GlobalRate=2.31 Time=Tue May 25 23:40:51 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](0) Loss=0.31836 Rate=2.22 GlobalRate=2.22 Time=Tue May 25 23:40:52 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:6](0) Loss=0.18818 Rate=1.69 GlobalRate=1.69 Time=Tue May 25 23:41:01 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:2](0) Loss=0.19772 Rate=1.67 GlobalRate=1.67 Time=Tue May 25 23:41:01 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](0) Loss=0.23120 Rate=1.46 GlobalRate=1.46 Time=Tue May 25 23:41:07 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:3](0) Loss=0.20489 Rate=1.43 GlobalRate=1.43 Time=Tue May 25 23:41:08 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:7](100) Loss=0.29743 Rate=8.11 GlobalRate=11.50 Time=Tue May 25 23:49:45 2021\n",
            "[xla:1](100) Loss=0.25231 Rate=7.99 GlobalRate=11.50 Time=Tue May 25 23:49:45 2021\n",
            "[xla:6](100) Loss=0.25377 Rate=8.00 GlobalRate=11.50 Time=Tue May 25 23:49:45 2021\n",
            "[xla:5](100) Loss=0.34436 Rate=8.26 GlobalRate=11.50 Time=Tue May 25 23:49:45 2021\n",
            "Top1 accuracy: 92.1875\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 90.625\n",
            "[xla:4](100) Loss=0.22291 Rate=8.08 GlobalRate=11.49 Time=Tue May 25 23:49:46 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:3](100) Loss=0.25318 Rate=7.81 GlobalRate=11.23 Time=Tue May 25 23:49:59 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:0](100) Loss=0.32699 Rate=8.04 GlobalRate=11.22 Time=Tue May 25 23:49:59 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:2](100) Loss=0.36233 Rate=7.71 GlobalRate=11.07 Time=Tue May 25 23:50:07 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Finished training epoch 51\n",
            "[xla:0](0) Loss=0.11650 Rate=2.62 GlobalRate=2.62 Time=Tue May 25 23:50:53 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:3](0) Loss=0.22966 Rate=2.32 GlobalRate=2.32 Time=Tue May 25 23:50:56 2021\n",
            "[xla:4](0) Loss=0.19643 Rate=2.32 GlobalRate=2.32 Time=Tue May 25 23:50:56 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:6](0) Loss=0.22815 Rate=2.26 GlobalRate=2.26 Time=Tue May 25 23:50:57 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](0) Loss=0.25531 Rate=2.12 GlobalRate=2.12 Time=Tue May 25 23:50:59 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:7](0) Loss=0.21936 Rate=1.90 GlobalRate=1.90 Time=Tue May 25 23:51:03 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](0) Loss=0.24593 Rate=1.39 GlobalRate=1.39 Time=Tue May 25 23:51:15 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](0) Loss=0.17442 Rate=1.35 GlobalRate=1.35 Time=Tue May 25 23:51:16 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](100) Loss=0.42170 Rate=8.10 GlobalRate=11.48 Time=Tue May 25 23:59:52 2021\n",
            "[xla:2](100) Loss=0.45707 Rate=7.99 GlobalRate=11.48 Time=Tue May 25 23:59:52 2021\n",
            "[xla:7](100) Loss=0.32889 Rate=8.02 GlobalRate=11.48 Time=Tue May 25 23:59:52 2021\n",
            "Top1 accuracy: 89.84375\n",
            "Top1 accuracy: 88.28125\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:5](100) Loss=0.38268 Rate=8.05 GlobalRate=11.48 Time=Tue May 25 23:59:52 2021\n",
            "Top1 accuracy: 89.84375\n",
            "[xla:6](100) Loss=0.21354 Rate=8.08 GlobalRate=11.47 Time=Tue May 25 23:59:52 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](100) Loss=0.33794 Rate=7.99 GlobalRate=11.19 Time=Wed May 26 00:00:07 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:4](100) Loss=0.26474 Rate=7.90 GlobalRate=11.17 Time=Wed May 26 00:00:07 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:1](100) Loss=0.28726 Rate=7.76 GlobalRate=11.16 Time=Wed May 26 00:00:08 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 52\n",
            "[xla:4](0) Loss=0.24192 Rate=2.38 GlobalRate=2.38 Time=Wed May 26 00:01:02 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](0) Loss=0.20401 Rate=2.26 GlobalRate=2.26 Time=Wed May 26 00:01:03 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:5](0) Loss=0.23932 Rate=2.24 GlobalRate=2.24 Time=Wed May 26 00:01:04 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:7](0) Loss=0.20262 Rate=2.19 GlobalRate=2.19 Time=Wed May 26 00:01:04 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](0) Loss=0.22179 Rate=2.08 GlobalRate=2.08 Time=Wed May 26 00:01:06 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:6](0) Loss=0.25738 Rate=1.75 GlobalRate=1.75 Time=Wed May 26 00:01:12 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:2](0) Loss=0.18376 Rate=1.70 GlobalRate=1.70 Time=Wed May 26 00:01:13 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:3](0) Loss=0.32030 Rate=1.31 GlobalRate=1.31 Time=Wed May 26 00:01:24 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:1](100) Loss=0.23425 Rate=8.07 GlobalRate=11.45 Time=Wed May 26 00:09:59 2021\n",
            "[xla:6](100) Loss=0.13389 Rate=7.97 GlobalRate=11.45 Time=Wed May 26 00:09:59 2021\n",
            "[xla:3](100) Loss=0.21149 Rate=7.97 GlobalRate=11.45 Time=Wed May 26 00:09:59 2021\n",
            "[xla:5](100) Loss=0.16771 Rate=8.06 GlobalRate=11.45 Time=Wed May 26 00:09:59 2021\n",
            "[xla:7](100) Loss=0.17448 Rate=8.05 GlobalRate=11.45 Time=Wed May 26 00:09:59 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 96.875\n",
            "[xla:2](100) Loss=0.18703 Rate=7.92 GlobalRate=11.38 Time=Wed May 26 00:10:03 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:4](100) Loss=0.11774 Rate=7.91 GlobalRate=11.17 Time=Wed May 26 00:10:14 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:0](100) Loss=0.13531 Rate=7.74 GlobalRate=11.02 Time=Wed May 26 00:10:21 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Finished training epoch 53\n",
            "[xla:2](0) Loss=0.14958 Rate=3.39 GlobalRate=3.39 Time=Wed May 26 00:11:02 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:4](0) Loss=0.13316 Rate=2.51 GlobalRate=2.51 Time=Wed May 26 00:11:08 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:3](0) Loss=0.24845 Rate=2.27 GlobalRate=2.27 Time=Wed May 26 00:11:11 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](0) Loss=0.20156 Rate=2.14 GlobalRate=2.14 Time=Wed May 26 00:11:13 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](0) Loss=0.15385 Rate=1.64 GlobalRate=1.64 Time=Wed May 26 00:11:22 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:0](0) Loss=0.17763 Rate=1.52 GlobalRate=1.52 Time=Wed May 26 00:11:25 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:5](0) Loss=0.13258 Rate=1.50 GlobalRate=1.50 Time=Wed May 26 00:11:25 2021\n",
            "[xla:6](0) Loss=0.14096 Rate=1.50 GlobalRate=1.50 Time=Wed May 26 00:11:26 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 96.875\n",
            "[xla:6](100) Loss=0.15205 Rate=7.81 GlobalRate=11.23 Time=Wed May 26 00:20:18 2021\n",
            "[xla:0](100) Loss=0.25015 Rate=7.80 GlobalRate=11.23 Time=Wed May 26 00:20:18 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](100) Loss=0.21360 Rate=7.89 GlobalRate=11.23 Time=Wed May 26 00:20:19 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](100) Loss=0.29799 Rate=7.92 GlobalRate=11.22 Time=Wed May 26 00:20:19 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:4](100) Loss=0.24434 Rate=7.98 GlobalRate=11.21 Time=Wed May 26 00:20:19 2021\n",
            "[xla:5](100) Loss=0.23161 Rate=7.79 GlobalRate=11.21 Time=Wed May 26 00:20:19 2021\n",
            "[xla:2](100) Loss=0.32752 Rate=8.24 GlobalRate=11.21 Time=Wed May 26 00:20:19 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](100) Loss=0.28619 Rate=7.80 GlobalRate=11.21 Time=Wed May 26 00:20:20 2021\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 92.1875\n",
            "Finished training epoch 54\n",
            "[xla:3](0) Loss=0.16431 Rate=2.37 GlobalRate=2.37 Time=Wed May 26 00:21:15 2021\n",
            "[xla:4](0) Loss=0.27718 Rate=2.37 GlobalRate=2.37 Time=Wed May 26 00:21:15 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:2](0) Loss=0.17972 Rate=2.11 GlobalRate=2.11 Time=Wed May 26 00:21:19 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:5](0) Loss=0.18640 Rate=2.02 GlobalRate=2.02 Time=Wed May 26 00:21:20 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:7](0) Loss=0.20307 Rate=1.94 GlobalRate=1.94 Time=Wed May 26 00:21:22 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](0) Loss=0.43813 Rate=1.91 GlobalRate=1.91 Time=Wed May 26 00:21:22 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:6](0) Loss=0.27479 Rate=1.71 GlobalRate=1.71 Time=Wed May 26 00:21:26 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:1](0) Loss=0.25741 Rate=1.32 GlobalRate=1.32 Time=Wed May 26 00:21:37 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](100) Loss=0.17897 Rate=7.93 GlobalRate=11.20 Time=Wed May 26 00:30:26 2021\n",
            "[xla:6](100) Loss=0.24732 Rate=7.80 GlobalRate=11.20 Time=Wed May 26 00:30:26 2021\n",
            "[xla:1](100) Loss=0.15169 Rate=7.79 GlobalRate=11.20 Time=Wed May 26 00:30:26 2021\n",
            "[xla:0](100) Loss=0.12923 Rate=7.82 GlobalRate=11.19 Time=Wed May 26 00:30:26 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](100) Loss=0.24450 Rate=7.84 GlobalRate=11.19 Time=Wed May 26 00:30:26 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:2](100) Loss=0.15815 Rate=7.86 GlobalRate=11.19 Time=Wed May 26 00:30:26 2021\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 93.75\n",
            "[xla:4](100) Loss=0.14630 Rate=7.92 GlobalRate=11.19 Time=Wed May 26 00:30:26 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 96.875\n",
            "[xla:7](100) Loss=0.13280 Rate=7.82 GlobalRate=11.18 Time=Wed May 26 00:30:27 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Finished training epoch 55\n",
            "[xla:0](0) Loss=0.12539 Rate=2.54 GlobalRate=2.54 Time=Wed May 26 00:31:26 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:5](0) Loss=0.21762 Rate=2.34 GlobalRate=2.34 Time=Wed May 26 00:31:28 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](0) Loss=0.16238 Rate=2.09 GlobalRate=2.09 Time=Wed May 26 00:31:31 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:7](0) Loss=0.17132 Rate=1.79 GlobalRate=1.79 Time=Wed May 26 00:31:36 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:6](0) Loss=0.17258 Rate=1.71 GlobalRate=1.71 Time=Wed May 26 00:31:38 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:4](0) Loss=0.18272 Rate=1.50 GlobalRate=1.50 Time=Wed May 26 00:31:43 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](0) Loss=0.21822 Rate=1.30 GlobalRate=1.30 Time=Wed May 26 00:31:50 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](0) Loss=0.13115 Rate=1.23 GlobalRate=1.23 Time=Wed May 26 00:31:52 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:4](100) Loss=0.16847 Rate=7.77 GlobalRate=11.18 Time=Wed May 26 00:40:39 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](100) Loss=0.20671 Rate=7.95 GlobalRate=11.16 Time=Wed May 26 00:40:39 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](100) Loss=0.24713 Rate=7.78 GlobalRate=11.16 Time=Wed May 26 00:40:40 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:6](100) Loss=0.20528 Rate=7.77 GlobalRate=11.15 Time=Wed May 26 00:40:40 2021\n",
            "[xla:1](100) Loss=0.20988 Rate=7.76 GlobalRate=11.15 Time=Wed May 26 00:40:40 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:2](100) Loss=0.29232 Rate=7.74 GlobalRate=11.11 Time=Wed May 26 00:40:42 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:3](100) Loss=0.23824 Rate=7.71 GlobalRate=10.97 Time=Wed May 26 00:40:50 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](100) Loss=0.31916 Rate=7.77 GlobalRate=10.97 Time=Wed May 26 00:40:50 2021\n",
            "Top1 accuracy: 93.75\n",
            "Finished training epoch 56\n",
            "[xla:5](0) Loss=0.18406 Rate=2.68 GlobalRate=2.68 Time=Wed May 26 00:41:39 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](0) Loss=0.19712 Rate=2.02 GlobalRate=2.02 Time=Wed May 26 00:41:47 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](0) Loss=0.24513 Rate=1.93 GlobalRate=1.93 Time=Wed May 26 00:41:49 2021\n",
            "[xla:4](0) Loss=0.11794 Rate=1.92 GlobalRate=1.92 Time=Wed May 26 00:41:49 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](0) Loss=0.21281 Rate=1.90 GlobalRate=1.90 Time=Wed May 26 00:41:49 2021\n",
            "Top1 accuracy: 99.21875\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:7](0) Loss=0.19653 Rate=1.86 GlobalRate=1.86 Time=Wed May 26 00:41:50 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:6](0) Loss=0.23348 Rate=1.66 GlobalRate=1.66 Time=Wed May 26 00:41:54 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](0) Loss=0.25096 Rate=1.56 GlobalRate=1.56 Time=Wed May 26 00:41:57 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:6](100) Loss=0.20784 Rate=7.86 GlobalRate=11.30 Time=Wed May 26 00:50:47 2021\n",
            "[xla:4](100) Loss=0.21620 Rate=7.90 GlobalRate=11.30 Time=Wed May 26 00:50:48 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 93.75\n",
            "[xla:1](100) Loss=0.15246 Rate=7.89 GlobalRate=11.29 Time=Wed May 26 00:50:48 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](100) Loss=0.17324 Rate=7.88 GlobalRate=11.29 Time=Wed May 26 00:50:48 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:5](100) Loss=0.16375 Rate=8.03 GlobalRate=11.23 Time=Wed May 26 00:50:51 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:7](100) Loss=0.21113 Rate=7.83 GlobalRate=11.22 Time=Wed May 26 00:50:52 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:2](100) Loss=0.18754 Rate=7.76 GlobalRate=11.17 Time=Wed May 26 00:50:54 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:3](100) Loss=0.30508 Rate=7.81 GlobalRate=11.15 Time=Wed May 26 00:50:55 2021\n",
            "Top1 accuracy: 93.75\n",
            "Finished training epoch 57\n",
            "[xla:0](0) Loss=0.18876 Rate=2.85 GlobalRate=2.85 Time=Wed May 26 00:51:51 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:6](0) Loss=0.16372 Rate=2.65 GlobalRate=2.65 Time=Wed May 26 00:51:53 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:4](0) Loss=0.18401 Rate=2.46 GlobalRate=2.46 Time=Wed May 26 00:51:55 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:1](0) Loss=0.16592 Rate=1.64 GlobalRate=1.64 Time=Wed May 26 00:52:08 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:2](0) Loss=0.15349 Rate=1.58 GlobalRate=1.58 Time=Wed May 26 00:52:09 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:7](0) Loss=0.17786 Rate=1.38 GlobalRate=1.38 Time=Wed May 26 00:52:15 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:5](0) Loss=0.18097 Rate=1.36 GlobalRate=1.36 Time=Wed May 26 00:52:15 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](0) Loss=0.27517 Rate=1.35 GlobalRate=1.35 Time=Wed May 26 00:52:16 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:6](100) Loss=0.16341 Rate=8.09 GlobalRate=11.34 Time=Wed May 26 01:00:58 2021\n",
            "[xla:5](100) Loss=0.29340 Rate=7.89 GlobalRate=11.34 Time=Wed May 26 01:00:58 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:3](100) Loss=0.26080 Rate=7.88 GlobalRate=11.33 Time=Wed May 26 01:00:59 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:0](100) Loss=0.19693 Rate=8.09 GlobalRate=11.24 Time=Wed May 26 01:01:03 2021\n",
            "[xla:1](100) Loss=0.15051 Rate=7.82 GlobalRate=11.24 Time=Wed May 26 01:01:04 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:7](100) Loss=0.26664 Rate=7.80 GlobalRate=11.21 Time=Wed May 26 01:01:05 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](100) Loss=0.31829 Rate=7.91 GlobalRate=11.14 Time=Wed May 26 01:01:09 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:2](100) Loss=0.31398 Rate=7.72 GlobalRate=11.10 Time=Wed May 26 01:01:11 2021\n",
            "Top1 accuracy: 93.75\n",
            "Finished training epoch 58\n",
            "[xla:1](0) Loss=0.29529 Rate=2.54 GlobalRate=2.54 Time=Wed May 26 01:02:03 2021\n",
            "[xla:6](0) Loss=0.15745 Rate=2.51 GlobalRate=2.51 Time=Wed May 26 01:02:03 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](0) Loss=0.21278 Rate=2.34 GlobalRate=2.34 Time=Wed May 26 01:02:05 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](0) Loss=0.11706 Rate=2.17 GlobalRate=2.17 Time=Wed May 26 01:02:07 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:4](0) Loss=0.12340 Rate=1.65 GlobalRate=1.65 Time=Wed May 26 01:02:17 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:7](0) Loss=0.22516 Rate=1.45 GlobalRate=1.45 Time=Wed May 26 01:02:22 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:2](0) Loss=0.19239 Rate=1.40 GlobalRate=1.40 Time=Wed May 26 01:02:24 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:5](0) Loss=0.10869 Rate=1.35 GlobalRate=1.35 Time=Wed May 26 01:02:25 2021\n",
            "Top1 accuracy: 100.0\n",
            "[xla:2](100) Loss=0.25339 Rate=7.82 GlobalRate=11.25 Time=Wed May 26 01:11:12 2021\n",
            "[xla:4](100) Loss=0.16438 Rate=7.83 GlobalRate=11.25 Time=Wed May 26 01:11:12 2021\n",
            "[xla:6](100) Loss=0.21087 Rate=8.00 GlobalRate=11.25 Time=Wed May 26 01:11:12 2021\n",
            "[xla:7](100) Loss=0.14535 Rate=7.82 GlobalRate=11.25 Time=Wed May 26 01:11:12 2021\n",
            "[xla:3](100) Loss=0.15284 Rate=7.95 GlobalRate=11.25 Time=Wed May 26 01:11:12 2021\n",
            "[xla:0](100) Loss=0.05760 Rate=7.91 GlobalRate=11.25 Time=Wed May 26 01:11:12 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:5](100) Loss=0.34081 Rate=7.82 GlobalRate=11.25 Time=Wed May 26 01:11:13 2021\n",
            "[xla:1](100) Loss=0.26464 Rate=8.00 GlobalRate=11.25 Time=Wed May 26 01:11:13 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Top1 accuracy: 92.96875\n",
            "Finished training epoch 59\n",
            "[xla:6](0) Loss=0.29921 Rate=2.66 GlobalRate=2.66 Time=Wed May 26 01:12:13 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:3](0) Loss=0.23181 Rate=2.43 GlobalRate=2.43 Time=Wed May 26 01:12:15 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:7](0) Loss=0.32150 Rate=2.40 GlobalRate=2.40 Time=Wed May 26 01:12:15 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:2](0) Loss=0.19939 Rate=1.99 GlobalRate=1.99 Time=Wed May 26 01:12:21 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](0) Loss=0.16453 Rate=1.94 GlobalRate=1.94 Time=Wed May 26 01:12:22 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:0](0) Loss=0.21260 Rate=1.67 GlobalRate=1.67 Time=Wed May 26 01:12:27 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](0) Loss=0.28804 Rate=1.47 GlobalRate=1.47 Time=Wed May 26 01:12:32 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:5](0) Loss=0.24916 Rate=1.42 GlobalRate=1.42 Time=Wed May 26 01:12:33 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](100) Loss=0.16651 Rate=8.08 GlobalRate=11.41 Time=Wed May 26 01:21:15 2021\n",
            "[xla:0](100) Loss=0.16532 Rate=7.94 GlobalRate=11.41 Time=Wed May 26 01:21:15 2021\n",
            "[xla:7](100) Loss=0.10970 Rate=8.07 GlobalRate=11.41 Time=Wed May 26 01:21:15 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:6](100) Loss=0.09090 Rate=8.14 GlobalRate=11.40 Time=Wed May 26 01:21:15 2021\n",
            "[xla:5](100) Loss=0.20774 Rate=7.93 GlobalRate=11.40 Time=Wed May 26 01:21:15 2021\n",
            "Top1 accuracy: 100.0\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:1](100) Loss=0.15738 Rate=7.91 GlobalRate=11.38 Time=Wed May 26 01:21:17 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:2](100) Loss=0.12906 Rate=7.89 GlobalRate=11.28 Time=Wed May 26 01:21:22 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:4](100) Loss=0.21533 Rate=7.74 GlobalRate=11.06 Time=Wed May 26 01:21:33 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Finished training epoch 60\n",
            "[xla:6](0) Loss=0.06692 Rate=2.63 GlobalRate=2.63 Time=Wed May 26 01:22:19 2021\n",
            "Top1 accuracy: 100.0\n",
            "[xla:7](0) Loss=0.13712 Rate=2.28 GlobalRate=2.28 Time=Wed May 26 01:22:23 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:2](0) Loss=0.11623 Rate=2.21 GlobalRate=2.21 Time=Wed May 26 01:22:24 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:1](0) Loss=0.14719 Rate=2.10 GlobalRate=2.10 Time=Wed May 26 01:22:26 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:4](0) Loss=0.09304 Rate=2.06 GlobalRate=2.06 Time=Wed May 26 01:22:26 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:0](0) Loss=0.08059 Rate=1.55 GlobalRate=1.55 Time=Wed May 26 01:22:36 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:5](0) Loss=0.13410 Rate=1.40 GlobalRate=1.40 Time=Wed May 26 01:22:41 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:3](0) Loss=0.08103 Rate=1.36 GlobalRate=1.36 Time=Wed May 26 01:22:42 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:4](100) Loss=0.21431 Rate=8.01 GlobalRate=11.44 Time=Wed May 26 01:31:20 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](100) Loss=0.24621 Rate=8.02 GlobalRate=11.43 Time=Wed May 26 01:31:21 2021\n",
            "[xla:5](100) Loss=0.11995 Rate=7.94 GlobalRate=11.42 Time=Wed May 26 01:31:21 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](100) Loss=0.18118 Rate=8.05 GlobalRate=11.42 Time=Wed May 26 01:31:21 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](100) Loss=0.08641 Rate=7.87 GlobalRate=11.32 Time=Wed May 26 01:31:26 2021\n",
            "[xla:2](100) Loss=0.22213 Rate=7.96 GlobalRate=11.31 Time=Wed May 26 01:31:26 2021\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](100) Loss=0.15049 Rate=7.72 GlobalRate=11.10 Time=Wed May 26 01:31:38 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:6](100) Loss=0.13031 Rate=7.90 GlobalRate=11.05 Time=Wed May 26 01:31:40 2021\n",
            "Top1 accuracy: 98.4375\n",
            "Finished training epoch 61\n",
            "[xla:7](0) Loss=0.35762 Rate=2.16 GlobalRate=2.16 Time=Wed May 26 01:32:32 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:6](0) Loss=0.35825 Rate=1.99 GlobalRate=1.99 Time=Wed May 26 01:32:34 2021\n",
            "[xla:5](0) Loss=0.21731 Rate=1.99 GlobalRate=1.99 Time=Wed May 26 01:32:34 2021\n",
            "Top1 accuracy: 89.0625\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](0) Loss=0.29171 Rate=1.90 GlobalRate=1.90 Time=Wed May 26 01:32:36 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:4](0) Loss=0.33164 Rate=1.88 GlobalRate=1.88 Time=Wed May 26 01:32:36 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:2](0) Loss=0.22101 Rate=1.80 GlobalRate=1.80 Time=Wed May 26 01:32:38 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](0) Loss=0.42292 Rate=1.69 GlobalRate=1.69 Time=Wed May 26 01:32:40 2021\n",
            "Top1 accuracy: 86.71875\n",
            "[xla:3](0) Loss=0.25973 Rate=1.67 GlobalRate=1.67 Time=Wed May 26 01:32:41 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](100) Loss=0.14673 Rate=8.02 GlobalRate=11.42 Time=Wed May 26 01:41:28 2021\n",
            "[xla:5](100) Loss=0.18751 Rate=7.99 GlobalRate=11.42 Time=Wed May 26 01:41:28 2021\n",
            "[xla:2](100) Loss=0.24083 Rate=7.96 GlobalRate=11.42 Time=Wed May 26 01:41:28 2021\n",
            "[xla:1](100) Loss=0.20369 Rate=7.97 GlobalRate=11.42 Time=Wed May 26 01:41:28 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](100) Loss=0.19593 Rate=7.94 GlobalRate=11.41 Time=Wed May 26 01:41:29 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](100) Loss=0.23063 Rate=7.76 GlobalRate=11.14 Time=Wed May 26 01:41:42 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:6](100) Loss=0.11174 Rate=7.76 GlobalRate=11.07 Time=Wed May 26 01:41:46 2021\n",
            "[xla:4](100) Loss=0.12321 Rate=7.73 GlobalRate=11.07 Time=Wed May 26 01:41:46 2021\n",
            "Top1 accuracy: 99.21875\n",
            "Top1 accuracy: 97.65625\n",
            "Finished training epoch 62\n",
            "[xla:3](0) Loss=0.26370 Rate=3.19 GlobalRate=3.19 Time=Wed May 26 01:42:32 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:4](0) Loss=0.34085 Rate=2.44 GlobalRate=2.44 Time=Wed May 26 01:42:38 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:1](0) Loss=0.24230 Rate=2.36 GlobalRate=2.36 Time=Wed May 26 01:42:39 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:7](0) Loss=0.25284 Rate=2.14 GlobalRate=2.14 Time=Wed May 26 01:42:41 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:6](0) Loss=0.28208 Rate=1.61 GlobalRate=1.61 Time=Wed May 26 01:42:51 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:5](0) Loss=0.29688 Rate=1.58 GlobalRate=1.58 Time=Wed May 26 01:42:52 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](0) Loss=0.34986 Rate=1.52 GlobalRate=1.52 Time=Wed May 26 01:42:54 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:2](0) Loss=0.28781 Rate=1.50 GlobalRate=1.50 Time=Wed May 26 01:42:54 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:6](100) Loss=0.17252 Rate=7.86 GlobalRate=11.30 Time=Wed May 26 01:51:43 2021\n",
            "[xla:5](100) Loss=0.18880 Rate=7.86 GlobalRate=11.30 Time=Wed May 26 01:51:43 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](100) Loss=0.13677 Rate=8.01 GlobalRate=11.29 Time=Wed May 26 01:51:44 2021\n",
            "[xla:0](100) Loss=0.14988 Rate=7.85 GlobalRate=11.29 Time=Wed May 26 01:51:44 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:7](100) Loss=0.19181 Rate=7.93 GlobalRate=11.28 Time=Wed May 26 01:51:44 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:1](100) Loss=0.38050 Rate=7.96 GlobalRate=11.25 Time=Wed May 26 01:51:46 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:3](100) Loss=0.14063 Rate=8.16 GlobalRate=11.19 Time=Wed May 26 01:51:49 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:2](100) Loss=0.23177 Rate=7.77 GlobalRate=11.17 Time=Wed May 26 01:51:50 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 63\n",
            "[xla:1](0) Loss=0.20740 Rate=2.63 GlobalRate=2.63 Time=Wed May 26 01:52:43 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](0) Loss=0.21939 Rate=2.57 GlobalRate=2.57 Time=Wed May 26 01:52:43 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:0](0) Loss=0.26651 Rate=2.52 GlobalRate=2.52 Time=Wed May 26 01:52:44 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:5](0) Loss=0.18746 Rate=2.17 GlobalRate=2.17 Time=Wed May 26 01:52:48 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](0) Loss=0.24808 Rate=1.81 GlobalRate=1.81 Time=Wed May 26 01:52:53 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:6](0) Loss=0.20485 Rate=1.56 GlobalRate=1.56 Time=Wed May 26 01:52:59 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:4](0) Loss=0.31001 Rate=1.51 GlobalRate=1.51 Time=Wed May 26 01:53:01 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:2](0) Loss=0.16725 Rate=1.33 GlobalRate=1.33 Time=Wed May 26 01:53:06 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](100) Loss=0.46163 Rate=7.87 GlobalRate=11.28 Time=Wed May 26 02:01:51 2021\n",
            "[xla:0](100) Loss=0.45923 Rate=8.02 GlobalRate=11.28 Time=Wed May 26 02:01:51 2021\n",
            "[xla:7](100) Loss=0.32560 Rate=8.03 GlobalRate=11.28 Time=Wed May 26 02:01:51 2021\n",
            "[xla:4](100) Loss=0.33672 Rate=7.84 GlobalRate=11.28 Time=Wed May 26 02:01:51 2021\n",
            "Top1 accuracy: 90.625\n",
            "Top1 accuracy: 90.625\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:5](100) Loss=0.38423 Rate=7.93 GlobalRate=11.27 Time=Wed May 26 02:01:52 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:2](100) Loss=0.39428 Rate=7.84 GlobalRate=11.27 Time=Wed May 26 02:01:52 2021\n",
            "Top1 accuracy: 90.625\n",
            "[xla:1](100) Loss=0.39023 Rate=8.04 GlobalRate=11.26 Time=Wed May 26 02:01:52 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:6](100) Loss=0.38464 Rate=7.83 GlobalRate=11.26 Time=Wed May 26 02:01:52 2021\n",
            "Top1 accuracy: 88.28125\n",
            "Top1 accuracy: 91.40625\n",
            "Finished training epoch 64\n",
            "[xla:0](0) Loss=0.21352 Rate=4.25 GlobalRate=4.25 Time=Wed May 26 02:02:39 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](0) Loss=0.16642 Rate=1.88 GlobalRate=1.88 Time=Wed May 26 02:02:58 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:6](0) Loss=0.13177 Rate=1.79 GlobalRate=1.79 Time=Wed May 26 02:02:59 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:7](0) Loss=0.12357 Rate=1.78 GlobalRate=1.78 Time=Wed May 26 02:03:00 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:3](0) Loss=0.25846 Rate=1.75 GlobalRate=1.75 Time=Wed May 26 02:03:00 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:5](0) Loss=0.13563 Rate=1.69 GlobalRate=1.69 Time=Wed May 26 02:03:02 2021\n",
            "[xla:2](0) Loss=0.23393 Rate=1.68 GlobalRate=1.68 Time=Wed May 26 02:03:02 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](0) Loss=0.30216 Rate=1.43 GlobalRate=1.43 Time=Wed May 26 02:03:08 2021\n",
            "Top1 accuracy: 89.0625\n",
            "[xla:6](100) Loss=0.17525 Rate=7.90 GlobalRate=11.33 Time=Wed May 26 02:11:54 2021\n",
            "[xla:1](100) Loss=0.23727 Rate=7.88 GlobalRate=11.33 Time=Wed May 26 02:11:54 2021\n",
            "[xla:0](100) Loss=0.21506 Rate=8.62 GlobalRate=11.33 Time=Wed May 26 02:11:54 2021\n",
            "[xla:2](100) Loss=0.27303 Rate=7.89 GlobalRate=11.33 Time=Wed May 26 02:11:54 2021\n",
            "[xla:7](100) Loss=0.21885 Rate=7.90 GlobalRate=11.33 Time=Wed May 26 02:11:54 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 92.96875\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](100) Loss=0.31132 Rate=7.89 GlobalRate=11.32 Time=Wed May 26 02:11:55 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:4](100) Loss=0.32890 Rate=7.78 GlobalRate=11.13 Time=Wed May 26 02:12:04 2021\n",
            "[xla:5](100) Loss=0.22753 Rate=7.75 GlobalRate=11.13 Time=Wed May 26 02:12:04 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 65\n",
            "[xla:0](0) Loss=0.26157 Rate=2.50 GlobalRate=2.50 Time=Wed May 26 02:12:55 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:2](0) Loss=0.21370 Rate=2.26 GlobalRate=2.26 Time=Wed May 26 02:12:58 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](0) Loss=0.26808 Rate=2.22 GlobalRate=2.22 Time=Wed May 26 02:12:58 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:6](0) Loss=0.29065 Rate=1.98 GlobalRate=1.98 Time=Wed May 26 02:13:02 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:7](0) Loss=0.26330 Rate=1.93 GlobalRate=1.93 Time=Wed May 26 02:13:02 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:4](0) Loss=0.18555 Rate=1.66 GlobalRate=1.66 Time=Wed May 26 02:13:08 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](0) Loss=0.18239 Rate=1.59 GlobalRate=1.59 Time=Wed May 26 02:13:10 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](0) Loss=0.19208 Rate=1.29 GlobalRate=1.29 Time=Wed May 26 02:13:19 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:5](100) Loss=0.11708 Rate=7.80 GlobalRate=11.20 Time=Wed May 26 02:22:06 2021\n",
            "[xla:2](100) Loss=0.11270 Rate=7.90 GlobalRate=11.20 Time=Wed May 26 02:22:06 2021\n",
            "[xla:3](100) Loss=0.10970 Rate=7.79 GlobalRate=11.20 Time=Wed May 26 02:22:06 2021\n",
            "[xla:0](100) Loss=0.10682 Rate=7.96 GlobalRate=11.20 Time=Wed May 26 02:22:06 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 99.21875\n",
            "Top1 accuracy: 96.875\n",
            "[xla:4](100) Loss=0.06360 Rate=7.78 GlobalRate=11.19 Time=Wed May 26 02:22:07 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:7](100) Loss=0.12096 Rate=7.79 GlobalRate=11.14 Time=Wed May 26 02:22:09 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:6](100) Loss=0.15515 Rate=7.78 GlobalRate=11.11 Time=Wed May 26 02:22:11 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](100) Loss=0.13623 Rate=7.76 GlobalRate=11.01 Time=Wed May 26 02:22:16 2021\n",
            "Top1 accuracy: 96.875\n",
            "Finished training epoch 66\n",
            "[xla:3](0) Loss=0.21254 Rate=2.69 GlobalRate=2.69 Time=Wed May 26 02:23:08 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:0](0) Loss=0.14103 Rate=2.53 GlobalRate=2.53 Time=Wed May 26 02:23:09 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:1](0) Loss=0.21071 Rate=2.28 GlobalRate=2.28 Time=Wed May 26 02:23:12 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:4](0) Loss=0.18539 Rate=2.12 GlobalRate=2.12 Time=Wed May 26 02:23:14 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:6](0) Loss=0.26142 Rate=1.92 GlobalRate=1.92 Time=Wed May 26 02:23:17 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:5](0) Loss=0.19999 Rate=1.67 GlobalRate=1.67 Time=Wed May 26 02:23:22 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:2](0) Loss=0.17689 Rate=1.46 GlobalRate=1.46 Time=Wed May 26 02:23:28 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:7](0) Loss=0.17544 Rate=1.43 GlobalRate=1.43 Time=Wed May 26 02:23:29 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](100) Loss=0.23166 Rate=7.94 GlobalRate=11.16 Time=Wed May 26 02:32:23 2021\n",
            "[xla:7](100) Loss=0.24627 Rate=7.76 GlobalRate=11.16 Time=Wed May 26 02:32:23 2021\n",
            "Top1 accuracy: 94.53125\n",
            "Top1 accuracy: 93.75\n",
            "[xla:6](100) Loss=0.11175 Rate=7.80 GlobalRate=11.15 Time=Wed May 26 02:32:24 2021\n",
            "[xla:1](100) Loss=0.25223 Rate=7.87 GlobalRate=11.15 Time=Wed May 26 02:32:24 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:5](100) Loss=0.16589 Rate=7.76 GlobalRate=11.15 Time=Wed May 26 02:32:24 2021\n",
            "[xla:2](100) Loss=0.12339 Rate=7.75 GlobalRate=11.14 Time=Wed May 26 02:32:24 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](100) Loss=0.14228 Rate=7.98 GlobalRate=11.14 Time=Wed May 26 02:32:24 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:4](100) Loss=0.19795 Rate=7.83 GlobalRate=11.14 Time=Wed May 26 02:32:24 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 94.53125\n",
            "Finished training epoch 67\n",
            "[xla:7](0) Loss=0.18950 Rate=2.86 GlobalRate=2.86 Time=Wed May 26 02:33:13 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:3](0) Loss=0.23214 Rate=2.47 GlobalRate=2.47 Time=Wed May 26 02:33:16 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:4](0) Loss=0.26149 Rate=2.43 GlobalRate=2.43 Time=Wed May 26 02:33:17 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:5](0) Loss=0.18548 Rate=2.06 GlobalRate=2.06 Time=Wed May 26 02:33:21 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:6](0) Loss=0.20202 Rate=1.79 GlobalRate=1.79 Time=Wed May 26 02:33:26 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:1](0) Loss=0.25123 Rate=1.60 GlobalRate=1.60 Time=Wed May 26 02:33:30 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:2](0) Loss=0.31443 Rate=1.51 GlobalRate=1.51 Time=Wed May 26 02:33:33 2021\n",
            "Top1 accuracy: 91.40625\n",
            "[xla:0](0) Loss=0.17196 Rate=1.37 GlobalRate=1.37 Time=Wed May 26 02:33:37 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](100) Loss=0.12248 Rate=8.08 GlobalRate=11.39 Time=Wed May 26 02:42:18 2021\n",
            "[xla:2](100) Loss=0.12323 Rate=7.92 GlobalRate=11.39 Time=Wed May 26 02:42:18 2021\n",
            "[xla:7](100) Loss=0.12465 Rate=8.19 GlobalRate=11.39 Time=Wed May 26 02:42:18 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 98.4375\n",
            "Top1 accuracy: 96.875\n",
            "[xla:1](100) Loss=0.19099 Rate=7.86 GlobalRate=11.30 Time=Wed May 26 02:42:22 2021\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:0](100) Loss=0.21646 Rate=7.86 GlobalRate=11.30 Time=Wed May 26 02:42:22 2021\n",
            "[xla:6](100) Loss=0.11691 Rate=7.87 GlobalRate=11.30 Time=Wed May 26 02:42:23 2021\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:4](100) Loss=0.24741 Rate=7.91 GlobalRate=11.15 Time=Wed May 26 02:42:30 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:5](100) Loss=0.14928 Rate=7.76 GlobalRate=11.05 Time=Wed May 26 02:42:35 2021\n",
            "Top1 accuracy: 98.4375\n",
            "Finished training epoch 68\n",
            "[xla:6](0) Loss=0.19622 Rate=2.91 GlobalRate=2.91 Time=Wed May 26 02:43:21 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](0) Loss=0.23836 Rate=2.56 GlobalRate=2.56 Time=Wed May 26 02:43:24 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:5](0) Loss=0.19642 Rate=2.30 GlobalRate=2.30 Time=Wed May 26 02:43:27 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:7](0) Loss=0.26671 Rate=2.00 GlobalRate=2.00 Time=Wed May 26 02:43:31 2021\n",
            "Top1 accuracy: 93.75\n",
            "[xla:3](0) Loss=0.23574 Rate=1.57 GlobalRate=1.57 Time=Wed May 26 02:43:40 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:1](0) Loss=0.33028 Rate=1.52 GlobalRate=1.52 Time=Wed May 26 02:43:41 2021\n",
            "Top1 accuracy: 92.1875\n",
            "[xla:2](0) Loss=0.19470 Rate=1.39 GlobalRate=1.39 Time=Wed May 26 02:43:45 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:4](0) Loss=0.25170 Rate=1.34 GlobalRate=1.34 Time=Wed May 26 02:43:47 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:7](100) Loss=0.20776 Rate=8.02 GlobalRate=11.47 Time=Wed May 26 02:52:23 2021\n",
            "Top1 accuracy: 92.96875\n",
            "[xla:0](100) Loss=0.06754 Rate=8.15 GlobalRate=11.46 Time=Wed May 26 02:52:23 2021\n",
            "[xla:6](100) Loss=0.15939 Rate=8.25 GlobalRate=11.46 Time=Wed May 26 02:52:23 2021\n",
            "Top1 accuracy: 99.21875\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:5](100) Loss=0.19151 Rate=7.95 GlobalRate=11.25 Time=Wed May 26 02:52:33 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](100) Loss=0.21744 Rate=7.78 GlobalRate=11.20 Time=Wed May 26 02:52:36 2021\n",
            "[xla:3](100) Loss=0.15047 Rate=7.78 GlobalRate=11.19 Time=Wed May 26 02:52:36 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 95.3125\n",
            "[xla:4](100) Loss=0.10577 Rate=7.76 GlobalRate=11.16 Time=Wed May 26 02:52:38 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:2](100) Loss=0.28538 Rate=7.70 GlobalRate=11.07 Time=Wed May 26 02:52:43 2021\n",
            "Top1 accuracy: 91.40625\n",
            "Finished training epoch 69\n",
            "[xla:1](0) Loss=0.20072 Rate=2.42 GlobalRate=2.42 Time=Wed May 26 02:53:34 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:0](0) Loss=0.17504 Rate=2.30 GlobalRate=2.30 Time=Wed May 26 02:53:36 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:6](0) Loss=0.16543 Rate=2.22 GlobalRate=2.22 Time=Wed May 26 02:53:37 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:3](0) Loss=0.17997 Rate=2.00 GlobalRate=2.00 Time=Wed May 26 02:53:40 2021\n",
            "[xla:5](0) Loss=0.09730 Rate=1.99 GlobalRate=1.99 Time=Wed May 26 02:53:40 2021\n",
            "Top1 accuracy: 96.09375\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:7](0) Loss=0.22183 Rate=1.37 GlobalRate=1.37 Time=Wed May 26 02:53:55 2021\n",
            "Top1 accuracy: 94.53125\n",
            "[xla:2](0) Loss=0.12192 Rate=1.30 GlobalRate=1.30 Time=Wed May 26 02:53:57 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:4](0) Loss=0.14079 Rate=1.28 GlobalRate=1.28 Time=Wed May 26 02:53:58 2021\n",
            "Top1 accuracy: 98.4375\n",
            "[xla:6](100) Loss=0.13868 Rate=7.83 GlobalRate=11.11 Time=Wed May 26 03:02:50 2021\n",
            "[xla:2](100) Loss=0.14274 Rate=7.73 GlobalRate=11.10 Time=Wed May 26 03:02:50 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](100) Loss=0.09151 Rate=7.87 GlobalRate=11.10 Time=Wed May 26 03:02:50 2021\n",
            "Top1 accuracy: 96.875\n",
            "[xla:0](100) Loss=0.25095 Rate=7.84 GlobalRate=11.09 Time=Wed May 26 03:02:50 2021\n",
            "Top1 accuracy: 99.21875\n",
            "[xla:3](100) Loss=0.21078 Rate=7.77 GlobalRate=11.09 Time=Wed May 26 03:02:51 2021\n",
            "[xla:7](100) Loss=0.14908 Rate=7.71 GlobalRate=11.09 Time=Wed May 26 03:02:51 2021\n",
            "[xla:5](100) Loss=0.23326 Rate=7.77 GlobalRate=11.09 Time=Wed May 26 03:02:51 2021\n",
            "Top1 accuracy: 95.3125\n",
            "Top1 accuracy: 96.875\n",
            "[xla:4](100) Loss=0.20971 Rate=7.72 GlobalRate=11.09 Time=Wed May 26 03:02:51 2021\n",
            "Top1 accuracy: 97.65625\n",
            "Top1 accuracy: 93.75\n",
            "Top1 accuracy: 96.09375\n",
            "Finished training epoch 70\n",
            "[xla:3](0) Loss=0.21347 Rate=2.44 GlobalRate=2.44 Time=Wed May 26 03:03:48 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:1](0) Loss=0.16026 Rate=2.37 GlobalRate=2.37 Time=Wed May 26 03:03:49 2021\n",
            "Top1 accuracy: 96.09375\n",
            "[xla:7](0) Loss=0.16713 Rate=2.18 GlobalRate=2.18 Time=Wed May 26 03:03:52 2021\n",
            "[xla:5](0) Loss=0.12033 Rate=2.16 GlobalRate=2.16 Time=Wed May 26 03:03:52 2021\n",
            "Top1 accuracy: 96.875\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:6](0) Loss=0.09879 Rate=1.71 GlobalRate=1.71 Time=Wed May 26 03:04:00 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:2](0) Loss=0.13459 Rate=1.69 GlobalRate=1.69 Time=Wed May 26 03:04:00 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:4](0) Loss=0.10740 Rate=1.63 GlobalRate=1.63 Time=Wed May 26 03:04:02 2021\n",
            "Top1 accuracy: 97.65625\n",
            "[xla:0](0) Loss=0.11472 Rate=1.44 GlobalRate=1.44 Time=Wed May 26 03:04:07 2021\n",
            "Top1 accuracy: 97.65625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}